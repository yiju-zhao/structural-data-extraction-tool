session_code,title,session_type,url,speakers,abstract,topics,nvidia_technologies
DLIT81642,Accelerate Apache Spark With GPU and AI: A Hands-On Workshop [DLIT81642],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81642/,"Rishi Chandra (Systems Software Engineer, NVIDIA); Navin Kumar (Sr. System Software Engineer, NVIDIA); Hirakendu Das (Principal Software Engineer, NVIDIA)","In this training lab, we'll introduce Aether — a set of automation and AI tools that speed up and reduce the cost of accelerated extract, transform, load and analytics workloads on the RAPIDS Accelerator for Apache Spark. Aether combines automation along with advanced AI tools to automatically test and optimize your Apache Spark workloads with GPU.",All Industries,"CUDA, cuDF, nvCOMP"
DLIT81682,Accelerate Drug Discovery With NVIDIA Libraries and Platforms [DLIT81682],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81682/,"Kristopher Kersten (Technical Marketing Engineer, NVIDIA); Neel Patel (Technical Marketing Engineer, NVIDIA)","The field of drug discovery is increasingly benefiting from AI, helping researchers build efficient predictive and generative workflows that drastically reduce time-to-clinic. NVIDIA accelerates this process with open-source solutions like BioNeMo Recipes, NIM, and Clara Open Models for Digital Biology, providing easy-to-adopt solutions for training and deploying foundation models and agentic AI systems for drug discovery. In this session, we'll demonstrate how the latest NVIDIA accelerated libraries and models streamline AI workflows, accelerate drug discovery, and enable more efficient biomolecular design and analysis.",Healthcare & Life Sciences,"CUDA, Clara, BioNeMo, NVIDIA NIM"
DLIT81700,Accelerate Robot Learning With Isaac Lab and Newton [DLIT81700],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81700/,"Akul Santhosh (Solution Architect, Robotics, NVIDIA); Eric Heiden (Sr. Research Scientist, NVIDIA); Mohammad Mohajerani (Sr. Product Manager, NVIDIA)","This hands-on lab introduces Newton, a GPU-accelerated physics engine. Then we'll integrate Newton with Isaac Lab, showing how they can work together in robot-learning workflows. You'll configure tasks to run on Newton, and train and evaluate policies in Isaac Lab with Newton providing high-fidelity, high-throughput physics. You'll leave knowing how to use Newton for more realistic robotics simulation.",All Industries,Isaac
DLIT82150,Accelerate Video Frame Extraction and Labeling [DLIT82150],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82150/,"Khanh Nguyen (Software Engineer, NVIDIA); Suseella Panguluri (Sr. Manager, NVIDIA); Radha Sri-Tharan (Data Engineer, HitL, NVIDIA)","Learn how to reduce the cost associated with frame extraction for computer vision post-processing using free and publicly-accessible American Sign Language data. Use a novel, open-source framework and contribute to the world's largest dataset.",Media & Entertainment,
DLIT81587,Accelerated Omics and Single-cell Analysis Using NVIDIA GPUs [DLIT81587],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81587/,"Gary Burnett (Technical Marketing Engineer, NVIDIA); Severin Dicks (NVIDIA); T.J. Chen (Product Lead, Genomics, NVIDIA)","The explosion of biological data generation and innovations in AI have opened new frontiers in scientific discovery and biomedicine. With the ability to process vast amounts of biological data, accelerated analysis and foundation model approaches are transforming digital biology. This workshop provides hands-on experience for how accelerated libraries and deep learning models can be leveraged to process and analyze complex biological data. Gain an understanding of the end-to-end process, from how NVIDIA libraries support data generation, pre-processing, and analysis of single-cell data, to how foundation models are being used and evaluated in the life sciences. Get an overview of relevant solutions in digital biology, such as Parabricks, RAPIDS-singlecell (developed by scverse), NVIDIA CUDA-X Data Science Libraries, and Clara Open Models.",Healthcare & Life Sciences,"Clara Parabricks, CUDA-X"
DLIT81567,Accelerating LLM Training and Inferencing With Reduced Precision Format [DLIT81567],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81567/,"Oleg Rybakov (Principal Software Engineer, NVIDIA); Leo Du (Sr. Solutions Architect, Generative AI, NVIDIA); Sergio Perez (Solutions Architect, NVIDIA)","Large-scale LLMs require enormous computational resources, making efficiency crucial for training. Learn how cutting-edge reduced-precision formats such as FP8, MXFP4 and NVFP4 can dramatically accelerate pre-training, post-training, and inference while maintaining accuracy close to full-precision baseline models. You’ll learn how NVIDIA's innovative NVFP4 format better captures dynamic range and reduces quantization error compared to MXFP4. We'll cover techniques including Random Hadamard Transforms, two-dimensional block quantization, stochastic rounding, and strategic placement of higher-precision layers to stabilize training. Gain practical skills with the software tools necessary for quantization-aware training and efficient inference deployment, helping your applications retain accuracy while benefiting from reduced precision.",All Industries,"Cloud / Data Center GPU, CUDA, TensorRT, Hopper, CUDA-X, NeMo, NSight Systems, Blackwell, NVIDIA AI Enterprise"
DLIT81776,Adding Safety and Perception to Industrial Robots [DLIT81776],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81776/,"Sammy Ochoa (Technical Marketing Engineer, NVIDIA); Edward Chan (coming soon, NVIDIA)","Learn to implement functional safety for robots using an ""outside-in"" approach. You will gain deep insight into building collaborative, AI-powered factory environments where vision systems and robotics converge to deliver operational intelligence and safety. We will connect industrial robots to factory-wide sensor infrastructure using NVIDIA Metropolis to build intelligent systems dedicated to robot safety. Through practical exercises, you will create a video analytics AI agent that extends a robot's real-time perception. This agent will enable critical safety features, such as automatic speed adjustments (slowing down or speeding up) and risk mitigation, essential for safe co-bot environments. To enable the outside-in approach for functional safety, this lab spotlights NVIDIA Halos for Outside-In Safety Agents powered by IGX Thor. Intermediate experience with Python, including packages, virtual environments, and scripting Familiarity with computer vision concepts, object detection, and AI inference pipelines Experience with robotics workflows and sensor integration Knowledge of data streaming, real-time analytics, and message-passing architectures",Manufacturing,"Metropolis, IGX"
DLIT82183,Advanced Workload Orchestration With NVIDIA Run:AI [DLIT82183],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82183/,"David Whitehouse (NVIDIA Academy Lab Manager, NVIDIA)","Take the next step in ML performance engineering with a deep dive into advanced orchestration on the NVIDIA Run:AI platform. This lab focuses on maximizing infrastructure efficiency through intelligent scheduling and automation. Explore capabilities such as GPU fractioning, GPU memory swap, and topology-aware multi-node placement—and learn how to apply them to complex distributed training and inference workloads. With hands-on guidance, you’ll build flexible, high-performance pipelines that dramatically improve speed, utilization, and throughput at scale.",All Industries,Mission Control
DLIT81592,"Advancing Multimodal Systems: Alignment, Information Typology, Reasoning, and Cross-Modal Flow [DLIT81592]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81592/,"Mireille Fares (Sr. AI Solution Architect, NVIDIA); Andrea Pilzer (HER Solutions Architect, NVIDIA)","This lab explores key principles for advancing multi-modal systems, focusing on multi-modal information typology, alignment, multi-step reasoning, and cross-modal flow. We analyze redundant, unique, and synergistic information, and examine multi-modal alignment through coarse-grained versus fine-grained behavior. The lab then investigates multi-step multi-modality reasoning with external knowledge, where agents integrate images, text, tables, and diagrams to solve complex tasks. Finally, we study multi-modal information flow through cross-modal translation, cross-modal editing, and cross-modal querying, supported by NIM examples for text-to-image generation, semantic image editing, and visual question-answering. Basic understanding of machine learning and deep learning concepts, including embeddings and neural network architectures. Familiarity with multimodal AI concepts, such as combining text, image, and other data modalities. Experience with Python programming and standard ML libraries (e.g., PyTorch, TensorFlow). Basic knowledge of data visualization techniques (e.g., PCA, t-SNE) for interpreting embeddings.",All Industries,
DLIT81800,Assembling Industrial Digital Twins with OpenUSD and NVIDIA Omniverse Libraries [DLIT81800],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81800/,"Jay Axe (Technical Product Manager, NVIDIA); Ernesto Pacheco (coming soon, NVIDIA)","In this hands-on lab, participants will explore how to build industrial digital twins from manufacturing facilities to AI factories, using OpenUSD and NVIDIA Omniverse libraries, drawing on real-world collaboration with industry leaders. The session walks through an end-to-end workflow, from CAD models to full digital twin assembly, demonstrating how manufacturers are transforming design and production through simulation and interoperability.",All Industries,Omniverse
DLIT81639,Automate 3D Data Pipelines With USD Exchange SDK [DLIT81639],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81639/,"Beau Perschall (Director, Omniverse Sim Data Ops, NVIDIA); Andrew Kaufman (Principal Software Engineer, NVIDIA)","In this instructor-led lab, you’ll learn how to build robust OpenUSD-based data pipelines using the USD Exchange SDK, enabling you to leverage your existing 3D software and tools for scalable physical AI workflows. You'll start from common 3D source formats and write Python-based code to extract, transform, and load assets into reusable, modular USD representations suitable for large-scale workflows. Through guided, hands-on exercises, you'll structure 3D content into composable USD assets, apply simulation-ready (“SimReady”) standards, and enrich assets with rigid-body physics that support downstream robotics and simulation workloads. By the end of the lab, you'll have automated an asset conversion pipeline capable of processing large 3D datasets, giving you a practical blueprint you can adapt to your own production environment. Intermediate experience with Python, including working with packages, virtual environments, and basic scripting. Familiarity with content concepts such as meshes, materials, transforms, and scene hierarchies common to 3D modeling applications. Understand command-line usage for running scripts and managing project files. Recommended: Have completed the Learn OpenUSD curriculum (https://docs.nvidia.com/learn-openusd/latest/index.html), covering fundamentals of USD-based scene representation and concepts (stages, layers, prims, and composition). Have basic familiarity with robotics or simulation or general 3D content workflows (for example, using simulation tools or working with physics-enabled assets)",Manufacturing,"RTX GPU, Isaac, Omniverse, DLSS, PhysX, NVIDIA NIM, Blackwell"
DLIT81878,Build a Public Safety Visual Search and Summarization Agent With Palantir AIP [DLIT81878],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81878/,"Nell Barber (Solutions Architect, NVIDIA)","In this hands-on training lab, you'll learn how to supercharge your video workflows by reimagining NVIDIA’s Visual Search and Summarization Agent Blueprint inside Palantir’s Artificial Intelligence Platform (AIP). We’ll demonstrate how to extract visual insights from input video in the form of captions and scene descriptions, and you’ll get your hands dirty processing and indexing those insights for retrieval tasks like summarization and Q&A. You’ll bring it all together by creating an interactive dashboard to view input video alongside timestamped summaries and query your visual agent in natural language. By the end of this lab, you'll know how to transform passive video streams and hours of recordings into active, decision-driving assets, empowering your enterprise to maximize the impact of your visual data without ever writing a single line of code.",Smart Cities / Spaces,
DLIT81774,Build a Video Analytics AI Agent With Vision Language Models [DLIT81774],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81774/,"Sammy Ochoa (Technical Marketing Engineer, NVIDIA)","New vision language models (VLMs) are transforming computer vision with scalable, reasoning zero-shot solutions. Learn about Cosmos Reason — a new open and fully customizable reasoning VLM for physical AI and robotics — that lets robots and vision AI agents reason like humans, using prior knowledge, physics understanding, and common sense to understand and act in the real world. In this lab, you'll build a video analytics AI agent using the NVIDIA Blueprint for Video Search and Summarization (VSS) with Cosmos Reason VLM.",All Industries,"HGX, DeepStream, TensorRT, Metropolis, TAO Toolkit, NVIDIA AI Enterprise, Cosmos"
DLIT81814,Build Agentic Workflows for Financial Applications [DLIT81814],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81814/,"David Williams (Solutions Architect, NVIDIA); Benjamin Wu (Sr. Solutions Architect, NVIDIA)","We'll walk you through how to turn financial services workflows into end‑to‑end AI agents, covering orchestration, tools, retrieval, and guardrails tailored to domain-specific applications in the financial services industry (FSI). Using NVIDIA’s NeMo Agent Toolkit and Blueprints, you'll get hands on to building multi‑agent systems that support use cases such as investment research and agentic commerce.",Financial Services,"NeMo, NVIDIA NIM, NVIDIA AI Enterprise"
DLIT81808,Build Contact-Rich Robot Manipulation Skills With Isaac Lab [DLIT81808],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81808/,"Ashwin Varghese Kuruttukulam (coming soon, NVIDIA); Ayusman Saha (coming soon, NVIDIA)","Learn how to develop contact‑rich manipulation policies in Isaac Lab, and deploy them using NVIDIA Isaac ROS. In this hands‑on lab, you will walk through a gear-assembly workflow that uses Isaac Lab to train an insertion policy, and then deploy it in ROS 2, together with perception models (segmentation and 3D pose estimation) and cuMotion for GPU‑accelerated planning. You'll see how to configure an Isaac for Manipulation workflow that begins with a simulated UR robot and depth cameras for training the policy, and then tune to achieve robust, repeatable sim‑to‑real performance on contact‑rich tasks.",All Industries,Isaac
DLIT82006,"Build Cost-Effective, Scalable RAG Pipelines: From Ingestion to Response Generation [DLIT82006]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82006/,"Ruchika Kharwar (Product Manager, NVIDIA)","We'll walk you through the full life cycle of a RAG pipeline: data ingestion, chunking and embedding, retrieval orchestration, and response generation, emphasizing robustness techniques such as hybrid retrieval, fallback strategies, caching, and constraint-aware prompting, along with patterns for monitoring quality and detecting drift over time. You'll also explore scaling concerns, including index sharding, cost-aware architecture choices, and aligning RAG design with product requirements and service-level agreements. By the end, you'll have implemented and evaluated a RAG pipeline that balances answer quality, latency, and reliability, providing a template for deploying similar systems in production.",All Industries,"NVIDIA NIM, NVIDIA AI Enterprise, cuVS"
DLIT81550,Build Domain AI Agents That Seamlessly Tap Into Your Existing Tools and Data With NVIDIA Nemotron and NeMo [DLIT81550],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81550/,"Shashank Verma (Sr. Technical Marketing Engineer, NVIDIA); Yang Yu (Solutions architect, NVIDIA)","Developing effective AI agents requires more than a powerful model — it demands the ability to use the tools, data, and systems that drive real-world workflows. Learn how to create a production-ready agent for a custom use case using NVIDIA NeMo powered by Nemotron models. You'll deploy NeMo modules, customize and evaluate model behavior, connect to data and tools, and apply guardrails for reliable operation. A central focus is enabling the agent to work fluidly with an existing data and tooling ecosystem — integrating APIs, function calls, and the Model Context Protocol (MCP) to accomplish meaningful tasks end to end. We'll also demonstrate a data flywheel that captures interactions to boost accuracy, reliability, latency, and cost over time. You'll build a complete system that you can extend in enterprise or personal environments. Basic experience with Python A general understanding of LLMs or agent workflows or Generative AI concepts (no deep ML background required) Familiarity with REST APIs or function-calling concepts is helpful but not mandatory Optional but beneficial: Exposure to NVIDIA NeMo, containerized development (Docker), or cloud workflows No prior experience with Nemotron models or NeMo is required.",All Industries,"NeMo, NVIDIA NIM"
DLIT81609,Build End-to-End Medical AI Workflows With NVIDIA Clara Open Models [DLIT81609],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81609/,"Ahmed Harouni (Technical Marketing Engineer, NVIDIA)","This comprehensive hands-on workshop demonstrates how to build production-ready medical AI workflows using NVIDIA Clara's latest open models and tools. You'll gain practical experience with NV-Segment, NV-Generate, NV-Reason, and MONAI Label to create powerful medical imaging applications.",Healthcare & Life Sciences,"MONAI, NVIDIA NIM"
DLIT81816,Build Robot-Ready Assets for Physically Accurate Simulations With Lightwheel [DLIT81816],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81816/,"Frank Chen (Director of Engineering, Lightwheel); Siyi Lin (Technical Artist Lead, Lightwheel)","In this hands-on lab, Lightwheel, a leading provider of simulation-ready assets, platforms, and synthetic data for embodied AI, guides you through the complete SimReady asset preparation workflow. You’ll learn to generate high-fidelity synthetic data using OpenUSD, configure accurate physics properties (mass, friction, collision geometry) with PhysX and Newton, and add semantic metadata along with manipulation affordances. You’ll validate your work by deploying trained robot agents inside NVIDIA Isaac Sim. By the end of the lab, you’ll know how to build simulation-ready scenes that support real-to-sim calibration and sim-to-real transfer, enabling robots to learn robustly in simulation and perform reliably in the real world. Recommended:",Manufacturing,"Isaac, Omniverse, PhysX"
DLIT81541,Build Surgical and Medical Robotics With NVIDIA Isaac for Healthcare: From Simulation to Deployment [DLIT81541],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81541/,"Maximilian Ofir (Technical Marketing Engineer, NVIDIA GmbH)","Gain hands-on experience in setting up simulation environments, generating and converting synthetic medical data, modifying scenes and assets, collecting and curating datasets via state-machine demonstrations, fine-tuning the GR00T N1 Vision-Language-Action (VLA) model, and testing robotic ultrasound tasks in simulation. We emphasize safe, efficient AI model development and deployment for healthcare applications. IsaacSim and IsaacLab foundational experience. Python and terminal experience. General understanding of deep learning, and vision language action models.",Healthcare & Life Sciences,"RTX GPU, AGX, Clara, Isaac, Clara Holoscan, MONAI, Cosmos"
DLIT81798,Building and Deploying Digital Twin Applications With Omniverse Kit App Streaming [DLIT81798],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81798/,"Sebastian Misiurek (Sr. Product Manager, Omniverse, NVIDIA); Andrew Wrenn (Cloud Software Engineer, NVIDIA)","Unlock the power of real-time 3D digital twin applications with NVIDIA Omniverse Kit App Streaming. In this lab, you'll build, containerize, deploy, and extend interactive 3D applications that stream directly to web clients, enabling scalable, remote simulation and control for digital twin solutions. We’re going to create a streaming-ready OpenUSD application and a front-end client, then package and deploy a solution using industry-standard tools and APIs. You’ll explore how to implement custom messaging between your app and client, allowing for rich, bi-directional interaction and integration with live data sources. You'll gain practical experience with the full development and deployment workflow for Omniverse Kit App Streaming and develop a solid foundation for building operational digital twins that deliver real-time insights and collaboration across your organization.",All Industries,
DLIT81699,Building and Testing Multi‑Robot Scenarios with Isaac Sim and ROS 2 [DLIT81699],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81699/,"Rishabh Chadha (Technical Marketing Engineer - Isaac, NVIDIA); Ayush Ghosh (Robotics Systems Engineer, NVIDIA)","Gain practical experience in orchestrating multi-robot collaboration, automating simulation workflows, and executing autonomous navigation and object manipulation tasks in a test scenario, using ROS 2, Simulation Interfaces, and Isaac Sim. These skills will empower you to deploy and test advanced robotics solutions.",All Industries,Isaac
DLIT81861,"Compress, Cut, and Distill: The Latest Gen AI Model Compression Techniques in Practice [DLIT81861]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81861/,"Lavinia Ghita (Solutions Architect, NVIDIA); Sergio Perez (Solutions Architect, NVIDIA); Harshita Seth (Solutions Architect, NVIDIA); Liana Mikaelyan (Sr. Solutions Architect, NVIDIA)","This training lab explores the art and engineering of compressing large language models to make them cheaper, faster, and easier to deploy while preserving practical capability. Designed for a broad audience that spans beginners to advanced practitioners, the workshop will introduce foundational concepts for newcomers, share implementation patterns and pitfalls for experienced engineers, and highlight cutting-edge research directions for specialists.",All Industries,
DLIT81697,"Configure Robot Simulations With OpenUSD and PhysX: Tuning, Stability, and Asset Authoring Best Practices [DLIT81697]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81697/,"Alexandra Kissel (Robotics Simulation Software Engineer, NVIDIA); Steven Feng (Robotics Engineer, NVIDIA)","Learn from NVIDIA experts about OpenUSD best practices and physics tuning of mechanisms, using the example of a robotic hand. Starting from a URDF file, see how to structure, assemble, and optimize USD. Then learn about the physics tuning process, to enable dexterous hands to behave realistically in simulation. We will focus on best practices that make complex hand models performant, controllable, and ready for downstream learning and control tasks. Intermediate experience with Python, including working with packages, virtual environments, and basic scripting. Familiarity with 3D content concepts such as meshes, materials, transforms, and scene hierarchies from tools like Blender, Maya, or similar DCC applications. Understand command-line usage for running scripts and managing project files. Have familiarity with robotics or simulation workflows (for example, using simulation tools or working with physics-enabled assets).",All Industries,Isaac
DLIT81948,Create Generative AI Workflow for Design and Visualization in ComfyUI [DLIT81948],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81948/,"Ashlee Martino-Tarr (3D Workflow Specialist, NVIDIA); Alessandro La Tona (3D Workflow Specialist, NVIDIA); Daniela Flamm Jackson (3D Workflow Specialist, NVIDIA)","The latest image and video generation models, combined with LLM, are fantastic tools to build powerful agentic AI workflows, but they're hard to access through too many cloud access points to efficiently iterate on concepts and stay up to date. In this two-hour instructor-led workshop, you'll learn how to use GPU acceleration for ComfyUI on local workstation or servers, pulling the latest models to build complex generative workflows. Workflows will range from relighting pictures/video, 3D workflows including Physically based rendering map generation, or even building storyboard from pictures and text. Whether you're a developer willing to learn what models work best for what tasks, or an industrial designer or digital artist willing to understand how to drive AI with your inputs, this course demonstrates how ComfyUI can be used to power design and visualization workflows with Gen AI.",AEC,"RTX GPU, RTX Virtual Workstations (vWS)"
DLIT81879,Create Vision AI Applications With Generative AI Coding Agents [DLIT81879],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81879/,"Carlos Garcia-Sierra (Product Manager - Metropolis AI Workflows, NVIDIA)","Computer vision is a cornerstone of the generative AI revolution, providing the essential visual metadata required by vision language models (VLMs) to extract actionable insights. In this two-hour instructor-led workshop, you will learn how to GPU-accelerate your video analytics workflow by combining the NVIDIA DeepStream SDK with the power of prompt engineering. Discover how to generate complete, GPU-accelerated DeepStream pipelines using simple natural language prompts. Whether you are a developer new to DeepStream or an advanced user looking to accelerate your prototyping, this course demonstrates how to produce intuitive, readable Python applications without the manual overhead. Join us to bridge the gap between traditional video analytics and modern GenAI development.",All Industries,"DeepStream, Metropolis, Cosmos, Blueprint"
DLIT81660,Data to Decisions: GPU-Accelerated Decision Optimization [DLIT81660],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81660/,"Burcin Bozkaya (Sr. Developer Relations Manager, NVIDIA); Adi Geva (Technical Marketing Engineer, NVIDIA)","Learn to optimize decision optimization problems with GPU-accelerated workflows using NVIDIA cuOpt, RAPIDS, CUDA-X libraries, and Nemotron models. This hands-on lab dives into advanced LP/MIP solver integration, accelerated primal heuristics, cutting-plane methods, and deployment patterns for large-scale, real-time optimization. Foundational knowledge of optimization: Familiarity with Linear Programming and Mixed Integer Programming concepts (constraints, relaxations, heuristics, cutting planes). Basic Python proficiency: Ability to read and modify Python scripts used in optimization workflows. Some experience with GPUs or CUDA-based frameworks: Prior exposure to GPU computing (e.g., RAPIDS, CUDA-X libraries) is helpful but not mandatory. Comfort with OR tooling: Experience with at least the optimization solver ecosystem",All Industries,"CUDA, CUDA-X, cuOPT"
DLIT82008,Deploy and Customize Your AI Factory: Make Your AI Factory Feel Like Home! [DLIT82008],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82008/,"Max Steele (Sr. Technical Instructor in AI and Data Center, NVIDIA); Terrell Bennett (Technical Training Content Developer, NVIDIA)","This hands-on lab will get you down and dirty with customizing an AI factory. Experience how typical administrator tasks are made easier with NVIDIA Mission Control, and explore the interfaces and tools that NVIDIA Mission Control provides for doing ""Day 1 and beyond"" work.",All Industries,"Grace CPU, DGX Platform, HGX, Infiniband Networking, Hopper, LaunchPad, Base Command Manager, Interconnect Networking, Blackwell, NVIDIA AI Enterprise, Mission Control"
DLIT81738,Deploy and Optimize LLMs and VLMs on NVIDIA Jetson Thor [DLIT81738],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81738/,"Chitoku Yato (Sr. Technical Product Marketing Manager, NVIDIA)","Learn to deploy, optimize, and accelerate large language models (LLMs) and vision-language models (VLMs) on NVIDIA Jetson Thor through hands-on exercises with real hardware. We'll demonstrate production-ready inference frameworks including vLLM and SGLang, apply NVIDIA ModelOpt for quantization, showcase systematic methods to achieve inference performance improvements, and explore advanced capabilities like tool calling and live VLM inference — all running on edge devices you can touch and interact with. Required: Basic understanding of Large Language Models and transformer architectures Familiarity with Python programming and container technologies (Docker) Experience with command-line interfaces and SSH for remote device access Laptop with network connectivity (Ethernet preferred, WiFi acceptable) Recommended:",All Industries,"Jetson, AGX, CUDA, TensorRT, JetPack, Blackwell, Cosmos"
DLIT81958,Deploy State-of-the-Art Gen AI on Your RTX PRO Workstation [DLIT81958],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81958/,"Julius Gregor Tischbein (Sr. Developer Technology Software Engineer, NVIDIA); Maximilian Mueller (Sr. Developer Technology Software Engineer, NVIDIA)","This session guides you through the end-to-end deployment of generative image models on NVIDIA RTX PRO workstations by leveraging ONNX Runtime and TensorRT-RTX. We'll demonstrate how to ship a multi-stage model pipeline across a wide set of hardware without sacrificing performance. This workflow will be powered by classic graphics APIs, ONNX Runtime, and the TensorRT-RTX Execution Provider. You'll leave with the skills to convert raw models into high-performance, offline-capable applications that run seamlessly across diverse hardware architectures.",All Industries,"RTX GPU, DGX Platform, RTX Virtual Workstations (vWS), Blackwell, DGX Spark"
DLIT81650,Develop AI-Powered Operational Dashboards for Digital Twin Applications [DLIT81650],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81650/,"Victor Yudin (Software Architect, NVIDIA); Justine Lin (Technical Marketing Engineer, NVIDIA)","Create intelligent operational dashboards for digital twin applications using NVIDIA Omniverse. Build compact, real-time monitoring interfaces with React to track factory metrics, robot states, and sensor data streams. Embed custom panels into Kit applications and deploy dashboards across local and cloud environments. Learn to integrate LLM agents for natural language interaction with your digital twin data. Through hands-on exercises, learn the workflow for dashboard creation for streaming deployment, enabling intelligent monitoring and control of complex industrial operations.",All Industries,
DLIT81725,Develop Production Agents with Eval-Driven Design [DLIT81725],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81725/,"Dhruv Nandakumar (Cybersecurity AI Solutions Architect, NVIDIA)","This training lab will explore new techniques for building robust, production-ready AI agents by focusing on an evaluation-driven design workflow. You'll learn how we use human-created datasets for iterative improvement and how to apply continuous eval and iterate cycles, including prompt changes and experimentation, to significantly improve agent performance. The prerequisites for this course are practical familiarity with AI/ML fundamentals, including Large Language Models (LLMs), and programming proficiency in Python. Attendees should also have a working understanding of basic prompt engineering and experience with the overall lifecycle of building an AI application, as the lab is focused on the advanced, production-ready stage of evaluation and iterative design.",All Industries,"NeMo, NVIDIA AI Enterprise"
DLIT82002,Efficient Workload Management for AI Factories: What Every Admin Needs to Know [DLIT82002],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82002/,"Max Steele (Sr. Technical Instructor in AI and Data Center, NVIDIA); Terrell Bennett (Technical Training Content Developer, NVIDIA)","In this hands-on lab you'll learn, as an AI factory administrator, how real workloads are run on a cluster. Intended for IT types (not data scientists!), this lab will have you configuring Run:ai, allocating and monitoring resources, and building a workload with NVIDIA NIMS to understand just what the user experience is, and what tools are at your disposal to make the AI factory workloads actually work.",All Industries,"DGX Platform, HGX, Infiniband Networking, LaunchPad, Base Command Manager, NVIDIA NIM, NVIDIA AI Enterprise, NVIDIA Run:ai, Mission Control"
DLIT81945,Faster Together: Train and Deploy a Speculative Decoding Model for Low-Latency LLM Inference [DLIT81945],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81945/,"Mireille Fares (Sr. AI Solution Architect, NVIDIA); Dmitry Mironov (Solutions Architect, NVIDIA)","Dive deep into theory and practice of low-latency inference by deploying NVIDIA TensorRT-LLM with advanced speculative decoding techniques. You'll train an Eagle-3 draft head to propose candidate tokens efficiently, serve it, and benchmark it using AIPerf to quantify how these strategies minimize latency.",Cloud Services,"TensorRT, Dynamo"
DLIT81641,Find the Bottleneck: Optimize AI Pipelines With Nsight Systems [DLIT81641],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81641/,"Sneha Latha Kottapalli (Sr. Systems Software Engineer, NVIDIA)","Learn about using NVIDIA Nsight Systems for bottleneck detection in AI pipelines and explore new features to optimize and scale the execution of your applications. This lab will guide you through the performance analysis process of GPU-accelerated AI applications that run across multiple, possibly containerized, compute instances. In addition to profiling of CPU, GPU, network and I/O activity, we'll show how NVTX and plugin mechanisms enable the collection of custom data to support an even more comprehensive and tailored analysis on the target platform. We'll also show how the recipe system can be used to identify bottlenecks in applications running across multiple nodes. This lab is for both beginners and experienced developers who want to learn about the latest features, tips, and tricks for performance analysis to get the most out of their hardware.",All Industries,NSight Systems
DLIT81936,"Fine-Tune a Telco Reasoning Model: A Guide to Synthetic Data, Tool Calling, and Evaluation [DLIT81936]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81936/,"Amparo Canaveras (Sr. Solutions Architect Generative AI, NVIDIA); Aiden Chang (Solutions Architect, NVIDIA); Ari Uskudar (Telco AI Principal, NVIDIA)","Network operation centers (NoC) are the central nervous system of telecommunications, but they are often overwhelmed by ""alarm storms."" In a traditional setup, engineers manually validate alarms, swivel between multiple dashboards, check topologies, and perform root-cause analysis. This manual process is time-consuming and prone to fatigue. To solve this, we are moving toward zero-touch, self-healing networks. In this tutorial, we'll walk through creating a fine-tuning playbook that integrates synthetic data generation, training, and evaluation pipelines. We'll demonstrate how to build an AI-driven reasoning model capable of autonomously performing NoC engineer workflows — detecting issues, calling tools, and remediating incidents without human intervention.",Telecommunications,"Cloud / Data Center GPU, CUDA, NeMo"
DLIT81754,From Ingestion to Inference: Mastering the High-Performance GPU Data Science Pipeline [DLIT81754],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81754/,"William Hill (Developer Advocate, Data Science, NVIDIA); Allison Ding (Developer Advocate - Data Science, NVIDIA)","Get a comprehensive guide to constructing a complete, high-performance data science pipeline that leverages GPU acceleration throughout its life cycle. We'll sequentially cover the pipeline's core components: data ingestion, exploration, processing, and model training. For the initial stages of data ingestion and exploration, we'll demonstrate the use of GPU-accelerated frameworks, specifically Polars and/or cuDF pandas, to achieve significant speedups in data manipulation and analysis. Then we'll showcase the power of the cuML library (part of the RAPIDS ecosystem) for training and testing various machine learning models entirely on the GPU.",All Industries,"RAPIDS, cuDF, cuML"
DLIT81485,Hands-On With Earth-2: Building Local and National Weather Resilience With AI [DLIT81485],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81485/,"Marius Koch (Solution Architect, NVIDIA); Jussi Leinonen (Solution Architect, NVIDIA); Alberto Carpentieri (Solutions Architect, NVIDIA)","We explore the life cycle of AI-based high-resolution regional weather forecasting applications, which are used by businesses and governments to achieve independent local weather and climate prediction capabilities at high accuracy and unprecedented speed. We'll start by creating a custom high-resolution model, guiding you through preparing a training dataset, training a downscaling diffusion model with NVIDIA PhysicsNeMo, and packaging it for real-time use. We then use NVIDIA Earth2Studio to integrate our custom model with a global AI-based weather forecasting model, such as FourCastNet 3, to build a full regional forecasting workflow, enabling sharper and more actionable local forecasts. We'll then discuss leveraging custom weather observations to improve the accuracy of the predictions, and deploying the workflow in operations so it can be productized as an inference service.",All Industries,Modulus
DLIT81668,Harness NVIDIA AI Advanced Tools for Generative AI in Digital Health [DLIT81668],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81668/,"Jin Li (Technical Marketing Engineer, NVIDIA); Abood Quraini (Technical Marketing Engineering Manager, NVIDIA); Ben Randoing (Technical Marketing Engineer, NVIDIA)","Explore the NVIDIA Data Flywheel, which uses agent deployment artifacts from production applications to increase the overall accuracy and reduce the latency/cost of agentic AI systems. We'll explore how to utilize the NeMo Microservices Platform for programmatic control of datasets, fine-tuning, evaluation, and inference. Familiarity with Python, basic understanding of how agentic systems work, hands-on knowledge is encouraged but not required.",Healthcare & Life Sciences,NeMo
DLIT82181,How to Accelerate AI Workflows With NVIDIA Run:AI [DLIT82181],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82181/,"David Whitehouse (NVIDIA Academy Lab Manager, NVIDIA)","Unlock faster, smarter AI development in this hands-on introduction to the NVIDIA Run:AI platform. In this lab, you’ll explore how Run:AI streamlines machine learning operations, removes infrastructure bottlenecks, and simplifies workload management to accelerate outcomes. Learn how dynamic resource allocation transforms efficiency across enterprise teams, ensuring workloads run faster, smoother, and at scale. Then apply what you learn directly in your lab environment as instructors guide you through real-world examples of accelerated ML operations. You’ll leave with practical skills and a strong foundation for optimizing performance with Run:AI.",All Industries,Mission Control
DLIT82184,How to Provision and Install NVIDIA Run:AI [DLIT82184],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82184/,"David Whitehouse (NVIDIA Academy Lab Manager, NVIDIA)","Get grounded in the practical fundamentals of deploying NVIDIA Run:AI from the ground up. This lab walks you through every stage of installation—from environment preparation to final validation—so you can confidently stand-up Run:AI within your own organization. Follow a guided, instructor-led deployment in your provided lab environment, learn how to verify installations, and practice diagnosing and resolving common setup issues. Whether you’re preparing for full production rollout or building a proof of concept, this session delivers the skills to deploy successfully and maintain stability.",All Industries,Mission Control
DLIT81484,How to Run AI-Powered Computer-Aided Engineering Simulations [DLIT81484],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81484/,"Ira Shokar (Solutions Architect, NVIDIA); Mark Hobbs (Solutions Architect, NVIDIA); Pablo Hermoso Moreno (Sr. Solutions Architect, NVIDIA)","In this lab, we explore how to build AI surrogate models for crash simulations, one of the most computationally intensive tasks in computer aided-engineering (CAE). Learn how modern AI architectures can reproduce high-fidelity physics simulations at a fraction of the cost, enabling faster design exploration and decision-making. We'll walk through the full workflow for developing an AI surrogate for CAE applications, including data preparation and analysis, training and optimization, loading and running inference with pre-trained models, and evaluating model accuracy and uncertainty. We'll also discuss how AI-accelerated workflows are transforming CAE across various industries and areas of research, and how these tools can integrate seamlessly into existing engineering pipelines.",HPC / Scientific Computing,Modulus
DLIT82259,Keep Calm and Train On: Scalable and Resilient Training With Megatron-Bridge and NeMo [DLIT82259],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82259/,"Shreya Gupta (Solutions Architect, NVIDIA); Mohak Chadha (Solutions Architect, NVIDIA); Pramod Kumbhar (Sr. Solutions Architect - HPC & AI, NVIDIA)","As modern data centers evolve into AI factories, training foundational models becomes critical. But scaling these training pipelines across tens of thousands of GPUs introduces significant challenges—such as node failures, network errors, checkpointing overhead—that can quickly turn occasional anomalies into frequent production issues. In our hands-on lab, learn about the challenges of running training pipelines and how to integrate resiliency and fault-tolerance features. We'll present various fault-tolerance mechanisms provided in frameworks like NVRx and PyTorch, and demonstrate how to achieve robust, scalable training in modern AI factories using NVIDIA NeMo. Gain practical insights into techniques for measuring I/O and overall infrastructure performance. You should be familiar with Python and deep learning frameworks, understand LLM training concepts, and be comfortable with Linux.",Public Sector and Sovereign AI,"CUDA, NCCL, NeMo"
DLIT82062,MLOps Best Practices: Build an AI Agent [DLIT82062],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82062/,"Ryan Kraus (Sr. Technical Marketing Engineer, NVIDIA)","Learn practical ways to implement MLOps first principles as you create autonomous AI agents using LangGraph and NVIDIA NIM by building an agentic system that demonstrates tool integration, multi-step reasoning, and adaptive planning. Master the foundational agent architecture that MLOps engineers use to automate tedious workflows like incident investigation, experiment documentation, and model health monitoring — then customize it for your own use cases.",All Industries,"Hopper, NVIDIA NIM, Nemotron"
DLIT81803,OpenUSD Asset Integration and Data Review With Clash Detection [DLIT81803],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81803/,"Martin Vovk (Sr. Solutions Architect, NVIDIA)","Integrate clash detection into your OpenUSD-based digital twin workflows using NVIDIA Omniverse libraries. In this lab, we’ll ensure ingested assets are run through conflict analysis using the Clash Detection SDK. You’ll create and execute collision detection queries, inspect and visualize results in an Omniverse viewport, and implement robust overlap detection in complex 3D scenes. We will learn the fundamentals of simulation for digital twins, engineering validation, and automated design verification workflows.",All Industries,Omniverse
DLIT82143,Optimize LLM Inference and RL Training With SGLang [DLIT82143],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82143/,,"This training lab shows you how to optimize and scale LLM workflows with SGLang. We walk through practical performance tuning using the SGL-Cookbook, dive into profiling and bottleneck analysis for developers, and demonstrate its deep integration into reinforcement learning (RL) training frameworks by showing how to use SGLang in a real RL run with the Miles RL framework.",All Industries,"Hopper, Blackwell, DGX Cloud, DGX Station"
DLIT81579,Optimize PyTorch Models for High-Performance Inference With Nsight Deep Learning Designer [DLIT81579],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81579/,"Timothee Brenet (Sr. Deep Learning Engineer, NVIDIA); Gaoyan Xie (Sr. Manager of Software Engineering, NVIDIA); Manoj Kumar Yennapureddy (Sr. Deep Learning Engineer, NVIDIA)",Learn how to use a graphical user interface-based integrated development environment (IDE) purpose-built for deep neural network developers to manage the end-to-end process of going from PyTorch to a deployment-ready model that yields the best inference performance. Learn how to use a GPU-based performance profiler to guide sound decision-making for model optimizations.,All Industries,"CUDA, TensorRT, NSight Systems, TAO Toolkit"
DLIT81572,Powering Specialized Agents: Architecting Synthetic Data Pipelines with NVIDIA Data Designer [DLIT81572],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81572/,"Yevgeniy Meyer (Principal Research Scientist, NVIDIA); Kirit Thadaka (Product Manager, NVIDIA)","Building a truly performant LLM agent means fine-tuning for your unique use-case. This requires training data that span multiple specialized domains or tools; for most real-world applications, the data you need simply don't exist. This hands-on workshop leverages NVIDIA Data Designer, our recently open-sourced, state-of-the-art framework, to bridge this gap. We'll cover the latest techniques developed at NVIDIA for producing high-quality reasoning data, including STEM and tool-calling workflows used to scale Nemotron models. By the end of this session, you will gain the skills to speed up data experimentation and drive innovation in your own AI projects. Basic Python and Jupyter notebooks Training or fine-tuning LLMs (conceptually) Using datasets for supervised fine-tuning and evaluation (classification, generation, or instruction-following tasks) Optional: prior exposure to NVIDIA NeMo, Hugging Face datasets/models, or other LLM fine-tuning stacks.",All Industries,"NeMo, NVIDIA AI Enterprise"
DLIT81881,Production-Ready Robotics on the NVIDIA Stack [DLIT81881],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81881/,"Sai Vemprala (CTO and Co-founder, General Robotics)","In this hands-on lab, General Robotics will guide you through a complete, end-to-end solution development workflow built on the NVIDIA ecosystem. You'll learn to: • Capture teleoperated demonstrations of real manual tasks • Augment, vary, and scale those tasks in simulation using NVIDIA Isaac • Generate high-volume synthetic datasets to expand coverage • Fine-tune modern robotics models using NVIDIA’s training infrastructure • Test policies and reinforcement learning models in advanced simulation, leveraging NVIDIA AI models like GraspGen, CuMotion, and Foundation Stereo • Deploy learned behaviors to real robots running on Jetson • Analyze system performance and iterate using the latest LLMs and agentic tools • Bridge the human–robot gap across development, validation, and deployment",Manufacturing,
DLIT81545,Profiling Python and AI workloads with Nsight Compute [DLIT81545],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81545/,"Felix Schmitt (Principal System Software Engineer, NVIDIA)","Learn how to use the Nsight Compute tool to profile CUDA and AI GPU kernels in the Python framework of your choice: Numba, Triton or PyTorch. Understand the optimization workflows provided by NVIDIA Nsight Compute UI and its ncu command line interface. Use the new scoreboard dependency analysis view and source page improvements like opcode to metric pipeline associations. Learn how to use the Nsight Jupyterlab Extension for profiling and streaming reports directly in Jupyter. Try the latest Nsight Python decorators for profiling from within any Python script.",All Industries,
DLIT81801,Real-Time Simulation for Real-Time Results: How AI Physics Can Accelerate Your AI Factory [DLIT81801],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81801/,"Abigail Breazeale (Sr. Technical Marketing Engineer, NVIDIA); Robert Cervellione (Sr. Product Manager – Omniverse, NVIDIA)","This hands-on lab introduces mechanical and simulation engineers to GPU-accelerated, real-time CFD workflows that combine interactive visualization with physics-AI models. Participants will use NVIDIA technologies to connect CFD simulations, PhysicsNeMo, and digital twin environments for faster iteration and more reliable design insights. We will configure and run real-time CFD cases, integrate PhysicsNeMo for accelerated prediction, and visualize results interactively for design exploration. The session will show how to move from traditional batch-style CFD to responsive, GPU-driven workflows that support rapid concept evaluation and collaborative design reviews.",Manufacturing,"Omniverse, NeMo"
DLIT81698,Scalable Environment Setup and Policy Evaluation in Simulation with Isaac Lab Arena and GR00T [DLIT81698],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81698/,"Asawaree Bhide (Robotics Technical Marketing Engineer, NVIDIA); Edith Llontop (Solutions Architect, NVIDIA)","In this hands-on lab, you’ll gain expertise on workflows for simulation-based policy evaluation, including how to setup simulation environments with Isaac Lab Arena, how to post-train GR00T models for custom tasks and how to evaluate trained policies in simulation at scale. NVIDIA Isaac Lab Arena is a framework for scalable policy evaluation in simulation. NVIDIA Isaac GR00T provides robot foundation models for cognition and control, built on NVIDIA Omniverse™ and Cosmos™.",All Industries,Isaac
DLIT82000,Split and Win: Dynamo's Prefill-Decode Disaggregation and Smart KV Routing for Extreme LLM Throughput [DLIT82000],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82000/,"Kyle Huang (WWFO) (Gen AI Solutions Architect, NVIDIA); Arun Raman (Sr. Solution Architect, NVIDIA); Utkarsh Uppal (Sr. Deep Learning Solutions Architect, NVIDIA)",Master the deployment of massive mixture-of-expert architectures by configuring Dynamo’s PD Disaggregation with Large Expert Parallelism to maximize GPU efficiency. Learn to optimize distributed data flows including KV Cache Aware Routing to achieve an order-of-magnitude increase in serving throughput while meeting strict production latency demands.,Cloud Services,"TensorRT, Dynamo"
DLIT81546,Supercharge Tabular ML Models With GPU-Accelerated Feature Engineering [DLIT81546],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81546/,"Chris Deotte (Sr. Data Scientist, NVIDIA); Ronay Ak (Sr. Data Scientist, NVIDIA)","Fast experimentation in feature engineering is essential to quickly discover the most valuable features that improve model performance. In this tutorial, we leverage NVIDIA cuDF and cuML libraries to accelerate the experimentation pipeline on GPUs with their zero-code change features, enabling faster feature engineering and quicker development of more accurate models. Basic understanding of Python and tabular data.",All Industries,"CUDA, RAPIDS, CUDA-X, cuDF, cuML"
DLIT81644,Synthetic Data Generation for Robot Learning With NVIDIA Cosmos World Foundation Models [DLIT81644],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81644/,"Stefanie Manzinger (Sr. Solutions Architect, NVIDIA)","This hands-on lab introduces roboticists, AI developers, and pipeline engineers to NVIDIA Cosmos world foundation models (WFMs) for synthetic data generation in robot learning pipelines. Participants will learn how to leverage simulation scenes from Isaac Sim and real-life images and videos to provide initial datasets and augment them with Cosmos Transfer, then evaluate data quality with Cosmos Reason—all within a production-ready robotics pipeline. Through this session, you'll experience an end-to-end data pipeline workflow, leveraging Cosmos WFMs to generate synthetic data from real-world and physically-accurate simulated data, and using Cosmos Reason as an intelligent critic to validate data quality. By completing this lab, you'll unlock the ability to generate high-quality training datasets, accelerating your action model development.",Manufacturing,"RTX GPU, Isaac, Omniverse, DLSS, Omniverse Replicator, NVIDIA NIM, Blackwell, NVIDIA AI Enterprise, Cosmos"
DLIT81818,Tabular Foundation Models for Financial Services [DLIT81818],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81818/,"Benjamin Wu (Sr. Solutions Architect, NVIDIA); Flora Huang (Sr. Solutions Architect, NVIDIA)","Tabular data powers entire industries, but building state-of-the-art models for structured data at scale remains complex. In this session, we’ll unveil a comprehensive workflow for building transformer-based tabular foundation models. Each stage of our reference architecture is GPU-accelerated: tabular synthetic data generation, feature engineering and tokenization, training large-scale tabular transformers, and deploying inference pipelines. We apply this workflow to the real-world problem of fraud detection in credit card transactions, highlighting best practices and NVIDIA’s ecosystem for scalable tabular AI.",Financial Services,"RAPIDS, cuDF, cuML, NeMo, Triton, NVIDIA AI Enterprise"
DLIT81565,The Kaggle Grandmasters Playbook: Battle-Tested Modeling Techniques for Tabular Data [DLIT81565],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81565/,"Chris Deotte (Sr. Data Scientist, NVIDIA); Gilberto Titericz Junior (Sr. Data Scientist, NVIDIA)","Our workshop highlights proven strategies for tabular data developed by NVIDIA’s Kaggle grandmasters, who have earned top honors in hundreds of international data science competitions. You'll practice rapid electronic design automation (EDA), large-scale feature engineering, model building, ensembling, and pseudo-labeling — all accelerated with GPUs for faster experimentation and better accuracy.",All Industries,"CUDA, RAPIDS, CUDA-X, cuDF, cuML"
DLIT81757,Training Lab: Advance World Simulation With 3D Gaussian Splatting for Large-Scale Environment Reconstruction [DLIT81757],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81757/,"Zoe LaLena (Solutions Architect, NVIDIA)","Learn how to reconstruct a large scene for robotics testing using NVIDIA Omniverse NuRec Gaussian-based reconstruction technologies to perform multi-GPU training, neural enhancement, object segmentation and extraction. This lab will walk through core concepts with a step-by-step workflow for data capture, reconstruction, generative enhancement, and object level-integration for robotics simulation in NVIDIA Isaac Lab.",Public Sector and Sovereign AI,"RTX GPU, Omniverse, Blackwell"
DLIT82021,Ultra Scale Runbook for PyTorch on NVIDIA GPUs for Training and Inference [DLIT82021],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82021/,"Syed Ahmed (Sr. Software Engineer, NVIDIA)","In this lab, we'll walk through large-scale training and deployment of a well-known mixture-of-experts (MoE) LLM. You'll learn how to scale MoE pre-training by composing several parallelism techniques (FSDP, Tensor Parallel, Pipeline Parallel), memory saving techniques (Activation Checkpointing, CPU Offloading), and torch.compile driven optimizations. We'll use TorchTitan as our pre-training framework. We'll also demonstrate how to deploy such a model using the vLLM framework. You'll learn how to apply CUDA-accelerated inference-specific optimizations available in vLLM.",All Industries,"BlueField DPU, Cloud / Data Center GPU, Grace CPU, DGX Platform, CUDA, Infiniband Networking, Ethernet Networking, Hopper, cuBLAS, CUDA-X, cuDDN, cuFFT, DALI, Interconnect Networking, NCCL, NSight Comute, NSight Systems, NVLink / NVSwitch, Triton, Blackwell, NVIDIA AI Enterprise, DGX Cloud, DGX Station"
DLIT81764,Unlock Real-Time Financial Decisions With GPU-Accelerated Portfolio Optimization [DLIT81764],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81764/,"Peihan Huo (Solution Architect, NVIDIA); Jianchi Chen (Chief Investment Officer, Kendall Square Capital); Ioana Boier (Global Head of Capital Markets Strategy, NVIDIA); Francisco Zhao (Senior Solutions Architect, NVIDIA)","Discover how to resolve the trade-off between computational speed and model complexity in financial portfolio management. This session combines NVIDIA’s Quantitative Portfolio Optimization developer example with exclusive insights from Kendall Square Capital, demonstrating how to accelerate large-scale, complex portfolio optimization problems without compromising result quality. Learn how to formulate data-driven models to leverage cuOpt and CUDA-X Data Science libraries to unlock accelerations up to triple-digit speed-ups compared to CPU-based solutions. Gain insights into how these innovations transform portfolio optimization from a slow batch process into a dynamic workflow, unlocking new frontiers in automated investing research and real-time rebalancing.",Financial Services,"CUDA, CUDA-X, cuDF, cuML, cuOPT"
DLIT81597,Using Reasoning VLAs to Develop Safer Autonomous Vehicles [DLIT81597],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81597/,"Ed Schmerling (Sr. Research Scientist, NVIDIA); Apoorva Sharma (Research Scientist, NVIDIA)","In this training lab, we'll demonstrate how state-of-the-art reasoning vision-language-actions (VLAs) models, like Alpamayo R1, can be used as part of a safety evaluation pipeline ready for next-generation, end-to-end AI-powered autonomous vehicles (AVs). Learn how to use these powerful reasoning models to aid in data curation for safety validation, using these models to mine the NVIDIA Physical AI Dataset to identify key scenarios to target with additional testing.",Automotive / Transportation,"DRIVE, DRIVE SDK, DRIVE AV, Blackwell, Cosmos"
DLIT81837,How to use Warp to Build GPU-Accelerated and Differentiable Physics Simulations [DLIT81837],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81837/,"Mohammad Mohajerani (Sr. Product Manager, NVIDIA); Sheel Nidhan (Sr. Technical Marketing Engineer, NVIDIA); Eric Shi (Sr. Engineering Manager, NVIDIA)","Discover how NVIDIA Warp enables the next generation of GPU-accelerated physics, geometry processing, and differentiable programming. This training lab introduces Warp’s core capabilities and modules, then moves into a hands-on notebook where participants build a high-performance physics solver entirely in Python. This is demonstrated through a practical computational fluid dynamics example based on a 2-D Navier–Stokes formulation. You'll leave with an understanding of what Warp is designed for, how its core building blocks work, and how it can be used alongside deep learning frameworks like PyTorch and JAX in modern computational engineering workflows.",All Industries,CUDA-X
DLIW82209,Accelerated Networking for AI Infrastructure [DLIW82209],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82209/,Nawar Nawar (NVIDIA),"Bring your own laptop to experience advanced networking in action with this hands-on workshop. You'll learn how to design a resilient Ethernet management network with BGP, VXLAN, EVPN, and MLAG for modern AI clusters. Dive into monitoring and validating InfiniBand communications using performance tests and subnet manager tools. And finally, learn the most unique networking technology for high-speed GPU-to-GPU workloads as you configure NVIDIA NVLink™ with NMX-C. Don’t miss this opportunity to gain practical expertise in building and optimizing scalable, high-performance AI infrastructure. Learning Objectives: Configure a multi-tenant Ethernet network using Cumulus Linux NOS. Validate, test and operate an E-W InfiniBand fabric for multi-node communication. Setup, manage and troubleshoot high performance NVLink fabric, using NMX control services for GB200 and GB300 deployments. Bring your own laptop to experience advanced networking in action with this hands-on workshop. You'll learn how to design a resilient Ethernet management network with BGP, VXLAN, EVPN, and MLAG for modern AI clusters. Dive into monitoring and validating InfiniBand communications using performance tests and subnet manager tools. And finally, learn the most unique networking technology for high-speed GPU-to-GPU workloads as you configure NVIDIA NVLink™ with NMX-C. Don’t miss this opportunity to gain practical expertise in building and optimizing scalable, high-performance AI infrastructure. Learning Objectives:",All Industries,
DLIW82267,Adding New Knowledge to LLMs [DLIW82267],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82267/,"John Jahanipour (Senior Solutions Architect, NVIDIA)","In today's AI landscape, even powerful Large Language Models (LLMs) face limitations when confronted with specialized business knowledge, technical domains, or cultural contexts absent from their training data. While retrieval-augmented generation can mitigate some gaps, true domain mastery requires deeper model adaptation. This comprehensive workshop equips developers with hands-on skills to transform open-source LLMs into domain-specialized AI assets. Through five interconnected modules, you'll master the complete lifecycle of model customization. By workshop completion, you'll possess the complete technical skillset to develop, deploy, and operate sovereign AI systems tailored to your specific requirements - from data preparation to production scaling. Bring your laptop; we'll provide the GPUs. In today's AI landscape, even powerful Large Language Models (LLMs) face limitations when confronted with specialized business knowledge, technical domains, or cultural contexts absent from their training data. While retrieval-augmented generation can mitigate some gaps, true domain mastery requires deeper model adaptation. This comprehensive workshop equips developers with hands-on skills to transform open-source LLMs into domain-specialized AI assets. Through five interconnected modules, you'll master the complete lifecycle of model customization. By workshop completion, you'll possess the complete technical skillset to develop, deploy, and operate sovereign AI systems tailored to your specific requirements - from data preparation to production scaling. Bring your laptop; we'll provide the GPUs.",All Industries,NeMo
DLIW82269,Building AI Agents with Multimodal Models [DLIW82269],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82269/,"Mark Moyou (Sr. Data Scientist, NVIDIA)","Just like how humans have multiple senses to perceive the world around them, computers have a variety of sensors to help perceive the human world. In the health industry, computed tomography (CT) scans provide a 3D representation used to detect potentially dangerous abnormalities. In the robotics industry, lidars are used to help robots see depth and navigate the complex topology around them. In this course, learners will develop neural network based multimodal models that can understand many different data types by exploring different fusion techniques. Just like how humans have multiple senses to perceive the world around them, computers have a variety of sensors to help perceive the human world. In the health industry, computed tomography (CT) scans provide a 3D representation used to detect potentially dangerous abnormalities. In the robotics industry, lidars are used to help robots see depth and navigate the complex topology around them. In this course, learners will develop neural network based multimodal models that can understand many different data types by exploring different fusion techniques.",All Industries,NVIDIA NIM
DLIW82270,Building LLM Applications With Prompt Engineering [DLIW82270],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82270/,"Matt Linder (Sr. Solutions Architect, NVIDIA)","With the incredible capabilities of large language models (LLMs), enterprises are eager to integrate them into their products and internal applications for a wide variety of use cases, including (but not limited to) text generation, large-scale document analysis, and chatbot assistants. The fastest way to begin leveraging LLMs for diverse tasks is by using modern prompt engineering techniques. These techniques are also foundational for more advanced LLM-based methods such as Retrieval-Augmented Generation (RAG) and Parameter-Efficient Fine-Tuning (PEFT). In this workshop, learners will work with an NVIDIA language model NIM, powered by the open-source Llama-3.1 large language model, alongside the popular LangChain library. The workshop will provide a foundational skill set for building a range of LLM-based applications using prompt engineering. With the incredible capabilities of large language models (LLMs), enterprises are eager to integrate them into their products and internal applications for a wide variety of use cases, including (but not limited to) text generation, large-scale document analysis, and chatbot assistants. The fastest way to begin leveraging LLMs for diverse tasks is by using modern prompt engineering techniques. These techniques are also foundational for more advanced LLM-based methods such as Retrieval-Augmented Generation (RAG) and Parameter-Efficient Fine-Tuning (PEFT). In this workshop, learners will work with an NVIDIA language model NIM, powered by the open-source Llama-3.1 large language model, alongside the popular LangChain library. The workshop will provide a foundational skill set for building a range of LLM-based applications using prompt engineering.",All Industries,NVIDIA NIM
DLIW82268,Building Observable and Scalable Multi-Agent Workflows for Asset Lifecycle Management [DLIW82268],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82268/,"Vineeth Kalluru (Sr. Solutions Architect, NVIDIA); Viraj Modak (AI Solutions Architect, NVIDIA)","Learn to develop multi-agent workflows tailored for Asset Lifecycle Management use cases within industrial process applications. You'll be introduced to the NVIDIA open-source NeMo Agent Toolkit (NAT) and its key features, enabling the creation of a comprehensive and customizable reference solution for this use case. You'll also be guided in effectively utilizing other components of NVIDIA AI stack, including NVIDIA Inference Microservices (NIM), cloud endpoints, and NVIDIA Tesseract time series foundational models. These components are used to design agents capable of executing frequently performed tasks such as data querying and analysis, Forecasting, Remaining useful life prediction, and Anomaly detection. Furthermore, you will gain insight into NAT’s marquee features, such as workflow observability and sizing, prompt optimization, and third-party connections. Learn to develop multi-agent workflows tailored for Asset Lifecycle Management use cases within industrial process applications. You'll be introduced to the NVIDIA open-source NeMo Agent Toolkit (NAT) and its key features, enabling the creation of a comprehensive and customizable reference solution for this use case. You'll also be guided in effectively utilizing other components of NVIDIA AI stack, including NVIDIA Inference Microservices (NIM), cloud endpoints, and NVIDIA Tesseract time series foundational models. These components are used to design agents capable of executing frequently performed tasks such as data querying and analysis, Forecasting, Remaining useful life prediction, and Anomaly detection. Furthermore, you will gain insight into NAT’s marquee features, such as workflow observability and sizing, prompt optimization, and third-party connections.",Manufacturing,NeMo
DLIW82274,Deploying and Optimizing AI Inference at Scale [DLIW82274],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82274/,"Anshul Jindal (Sr. Solutions Architect, NVIDIA); Mohak Chadha (Solutions Architect, NVIDIA); Severine Habert (Solutions Architect, NVIDIA)","As foundation models move toward deeper test-time computation, inference becomes the dominant scaling constraint. Latency, throughput, and cost are governed by a small set of forces: autoregressive decoding, KV-cache growth, memory bandwidth, and scheduling under contention. This workshop frames large-scale inference through these emerging laws of inference, starting from first principles and building toward real systems. Learners begin with monolithic and gateway-based vLLM deployments on Kubernetes to establish baseline behavior, then transition to NVIDIA Dynamo to operate aggregated and disaggregated inference architectures using built-in KV-aware routing and scheduling. A core emphasis is observability: attendees will deploy a full stack (Prometheus, Grafana, Loki, Tempo) to monitor metrics, capture structured logs, and perform distributed tracing. The outcome is a principled understanding of where inference time and money go - and how architectural choices bend those curves in production. As foundation models move toward deeper test-time computation, inference becomes the dominant scaling constraint. Latency, throughput, and cost are governed by a small set of forces: autoregressive decoding, KV-cache growth, memory bandwidth, and scheduling under contention. This workshop frames large-scale inference through these emerging laws of inference, starting from first principles and building toward real systems. Learners begin with monolithic and gateway-based vLLM deployments on Kubernetes to establish baseline behavior, then transition to NVIDIA Dynamo to operate aggregated and disaggregated inference architectures using built-in KV-aware routing and scheduling. A core emphasis is observability: attendees will deploy a full stack (Prometheus, Grafana, Loki, Tempo) to monitor metrics, capture structured logs, and perform distributed tracing. The outcome is a principled understanding of where inference time and money go - and how architectural choices bend those curves in production.",All Industries,Dynamo
DLIW82265,Fundamentals of GPU-Accelerated Workflows with CUDA Python [DLIW82265],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82265/,"Katrina Riehl (Principal Technical Product Manager, NVIDIA); Bryce Lelbach (Principal Architect, NVIDIA)","This course delivers a hands-on introduction to GPU-accelerated computing in Python, empowering developers to build fast, scalable applications using NVIDIA’s CUDA ecosystem. Through guided notebooks, participants master CuPy for array acceleration, cuDF for GPU DataFrames, and the cuda-python API to write custom kernels—all without leaving Python. Real-world exercises in data science, machine learning, and scientific computing emphasize performance, interoperability, and end-to-end efficiency. Learners progress from drop-in speedups to fully integrated GPU pipelines, mastering data movement, asynchronous execution, and profiling with Nsight tools. By the end, attendees can transform CPU-bound Python code into production-grade GPU solutions, bridge prototyping to deployment, and apply best practices for performance and reproducibility in modern accelerated computing. This course delivers a hands-on introduction to GPU-accelerated computing in Python, empowering developers to build fast, scalable applications using NVIDIA’s CUDA ecosystem. Through guided notebooks, participants master CuPy for array acceleration, cuDF for GPU DataFrames, and the cuda-python API to write custom kernels—all without leaving Python. Real-world exercises in data science, machine learning, and scientific computing emphasize performance, interoperability, and end-to-end efficiency. Learners progress from drop-in speedups to fully integrated GPU pipelines, mastering data movement, asynchronous execution, and profiling with Nsight tools. By the end, attendees can transform CPU-bound Python code into production-grade GPU solutions, bridge prototyping to deployment, and apply best practices for performance and reproducibility in modern accelerated computing.",HPC / Scientific Computing,CUDA
DLIW82273,"How to Simulate, Train, Validate, and Deploy an End-to-End Robotics Workflow with NVIDIA Isaac [DLIW82273]",Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82273/,"Maycon da Silva Carvalho (Sr. Solutions Architect, NVIDIA); Kartik Sachdev (Solutions Architect, NVIDIA)","In this full-day workshop, we'll guide you through an end-to-end robotic workflow—from simulation-based training to real-world robot deployment. You'll simulate the robot in NVIDIA Isaac Sim™, train the policies in Isaac Lab, validate the trained skills through software-in-the-loop testing, and deploy them to physical robots. Through practical exercises, you'll gain end-to-end experience in the techniques that bridge the sim-to-real gap: synthetic data generation, policy training and refinement, hardware testing on edge devices, and real-robot deployment. This workshop demonstrates how simulation accelerates robot learning and reduces the time and cost of bringing AI-powered automation to production environments. In this full-day workshop, we'll guide you through an end-to-end robotic workflow—from simulation-based training to real-world robot deployment. You'll simulate the robot in NVIDIA Isaac Sim™, train the policies in Isaac Lab, validate the trained skills through software-in-the-loop testing, and deploy them to physical robots. Through practical exercises, you'll gain end-to-end experience in the techniques that bridge the sim-to-real gap: synthetic data generation, policy training and refinement, hardware testing on edge devices, and real-robot deployment. This workshop demonstrates how simulation accelerates robot learning and reduces the time and cost of bringing AI-powered automation to production environments.",Retail / Consumer Packaged Goods,Isaac
DLIW82272,OpenUSD Crash Course: Build 3D Data Pipelines for Physical AI [DLIW82272],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82272/,"Daniel Roizman (CEO, UME.Studio)","Discover how OpenUSD principles and Python scripting can build scalable 3D data pipelines for manufacturing, robotics, and physical AI applications. Throughout this full-day workshop, you'll learn composition arc techniques, asset hierarchy design, and performance optimization strategies essential for production pipelines. Develop practical skills in automating 3D asset workflows, managing complex scene data, and preparing simulation environments for physical AI training. This workshop directly prepares you for the NVIDIA-Certified Professional: OpenUSD Development exam. Discover how OpenUSD principles and Python scripting can build scalable 3D data pipelines for manufacturing, robotics, and physical AI applications. Throughout this full-day workshop, you'll learn composition arc techniques, asset hierarchy design, and performance optimization strategies essential for production pipelines. Develop practical skills in automating 3D asset workflows, managing complex scene data, and preparing simulation environments for physical AI training. This workshop directly prepares you for the NVIDIA-Certified Professional: OpenUSD Development exam.",All Industries,Omniverse
QA81637,PMPP Edition 5 Unveiled: Ask Dr. Wen Mei and the CUDA Team Your Questions [QA81637],Q&A with NVIDIA,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-qa81637/,"Anshuman Bhat (Group Product Manager - CUDA, Group Product Manager - CUDA); Wen-Mei Hwu (Sr. Distinguished Research Scientist, Senior Distinguished Research Scientist and Senior Research Director at NVIDIA)","Join Dr. Wen-Mei Hwu and NVIDIA experts for a live Q&A exploring key updates in the CUDA ecosystem since the last edition of his book Programming Massively Parallel Processors (PMPP). This session offers a rare opportunity to engage directly with Wen-Mei and his team of CUDA engineers, who will answer technical questions, share new features introduced in PMPP Edition 5, and discuss emerging topics under consideration for the sixth edition.",Academia / Higher Education,"DGX Platform, CUDA, NSight Comute, NSight Systems, DGX Spark"
