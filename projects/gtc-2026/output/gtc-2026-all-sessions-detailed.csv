session_code,title,session_type,url,speakers,abstract,topics,nvidia_technologies
CWES81440,Leverage Acceleration for AI and HPC in Algorithmic Trading [CWES81440],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81440/,"Yuliana Zamora (Sr. Developer Relations Manager, NVIDIA); Pooja Aniker (Solutions Architect, NVIDIA); Mark Bennett (Sr. Solutions Architect, NVIDIA); Derek Beattie (Solutions Architect, NVIDIA); Siddharth Samsi (Sr. Solutions Architect, NVIDIA); Manasa Murthy (Digital Marketing Organization Manager, NVIDIA); Peihan Huo (Solution Architect, NVIDIA); Bogdan Vioreanu (Sr. Solutions Architect, NVIDIA); Roman Yokunda Enzmann (Solutions Architect, NVIDIA); Lavinia Ghita (Solutions Architect, NVIDIA); Martin Marciniszyn Mehringer (Sr. AI Developer Technology Manager, NVIDIA); Yongming Shi (Solution Architect Manager, NVIDIA); Dhruv Desai (Sr. Solutions Architect, NVIDIA)","Join this interactive session with NVIDIA experts to discover how the convergence of artificial intelligence and high performance computing (HPC) is reshaping algorithmic trading. As trading strategies grow in complexity, the need for high-throughput processing and advanced modeling capabilities becomes critical. Speak with our experts about the latest methods to leverage acceleration for data-intensive tasks, from training sophisticated AI models to running massive-scale simulations.",Financial Services,"CUDA, Grace, Mission Control, NCCL, NVLink, RAPIDS, TensorRT, Triton, cuBLAS, cuDF, cuML"
CWES81447,Unleashing AI at Scale: Meet the NVIDIA Networking Experts [CWES81447],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81447/,"Taylor Allison (Sr. Networking Product Marketing Manager, NVIDIA); Scot Schultz (Sr. Director, HPC and Technical Computing, NVIDIA); David Iles (Sr. Director, Ethernet Switching, NVIDIA); Moshe Lavi (Senior Director of Product Management, NVIDIA); Avi Alkobi (Sr. Director of Business Development and Technology Alliances, NVIDIA)","Join us for an interactive session and engage directly with NVIDIA's networking experts. We'll cover our full-stack networking platform, including NVLINK, Spectrum-X Ethernet, InfiniBand, and BlueField DPUs, and networking software like Cumulus. Learn how these technologies accelerate every phase of AI, from training to inference, and how tools like NVIDIA AIR can help you validate your infrastructure. This session is designed to answer your specific questions and provide the strategic insights you need to unleash your AI at scale.",All Industries,"Bluefield, NCCL, NVLink"
CWES81458,Everything You Wanted to Know About AI Factories! [CWES81458],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81458/,"Yang Yang (Solution Architect, NVIDIA); Scott Ellis (Sr. Director, Solutions Architecture and Engineering, NVIDIA); Jeff Weiss (Sr. Director, NVIDIA); Robert Magno (Manager Solution Architects, NVIDIA); John Fragalla (Principal Architect, NVIDIA); Hans Mortensen (Grace Product Specialist – NVIDIA Solutions Architecture, NVIDIA); Paul Bryan (DGX Solution Architect, NVIDIA)","Learn what goes into an AI Factory. Hardware, software, networking, storage ... nothing is off limits. Want to understand more about how RTX PRO can be used with Spectrum-X networking and Run:ai? Have questions about how NVIDIA Mission Control helps GB300 systems run jobs at peak efficiency? This is the place to be.",All Industries,"Bluefield, DGX, Grace, Mission Control, NVLink"
CWES81461,Distributed Inference at Scale Using Dynamo [CWES81461],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81461/,"Akshatha Kamath (Product Manager, NVIDIA); Neelay Shah (Principal Software Architect, NVIDIA); Vikram Sharma Mailthody (Sr. Research Scientist, NVIDIA); Harry Kim (Principal Product Manager, NVIDIA); Kyle Kranen (Team Lead/Manager - Deep Learning Algorithms, NVIDIA); Anish Maddipoti (Product Manager, NVIDIA); Amr Elmeleegy (Product Marketing Manager, NVIDIA)","NVIDIA Dynamo is a distributed inference serving framework built to run LLMs efficiently, reliably, and at massive scale. It helps AI providers reduce cost-per-token, meet strict service level objectives, and scale deployments using Kubernetes across large GPU clusters. Learn how Dynamo delivers high-performance distributed inference across frameworks such as SGLang, TensorRT-LLM, and vLLM. We’ll explore key capabilities — including disaggregated serving, KV-cache-aware routing, topology-aware scheduling, and intelligent memory and cache management — that make Dynamo a powerful foundation for production workloads. Whether you’re evaluating Dynamo, experimenting it, or deepening your understanding of its capabilities and real-world impact, join us to ask questions, see how the system works under the hood, and get practical guidance from the experts who build and deploy it.",All Industries,"TensorRT, vLLM"
CWES81471,Accelerate Your AI Infrastructure at Scale [CWES81471],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81471/,"Nicola Bianchi (Sr. Solution Architect, NVIDIA); Kristof De Brouwer (Sr. Solution Architect, NVIDIA); Pramod Kumbhar (Sr. Solutions Architect - HPC & AI, NVIDIA)","This session will be an extension to the session led by NVIDIA senior solutions architects Kristof De Brouwer and Nicola Bianchi titled ""Mastering AI Infrastructure At Scale — a DevOps Playbook."" You can ask questions about your scaled AI deployments of our technical experts, explore deployment strategies in depth, and engage in discussions on optimizing NVIDIA AI infrastructure for your specific environments.",HPC / Scientific Computing,"Bluefield, DGX, GB200, Grace, NVLink"
CWES81472,Build Industrial Digital Twins for the Era of Physical AI [CWES81472],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81472/,"Mike Geyer (Omniverse Manufacturing Product Management Lead, NVIDIA); James McKenna (Product Manager, NVIDIA Omniverse, NVIDIA); Adam Brasic (Sr. Solutions Architect, NVIDIA); Teresa Conceicao (Solutions Architect Manager - Omniverse, NVIDIA); Roy C Anthony (Sr. Manager, Solutions Architecture, NVIDIA); Florian Gantert (Global Business Development and Strategy for Omniverse, NVIDIA)","Want to learn how to get started building industrial facility digital twins with NVIDIA Omniverse libraries and OpenUSD? Join this interactive support session with NVIDIA technical product managers and solutions architects to get direct help and surface your questions, issues, and ideas specific to your use case.",Manufacturing,Omniverse
CWES81473,Ask Us Anything About NVIDIA Mission Control [CWES81473],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81473/,"Robert Stober (Solutions Architect, NVIDIA); Salah Chaou (Solutions Architect, NVIDIA); Jeff Weiss (Sr. Director, NVIDIA); Chad Chapman (Sr. Solutions Architect, NVIDIA); Charu Ramachandran (Sr. Solutions Architect, NVIDIA); Scott Ellis (Sr. Director, Solutions Architecture and Engineering, NVIDIA)",What is Mission Control? What goes into operating a high performance AI factory? How does Mission Control integrate with other tools and processes? This session is the place to get those types of questions answered!,All Industries,"CUDA, DGX, Grace, Mission Control, NCCL, NIM"
CWES81474,"Automating AI Factory Infrastructure (Ansible, GitOps, etc.) [CWES81474]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81474/,"Vallard Benincosa (Solutions Architect, NVIDIA); Scott Ellis (Sr. Director, Solutions Architecture and Engineering, NVIDIA); Martin Piercy (Sr. Solutions Architect, NVIDIA); Jeff Weiss (Sr. Director, NVIDIA); Chad Chapman (Sr. Solutions Architect, NVIDIA); David Dean (Sr. Solutions Architect, NVIDIA)","AI factories are hard, but automation can make life easier. Join us to get your questions answered about how to use industry standard and product-specific tools to automate the deployment and operation of your AI factory.",All Industries,Mission Control
CWES81481,Next-Gen Data Systems: GPU Acceleration for SQL and Vector Databases [CWES81481],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81481/,"Tanmay Gujar (Developer Technology Engineer, NVIDIA); Corey Nolet (Principal Engineer, ML, Data Mining, and Vector Search, NVIDIA); Todd Mostak (Sr. Director of Engineering, NVIDIA); Felipe Aramburu (Distinguished Solutions Architect, NVIDIA); Manas Singh (TPM, Vector Search, NVIDIA)","AI applications increasingly rely on fast, scalable access to both structured data and high-dimensional vector embeddings. Traditional CPU-based systems struggle to meet these demands at scale. We'll explore how to accelerate SQL databases and vector search engines with GPUs, enabling rapid index builds, low-latency queries, and seamless integration of analytical and AI workloads. Learn how GPU-accelerated data systems unlock new performance levels for modern AI pipelines.",All Industries,"CUDA, cuDF, nvCOMP"
CWES81506,Accelerated Computing in Financial Services for Banking [CWES81506],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81506/,"Benika Hall (Sr. Solutions Architect, NVIDIA); James Sutton (Sr. Solutions Architect, Gen AI, NVIDIA); Benjamin Wu (Sr. Solutions Architect, NVIDIA); Ellie Arbab (Solutions Architect, NVIDIA); Jessica Clark (Sr. Solutions Architect, NVIDIA); Bogdan Vioreanu (Sr. Solutions Architect, NVIDIA); Roman Yokunda Enzmann (Solutions Architect, NVIDIA); David Williams (Solutions Architect, NVIDIA); Alex Stephens (Sr. Solutions Architect, Financial Services, NVIDIA); Yongming Shi (Solution Architect Manager, NVIDIA); Marcus Manos (Solutions Architect, NVIDIA); Anass Majji (Solution Architect, NVIDIA); Emanuel Scoullos (Sr. Solutions Architect, NVIDIA); Flora Huang (Sr. Solutions Architect, NVIDIA)","Join this interactive session with NVIDIA experts to learn best practices and latest techniques for deploying AI applications and accelerated computing to banking use cases. We'll answer your questions, share implementation insights, and discuss architectural patterns for deploying AI reliably across on-premises, cloud, and hybrid environments. Gain practical guidance on navigating regulatory, data, and governance challenges, and learn how to design robust, efficient, and scalable solutions that unlock new products, services, and operational efficiencies for banks and financial institutions.",Financial Services,"CUDA, Grace, RAPIDS, Triton, cuDF"
CWES81524,"Connect With Cybersecurity, Agentic AI, and Threat Hunter Experts [CWES81524]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81524/,"Neha Hudait (Sr. Security Product Manager, NVIDIA); Ofir Arkin (Sr. Distinguished Engineer, NVIDIA); Hsin Chen (Sr. Data Scientist, Cybersecurity AI, NVIDIA); Marcela Denniston (SDO Executive, NVIDIA); Leon Derczynski (Principal Research Scientist, NVIDIA); Rich Harang (Principal AI Security Engineer, NVIDIA); Becca Lynch (Offensive Security Researcher, NVIDIA); Daniel Rohrer (VP of Software Product Security, NVIDIA); Laura Seletos (Principal Cloud Security Architect, NVIDIA); Julien Soriano (Security Executive, NVIDIA)",Join NVIDIA cybersecurity and agentic AI experts to learn how NVIDIA technology and agentic systems can be applied to strengthen your cybersecurity posture.,All Industries,NIM
CWES81535,CUDA Developer Best Practices [CWES81535],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81535/,"Jake Hemstad (Software Engineering Manager, NVIDIA); Georgii Evtushenko (Sr. Software Engineer, NVIDIA); Trent Nelson (Principal Software Engineer, NVIDIA); Leo Fang (Python CUDA Tech Lead, NVIDIA); Jaydeep Marathe (Principal Software Engineer, NVIDIA); Jonathan Bentz (CUDA Technical Marketing Engineer, NVIDIA); Vyas Ramasubramani (NVIDIA); Jonathan Dekhtiar (NVIDIA); Rafael Campana (Sr. Engineering Director of CUDA Developer Tools, NVIDIA); Ashwin Srinath (Senior Software Engineer, NVIDIA); Bryce Lelbach (Principal Architect, NVIDIA)","Join this live Q&A session with some of NVIDIA’s own CUDA developers to demystify the process of building real-world CUDA applications. From utilizing CUDA accelerated libraries, profilers, and debugging tools to setting up CI pipelines, packaging, and builds—this session covers the entire development life cycle. If you’re looking for practical guidance on integrating GPU acceleration into your software, this is the perfect opportunity to get answers and advice from engineers who develop and maintain CUDA software every day.",HPC / Scientific Computing,CUDA
CWES81538,"Multi-Modal RAG: Build Agentic AI Systems With Video, Audio, and Text [CWES81538]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81538/,"Maryam Najafian (Principal SWE, Agentic AI Tech Lead, NVIDIA); Rachel Allen (Engineering Manager, Cybersecurity AI, NVIDIA); Nave Algarici (Generative AI Product Manager, NVIDIA); Annie Surla (Developer Advocate Engineer, NVIDIA); Edward Li (Technical Marketing Engineer, NVIDIA); Bo Liu (Sr. Research Manager, NVIDIA); Sean Sodha (Sr. Software Product Manager, NVIDIA); Daniel Fatade (Sr. Solutions Architect, Gen AI, NVIDIA); Michael Demoret (Engineering Manager, Cybersecurity AI, NVIDIA); Randy Gelhausen (Sr. Engineering Manager, NVIDIA); Tanay Varshney (Developer Advocate Engineer for Deep Learning SW, NVIDIA); Ruchika Kharwar (Product Manager, NVIDIA)","Enterprise developers are moving beyond text-based retrieval-augmented generation (RAG) to harness multi-modal data—video, audio, and text. This Connect with the Experts session explores best practices for designing and optimizing multi-modal agentic RAG systems. Learn to combine speech recognition, visual understanding, and LLMs to enable context-rich, dynamic enterprise AI applications. The discussion covers real-world implementation including vector indexing of multi-modal embeddings, latency optimization for large-scale deployments, and fine-tuning for domain-specific retrieval. Gain insights into integrating NVIDIA Nemotron models and cuVS accelerated vector search to create unified RAG pipelines that reason across diverse data types. Engage with NVIDIA experts and fellow developers to exchange design patterns and best practices for powering next-generation enterprise intelligence.",All Industries,"NIM, NeMo"
CWES81540,"Scale MoE Training With Megatron Core: Features, Optimizations, and Best Practices [CWES81540]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81540/,"Jack Chang (DevTech Engineer, NVIDIA); Yigong Qin (Developer Technology Engineer, NVIDIA); Hongxiao Bai (Sr. DevTech Engineer, NVIDIA); Hongbin Liu (Developer Technology, NVIDIA); Zijie Yan (Sr. DevTech Engineer, NVIDIA); Yuzhong Wang (DevTech Engineer, NVIDIA); Dennis Liu (Sr. DevTech Engineer, NVIDIA); Kunlun Li (Software Engineer, NVIDIA); Xin Yao (Sr. DevTech Engineer, NVIDIA); Zhongbo Zhu (DevTech Engineer, AI, NVIDIA); Yan Bai (DevTech Engineer, NVIDIA)","Engage directly with the Megatron Core MoE development team to explore mixture of experts (MoE) training at scale. This interactive session offers a unique opportunity to discuss the latest advancements in MoE training framework, roadmap, and best practices with the engineers who build it. We'll cover how to train state-of-the-art models like DeepSeek-V3 and Qwen, and share strategies for achieving optimal performance on the latest Grace Blackwell hardware. We'll dive into key features such as leveraging FP8 for accelerated training, implementing efficient expert parallelism with DeepEP/HybridEP, maximizing communication efficiency with 1F1B EP Overlap, and minimizing memory footprint. Whether you're building the next foundation model or optimizing an existing training pipeline, this session delivers actionable insights to maximize throughput and harness the full power of Megatron Core.",Consumer Internet,"Grace, Megatron, NeMo"
CWES81549,"What's in Your Developer Toolbox? CUDA, AI, and Graphics Profiling, Optimization, and Debugging Tools [CWES81549]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81549/,"Rafael Campana (Sr. Engineering Director of CUDA Developer Tools, NVIDIA); Holly Wilper (Manager, System Software Tools, NVIDIA); Magnus Strengert (Software Engineering Manager, NVIDIA); Jonathan Litt (Technical Product Manager, NVIDIA); Jackson Marusarz (Technical Product Manager, NVIDIA); Gaoyan Xie (Sr. Manager of Software Engineering, NVIDIA)","Several experts from the tools development and management teams will be available to talk about getting started, best practices, and advanced techniques for application debugging and optimization with NVIDIA developer tools. You can ask questions about anything from high-level concepts to specific tools details and also discuss plans and suggestions for improving the tools in the future. We can provide a brief overview of the NVIDIA Nsight family of design, profiling, and debugging tools, including an introduction to the latest features and copilot integrations for developing CUDA compute, AI, and graphics applications on the newest platforms.",All Industries,CUDA
CWES81554,Real-World Federated Learning With NVIDIA FLARE [CWES81554],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81554/,"Holger Roth (Principal Federated Learning Scientist, NVIDIA); Yuan-Ting Hsieh (Senior Software Engineer, NVIDIA); Chester Chen (Sr. Product and Engineering Manager, NVIDIA); Isaac Yang (Software Engineer, NVIDIA); Jiahui Guan (Senior Solution Architect, NVIDIA); Zhijin Li (Sr. Solutions Architect, NVIDIA)","Federated learning is transforming data-centric industries such as healthcare, life sciences, finance, and transportation — domains where privacy, compliance, and data governance are essential. NVIDIA FLARE enables collaborative model training across institutions without moving sensitive data, unlocking insights from distributed datasets that would otherwise remain siloed. Today, organizations worldwide are deploying federated learning in production, using NVIDIA FLARE to build more accurate diagnostic models, accelerate drug discovery, improve financial risk modeling, and optimize transportation systems. With Confidential Computing on NVIDIA GPUs, FLARE supports secure, decentralized pipelines that maintain data protection and execution integrity across every site, even when running complex multi-party workflows. Meet the experts behind NVIDIA FLARE and join the discussion.",Healthcare & Life Sciences,"CUDA, FLARE, Isaac"
CWES81555,"Leverage AI and Accelerated Computing for Digital Biology: Parabricks, BioNeMo and Clara Open Models [CWES81555]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81555/,"Kyle Gion (Product Manager, Digital Biology Research, NVIDIA); Neha Tadimeti (Product Manager, NVIDIA); Severin Dicks (NVIDIA); T.J. Chen (Product Lead, Genomics, NVIDIA); Daniel Puleri (HPC Engineer, NVIDIA); Steven Kothen-Hill (Sr. Deep Learning Bioinformatics Scientist, NVIDIA); Peter St. John (Machine Learning Engineer, NVIDIA); Pankaj Vats (Sr. Bioinformatics/Genomics Scientist, NVIDIA); Jonathan Mitchell (Sr. Machine Learning Engineer, NVIDIA); Mahan Salehi (Product Manager, NVIDIA); Xin Yu (Sr. Solution Architect, NVIDIA); Kushal Shah (NVIDIA); Darren Hsu (Solutions Architect, NVIDIA); Isabel Wilkinson (NVIDIA)","Join NVIDIA experts to explore the field of digital biology. Discuss the latest advancements in accelerated computing and foundation models for drug discovery and genomics — from bioinformatics tooling to protein structure prediction, molecular dynamics to molecular generation, and much more. Learn how NVIDIA BioNeMo, Parabricks, and RAPIDS-singlecell, together with NVIDIA NIM, empower developers, researchers, and enterprises to quickly create generative AI solutions across chemistry, biology, and genomics. Engage directly with our product managers, developer relations, and solution architects to address your challenges and answer your questions.",Healthcare & Life Sciences,"BioNeMo, CUDA, Clara, DALI, DGX, NIM, Parabricks, RAPIDS, TensorRT, Triton, cuBLAS, cuGraph, cuML"
CWES81568,Build Smarter Robots With Simulation-First Approach Using NVIDIA Isaac Sim and Isaac Lab [CWES81568],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81568/,"Teresa Conceicao (Solutions Architect Manager - Omniverse, NVIDIA); Edith Llontop (Solutions Architect, NVIDIA); Akul Santhosh (Solution Architect, Robotics, NVIDIA); Aravindh Shanmuganathan (NVIDIA); Kartik Sachdev (Solutions Architect, NVIDIA); Kelly Guo (Engineering Manager, NVIDIA); Gavriel State (Sr. Director - Simulation and AI, NVIDIA)","Next-generation robots need the ability to sense, plan, and act with full autonomy. A simulation-first approach is key to building robots that are adaptable and efficient — supporting rapid development of robust policies and smooth transfer to new tasks across robot embodiments. Connect with NVIDIA experts to learn how NVIDIA Isaac Sim and Isaac Lab can accelerate your robotics pipeline. Explore how to generate synthetic data, train advanced robot policies, and run software-in-the-loop testing to validate your entire stack and close the gap between simulation and real-world deployment.",All Industries,"Isaac, Omniverse"
CWES81583,AI for Payments [CWES81583],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81583/,"Benjamin Wu (Sr. Solutions Architect, NVIDIA); Jessica Clark (Sr. Solutions Architect, NVIDIA); Roman Yokunda Enzmann (Solutions Architect, NVIDIA); David Williams (Solutions Architect, NVIDIA); Alex Stephens (Sr. Solutions Architect, Financial Services, NVIDIA); Marcus Manos (Solutions Architect, NVIDIA); Anass Majji (Solution Architect, NVIDIA); Flora Huang (Sr. Solutions Architect, NVIDIA)","Learn from the NVIDIA financial services Solution Architecture team how artificial intelligence is being applied in the payments industry. We'll discuss techniques like tabular transformers, graph neural networks, and NVIDIA NIMs for large language models, and how they apply to critical payments workflows like fraud detection, anti-money laundering, and customer experience.",Financial Services,"DGX, Morpheus, NCCL, NIM, RAPIDS, TensorRT, Triton, cuDF, cuGraph, cuML"
CWES81586,Connect With the Experts on the Technology Behind DGX Cloud [CWES81586],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81586/,"Andrew Liu (Enterprise Products) (Technical Marketing Engineering Manager, NVIDIA Corporation); Christian Shrauder (Director, Cloud Integration Architecture, NVIDIA); Ed Balduf (Cloud Integration Architect, NVIDIA); Peter Cross (Sr. Technical Marketing Engineer, NVIDIA); Pete MacKinnon (Senior Architect, NVIDIA); Yuze Ma (Senior Product Manager, NVIDIA); Sowmyan Soman (Principal Cloud Integration Architect, NVIDIA); Andrew Thappa (Product Manager, Inference, NVIDIA)","Join the DGX Cloud team to ask questions and learn about the technical details, design philosophies, common issues and solutions, and challenges we’re trying to solve, across our portfolio of technologies from GPU Health to distributed inference at scale, and more.",All Industries,"CUDA, DGX, NIM, NeMo, TensorRT, Triton"
CWES81591,Tile Programming for GPUs [CWES81591],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81591/,"Bryce Lelbach (Principal Architect, NVIDIA); Stephen Jones (CUDA Architect, NVIDIA); Jared Roesch (NVIDIA); Jaydeep Marathe (Principal Software Engineer, NVIDIA); Andy Terrel (CUDA Python Product Lead, NVIDIA); Rob Armstrong (CUDA Technical PM Lead, NVIDIA)","Bring your questions about performance portability, integration with existing frameworks, and migrating from traditional SIMT kernels for an in-depth discussion of when and how to use each model effectively. Connect with CUDA experts who can help you navigate the new generation of tile-based GPU programming models, including OpenAI’s Triton, NVIDIA’s CuTe DSL in CUTLASS, and the recently announced cuTile tile programming model for CUDA. Come explore how these array- and tile-centric abstractions automate memory movement, pipelining, and Tensor Core utilization while still letting you write high-performance kernels in Python or C++ for AI, scientific computing, and HPC workloads.",All Industries,"CUDA, Triton"
CWES81600,3D Gaussian Splatting for Physical AI Simulation [CWES81600],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81600/,"Harel Omer (Sr. Product Manager, Robotics, NVIDIA); Zoe LaLena (Solutions Architect, NVIDIA); Brent Bartlett (Sr. Solutions Architect, NVIDIA); Matthew Cragun (Director of Product, Autonomous Vehicles, NVIDIA); Itai Zadok (Sr. Product Manager, NVIDIA); Riccardo de Lutio (Research Scientist, NVIDIA); Mohamed Hosny (System SW Engineering Manager, NVIDIA)","Advances in 3D Gaussian-based reconstruction are transforming simulation for autonomous vehicles and robotics. This interactive session offers an opportunity to connect directly with experts on cutting-edge techniques for indoor and outdoor physical AI simulation. Learn how Gaussian splatting enables real-time rendering of complex, photorealistic environments with greater computational efficiency than traditional 3D reconstruction methods. Whether you’re a researcher, developer, or industry professional, this session provides the technical grounding and networking opportunities needed to apply 3D Gaussian splatting in simulation pipelines that accelerate autonomy development.",Automotive / Transportation,"Isaac, Omniverse"
CWES81615,Inter-GPU Communication Techniques and Libraries for HPC and AI [CWES81615],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81615/,"Pak Markthub (Sr. Software Engineer, NVIDIA); Jiri Kraus (Principal Developer Technology, NVIDIA); Arnav Goel (Sr. Software Engineer, NVIDIA); Jim Dinan (Distinguished Engineer, NVIDIA); Sylvain Jeaugey (Distinguished Engineer, NVIDIA); Akshay Venkatesh (Sr. Software Engineer, NVIDIA); Oded Green (Sr. Developer Technology Engineer, NVIDIA)","Discuss with experts everything related to inter-GPU communication through NVLink, Infiniband, or other networks. We'll cover all communication libraries: NCCL, MPI, UCX/UCC and NVSHMEM. This is the perfect place to discuss performance benefits of GPU Direct, NVLink, Infiniband, and SHARP to accelerate your deep learning training workload or your HPC application.",All Industries,"CUDA, NCCL, NVLink"
CWES81626,From Sandbox to Scale: Build Production-Ready AI Agents for Your Business [CWES81626],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81626/,"Meghana Puvvadi (Director of Engineering, AI/ML Enterprise, NVIDIA); Michael Demoret (Engineering Manager, Cybersecurity AI, NVIDIA); Rachel Allen (Engineering Manager, Cybersecurity AI, NVIDIA); JB Blair (Solutions Architect Manager, NVIDIA); Dhruv Nandakumar (Cybersecurity AI Solutions Architect, NVIDIA); Rich Harang (Principal AI Security Engineer, NVIDIA); Hsin Chen (Sr. Data Scientist, Cybersecurity AI, NVIDIA); Nic Borensztein (Principal Solutions Architect, NVIDIA); Matt Penn (Solutions Architect, NVIDIA); Sean Lopp (Sr. Engineer, NVIDIA); Colt McAnlis (Principal Architect, NVIDIA); Ryan Angilly (Principal Engineer, NVIDIA)","Join our experts for a candid, face-to-face discussion on the critical steps needed to take your AI agents from proof-of-concept to production. We'll go beyond the basics, diving into real-world challenges like building for scale, ensuring robust security, and maintaining performance in enterprise environments. This is your chance to get practical advice, ask your toughest questions, and learn what it takes to build agents that truly deliver value for the business.",All Industries,"NIM, NeMo"
CWES81635,"Next-Generation Discovery: Agentic AI for Science, AI-Driven Simulation, and GPU-Accelerated Chemistry [CWES81635]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81635/,"Justin Smith (Sr. Developer Relations Manager, NVIDIA); Stefan Maintz (DevTech Manager, NVIDIA); Yutong Zhao (Product Manager, NVIDIA); Alan Gray (Principal Developer Technology Engineer, NVIDIA); Evan Weinberg (Sr. Compute Developer Technology Engineer, NVIDIA); Piero Altoe (Developer Relations Manager, NVIDIA); Robert Parrish (Sr. Engineering Manager, NVIDIA); Logan Ward (Application Engineer, NVIDIA)","Accelerate your scientific discovery pipeline by connecting directly with experts spanning autonomous AI agents for science, AI for molecular and materials simulation, and high-performance traditional atomistic simulation. You will explore how to leverage the latest GPU-optimized tools — including NVIDIA ALCHEMI Toolkit, cuEquivariance, VASP, and GROMACS — to maximize accuracy and computational throughput for your specific research challenges.",HPC / Scientific Computing,CUDA
CWES81646,"MedTech: Physical AI for Imaging, Intervention, and Robotics [CWES81646]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81646/,"Zhijin Li (Sr. Solutions Architect, NVIDIA); Jay Carlson (Holoscan Product Manager, NVIDIA); Daguang Xu (Sr. Research Manager, NVIDIA); Oliver Kutter (Solution Architect Manager, NVIDIA); Mikael Brudfors (Sr. Solution Architect, NVIDIA); Andres Diaz-Pinto (Sr. AI Scientist, NVIDIA); Mahdi Azizian (Sr. Director, Holoscan Platform and Medical Technologies, NVIDIA); Mostafa Toloui (Holoscan Product Management Lead, NVIDIA); Anas Abidin (Manager of Healthcare Solution Architecture and Engineering, NVIDIA); Rahul Choudhury (Sr. Software Engineering Manager, NVIDIA); Bob Keating (NVIDIA); Bogdan Mitrea (Senior Solution Architect, NVIDIA); Stephen Aylward (Global Alliance Manager for Developer Relations, MedTech, NVIDIA); Nadim Daher (Healthcare Ecosystem Development, NVIDIA)","Physical AI is redefining how next-generation medical devices perceive, decide, and act in the real world. From advanced imaging systems and autonomous interventional workflows to intelligent surgical robots, developers now require a unified stack that bridges data, simulation, and real-time runtime and control. NVIDIA’s platforms — such as Holoscan, Isaac for Healthcare, Omniverse, Cosmos and Metropolis — deliver an end-to-end foundation for building and scaling physical AI: model training with domain-specific foundation models, high-fidelity digital twins for procedure-aware simulation, and deterministic low-latency deployment at the edge. Join NVIDIA experts to learn how to leverage our full-stack technologies to accelerate your development — from imaging and interventional systems to next-generation robotics — and bring safer, smarter MedTech to market faster.",Healthcare & Life Sciences,"Holoscan, Isaac, Omniverse"
CWES81655,Build End-to-End Medical AI Workflows With NVIDIA Clara Open Models [CWES81655],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81655/,"Sean Huver (Sr. Manager and Principal ML Engineer, NVIDIA); Maximilian Ofir (Technical Marketing Engineer, NVIDIA GmbH); Daguang Xu (Sr. Research Manager, NVIDIA); Pengfei Guo (Applied Research Scientist, NVIDIA); Andriy Myronenko (Sr. Research Scientist, NVIDIA); Andres Diaz-Pinto (Sr. AI Scientist, NVIDIA); Ahmed Harouni (Technical Marketing Engineer, NVIDIA); Nigel Nelson (Machine Learning Engineer, NVIDIA); Michael Zephyr (Technical Product Manager, NVIDIA); Walter Simson (Machine Learning Engineer, NVIDIA)","Connect with experts on NVIDIA Clara Open Models enabling end-to-end medical AI workflows — from real-time segmentation and synthetic data generation to explainable clinical reasoning and healthcare robotics. Explore deployment strategies across imaging, surgical simulation, and autonomous systems.",Healthcare & Life Sciences,"CUDA, Clara, DGX, Holoscan, Isaac, TensorRT"
CWES81670,Maximize Memory Bandwidth on Modern GPUs [CWES81670],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81670/,"Samuel Mish (DevTech Engineer, NVIDIA); Francis Tseng (Principal Accelerated Computing Architect, NVIDIA); Benedikt Dorschner (Sr. DevTech Engineer, NVIDIA); Kate Clark (Distinguished DevTech Engineer, NVIDIA); Matthew Martineau (Sr. Developer Technology Engineer, NVIDIA)","Struggling to fully utilize GPU memory bandwidth on modern architectures? In this interactive session, NVIDIA engineers will work with you in real time to diagnose and optimize memory-bound kernels. Bring your own code, performance traces, or ideas and get hands-on guidance on loop unrolling, vectorization, prefetching, and asynchronous Tensor Memory Accelerator (TMA) pipelines. Learn to recognize common pitfalls, explore TMA patterns, and apply producer–consumer pipelines to maximize throughput. Walk away with practical, actionable solutions tailored to your workloads.",HPC / Scientific Computing,CUDA
CWES81679,"Turbocharge Your LLM Inference: Expert Strategies for Lightning-Fast, Scalable AI Deployment [CWES81679]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81679/,"Haohang Huang (Sr. AI DevTech Engineer, NVIDIA); Nikita Korobov (AI Developer Technology engineer, NVIDIA); Martin Marciniszyn Mehringer (Sr. AI Developer Technology Manager, NVIDIA); Robin Kobus (Developer Technology Engineer, NVIDIA); Julien Debache (AI Developer Technology Engineer, NVIDIA)","Explore cutting-edge methods for accelerating large language model (LLM) inference with NVIDIA technologies. This interactive session dives into deploying and scaling models using TensorRT-LLM with PyTorch integration, alongside modern speculation and quantization techniques that boost efficiency. Learn from NVIDIA experts how to fine-tune inference pipelines, optimize GPU performance, and build scalable, high-throughput deployments across advanced systems like the GB200 NVL72.",All Industries,"CUDA, GB200, TensorRT, vLLM"
CWES81692,Unlock Peak Performance and Stability: End-to-End Benchmarking of AI Infrastructure [CWES81692],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81692/,"Giovanni Mascari (Sr. Solutions Architect - HPC & AI, NVIDIA); Vasileios Karakasis (Sr. Systems Software Engineer, NVIDIA); Sriharsha Niverty (Systems Software Engineer, NVIDIA); Michal Marcinkiewicz (Engineering Manager, Deep Learning Algorithms, NVIDIA); Mohak Chadha (Solutions Architect, NVIDIA); Pramod Kumbhar (Sr. Solutions Architect - HPC & AI, NVIDIA); Patrick Atkinson (Sr. Developer Technology Engineer, NVIDIA)","Delivering peak performance and stability in large-scale AI infrastructure is increasingly challenging as workloads and hardware continuously evolve. This requires rapid, end-to-end benchmarking and performance debugging across every layer of the hardware and software stack. Join this interactive session to connect with NVIDIA experts and learn about the benchmarks, tools, and methodologies we use internally at NVIDIA — and make available to you — to measure, optimize, and operate AI infrastructure at scale.",All Industries,
CWES81740,A Deep Dive Into Omniverse Libraries for OpenUSD and Physical AI Development [CWES81740],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81740/,"Sebastian Misiurek (Sr. Product Manager, Omniverse, NVIDIA); Neelakantan Mani (Sr. Product Manager, Omniverse Physics, NVIDIA); Stephanie Rubenstein (Sr. Product Marketing Manager, NVIDIA); Richard Yarlett (Technical Marketing Engineer, Omniverse, NVIDIA); Brian Harrison (Sr. Director of Product Management Omniverse, NVIDIA)","Join this interactive Q&A session to get direct, actionable advice from NVIDIA's core engineering teams on overcoming the critical developer friction points in building large-scale, physically accurate digital twins for robotics, autonomous vehicles, and manufacturing. This is your unique opportunity to discuss your specific use cases and technical challenges directly with the experts who develop and maintain the core Omniverse libraries and technologies for world simulation, including OpenUSD, PhysX, RTX, and more.",All Industries,Omniverse
CWES81756,"Next-Gen Digital Health Agents for Language, Speech, and Analytics [CWES81756]",Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81756/,"Brad Genereaux (Global Lead, Healthcare Alliances, NVIDIA); Jinhan Wang (NVIDIA); Myung Jae Yoo (NVIDIA); Cedric Steenbeke (HCLS Startups Developer Relations Lead, EMEA, NVIDIA); Chelsea Sumner (Healthcare Startups Lead, Americas, NVIDIA); Arun Venkatesan (Sr. Product Manager, Deep Learning Software, NVIDIA); Reza Negahdar (Sr. Solutions Architect, NVIDIA); Abood Quraini (Technical Marketing Engineering Manager, NVIDIA); Ben Randoing (Technical Marketing Engineer, NVIDIA); Jin Li (Technical Marketing Engineer, NVIDIA); Jonny Hancox (Senior Solution Architect, NVIDIA); Ignacio Sarasua (Solutions Architect, NVIDIA); Seyed-Ahmad Ahmadi (Senior Solutions Architect, NVIDIA); Jiahui Guan (Senior Solution Architect, NVIDIA)","The future of digital health is agentic. Join NVIDIA experts to discuss how AI agents are transforming the ecosystem by bridging the gap between perception and reasoning. Discuss the implementation of advanced pipelines that utilize conversational AI and speech for patient interaction, computer vision for diagnostics, and deep analytics for decision support. Whether you are a researcher or an enterprise developer, engage with our team to understand how NVIDIA NIM, blueprints, and SDKs can help you deploy robust, multi-modal agents that drive real-world clinical, research, revenue cycle, and administrative outcomes.",Healthcare & Life Sciences,"Clara, NIM, RAPIDS, TensorRT, Triton"
CWES81759,Quantum Computing and AI [CWES81759],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81759/,"Monica Van Dieren (Sr. Technical Marketing Engineer, Quantum and HPC, NVIDIA); Jin-Sung Kim (Developer Relations Manager for Quantum Computing, NVIDIA); Mark Wolf (Technical Marketing Engineer, NVIDIA); Elica (Elitsa) Kyoseva (Director of Quantum Algorithm Engineering, NVIDIA)","Join us to discuss how AI is driving key breakthroughs in quantum computing. From discovering new quantum algorithms with generative AI and building AI-based quantum error correction decoders to enabling the low-latency integration of QPUs and AI supercomputing with NVQLink — whatever your interest in quantum computing, we'll show you how AI can accelerate your work. We’ll answer your questions about realizing these capabilities by architecting hybrid workflows with CUDA-Q, and show you how to leverage CUDA-Q Academic to prepare the next generation of experts to drive this convergence.",HPC / Scientific Computing,CUDA
CWES81771,How to Run and Optimize Your Workloads on the NVIDIA Grace and Vera CPUs [CWES81771],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81771/,"Mathias Wagner (Sr. Developer Technology Engineer, NVIDIA); Lukas Alt (Developer Technology Engineer, NVIDIA)","Join us to explore how NVIDIA's latest generation of ARM-based CPUs can boost data center performance and energy efficiency. We'll help you optimize your applications for the current NVIDIA Grace architecture while providing insights into NVIDIA Vera CPU, the next-generation processor based on a custom NVIDIA core — available in the second half 2026. Learn practical strategies to enable your code to run efficiently on these CPUs and understand how to take advantage of the next architectural improvements. We welcome participants interested in evaluating and deploying Grace today, as well as those considering adopting Vera in the future. You should have a foundational understanding of CPU programming. Bring your application-specific and general questions — we're here to help you prepare for both current and future generations of NVIDIA's data center processors.",All Industries,"Grace, Vera"
CWES81817,Best Practices in Building Your AI Factory: Connect With NVIDIA MLOps and AIOps Experts [CWES81817],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81817/,"William Benton (Principal Product Architect, NVIDIA); Nik Spirin (Director, Generative AI and LLMOps Platform, NVIDIA); Erik Bohnhorst (Sr. Product Manager, NVIDIA); Michael Balint (Director, Product Architecture, NVIDIA); Nic Borensztein (Principal Solutions Architect, NVIDIA)","As organizations shift from traditional data center to AI factories, building a full-stack AI infrastructure can be challenging. Connect with NVIDIA experts on how to quickly deploy your AI factories, and learn best practices for your ML/AI workflows.",All Industries,"NIM, NeMo"
CWES81843,The Developer’s Roadmap to Physical AI: Bridging Digital Models and Real-World Systems [CWES81843],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81843/,"Abubakr Karali (Sr. Solutions Architect, NVIDIA); Maycon da Silva Carvalho (Sr. Solutions Architect, NVIDIA); Stephanie Rubenstein (Sr. Product Marketing Manager, NVIDIA); Chiara Refaeuter (Startups Partner Manager, NVIDIA); Cobus Bothma (Sr. Product Manager, NVIDIA)","The era of generative AI has mastered digital content, but the next frontier lies in the physical world. For developers comfortable with LLMs and retrieval-augmented generation (RAG), the leap into physical AI—robotics, autonomous systems, and edge computing—can feel like starting from zero. This session will bridge that gap. We will deconstruct physical AI workflows, showing you how to translate digital reasoning into physical action. We'll explore how to move beyond text-based inputs to incorporate multi-modal sensing and spatial intelligence, turning static models into interactive, real-world agents.",All Industries,"Isaac, Jetson, Omniverse"
CWES81886,CUDA on Windows and WSL [CWES81886],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81886/,"Jalpa Patel (Sr. Systems Software Engineer, NVIDIA); Raphael Boissel (Principal Software Engineer, NVIDIA); Mike Delorme (Sr. Manager, CUDA Software Engineering, NVIDIA)","Join us for a CWE session with the CUDA Windows and WSL engineering group to ask any questions you might have about performance, best practices, and how to leverage some of our new features and new platforms. Bring your questions/requests for customized answers on any topics: WSL containers, tuning programs for MCDM/WDDM, graphics interoperability (DirectX, Vulkan, OpenGL) and AI in games—even some of the most niche memory allocation and optimizations problems, and much more.",HPC / Scientific Computing,CUDA
CWES81905,Accelerate Data Compression and Decompression on GPUs with nvCOMP [CWES81905],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81905/,"Naveen Himthani (Sr. Software Engineer, NVIDIA); Eric Schmidt (Sr. DevTech Engineer, NVIDIA); Makan Taghavi (Sr. Product Manager for Image Processing and Data Compression, NVIDIA); Balazs Nagy (Sr. CUDA Math Libraries Engineer, NVIDIA)","Join NVIDIA experts to discuss GPU-accelerated compression and decompression with nvCOMP and dedicated hardware decompress engines for data analytics, genomics, deep learning, and more. We’ll walk through best practices for offloading decompression to Blackwell’s dedicated engine, show how the latest nvCOMP APIs (including Python APIs) simplify integration into existing CPU and GPU pipelines, and talk through real-world performance tuning patterns.",All Industries,"CUDA, cuDF, nvCOMP"
CWES81912,Reinforcement Learning in the Modern AI Stack [CWES81912],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81912/,"Chris Alexiuk (Deep Learning Developer Advocate, NVIDIA); Shashank Verma (Sr. Technical Marketing Engineer, NVIDIA); Christopher Wing (Senior Product Manager, NVIDIA)","Explore new solutions for navigating the expanding landscape of reinforcement learning (RL) — know when to use RL, which flavor fits your domain, and what tooling accelerates your path to production. Get practical guidance on stacks, environments, and implementation strategies from hands-on practitioners.",All Industries,NeMo
CWES81955,NVIDIA 101: From Chips to Software — How NVIDIA's AI Platform Enables the AI Revolution [CWES81955],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81955/,"Rambo Jacoby (Principal Engineer, NVIDIA)","This session is a continuation of the ""NVIDIA 101: From Chips to Software — How NVIDIA's AI Platform Enables the AI Revolution"" session led by Rambo Jacoby. In this session, you'll get the opportunity to touch and feel NVIDIA's hardware and ask any questions you may have about NVIDIA's platform, and to ask follow up questions from Rambo's earlier session, directly from Rambo himself.",All Industries,"CUDA, Omniverse"
CWES81960,Maximize GPU Resources in Your Virtualized Environment: Best Practices for Sizing and Deployment [CWES81960],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes81960/,"Jimmy Rotella (Sr. Solutions Architect, NVIDIA); Anshul Fadnavis (Product Management, NVIDIA); Kelly Siggers (Solution Architect, NVIDIA); Phoebe Lee (Sr. Product Marketing Manager, NVIDIA); Randall Siggers (Sr. Solution Architect, NVIDIA)","Join this interactive session for direct insights and recommendations from NVIDIA specialists on fully utilizing your virtualized GPUs to deploy graphic-intensive apps, digital twin simulations, AI development, and more. Engage with experts who've navigated virtualization complexities, offering practical advice and proven methodologies. Bring your questions and leave with actionable strategies to enhance your virtualized data center operations.",All Industries,Omniverse
CWES82007,Best Practices for Accelerating LLM and VLM Inference With vLLM [CWES82007],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes82007/,"Pavani Majety (Sr. Deep Learning Engineer, Inference, NVIDIA); Benjamin Chislett (Sr. Software Engineer, NVIDIA); Xin Li (Engineering Manager, NVIDIA); Shang Wang (Manager, AI Systems Software, NVIDIA)","Meet with the experts at NVIDIA to learn how to accelerate vLLM inference performance on NVIDIA GPUs. Our experts at NVIDIA help make vLLM more performance and scalable. We cover a diversity of workloads running from DGX spark to NVIDIA GB200 NVL72. Join us for a deep dive in various optimization techniques, including speculative decoding, kernel performance, deployment recipes, reinforcement learning, and open-source software collaborations. Connect with us and share your vLLM use case, and together we'll explore how we can help improve the framework!",All Industries,"CUDA, DGX, GB200, Grace, NCCL, cuBLAS, vLLM"
CWES82212,Boost Data Science Pipelines With Accelerated Libraries [CWES82212],Connect With the Experts,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-cwes82212/,"Nick Becker (Sr. Technical Product Manager, Data Processing Product Management Lead)","Drop into these walk-up office hours to meet the experts building NVIDIA’s CUDA-X data science libraries and talk through your end-to-end pipeline needs. ​Get practical guidance on where cuDF, cuML, cuGraph, and GPU-accelerated Spark can boost productivity in your workflow. ​Discuss how to experiment and scale from DGX Spark to the largest supercomputers, and share feedback that can help shape upcoming releases.",Financial Services,"CUDA, DGX, RAPIDS, cuDF, cuGraph, cuML"
DLIT81642,Accelerate Apache Spark With GPU and AI: A Hands-On Workshop [DLIT81642],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81642/,"Rishi Chandra (Systems Software Engineer, NVIDIA); Navin Kumar (Sr. System Software Engineer, NVIDIA); Hirakendu Das (Principal Software Engineer, NVIDIA)","In this training lab, we'll introduce Aether — a set of automation and AI tools that speed up and reduce the cost of accelerated extract, transform, load and analytics workloads on the RAPIDS Accelerator for Apache Spark. Aether combines automation along with advanced AI tools to automatically test and optimize your Apache Spark workloads with GPU.",All Industries,"CUDA, cuDF, nvCOMP"
DLIT81682,Accelerate Drug Discovery With NVIDIA Libraries and Platforms [DLIT81682],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81682/,"Kristopher Kersten (Technical Marketing Engineer, NVIDIA); Neel Patel (Technical Marketing Engineer, NVIDIA)","The field of drug discovery is increasingly benefiting from AI, helping researchers build efficient predictive and generative workflows that drastically reduce time-to-clinic. NVIDIA accelerates this process with open-source solutions like BioNeMo Recipes, NIM, and Clara Open Models for Digital Biology, providing easy-to-adopt solutions for training and deploying foundation models and agentic AI systems for drug discovery. In this session, we'll demonstrate how the latest NVIDIA accelerated libraries and models streamline AI workflows, accelerate drug discovery, and enable more efficient biomolecular design and analysis.",Healthcare & Life Sciences,"CUDA, Clara, BioNeMo, NVIDIA NIM"
DLIT81700,Accelerate Robot Learning With Isaac Lab and Newton [DLIT81700],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81700/,"Akul Santhosh (Solution Architect, Robotics, NVIDIA); Eric Heiden (Sr. Research Scientist, NVIDIA); Mohammad Mohajerani (Sr. Product Manager, NVIDIA)","This hands-on lab introduces Newton, a GPU-accelerated physics engine. Then we'll integrate Newton with Isaac Lab, showing how they can work together in robot-learning workflows. You'll configure tasks to run on Newton, and train and evaluate policies in Isaac Lab with Newton providing high-fidelity, high-throughput physics. You'll leave knowing how to use Newton for more realistic robotics simulation.",All Industries,Isaac
DLIT82150,Accelerate Video Frame Extraction and Labeling [DLIT82150],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82150/,"Khanh Nguyen (Software Engineer, NVIDIA); Suseella Panguluri (Sr. Manager, NVIDIA); Radha Sri-Tharan (Data Engineer, HitL, NVIDIA)","Learn how to reduce the cost associated with frame extraction for computer vision post-processing using free and publicly-accessible American Sign Language data. Use a novel, open-source framework and contribute to the world's largest dataset.",Media & Entertainment,
DLIT81587,Accelerated Omics and Single-cell Analysis Using NVIDIA GPUs [DLIT81587],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81587/,"Gary Burnett (Technical Marketing Engineer, NVIDIA); Severin Dicks (NVIDIA); T.J. Chen (Product Lead, Genomics, NVIDIA)","The explosion of biological data generation and innovations in AI have opened new frontiers in scientific discovery and biomedicine. With the ability to process vast amounts of biological data, accelerated analysis and foundation model approaches are transforming digital biology. This workshop provides hands-on experience for how accelerated libraries and deep learning models can be leveraged to process and analyze complex biological data. Gain an understanding of the end-to-end process, from how NVIDIA libraries support data generation, pre-processing, and analysis of single-cell data, to how foundation models are being used and evaluated in the life sciences. Get an overview of relevant solutions in digital biology, such as Parabricks, RAPIDS-singlecell (developed by scverse), NVIDIA CUDA-X Data Science Libraries, and Clara Open Models.",Healthcare & Life Sciences,"Clara Parabricks, CUDA-X"
DLIT81567,Accelerating LLM Training and Inferencing With Reduced Precision Format [DLIT81567],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81567/,"Oleg Rybakov (Principal Software Engineer, NVIDIA); Leo Du (Sr. Solutions Architect, Generative AI, NVIDIA); Sergio Perez (Solutions Architect, NVIDIA)","Large-scale LLMs require enormous computational resources, making efficiency crucial for training. Learn how cutting-edge reduced-precision formats such as FP8, MXFP4 and NVFP4 can dramatically accelerate pre-training, post-training, and inference while maintaining accuracy close to full-precision baseline models. You’ll learn how NVIDIA's innovative NVFP4 format better captures dynamic range and reduces quantization error compared to MXFP4. We'll cover techniques including Random Hadamard Transforms, two-dimensional block quantization, stochastic rounding, and strategic placement of higher-precision layers to stabilize training. Gain practical skills with the software tools necessary for quantization-aware training and efficient inference deployment, helping your applications retain accuracy while benefiting from reduced precision.",All Industries,"Cloud / Data Center GPU, CUDA, TensorRT, Hopper, CUDA-X, NeMo, NSight Systems, Blackwell, NVIDIA AI Enterprise"
DLIT81776,Adding Safety and Perception to Industrial Robots [DLIT81776],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81776/,"Sammy Ochoa (Technical Marketing Engineer, NVIDIA); Edward Chan (coming soon, NVIDIA)","Learn to implement functional safety for robots using an ""outside-in"" approach. You will gain deep insight into building collaborative, AI-powered factory environments where vision systems and robotics converge to deliver operational intelligence and safety. We will connect industrial robots to factory-wide sensor infrastructure using NVIDIA Metropolis to build intelligent systems dedicated to robot safety. Through practical exercises, you will create a video analytics AI agent that extends a robot's real-time perception. This agent will enable critical safety features, such as automatic speed adjustments (slowing down or speeding up) and risk mitigation, essential for safe co-bot environments. To enable the outside-in approach for functional safety, this lab spotlights NVIDIA Halos for Outside-In Safety Agents powered by IGX Thor. Intermediate experience with Python, including packages, virtual environments, and scripting Familiarity with computer vision concepts, object detection, and AI inference pipelines Experience with robotics workflows and sensor integration Knowledge of data streaming, real-time analytics, and message-passing architectures",Manufacturing,"Metropolis, IGX"
DLIT82183,Advanced Workload Orchestration With NVIDIA Run:AI [DLIT82183],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82183/,"David Whitehouse (NVIDIA Academy Lab Manager, NVIDIA)","Take the next step in ML performance engineering with a deep dive into advanced orchestration on the NVIDIA Run:AI platform. This lab focuses on maximizing infrastructure efficiency through intelligent scheduling and automation. Explore capabilities such as GPU fractioning, GPU memory swap, and topology-aware multi-node placement—and learn how to apply them to complex distributed training and inference workloads. With hands-on guidance, you’ll build flexible, high-performance pipelines that dramatically improve speed, utilization, and throughput at scale.",All Industries,Mission Control
DLIT81592,"Advancing Multimodal Systems: Alignment, Information Typology, Reasoning, and Cross-Modal Flow [DLIT81592]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81592/,"Mireille Fares (Sr. AI Solution Architect, NVIDIA); Andrea Pilzer (HER Solutions Architect, NVIDIA)","This lab explores key principles for advancing multi-modal systems, focusing on multi-modal information typology, alignment, multi-step reasoning, and cross-modal flow. We analyze redundant, unique, and synergistic information, and examine multi-modal alignment through coarse-grained versus fine-grained behavior. The lab then investigates multi-step multi-modality reasoning with external knowledge, where agents integrate images, text, tables, and diagrams to solve complex tasks. Finally, we study multi-modal information flow through cross-modal translation, cross-modal editing, and cross-modal querying, supported by NIM examples for text-to-image generation, semantic image editing, and visual question-answering. Basic understanding of machine learning and deep learning concepts, including embeddings and neural network architectures. Familiarity with multimodal AI concepts, such as combining text, image, and other data modalities. Experience with Python programming and standard ML libraries (e.g., PyTorch, TensorFlow). Basic knowledge of data visualization techniques (e.g., PCA, t-SNE) for interpreting embeddings.",All Industries,
DLIT81800,Assembling Industrial Digital Twins with OpenUSD and NVIDIA Omniverse Libraries [DLIT81800],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81800/,"Jay Axe (Technical Product Manager, NVIDIA); Ernesto Pacheco (coming soon, NVIDIA)","In this hands-on lab, participants will explore how to build industrial digital twins from manufacturing facilities to AI factories, using OpenUSD and NVIDIA Omniverse libraries, drawing on real-world collaboration with industry leaders. The session walks through an end-to-end workflow, from CAD models to full digital twin assembly, demonstrating how manufacturers are transforming design and production through simulation and interoperability.",All Industries,Omniverse
DLIT81639,Automate 3D Data Pipelines With USD Exchange SDK [DLIT81639],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81639/,"Beau Perschall (Director, Omniverse Sim Data Ops, NVIDIA); Andrew Kaufman (Principal Software Engineer, NVIDIA)","In this instructor-led lab, you’ll learn how to build robust OpenUSD-based data pipelines using the USD Exchange SDK, enabling you to leverage your existing 3D software and tools for scalable physical AI workflows. You'll start from common 3D source formats and write Python-based code to extract, transform, and load assets into reusable, modular USD representations suitable for large-scale workflows. Through guided, hands-on exercises, you'll structure 3D content into composable USD assets, apply simulation-ready (“SimReady”) standards, and enrich assets with rigid-body physics that support downstream robotics and simulation workloads. By the end of the lab, you'll have automated an asset conversion pipeline capable of processing large 3D datasets, giving you a practical blueprint you can adapt to your own production environment. Intermediate experience with Python, including working with packages, virtual environments, and basic scripting. Familiarity with content concepts such as meshes, materials, transforms, and scene hierarchies common to 3D modeling applications. Understand command-line usage for running scripts and managing project files. Recommended: Have completed the Learn OpenUSD curriculum (https://docs.nvidia.com/learn-openusd/latest/index.html), covering fundamentals of USD-based scene representation and concepts (stages, layers, prims, and composition). Have basic familiarity with robotics or simulation or general 3D content workflows (for example, using simulation tools or working with physics-enabled assets)",Manufacturing,"RTX GPU, Isaac, Omniverse, DLSS, PhysX, NVIDIA NIM, Blackwell"
DLIT81878,Build a Public Safety Visual Search and Summarization Agent With Palantir AIP [DLIT81878],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81878/,"Nell Barber (Solutions Architect, NVIDIA)","In this hands-on training lab, you'll learn how to supercharge your video workflows by reimagining NVIDIA’s Visual Search and Summarization Agent Blueprint inside Palantir’s Artificial Intelligence Platform (AIP). We’ll demonstrate how to extract visual insights from input video in the form of captions and scene descriptions, and you’ll get your hands dirty processing and indexing those insights for retrieval tasks like summarization and Q&A. You’ll bring it all together by creating an interactive dashboard to view input video alongside timestamped summaries and query your visual agent in natural language. By the end of this lab, you'll know how to transform passive video streams and hours of recordings into active, decision-driving assets, empowering your enterprise to maximize the impact of your visual data without ever writing a single line of code.",Smart Cities / Spaces,
DLIT81774,Build a Video Analytics AI Agent With Vision Language Models [DLIT81774],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81774/,"Sammy Ochoa (Technical Marketing Engineer, NVIDIA)","New vision language models (VLMs) are transforming computer vision with scalable, reasoning zero-shot solutions. Learn about Cosmos Reason — a new open and fully customizable reasoning VLM for physical AI and robotics — that lets robots and vision AI agents reason like humans, using prior knowledge, physics understanding, and common sense to understand and act in the real world. In this lab, you'll build a video analytics AI agent using the NVIDIA Blueprint for Video Search and Summarization (VSS) with Cosmos Reason VLM.",All Industries,"HGX, DeepStream, TensorRT, Metropolis, TAO Toolkit, NVIDIA AI Enterprise, Cosmos"
DLIT81814,Build Agentic Workflows for Financial Applications [DLIT81814],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81814/,"David Williams (Solutions Architect, NVIDIA); Benjamin Wu (Sr. Solutions Architect, NVIDIA)","We'll walk you through how to turn financial services workflows into end‑to‑end AI agents, covering orchestration, tools, retrieval, and guardrails tailored to domain-specific applications in the financial services industry (FSI). Using NVIDIA’s NeMo Agent Toolkit and Blueprints, you'll get hands on to building multi‑agent systems that support use cases such as investment research and agentic commerce.",Financial Services,"NeMo, NVIDIA NIM, NVIDIA AI Enterprise"
DLIT81808,Build Contact-Rich Robot Manipulation Skills With Isaac Lab [DLIT81808],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81808/,"Ashwin Varghese Kuruttukulam (coming soon, NVIDIA); Ayusman Saha (coming soon, NVIDIA)","Learn how to develop contact‑rich manipulation policies in Isaac Lab, and deploy them using NVIDIA Isaac ROS. In this hands‑on lab, you will walk through a gear-assembly workflow that uses Isaac Lab to train an insertion policy, and then deploy it in ROS 2, together with perception models (segmentation and 3D pose estimation) and cuMotion for GPU‑accelerated planning. You'll see how to configure an Isaac for Manipulation workflow that begins with a simulated UR robot and depth cameras for training the policy, and then tune to achieve robust, repeatable sim‑to‑real performance on contact‑rich tasks.",All Industries,Isaac
DLIT82006,"Build Cost-Effective, Scalable RAG Pipelines: From Ingestion to Response Generation [DLIT82006]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82006/,"Ruchika Kharwar (Product Manager, NVIDIA)","We'll walk you through the full life cycle of a RAG pipeline: data ingestion, chunking and embedding, retrieval orchestration, and response generation, emphasizing robustness techniques such as hybrid retrieval, fallback strategies, caching, and constraint-aware prompting, along with patterns for monitoring quality and detecting drift over time. You'll also explore scaling concerns, including index sharding, cost-aware architecture choices, and aligning RAG design with product requirements and service-level agreements. By the end, you'll have implemented and evaluated a RAG pipeline that balances answer quality, latency, and reliability, providing a template for deploying similar systems in production.",All Industries,"NVIDIA NIM, NVIDIA AI Enterprise, cuVS"
DLIT81550,Build Domain AI Agents That Seamlessly Tap Into Your Existing Tools and Data With NVIDIA Nemotron and NeMo [DLIT81550],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81550/,"Shashank Verma (Sr. Technical Marketing Engineer, NVIDIA); Yang Yu (Solutions architect, NVIDIA)","Developing effective AI agents requires more than a powerful model — it demands the ability to use the tools, data, and systems that drive real-world workflows. Learn how to create a production-ready agent for a custom use case using NVIDIA NeMo powered by Nemotron models. You'll deploy NeMo modules, customize and evaluate model behavior, connect to data and tools, and apply guardrails for reliable operation. A central focus is enabling the agent to work fluidly with an existing data and tooling ecosystem — integrating APIs, function calls, and the Model Context Protocol (MCP) to accomplish meaningful tasks end to end. We'll also demonstrate a data flywheel that captures interactions to boost accuracy, reliability, latency, and cost over time. You'll build a complete system that you can extend in enterprise or personal environments. Basic experience with Python A general understanding of LLMs or agent workflows or Generative AI concepts (no deep ML background required) Familiarity with REST APIs or function-calling concepts is helpful but not mandatory Optional but beneficial: Exposure to NVIDIA NeMo, containerized development (Docker), or cloud workflows No prior experience with Nemotron models or NeMo is required.",All Industries,"NeMo, NVIDIA NIM"
DLIT81609,Build End-to-End Medical AI Workflows With NVIDIA Clara Open Models [DLIT81609],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81609/,"Ahmed Harouni (Technical Marketing Engineer, NVIDIA)","This comprehensive hands-on workshop demonstrates how to build production-ready medical AI workflows using NVIDIA Clara's latest open models and tools. You'll gain practical experience with NV-Segment, NV-Generate, NV-Reason, and MONAI Label to create powerful medical imaging applications.",Healthcare & Life Sciences,"MONAI, NVIDIA NIM"
DLIT81816,Build Robot-Ready Assets for Physically Accurate Simulations With Lightwheel [DLIT81816],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81816/,"Frank Chen (Director of Engineering, Lightwheel); Siyi Lin (Technical Artist Lead, Lightwheel)","In this hands-on lab, Lightwheel, a leading provider of simulation-ready assets, platforms, and synthetic data for embodied AI, guides you through the complete SimReady asset preparation workflow. You’ll learn to generate high-fidelity synthetic data using OpenUSD, configure accurate physics properties (mass, friction, collision geometry) with PhysX and Newton, and add semantic metadata along with manipulation affordances. You’ll validate your work by deploying trained robot agents inside NVIDIA Isaac Sim. By the end of the lab, you’ll know how to build simulation-ready scenes that support real-to-sim calibration and sim-to-real transfer, enabling robots to learn robustly in simulation and perform reliably in the real world. Recommended:",Manufacturing,"Isaac, Omniverse, PhysX"
DLIT81541,Build Surgical and Medical Robotics With NVIDIA Isaac for Healthcare: From Simulation to Deployment [DLIT81541],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81541/,"Maximilian Ofir (Technical Marketing Engineer, NVIDIA GmbH)","Gain hands-on experience in setting up simulation environments, generating and converting synthetic medical data, modifying scenes and assets, collecting and curating datasets via state-machine demonstrations, fine-tuning the GR00T N1 Vision-Language-Action (VLA) model, and testing robotic ultrasound tasks in simulation. We emphasize safe, efficient AI model development and deployment for healthcare applications. IsaacSim and IsaacLab foundational experience. Python and terminal experience. General understanding of deep learning, and vision language action models.",Healthcare & Life Sciences,"RTX GPU, AGX, Clara, Isaac, Clara Holoscan, MONAI, Cosmos"
DLIT81798,Building and Deploying Digital Twin Applications With Omniverse Kit App Streaming [DLIT81798],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81798/,"Sebastian Misiurek (Sr. Product Manager, Omniverse, NVIDIA); Andrew Wrenn (Cloud Software Engineer, NVIDIA)","Unlock the power of real-time 3D digital twin applications with NVIDIA Omniverse Kit App Streaming. In this lab, you'll build, containerize, deploy, and extend interactive 3D applications that stream directly to web clients, enabling scalable, remote simulation and control for digital twin solutions. We’re going to create a streaming-ready OpenUSD application and a front-end client, then package and deploy a solution using industry-standard tools and APIs. You’ll explore how to implement custom messaging between your app and client, allowing for rich, bi-directional interaction and integration with live data sources. You'll gain practical experience with the full development and deployment workflow for Omniverse Kit App Streaming and develop a solid foundation for building operational digital twins that deliver real-time insights and collaboration across your organization.",All Industries,
DLIT81699,Building and Testing Multi‑Robot Scenarios with Isaac Sim and ROS 2 [DLIT81699],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81699/,"Rishabh Chadha (Technical Marketing Engineer - Isaac, NVIDIA); Ayush Ghosh (Robotics Systems Engineer, NVIDIA)","Gain practical experience in orchestrating multi-robot collaboration, automating simulation workflows, and executing autonomous navigation and object manipulation tasks in a test scenario, using ROS 2, Simulation Interfaces, and Isaac Sim. These skills will empower you to deploy and test advanced robotics solutions.",All Industries,Isaac
DLIT81861,"Compress, Cut, and Distill: The Latest Gen AI Model Compression Techniques in Practice [DLIT81861]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81861/,"Lavinia Ghita (Solutions Architect, NVIDIA); Sergio Perez (Solutions Architect, NVIDIA); Harshita Seth (Solutions Architect, NVIDIA); Liana Mikaelyan (Sr. Solutions Architect, NVIDIA)","This training lab explores the art and engineering of compressing large language models to make them cheaper, faster, and easier to deploy while preserving practical capability. Designed for a broad audience that spans beginners to advanced practitioners, the workshop will introduce foundational concepts for newcomers, share implementation patterns and pitfalls for experienced engineers, and highlight cutting-edge research directions for specialists.",All Industries,
DLIT81697,"Configure Robot Simulations With OpenUSD and PhysX: Tuning, Stability, and Asset Authoring Best Practices [DLIT81697]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81697/,"Alexandra Kissel (Robotics Simulation Software Engineer, NVIDIA); Steven Feng (Robotics Engineer, NVIDIA)","Learn from NVIDIA experts about OpenUSD best practices and physics tuning of mechanisms, using the example of a robotic hand. Starting from a URDF file, see how to structure, assemble, and optimize USD. Then learn about the physics tuning process, to enable dexterous hands to behave realistically in simulation. We will focus on best practices that make complex hand models performant, controllable, and ready for downstream learning and control tasks. Intermediate experience with Python, including working with packages, virtual environments, and basic scripting. Familiarity with 3D content concepts such as meshes, materials, transforms, and scene hierarchies from tools like Blender, Maya, or similar DCC applications. Understand command-line usage for running scripts and managing project files. Have familiarity with robotics or simulation workflows (for example, using simulation tools or working with physics-enabled assets).",All Industries,Isaac
DLIT81948,Create Generative AI Workflow for Design and Visualization in ComfyUI [DLIT81948],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81948/,"Ashlee Martino-Tarr (3D Workflow Specialist, NVIDIA); Alessandro La Tona (3D Workflow Specialist, NVIDIA); Daniela Flamm Jackson (3D Workflow Specialist, NVIDIA)","The latest image and video generation models, combined with LLM, are fantastic tools to build powerful agentic AI workflows, but they're hard to access through too many cloud access points to efficiently iterate on concepts and stay up to date. In this two-hour instructor-led workshop, you'll learn how to use GPU acceleration for ComfyUI on local workstation or servers, pulling the latest models to build complex generative workflows. Workflows will range from relighting pictures/video, 3D workflows including Physically based rendering map generation, or even building storyboard from pictures and text. Whether you're a developer willing to learn what models work best for what tasks, or an industrial designer or digital artist willing to understand how to drive AI with your inputs, this course demonstrates how ComfyUI can be used to power design and visualization workflows with Gen AI.",AEC,"RTX GPU, RTX Virtual Workstations (vWS)"
DLIT81879,Create Vision AI Applications With Generative AI Coding Agents [DLIT81879],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81879/,"Carlos Garcia-Sierra (Product Manager - Metropolis AI Workflows, NVIDIA)","Computer vision is a cornerstone of the generative AI revolution, providing the essential visual metadata required by vision language models (VLMs) to extract actionable insights. In this two-hour instructor-led workshop, you will learn how to GPU-accelerate your video analytics workflow by combining the NVIDIA DeepStream SDK with the power of prompt engineering. Discover how to generate complete, GPU-accelerated DeepStream pipelines using simple natural language prompts. Whether you are a developer new to DeepStream or an advanced user looking to accelerate your prototyping, this course demonstrates how to produce intuitive, readable Python applications without the manual overhead. Join us to bridge the gap between traditional video analytics and modern GenAI development.",All Industries,"DeepStream, Metropolis, Cosmos, Blueprint"
DLIT81660,Data to Decisions: GPU-Accelerated Decision Optimization [DLIT81660],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81660/,"Burcin Bozkaya (Sr. Developer Relations Manager, NVIDIA); Adi Geva (Technical Marketing Engineer, NVIDIA)","Learn to optimize decision optimization problems with GPU-accelerated workflows using NVIDIA cuOpt, RAPIDS, CUDA-X libraries, and Nemotron models. This hands-on lab dives into advanced LP/MIP solver integration, accelerated primal heuristics, cutting-plane methods, and deployment patterns for large-scale, real-time optimization. Foundational knowledge of optimization: Familiarity with Linear Programming and Mixed Integer Programming concepts (constraints, relaxations, heuristics, cutting planes). Basic Python proficiency: Ability to read and modify Python scripts used in optimization workflows. Some experience with GPUs or CUDA-based frameworks: Prior exposure to GPU computing (e.g., RAPIDS, CUDA-X libraries) is helpful but not mandatory. Comfort with OR tooling: Experience with at least the optimization solver ecosystem",All Industries,"CUDA, CUDA-X, cuOPT"
DLIT82008,Deploy and Customize Your AI Factory: Make Your AI Factory Feel Like Home! [DLIT82008],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82008/,"Max Steele (Sr. Technical Instructor in AI and Data Center, NVIDIA); Terrell Bennett (Technical Training Content Developer, NVIDIA)","This hands-on lab will get you down and dirty with customizing an AI factory. Experience how typical administrator tasks are made easier with NVIDIA Mission Control, and explore the interfaces and tools that NVIDIA Mission Control provides for doing ""Day 1 and beyond"" work.",All Industries,"Grace CPU, DGX Platform, HGX, Infiniband Networking, Hopper, LaunchPad, Base Command Manager, Interconnect Networking, Blackwell, NVIDIA AI Enterprise, Mission Control"
DLIT81738,Deploy and Optimize LLMs and VLMs on NVIDIA Jetson Thor [DLIT81738],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81738/,"Chitoku Yato (Sr. Technical Product Marketing Manager, NVIDIA)","Learn to deploy, optimize, and accelerate large language models (LLMs) and vision-language models (VLMs) on NVIDIA Jetson Thor through hands-on exercises with real hardware. We'll demonstrate production-ready inference frameworks including vLLM and SGLang, apply NVIDIA ModelOpt for quantization, showcase systematic methods to achieve inference performance improvements, and explore advanced capabilities like tool calling and live VLM inference — all running on edge devices you can touch and interact with. Required: Basic understanding of Large Language Models and transformer architectures Familiarity with Python programming and container technologies (Docker) Experience with command-line interfaces and SSH for remote device access Laptop with network connectivity (Ethernet preferred, WiFi acceptable) Recommended:",All Industries,"Jetson, AGX, CUDA, TensorRT, JetPack, Blackwell, Cosmos"
DLIT81958,Deploy State-of-the-Art Gen AI on Your RTX PRO Workstation [DLIT81958],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81958/,"Julius Gregor Tischbein (Sr. Developer Technology Software Engineer, NVIDIA); Maximilian Mueller (Sr. Developer Technology Software Engineer, NVIDIA)","This session guides you through the end-to-end deployment of generative image models on NVIDIA RTX PRO workstations by leveraging ONNX Runtime and TensorRT-RTX. We'll demonstrate how to ship a multi-stage model pipeline across a wide set of hardware without sacrificing performance. This workflow will be powered by classic graphics APIs, ONNX Runtime, and the TensorRT-RTX Execution Provider. You'll leave with the skills to convert raw models into high-performance, offline-capable applications that run seamlessly across diverse hardware architectures.",All Industries,"RTX GPU, DGX Platform, RTX Virtual Workstations (vWS), Blackwell, DGX Spark"
DLIT81650,Develop AI-Powered Operational Dashboards for Digital Twin Applications [DLIT81650],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81650/,"Victor Yudin (Software Architect, NVIDIA); Justine Lin (Technical Marketing Engineer, NVIDIA)","Create intelligent operational dashboards for digital twin applications using NVIDIA Omniverse. Build compact, real-time monitoring interfaces with React to track factory metrics, robot states, and sensor data streams. Embed custom panels into Kit applications and deploy dashboards across local and cloud environments. Learn to integrate LLM agents for natural language interaction with your digital twin data. Through hands-on exercises, learn the workflow for dashboard creation for streaming deployment, enabling intelligent monitoring and control of complex industrial operations.",All Industries,
DLIT81725,Develop Production Agents with Eval-Driven Design [DLIT81725],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81725/,"Dhruv Nandakumar (Cybersecurity AI Solutions Architect, NVIDIA)","This training lab will explore new techniques for building robust, production-ready AI agents by focusing on an evaluation-driven design workflow. You'll learn how we use human-created datasets for iterative improvement and how to apply continuous eval and iterate cycles, including prompt changes and experimentation, to significantly improve agent performance. The prerequisites for this course are practical familiarity with AI/ML fundamentals, including Large Language Models (LLMs), and programming proficiency in Python. Attendees should also have a working understanding of basic prompt engineering and experience with the overall lifecycle of building an AI application, as the lab is focused on the advanced, production-ready stage of evaluation and iterative design.",All Industries,"NeMo, NVIDIA AI Enterprise"
DLIT82002,Efficient Workload Management for AI Factories: What Every Admin Needs to Know [DLIT82002],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82002/,"Max Steele (Sr. Technical Instructor in AI and Data Center, NVIDIA); Terrell Bennett (Technical Training Content Developer, NVIDIA)","In this hands-on lab you'll learn, as an AI factory administrator, how real workloads are run on a cluster. Intended for IT types (not data scientists!), this lab will have you configuring Run:ai, allocating and monitoring resources, and building a workload with NVIDIA NIMS to understand just what the user experience is, and what tools are at your disposal to make the AI factory workloads actually work.",All Industries,"DGX Platform, HGX, Infiniband Networking, LaunchPad, Base Command Manager, NVIDIA NIM, NVIDIA AI Enterprise, NVIDIA Run:ai, Mission Control"
DLIT81945,Faster Together: Train and Deploy a Speculative Decoding Model for Low-Latency LLM Inference [DLIT81945],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81945/,"Mireille Fares (Sr. AI Solution Architect, NVIDIA); Dmitry Mironov (Solutions Architect, NVIDIA)","Dive deep into theory and practice of low-latency inference by deploying NVIDIA TensorRT-LLM with advanced speculative decoding techniques. You'll train an Eagle-3 draft head to propose candidate tokens efficiently, serve it, and benchmark it using AIPerf to quantify how these strategies minimize latency.",Cloud Services,"TensorRT, Dynamo"
DLIT81641,Find the Bottleneck: Optimize AI Pipelines With Nsight Systems [DLIT81641],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81641/,"Sneha Latha Kottapalli (Sr. Systems Software Engineer, NVIDIA)","Learn about using NVIDIA Nsight Systems for bottleneck detection in AI pipelines and explore new features to optimize and scale the execution of your applications. This lab will guide you through the performance analysis process of GPU-accelerated AI applications that run across multiple, possibly containerized, compute instances. In addition to profiling of CPU, GPU, network and I/O activity, we'll show how NVTX and plugin mechanisms enable the collection of custom data to support an even more comprehensive and tailored analysis on the target platform. We'll also show how the recipe system can be used to identify bottlenecks in applications running across multiple nodes. This lab is for both beginners and experienced developers who want to learn about the latest features, tips, and tricks for performance analysis to get the most out of their hardware.",All Industries,NSight Systems
DLIT81936,"Fine-Tune a Telco Reasoning Model: A Guide to Synthetic Data, Tool Calling, and Evaluation [DLIT81936]",Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81936/,"Amparo Canaveras (Sr. Solutions Architect Generative AI, NVIDIA); Aiden Chang (Solutions Architect, NVIDIA); Ari Uskudar (Telco AI Principal, NVIDIA)","Network operation centers (NoC) are the central nervous system of telecommunications, but they are often overwhelmed by ""alarm storms."" In a traditional setup, engineers manually validate alarms, swivel between multiple dashboards, check topologies, and perform root-cause analysis. This manual process is time-consuming and prone to fatigue. To solve this, we are moving toward zero-touch, self-healing networks. In this tutorial, we'll walk through creating a fine-tuning playbook that integrates synthetic data generation, training, and evaluation pipelines. We'll demonstrate how to build an AI-driven reasoning model capable of autonomously performing NoC engineer workflows — detecting issues, calling tools, and remediating incidents without human intervention.",Telecommunications,"Cloud / Data Center GPU, CUDA, NeMo"
DLIT81754,From Ingestion to Inference: Mastering the High-Performance GPU Data Science Pipeline [DLIT81754],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81754/,"William Hill (Developer Advocate, Data Science, NVIDIA); Allison Ding (Developer Advocate - Data Science, NVIDIA)","Get a comprehensive guide to constructing a complete, high-performance data science pipeline that leverages GPU acceleration throughout its life cycle. We'll sequentially cover the pipeline's core components: data ingestion, exploration, processing, and model training. For the initial stages of data ingestion and exploration, we'll demonstrate the use of GPU-accelerated frameworks, specifically Polars and/or cuDF pandas, to achieve significant speedups in data manipulation and analysis. Then we'll showcase the power of the cuML library (part of the RAPIDS ecosystem) for training and testing various machine learning models entirely on the GPU.",All Industries,"RAPIDS, cuDF, cuML"
DLIT81485,Hands-On With Earth-2: Building Local and National Weather Resilience With AI [DLIT81485],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81485/,"Marius Koch (Solution Architect, NVIDIA); Jussi Leinonen (Solution Architect, NVIDIA); Alberto Carpentieri (Solutions Architect, NVIDIA)","We explore the life cycle of AI-based high-resolution regional weather forecasting applications, which are used by businesses and governments to achieve independent local weather and climate prediction capabilities at high accuracy and unprecedented speed. We'll start by creating a custom high-resolution model, guiding you through preparing a training dataset, training a downscaling diffusion model with NVIDIA PhysicsNeMo, and packaging it for real-time use. We then use NVIDIA Earth2Studio to integrate our custom model with a global AI-based weather forecasting model, such as FourCastNet 3, to build a full regional forecasting workflow, enabling sharper and more actionable local forecasts. We'll then discuss leveraging custom weather observations to improve the accuracy of the predictions, and deploying the workflow in operations so it can be productized as an inference service.",All Industries,Modulus
DLIT81668,Harness NVIDIA AI Advanced Tools for Generative AI in Digital Health [DLIT81668],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81668/,"Jin Li (Technical Marketing Engineer, NVIDIA); Abood Quraini (Technical Marketing Engineering Manager, NVIDIA); Ben Randoing (Technical Marketing Engineer, NVIDIA)","Explore the NVIDIA Data Flywheel, which uses agent deployment artifacts from production applications to increase the overall accuracy and reduce the latency/cost of agentic AI systems. We'll explore how to utilize the NeMo Microservices Platform for programmatic control of datasets, fine-tuning, evaluation, and inference. Familiarity with Python, basic understanding of how agentic systems work, hands-on knowledge is encouraged but not required.",Healthcare & Life Sciences,NeMo
DLIT82181,How to Accelerate AI Workflows With NVIDIA Run:AI [DLIT82181],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82181/,"David Whitehouse (NVIDIA Academy Lab Manager, NVIDIA)","Unlock faster, smarter AI development in this hands-on introduction to the NVIDIA Run:AI platform. In this lab, you’ll explore how Run:AI streamlines machine learning operations, removes infrastructure bottlenecks, and simplifies workload management to accelerate outcomes. Learn how dynamic resource allocation transforms efficiency across enterprise teams, ensuring workloads run faster, smoother, and at scale. Then apply what you learn directly in your lab environment as instructors guide you through real-world examples of accelerated ML operations. You’ll leave with practical skills and a strong foundation for optimizing performance with Run:AI.",All Industries,Mission Control
DLIT82184,How to Provision and Install NVIDIA Run:AI [DLIT82184],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82184/,"David Whitehouse (NVIDIA Academy Lab Manager, NVIDIA)","Get grounded in the practical fundamentals of deploying NVIDIA Run:AI from the ground up. This lab walks you through every stage of installation—from environment preparation to final validation—so you can confidently stand-up Run:AI within your own organization. Follow a guided, instructor-led deployment in your provided lab environment, learn how to verify installations, and practice diagnosing and resolving common setup issues. Whether you’re preparing for full production rollout or building a proof of concept, this session delivers the skills to deploy successfully and maintain stability.",All Industries,Mission Control
DLIT81484,How to Run AI-Powered Computer-Aided Engineering Simulations [DLIT81484],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81484/,"Ira Shokar (Solutions Architect, NVIDIA); Mark Hobbs (Solutions Architect, NVIDIA); Pablo Hermoso Moreno (Sr. Solutions Architect, NVIDIA)","In this lab, we explore how to build AI surrogate models for crash simulations, one of the most computationally intensive tasks in computer aided-engineering (CAE). Learn how modern AI architectures can reproduce high-fidelity physics simulations at a fraction of the cost, enabling faster design exploration and decision-making. We'll walk through the full workflow for developing an AI surrogate for CAE applications, including data preparation and analysis, training and optimization, loading and running inference with pre-trained models, and evaluating model accuracy and uncertainty. We'll also discuss how AI-accelerated workflows are transforming CAE across various industries and areas of research, and how these tools can integrate seamlessly into existing engineering pipelines.",HPC / Scientific Computing,Modulus
DLIT82259,Keep Calm and Train On: Scalable and Resilient Training With Megatron-Bridge and NeMo [DLIT82259],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82259/,"Shreya Gupta (Solutions Architect, NVIDIA); Mohak Chadha (Solutions Architect, NVIDIA); Pramod Kumbhar (Sr. Solutions Architect - HPC & AI, NVIDIA)","As modern data centers evolve into AI factories, training foundational models becomes critical. But scaling these training pipelines across tens of thousands of GPUs introduces significant challenges—such as node failures, network errors, checkpointing overhead—that can quickly turn occasional anomalies into frequent production issues. In our hands-on lab, learn about the challenges of running training pipelines and how to integrate resiliency and fault-tolerance features. We'll present various fault-tolerance mechanisms provided in frameworks like NVRx and PyTorch, and demonstrate how to achieve robust, scalable training in modern AI factories using NVIDIA NeMo. Gain practical insights into techniques for measuring I/O and overall infrastructure performance. You should be familiar with Python and deep learning frameworks, understand LLM training concepts, and be comfortable with Linux.",Public Sector and Sovereign AI,"CUDA, NCCL, NeMo"
DLIT82062,MLOps Best Practices: Build an AI Agent [DLIT82062],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82062/,"Ryan Kraus (Sr. Technical Marketing Engineer, NVIDIA)","Learn practical ways to implement MLOps first principles as you create autonomous AI agents using LangGraph and NVIDIA NIM by building an agentic system that demonstrates tool integration, multi-step reasoning, and adaptive planning. Master the foundational agent architecture that MLOps engineers use to automate tedious workflows like incident investigation, experiment documentation, and model health monitoring — then customize it for your own use cases.",All Industries,"Hopper, NVIDIA NIM, Nemotron"
DLIT81803,OpenUSD Asset Integration and Data Review With Clash Detection [DLIT81803],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81803/,"Martin Vovk (Sr. Solutions Architect, NVIDIA)","Integrate clash detection into your OpenUSD-based digital twin workflows using NVIDIA Omniverse libraries. In this lab, we’ll ensure ingested assets are run through conflict analysis using the Clash Detection SDK. You’ll create and execute collision detection queries, inspect and visualize results in an Omniverse viewport, and implement robust overlap detection in complex 3D scenes. We will learn the fundamentals of simulation for digital twins, engineering validation, and automated design verification workflows.",All Industries,Omniverse
DLIT82143,Optimize LLM Inference and RL Training With SGLang [DLIT82143],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82143/,,"This training lab shows you how to optimize and scale LLM workflows with SGLang. We walk through practical performance tuning using the SGL-Cookbook, dive into profiling and bottleneck analysis for developers, and demonstrate its deep integration into reinforcement learning (RL) training frameworks by showing how to use SGLang in a real RL run with the Miles RL framework.",All Industries,"Hopper, Blackwell, DGX Cloud, DGX Station"
DLIT81579,Optimize PyTorch Models for High-Performance Inference With Nsight Deep Learning Designer [DLIT81579],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81579/,"Timothee Brenet (Sr. Deep Learning Engineer, NVIDIA); Gaoyan Xie (Sr. Manager of Software Engineering, NVIDIA); Manoj Kumar Yennapureddy (Sr. Deep Learning Engineer, NVIDIA)",Learn how to use a graphical user interface-based integrated development environment (IDE) purpose-built for deep neural network developers to manage the end-to-end process of going from PyTorch to a deployment-ready model that yields the best inference performance. Learn how to use a GPU-based performance profiler to guide sound decision-making for model optimizations.,All Industries,"CUDA, TensorRT, NSight Systems, TAO Toolkit"
DLIT81572,Powering Specialized Agents: Architecting Synthetic Data Pipelines with NVIDIA Data Designer [DLIT81572],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81572/,"Yevgeniy Meyer (Principal Research Scientist, NVIDIA); Kirit Thadaka (Product Manager, NVIDIA)","Building a truly performant LLM agent means fine-tuning for your unique use-case. This requires training data that span multiple specialized domains or tools; for most real-world applications, the data you need simply don't exist. This hands-on workshop leverages NVIDIA Data Designer, our recently open-sourced, state-of-the-art framework, to bridge this gap. We'll cover the latest techniques developed at NVIDIA for producing high-quality reasoning data, including STEM and tool-calling workflows used to scale Nemotron models. By the end of this session, you will gain the skills to speed up data experimentation and drive innovation in your own AI projects. Basic Python and Jupyter notebooks Training or fine-tuning LLMs (conceptually) Using datasets for supervised fine-tuning and evaluation (classification, generation, or instruction-following tasks) Optional: prior exposure to NVIDIA NeMo, Hugging Face datasets/models, or other LLM fine-tuning stacks.",All Industries,"NeMo, NVIDIA AI Enterprise"
DLIT81881,Production-Ready Robotics on the NVIDIA Stack [DLIT81881],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81881/,"Sai Vemprala (CTO and Co-founder, General Robotics)","In this hands-on lab, General Robotics will guide you through a complete, end-to-end solution development workflow built on the NVIDIA ecosystem. You'll learn to: • Capture teleoperated demonstrations of real manual tasks • Augment, vary, and scale those tasks in simulation using NVIDIA Isaac • Generate high-volume synthetic datasets to expand coverage • Fine-tune modern robotics models using NVIDIA’s training infrastructure • Test policies and reinforcement learning models in advanced simulation, leveraging NVIDIA AI models like GraspGen, CuMotion, and Foundation Stereo • Deploy learned behaviors to real robots running on Jetson • Analyze system performance and iterate using the latest LLMs and agentic tools • Bridge the human–robot gap across development, validation, and deployment",Manufacturing,
DLIT81545,Profiling Python and AI workloads with Nsight Compute [DLIT81545],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81545/,"Felix Schmitt (Principal System Software Engineer, NVIDIA)","Learn how to use the Nsight Compute tool to profile CUDA and AI GPU kernels in the Python framework of your choice: Numba, Triton or PyTorch. Understand the optimization workflows provided by NVIDIA Nsight Compute UI and its ncu command line interface. Use the new scoreboard dependency analysis view and source page improvements like opcode to metric pipeline associations. Learn how to use the Nsight Jupyterlab Extension for profiling and streaming reports directly in Jupyter. Try the latest Nsight Python decorators for profiling from within any Python script.",All Industries,
DLIT81801,Real-Time Simulation for Real-Time Results: How AI Physics Can Accelerate Your AI Factory [DLIT81801],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81801/,"Abigail Breazeale (Sr. Technical Marketing Engineer, NVIDIA); Robert Cervellione (Sr. Product Manager – Omniverse, NVIDIA)","This hands-on lab introduces mechanical and simulation engineers to GPU-accelerated, real-time CFD workflows that combine interactive visualization with physics-AI models. Participants will use NVIDIA technologies to connect CFD simulations, PhysicsNeMo, and digital twin environments for faster iteration and more reliable design insights. We will configure and run real-time CFD cases, integrate PhysicsNeMo for accelerated prediction, and visualize results interactively for design exploration. The session will show how to move from traditional batch-style CFD to responsive, GPU-driven workflows that support rapid concept evaluation and collaborative design reviews.",Manufacturing,"Omniverse, NeMo"
DLIT81698,Scalable Environment Setup and Policy Evaluation in Simulation with Isaac Lab Arena and GR00T [DLIT81698],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81698/,"Asawaree Bhide (Robotics Technical Marketing Engineer, NVIDIA); Edith Llontop (Solutions Architect, NVIDIA)","In this hands-on lab, you’ll gain expertise on workflows for simulation-based policy evaluation, including how to setup simulation environments with Isaac Lab Arena, how to post-train GR00T models for custom tasks and how to evaluate trained policies in simulation at scale. NVIDIA Isaac Lab Arena is a framework for scalable policy evaluation in simulation. NVIDIA Isaac GR00T provides robot foundation models for cognition and control, built on NVIDIA Omniverse™ and Cosmos™.",All Industries,Isaac
DLIT82000,Split and Win: Dynamo's Prefill-Decode Disaggregation and Smart KV Routing for Extreme LLM Throughput [DLIT82000],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82000/,"Kyle Huang (WWFO) (Gen AI Solutions Architect, NVIDIA); Arun Raman (Sr. Solution Architect, NVIDIA); Utkarsh Uppal (Sr. Deep Learning Solutions Architect, NVIDIA)",Master the deployment of massive mixture-of-expert architectures by configuring Dynamo’s PD Disaggregation with Large Expert Parallelism to maximize GPU efficiency. Learn to optimize distributed data flows including KV Cache Aware Routing to achieve an order-of-magnitude increase in serving throughput while meeting strict production latency demands.,Cloud Services,"TensorRT, Dynamo"
DLIT81546,Supercharge Tabular ML Models With GPU-Accelerated Feature Engineering [DLIT81546],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81546/,"Chris Deotte (Sr. Data Scientist, NVIDIA); Ronay Ak (Sr. Data Scientist, NVIDIA)","Fast experimentation in feature engineering is essential to quickly discover the most valuable features that improve model performance. In this tutorial, we leverage NVIDIA cuDF and cuML libraries to accelerate the experimentation pipeline on GPUs with their zero-code change features, enabling faster feature engineering and quicker development of more accurate models. Basic understanding of Python and tabular data.",All Industries,"CUDA, RAPIDS, CUDA-X, cuDF, cuML"
DLIT81644,Synthetic Data Generation for Robot Learning With NVIDIA Cosmos World Foundation Models [DLIT81644],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81644/,"Stefanie Manzinger (Sr. Solutions Architect, NVIDIA)","This hands-on lab introduces roboticists, AI developers, and pipeline engineers to NVIDIA Cosmos world foundation models (WFMs) for synthetic data generation in robot learning pipelines. Participants will learn how to leverage simulation scenes from Isaac Sim and real-life images and videos to provide initial datasets and augment them with Cosmos Transfer, then evaluate data quality with Cosmos Reason—all within a production-ready robotics pipeline. Through this session, you'll experience an end-to-end data pipeline workflow, leveraging Cosmos WFMs to generate synthetic data from real-world and physically-accurate simulated data, and using Cosmos Reason as an intelligent critic to validate data quality. By completing this lab, you'll unlock the ability to generate high-quality training datasets, accelerating your action model development.",Manufacturing,"RTX GPU, Isaac, Omniverse, DLSS, Omniverse Replicator, NVIDIA NIM, Blackwell, NVIDIA AI Enterprise, Cosmos"
DLIT81818,Tabular Foundation Models for Financial Services [DLIT81818],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81818/,"Benjamin Wu (Sr. Solutions Architect, NVIDIA); Flora Huang (Sr. Solutions Architect, NVIDIA)","Tabular data powers entire industries, but building state-of-the-art models for structured data at scale remains complex. In this session, we’ll unveil a comprehensive workflow for building transformer-based tabular foundation models. Each stage of our reference architecture is GPU-accelerated: tabular synthetic data generation, feature engineering and tokenization, training large-scale tabular transformers, and deploying inference pipelines. We apply this workflow to the real-world problem of fraud detection in credit card transactions, highlighting best practices and NVIDIA’s ecosystem for scalable tabular AI.",Financial Services,"RAPIDS, cuDF, cuML, NeMo, Triton, NVIDIA AI Enterprise"
DLIT81565,The Kaggle Grandmasters Playbook: Battle-Tested Modeling Techniques for Tabular Data [DLIT81565],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81565/,"Chris Deotte (Sr. Data Scientist, NVIDIA); Gilberto Titericz Junior (Sr. Data Scientist, NVIDIA)","Our workshop highlights proven strategies for tabular data developed by NVIDIA’s Kaggle grandmasters, who have earned top honors in hundreds of international data science competitions. You'll practice rapid electronic design automation (EDA), large-scale feature engineering, model building, ensembling, and pseudo-labeling — all accelerated with GPUs for faster experimentation and better accuracy.",All Industries,"CUDA, RAPIDS, CUDA-X, cuDF, cuML"
DLIT81757,Training Lab: Advance World Simulation With 3D Gaussian Splatting for Large-Scale Environment Reconstruction [DLIT81757],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81757/,"Zoe LaLena (Solutions Architect, NVIDIA)","Learn how to reconstruct a large scene for robotics testing using NVIDIA Omniverse NuRec Gaussian-based reconstruction technologies to perform multi-GPU training, neural enhancement, object segmentation and extraction. This lab will walk through core concepts with a step-by-step workflow for data capture, reconstruction, generative enhancement, and object level-integration for robotics simulation in NVIDIA Isaac Lab.",Public Sector and Sovereign AI,"RTX GPU, Omniverse, Blackwell"
DLIT82021,Ultra Scale Runbook for PyTorch on NVIDIA GPUs for Training and Inference [DLIT82021],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit82021/,"Syed Ahmed (Sr. Software Engineer, NVIDIA)","In this lab, we'll walk through large-scale training and deployment of a well-known mixture-of-experts (MoE) LLM. You'll learn how to scale MoE pre-training by composing several parallelism techniques (FSDP, Tensor Parallel, Pipeline Parallel), memory saving techniques (Activation Checkpointing, CPU Offloading), and torch.compile driven optimizations. We'll use TorchTitan as our pre-training framework. We'll also demonstrate how to deploy such a model using the vLLM framework. You'll learn how to apply CUDA-accelerated inference-specific optimizations available in vLLM.",All Industries,"BlueField DPU, Cloud / Data Center GPU, Grace CPU, DGX Platform, CUDA, Infiniband Networking, Ethernet Networking, Hopper, cuBLAS, CUDA-X, cuDDN, cuFFT, DALI, Interconnect Networking, NCCL, NSight Comute, NSight Systems, NVLink / NVSwitch, Triton, Blackwell, NVIDIA AI Enterprise, DGX Cloud, DGX Station"
DLIT81764,Unlock Real-Time Financial Decisions With GPU-Accelerated Portfolio Optimization [DLIT81764],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81764/,"Peihan Huo (Solution Architect, NVIDIA); Jianchi Chen (Chief Investment Officer, Kendall Square Capital); Ioana Boier (Global Head of Capital Markets Strategy, NVIDIA); Francisco Zhao (Senior Solutions Architect, NVIDIA)","Discover how to resolve the trade-off between computational speed and model complexity in financial portfolio management. This session combines NVIDIA’s Quantitative Portfolio Optimization developer example with exclusive insights from Kendall Square Capital, demonstrating how to accelerate large-scale, complex portfolio optimization problems without compromising result quality. Learn how to formulate data-driven models to leverage cuOpt and CUDA-X Data Science libraries to unlock accelerations up to triple-digit speed-ups compared to CPU-based solutions. Gain insights into how these innovations transform portfolio optimization from a slow batch process into a dynamic workflow, unlocking new frontiers in automated investing research and real-time rebalancing.",Financial Services,"CUDA, CUDA-X, cuDF, cuML, cuOPT"
DLIT81597,Using Reasoning VLAs to Develop Safer Autonomous Vehicles [DLIT81597],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81597/,"Ed Schmerling (Sr. Research Scientist, NVIDIA); Apoorva Sharma (Research Scientist, NVIDIA)","In this training lab, we'll demonstrate how state-of-the-art reasoning vision-language-actions (VLAs) models, like Alpamayo R1, can be used as part of a safety evaluation pipeline ready for next-generation, end-to-end AI-powered autonomous vehicles (AVs). Learn how to use these powerful reasoning models to aid in data curation for safety validation, using these models to mine the NVIDIA Physical AI Dataset to identify key scenarios to target with additional testing.",Automotive / Transportation,"DRIVE, DRIVE SDK, DRIVE AV, Blackwell, Cosmos"
DLIT81837,How to use Warp to Build GPU-Accelerated and Differentiable Physics Simulations [DLIT81837],Training Lab,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dlit81837/,"Mohammad Mohajerani (Sr. Product Manager, NVIDIA); Sheel Nidhan (Sr. Technical Marketing Engineer, NVIDIA); Eric Shi (Sr. Engineering Manager, NVIDIA)","Discover how NVIDIA Warp enables the next generation of GPU-accelerated physics, geometry processing, and differentiable programming. This training lab introduces Warp’s core capabilities and modules, then moves into a hands-on notebook where participants build a high-performance physics solver entirely in Python. This is demonstrated through a practical computational fluid dynamics example based on a 2-D Navier–Stokes formulation. You'll leave with an understanding of what Warp is designed for, how its core building blocks work, and how it can be used alongside deep learning frameworks like PyTorch and JAX in modern computational engineering workflows.",All Industries,CUDA-X
DLIW82209,Accelerated Networking for AI Infrastructure [DLIW82209],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82209/,Nawar Nawar (NVIDIA),"Bring your own laptop to experience advanced networking in action with this hands-on workshop. You'll learn how to design a resilient Ethernet management network with BGP, VXLAN, EVPN, and MLAG for modern AI clusters. Dive into monitoring and validating InfiniBand communications using performance tests and subnet manager tools. And finally, learn the most unique networking technology for high-speed GPU-to-GPU workloads as you configure NVIDIA NVLink™ with NMX-C. Don’t miss this opportunity to gain practical expertise in building and optimizing scalable, high-performance AI infrastructure. Learning Objectives: Configure a multi-tenant Ethernet network using Cumulus Linux NOS. Validate, test and operate an E-W InfiniBand fabric for multi-node communication. Setup, manage and troubleshoot high performance NVLink fabric, using NMX control services for GB200 and GB300 deployments. Bring your own laptop to experience advanced networking in action with this hands-on workshop. You'll learn how to design a resilient Ethernet management network with BGP, VXLAN, EVPN, and MLAG for modern AI clusters. Dive into monitoring and validating InfiniBand communications using performance tests and subnet manager tools. And finally, learn the most unique networking technology for high-speed GPU-to-GPU workloads as you configure NVIDIA NVLink™ with NMX-C. Don’t miss this opportunity to gain practical expertise in building and optimizing scalable, high-performance AI infrastructure. Learning Objectives:",All Industries,
DLIW82267,Adding New Knowledge to LLMs [DLIW82267],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82267/,"John Jahanipour (Senior Solutions Architect, NVIDIA)","In today's AI landscape, even powerful Large Language Models (LLMs) face limitations when confronted with specialized business knowledge, technical domains, or cultural contexts absent from their training data. While retrieval-augmented generation can mitigate some gaps, true domain mastery requires deeper model adaptation. This comprehensive workshop equips developers with hands-on skills to transform open-source LLMs into domain-specialized AI assets. Through five interconnected modules, you'll master the complete lifecycle of model customization. By workshop completion, you'll possess the complete technical skillset to develop, deploy, and operate sovereign AI systems tailored to your specific requirements - from data preparation to production scaling. Bring your laptop; we'll provide the GPUs. In today's AI landscape, even powerful Large Language Models (LLMs) face limitations when confronted with specialized business knowledge, technical domains, or cultural contexts absent from their training data. While retrieval-augmented generation can mitigate some gaps, true domain mastery requires deeper model adaptation. This comprehensive workshop equips developers with hands-on skills to transform open-source LLMs into domain-specialized AI assets. Through five interconnected modules, you'll master the complete lifecycle of model customization. By workshop completion, you'll possess the complete technical skillset to develop, deploy, and operate sovereign AI systems tailored to your specific requirements - from data preparation to production scaling. Bring your laptop; we'll provide the GPUs.",All Industries,NeMo
DLIW82269,Building AI Agents with Multimodal Models [DLIW82269],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82269/,"Mark Moyou (Sr. Data Scientist, NVIDIA)","Just like how humans have multiple senses to perceive the world around them, computers have a variety of sensors to help perceive the human world. In the health industry, computed tomography (CT) scans provide a 3D representation used to detect potentially dangerous abnormalities. In the robotics industry, lidars are used to help robots see depth and navigate the complex topology around them. In this course, learners will develop neural network based multimodal models that can understand many different data types by exploring different fusion techniques. Just like how humans have multiple senses to perceive the world around them, computers have a variety of sensors to help perceive the human world. In the health industry, computed tomography (CT) scans provide a 3D representation used to detect potentially dangerous abnormalities. In the robotics industry, lidars are used to help robots see depth and navigate the complex topology around them. In this course, learners will develop neural network based multimodal models that can understand many different data types by exploring different fusion techniques.",All Industries,NVIDIA NIM
DLIW82270,Building LLM Applications With Prompt Engineering [DLIW82270],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82270/,"Matt Linder (Sr. Solutions Architect, NVIDIA)","With the incredible capabilities of large language models (LLMs), enterprises are eager to integrate them into their products and internal applications for a wide variety of use cases, including (but not limited to) text generation, large-scale document analysis, and chatbot assistants. The fastest way to begin leveraging LLMs for diverse tasks is by using modern prompt engineering techniques. These techniques are also foundational for more advanced LLM-based methods such as Retrieval-Augmented Generation (RAG) and Parameter-Efficient Fine-Tuning (PEFT). In this workshop, learners will work with an NVIDIA language model NIM, powered by the open-source Llama-3.1 large language model, alongside the popular LangChain library. The workshop will provide a foundational skill set for building a range of LLM-based applications using prompt engineering. With the incredible capabilities of large language models (LLMs), enterprises are eager to integrate them into their products and internal applications for a wide variety of use cases, including (but not limited to) text generation, large-scale document analysis, and chatbot assistants. The fastest way to begin leveraging LLMs for diverse tasks is by using modern prompt engineering techniques. These techniques are also foundational for more advanced LLM-based methods such as Retrieval-Augmented Generation (RAG) and Parameter-Efficient Fine-Tuning (PEFT). In this workshop, learners will work with an NVIDIA language model NIM, powered by the open-source Llama-3.1 large language model, alongside the popular LangChain library. The workshop will provide a foundational skill set for building a range of LLM-based applications using prompt engineering.",All Industries,NVIDIA NIM
DLIW82268,Building Observable and Scalable Multi-Agent Workflows for Asset Lifecycle Management [DLIW82268],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82268/,"Vineeth Kalluru (Sr. Solutions Architect, NVIDIA); Viraj Modak (AI Solutions Architect, NVIDIA)","Learn to develop multi-agent workflows tailored for Asset Lifecycle Management use cases within industrial process applications. You'll be introduced to the NVIDIA open-source NeMo Agent Toolkit (NAT) and its key features, enabling the creation of a comprehensive and customizable reference solution for this use case. You'll also be guided in effectively utilizing other components of NVIDIA AI stack, including NVIDIA Inference Microservices (NIM), cloud endpoints, and NVIDIA Tesseract time series foundational models. These components are used to design agents capable of executing frequently performed tasks such as data querying and analysis, Forecasting, Remaining useful life prediction, and Anomaly detection. Furthermore, you will gain insight into NAT’s marquee features, such as workflow observability and sizing, prompt optimization, and third-party connections. Learn to develop multi-agent workflows tailored for Asset Lifecycle Management use cases within industrial process applications. You'll be introduced to the NVIDIA open-source NeMo Agent Toolkit (NAT) and its key features, enabling the creation of a comprehensive and customizable reference solution for this use case. You'll also be guided in effectively utilizing other components of NVIDIA AI stack, including NVIDIA Inference Microservices (NIM), cloud endpoints, and NVIDIA Tesseract time series foundational models. These components are used to design agents capable of executing frequently performed tasks such as data querying and analysis, Forecasting, Remaining useful life prediction, and Anomaly detection. Furthermore, you will gain insight into NAT’s marquee features, such as workflow observability and sizing, prompt optimization, and third-party connections.",Manufacturing,NeMo
DLIW82274,Deploying and Optimizing AI Inference at Scale [DLIW82274],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82274/,"Anshul Jindal (Sr. Solutions Architect, NVIDIA); Mohak Chadha (Solutions Architect, NVIDIA); Severine Habert (Solutions Architect, NVIDIA)","As foundation models move toward deeper test-time computation, inference becomes the dominant scaling constraint. Latency, throughput, and cost are governed by a small set of forces: autoregressive decoding, KV-cache growth, memory bandwidth, and scheduling under contention. This workshop frames large-scale inference through these emerging laws of inference, starting from first principles and building toward real systems. Learners begin with monolithic and gateway-based vLLM deployments on Kubernetes to establish baseline behavior, then transition to NVIDIA Dynamo to operate aggregated and disaggregated inference architectures using built-in KV-aware routing and scheduling. A core emphasis is observability: attendees will deploy a full stack (Prometheus, Grafana, Loki, Tempo) to monitor metrics, capture structured logs, and perform distributed tracing. The outcome is a principled understanding of where inference time and money go - and how architectural choices bend those curves in production. As foundation models move toward deeper test-time computation, inference becomes the dominant scaling constraint. Latency, throughput, and cost are governed by a small set of forces: autoregressive decoding, KV-cache growth, memory bandwidth, and scheduling under contention. This workshop frames large-scale inference through these emerging laws of inference, starting from first principles and building toward real systems. Learners begin with monolithic and gateway-based vLLM deployments on Kubernetes to establish baseline behavior, then transition to NVIDIA Dynamo to operate aggregated and disaggregated inference architectures using built-in KV-aware routing and scheduling. A core emphasis is observability: attendees will deploy a full stack (Prometheus, Grafana, Loki, Tempo) to monitor metrics, capture structured logs, and perform distributed tracing. The outcome is a principled understanding of where inference time and money go - and how architectural choices bend those curves in production.",All Industries,Dynamo
DLIW82265,Fundamentals of GPU-Accelerated Workflows with CUDA Python [DLIW82265],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82265/,"Katrina Riehl (Principal Technical Product Manager, NVIDIA); Bryce Lelbach (Principal Architect, NVIDIA)","This course delivers a hands-on introduction to GPU-accelerated computing in Python, empowering developers to build fast, scalable applications using NVIDIA’s CUDA ecosystem. Through guided notebooks, participants master CuPy for array acceleration, cuDF for GPU DataFrames, and the cuda-python API to write custom kernels—all without leaving Python. Real-world exercises in data science, machine learning, and scientific computing emphasize performance, interoperability, and end-to-end efficiency. Learners progress from drop-in speedups to fully integrated GPU pipelines, mastering data movement, asynchronous execution, and profiling with Nsight tools. By the end, attendees can transform CPU-bound Python code into production-grade GPU solutions, bridge prototyping to deployment, and apply best practices for performance and reproducibility in modern accelerated computing. This course delivers a hands-on introduction to GPU-accelerated computing in Python, empowering developers to build fast, scalable applications using NVIDIA’s CUDA ecosystem. Through guided notebooks, participants master CuPy for array acceleration, cuDF for GPU DataFrames, and the cuda-python API to write custom kernels—all without leaving Python. Real-world exercises in data science, machine learning, and scientific computing emphasize performance, interoperability, and end-to-end efficiency. Learners progress from drop-in speedups to fully integrated GPU pipelines, mastering data movement, asynchronous execution, and profiling with Nsight tools. By the end, attendees can transform CPU-bound Python code into production-grade GPU solutions, bridge prototyping to deployment, and apply best practices for performance and reproducibility in modern accelerated computing.",HPC / Scientific Computing,CUDA
DLIW82273,"How to Simulate, Train, Validate, and Deploy an End-to-End Robotics Workflow with NVIDIA Isaac [DLIW82273]",Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82273/,"Maycon da Silva Carvalho (Sr. Solutions Architect, NVIDIA); Kartik Sachdev (Solutions Architect, NVIDIA)","In this full-day workshop, we'll guide you through an end-to-end robotic workflow—from simulation-based training to real-world robot deployment. You'll simulate the robot in NVIDIA Isaac Sim™, train the policies in Isaac Lab, validate the trained skills through software-in-the-loop testing, and deploy them to physical robots. Through practical exercises, you'll gain end-to-end experience in the techniques that bridge the sim-to-real gap: synthetic data generation, policy training and refinement, hardware testing on edge devices, and real-robot deployment. This workshop demonstrates how simulation accelerates robot learning and reduces the time and cost of bringing AI-powered automation to production environments. In this full-day workshop, we'll guide you through an end-to-end robotic workflow—from simulation-based training to real-world robot deployment. You'll simulate the robot in NVIDIA Isaac Sim™, train the policies in Isaac Lab, validate the trained skills through software-in-the-loop testing, and deploy them to physical robots. Through practical exercises, you'll gain end-to-end experience in the techniques that bridge the sim-to-real gap: synthetic data generation, policy training and refinement, hardware testing on edge devices, and real-robot deployment. This workshop demonstrates how simulation accelerates robot learning and reduces the time and cost of bringing AI-powered automation to production environments.",Retail / Consumer Packaged Goods,Isaac
DLIW82272,OpenUSD Crash Course: Build 3D Data Pipelines for Physical AI [DLIW82272],Full-Day Workshop,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-dliw82272/,"Daniel Roizman (CEO, UME.Studio)","Discover how OpenUSD principles and Python scripting can build scalable 3D data pipelines for manufacturing, robotics, and physical AI applications. Throughout this full-day workshop, you'll learn composition arc techniques, asset hierarchy design, and performance optimization strategies essential for production pipelines. Develop practical skills in automating 3D asset workflows, managing complex scene data, and preparing simulation environments for physical AI training. This workshop directly prepares you for the NVIDIA-Certified Professional: OpenUSD Development exam. Discover how OpenUSD principles and Python scripting can build scalable 3D data pipelines for manufacturing, robotics, and physical AI applications. Throughout this full-day workshop, you'll learn composition arc techniques, asset hierarchy design, and performance optimization strategies essential for production pipelines. Develop practical skills in automating 3D asset workflows, managing complex scene data, and preparing simulation environments for physical AI training. This workshop directly prepares you for the NVIDIA-Certified Professional: OpenUSD Development exam.",All Industries,Omniverse
QA81637,PMPP Edition 5 Unveiled: Ask Dr. Wen Mei and the CUDA Team Your Questions [QA81637],Q&A with NVIDIA,https://www.nvidia.com/gtc/session-catalog/sessions/gtc26-qa81637/,"Anshuman Bhat (Group Product Manager - CUDA, Group Product Manager - CUDA); Wen-Mei Hwu (Sr. Distinguished Research Scientist, Senior Distinguished Research Scientist and Senior Research Director at NVIDIA)","Join Dr. Wen-Mei Hwu and NVIDIA experts for a live Q&A exploring key updates in the CUDA ecosystem since the last edition of his book Programming Massively Parallel Processors (PMPP). This session offers a rare opportunity to engage directly with Wen-Mei and his team of CUDA engineers, who will answer technical questions, share new features introduced in PMPP Edition 5, and discuss emerging topics under consideration for the sixth edition.",Academia / Higher Education,"DGX Platform, CUDA, NSight Comute, NSight Systems, DGX Spark"
