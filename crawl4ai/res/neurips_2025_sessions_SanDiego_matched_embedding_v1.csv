bu_name,session_title,session_type,session_date,session_time,cosine_similarity,recommendation_reason,focus_areas
CBG,  → PlayerOne: Egocentric World Simulator,Oral Paper,FRI 5 DEC,10:00-11:00,0.51195264,该团队在运动分割、单目4D重建与轨迹控制方面的挑战，与PlayerOne的4D场景-视频联合重建、部件解耦运动注入及长视频一致性框架高度契合，能实现对齐质量与生成稳定性的显著提升。,4D场景-视频联合重建：将单目输入转化为可解析的4D场景并与视频帧保持一致。; 部件解耦运动注入：实现对人体/物体的部件级别运动分离与可控重现。; Egocentric-Exocentric数据对齐与自监督：融合正/反向视角数据提升轨迹估计与动作一致性。; 长时序一致性建模：设计跨帧的一致性损失与评估，确保长视频的场景和动作稳定。; 大规模预训练迁移：在egocentric文本-视频数据上预训练，提升单目4D重建和分割的泛化能力。
CBG,  → BEDLAM2.0: Synthetic humans and cameras in motion,Oral Paper,FRI 5 DEC,10:00-11:00,0.513305,BEDLAM2.0提供世界坐标下的3D人体与相机运动真值，能直接支撑团队在单目视频的3D/4D重建、分割与长视频一致性研究，提升鲁棒性与数据驱动效果。,将 BEDLAM2.0 的 ground-truth 世界坐标人体姿态与相机轨迹用于监督自监督/弱监督的单目3D/4D重建模型，提升跨域鲁棒性。; 研究单目视频中运动物体分割与3D人体分离的联合框架，利用 BEDLAM2.0 的多样化体型、衣着和环境以提升泛化。; 设计点云/姿态稀疏重建的高效算法，结合已知相机轨迹实现世界坐标下的位姿估计与运动重建。; 长视频一致性：引入时间约束、轨迹平滑与全局优化，抑制跨帧漂移，提升长期稳定性。; 基于 synthetic data 的领域自适应与数据增强策略，提升在真实视频中的表现。
DCN,AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG @ NeurIPS’25),Workshop,SAT 6 DEC,8 a.m.,0.5346949,本Session聚焦NextG网络中的AI原生设计，团队关注数据中心AI训练/推理的网络协同与跨DC流量优化，便于对接大模型驱动的网络管理与资源调度。,数据中心与跨DC网络的AI原生协同设计：将计算/存储与网络共同优化，面向AI训练/推理的带宽、延迟与可靠性目标。; 基于强化学习/在线学习的动态资源调度与流量工程：在数据中心与边缘/网络互连环境实现自适应资源分配。; 大模型与生成式AI在网络运维中的应用：网络自优化、自动规划、故障检测与解释性分析。; 高维稀疏信号下的数据高效学习与跨域迁移：跨数据中心与无线边缘场景的样本效率与鲁棒性。; 硬件-软件协同设计与低功耗AI加速：为数据中心和NextG网络提供高效、实时的AI推理与控制。
海思,Ling 2.0 and Ling-1T: Scaling Knowledge-Enhanced Large Language Models for Reasoning and Efficiency,Expo Talk Panel,TUE 2 DEC,4 p.m.,0.5292859,该团队专注大模型与扩散模型的加速，痛点包括低延迟对话、多模态融合与长上下文推理。Session 的稀疏MoE、混合注意力与高效训练体系正契合，具备推动跨域推理与知识增强落地的潜力。,千亿/万亿参数模型的高效训练系统、稀疏MoE与1F1B调度、FP8流水线; Ling Scaling Law 在跨域推理中的应用与评估; 稀疏注意力+分块缓存实现线性/近线性长上下文推理; 多模态统一特征空间与快速条件生成（文本、图像、草图、深度图）; RL对齐与知识增强在对话与推理中的落地策略
海思,"  → Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free",Oral Paper,THU 4 DEC,3:30-4:30,0.54289615,本会话在缩放点积注意后引入头部门控，提升非线性、稀疏化与长上下文推理能力，并提供MoE与稠密模型的实证对比。对海思在降低推理延迟、实现线性/次线性复杂度方面具有直接技术连接点，且可复用代码资源。,Gate-after-SDPA 的实验对比：不同门控位置、不同头数对性能与训练/推理成本的影响; 研究 softmax 低秩映射中的非线性引入及其对模型能力与稳定性的作用; 实现并评估基于查询的稀疏门控分数，用于调制 SDPA 输出及其对长上下文的影响; 验证稀疏门控对缓解 attention sink、避免激活爆炸以及提升长文本推理的效果; 面向低延迟推理的落地方案：门控注意与分块缓存、快速注意实现的集成与成本优化
海思,  → Large Language Diffusion Models,Oral Paper,FRI 5 DEC,10:00-11:00,0.6646968,本组聚焦大语言模型与扩散模型的加速，Session展示了扩散式语言建模在对话与推理中的潜力及与自回归的对比，能对接团队的低延迟、跨模态融合与长上下文研究需求。,低延迟对话推理的扩散模型优化：采样速度、蒸馏/量化等技术路径; 多模态条件生成的统一特征空间与高效融合策略：文本、图像、草图、深度图的对齐与跨模态注意力设计; 长上下文的高效注意力实现：稀疏注意力、分块缓存与线性/次线性复杂度; SFT后对话指令遵循性提升：在扩散LLMs中的对话管理与上下文保持评估
海思,  → Memory Mosaics at scale,Oral Paper,FRI 5 DEC,10:00-11:00,0.5563355,该团队的低延迟推理、跨模态融合与长上下文处理挑战，与Memory Mosaics在大规模知识存储与快速新任务适应方面的优势高度契合，具备明显协同潜力。,将 Memory Mosaics v2 作为外部记忆模块接入大语言模型架构，评估对长上下文与新任务的推理效率提升。; 研究多模态记忆对齐与跨模态特征空间统一方法，以降低多模态条件生成的延迟。; 探索基于记忆模组的检索-增强推理与稀疏注意力结合策略，达到线性或次线性复杂度的长上下文处理。; 评估和对比数据效率：在一个 trillion token 规模的训练下，Memory Mosaics 与 Transformer 比较的成本、可扩展性、知识存储比。; 硬件友好实现与推理加速：缓存策略、分块处理、并行执行与加速器适配。
海思,  → Boosting Knowledge Utilization in Multimodal Large Language Models via Adaptive Logits Fusion and Attention Reallocation,Oral Paper,FRI 5 DEC,10:00-11:00,0.613363,结合Session中的知识检索增强和输出解耦思路，与海思在低延迟多模态统一特征与长上下文注意力优化目标高度契合，具可操作的对接点。,无训练即插即用的 ALFAR 风格方法在现有大语言模型与多模态工作流中的落地方案; 动态注意力重分配机制的实现与评估，按 query-context 相关性映射跨模态注意力权重; 输出层知识融合：将参数知识与上下文知识解耦并对输出 logits 加权，缓解知识冲突; 多模态特征统一空间的设计与高效对齐，覆盖文本、图像、草图、深度图等模态; 面向长上下文的稀疏注意力与分块缓存策略，追求线性或次线性复杂度并评估时延影响
海思,  → HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models,Oral Paper,FRI 5 DEC,10:00-11:00,0.5497438,HyperET通过超球面实现跨模态多粒度对齐与高效训练，参数更少、成本更低，契合海思对低延迟与统一特征空间的目标，具有明确技术对接点。,在超球面中的跨模态多粒度对齐：动态半径调整和Mobius乘法的实现与评估; 参数高效适配：采用对角、块对角、带状矩阵的可学习映射，用于对齐与微调; 多模态条件的统一表征：图像、草图、深度等模态的层次化对齐损失设计; 与低延迟推理的协同：将超球面对齐作为前端编码，结合缓存/分块策略降低延迟; 长上下文与稀疏注意力的协同研究：探索超球面对齐与稀疏注意力的集成以实现线性/次线性复杂度
海思,  → KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction,Oral Paper,FRI 5 DEC,3:30-4:30,0.55498505,该团队专注大模型加速与多模态推理，KVzip 的跨查询缓存压缩与上下文重建，可显著降低长上下文下的缓存与解码延迟，且具扩展到多模态注意力与对话一致性的潜力。,扩展跨查询缓存到多模态跨注意力，建立文本/图像等模态的统一 KV 表征和缓存策略; 将上下文重建重要性评估与稀疏/分块注意力结合，实现线性或次线性复杂度的缓存剔除; 将 KV 缓存压缩/剔除概念应用于扩散模型的跨注意力以加速条件生成; 与 FlashAttention 等系统结合，优化大上下文（>100k）场景下的解码延迟和内存带宽; 在 LLaMA3.1、Qwen2.5、Gemma3 上进行端到端评估，关注对话一致性、回答质量与检索能力
海思,Workshop on Multi-Turn Interactions in Large Language Models,Workshop,SAT 6 DEC,8 a.m.,0.53497916,该团队专注大语言模型的低延迟对话、跨模态融合与长上下文推理，契合 Session 的多轮交互与对齐、长时序评估等核心议题，有助提炼可落地的多轮任务与评估方法。,长上下文对齐与稳健性维护策略（多轮对齐、长期安全与公平性）; 跨模态条件下的快速统一特征空间与跨模态生成调度; 稀疏注意力与分块缓存的长上下文推理实现（线性/次线性复杂度优化）; 实时低延迟的多轮交互推理架构与对话质量权衡; 面向长时序评估的任务设计、基准数据集与评估指标
计算,Beyond Benchmarks: Rethinking Reasoning in Language Models,Expo Talk Panel,TUE 2 DEC,8:30 a.m.,0.52316386,该团队聚焦高效架构与训推新范式，Session聚焦推理过程与评估方法在跨模态/智能体负载下的表现与局限，能提供硬件成本、低精度推理与未来计算架构演进的前瞻性洞见，帮助团队把握方向，实现跨阶段协同设计的落地路径。,评估推理过程与记忆/检索的区别：设计分步测试、对比干扰项、量化推理成本与可解释性。; 分析低精度训练/推理在推理过程中的成本与瓶颈：内存带宽、数值稳定性、中间结果存储策略。; 面向多模态/智能体负载的硬件需求：研究跨模态信息整合对算力和存储的影响，提出硬件友好的推理路径。; 建立鲁棒的推理评估框架，关注输入扰动、上下文迁移和新任务的泛化能力，避免只看最终答案。; 探讨推理范式的实际设计要点：何时需要显式推理链、如何设计高效近似推理、并与低精度训练信号对齐。
计算,Recent developments in embodied AI,Expo Talk Panel,TUE 2 DEC,4 p.m.,0.51182896,结合具身AI中的多模态大模型、端到端训练与边缘推理，洞察强化学习与长期记忆对计算体系的影响，帮助团队把握高效架构与低精度训推的新范式。,具身AI中的多模态大模型与世界模型的端到端训练与对齐方法; 边缘端的流式推理和高效数据生成在实际场景中的工程化实现; 低精度训推范式及其对计算架构、编译器与硬件的影响; 状态跟踪、长期记忆与跨模态交互的高效表示、推理与评估方法
计算,Distributed Orthonormal Updates for Large-Scale Training,Expo Talk Panel,TUE 2 DEC,4 p.m.,0.545516,该团队专注高效模型架构与训推新范式，此会提供正交更新优化器在分布式训练中的落地经验与实现要点，便于对接其计算系统与低精度训推需求。,正交更新优化器的核心原理、在大规模分布式训练中的稳定性与收敛性分析，以及 Muon 与 Dion 的设计差异与适用场景; 将正交更新落地到现有训练管线的集成方法，包括与混合精度、分布式策略、梯度通信的兼容性与实现步骤; 与 AdamW 等传统优化器的性能对比、在超大规模模型中的速度与收敛性优势与局限性; 低精度训推环境（如 FP16、bf16、INT8）下的稳定性与实现要点，以及对模型精度的影响评估; 面向前沿应用负载（多模态、Agentic、具身等）的适配策略、基准测试与对计算架构的新诉求分析
计算,Ling 2.0 and Ling-1T: Scaling Knowledge-Enhanced Large Language Models for Reasoning and Efficiency,Expo Talk Panel,TUE 2 DEC,4 p.m.,0.59206575,结合 Ling 2.0 的知识增强与高效训练体系，团队可把握跨域推理、混合注意力与 RL 对训推与产业应用的影响，提升对未来计算架构与低精度训练趋势的前瞻性判断。,高效 trillion-parameter 训推流水线：FP8/混合精度、1F1B 调度、MoE 架构对计算系统的影响与优化要点;  Ling Scaling Law 及跨域推理：从规模律出发的模型结构与推理性能需求，指导架构演进方向;  混合注意力与 RL 对齐策略：提升简洁推理、长上下文理解与可信度的实现路径;  行业应用对接与部署评估：金融风险建模、知识驱动代理，以及开源实现（Hugging Face/ModelScope）的落地评估;  低精度训推范式与硬件趋势：MXFP6/NVFP4 等研究方向对下一代芯片算力与精度定义的影响
计算,Rich Sutton_The Oak Architecture: A Vision of SuperIntelligence from Experience,Invited Talk,WED 3 DEC,8:30 a.m.,0.5160768,理由：Oak架构强调持续学习、世界模型与分层规划，与贵团队的高效架构与新训推范式高度契合，能提供自适应步长、在线校验与层级抽象在低精度计算中的落地路径。,自适应元学习步长与在线校验在高效模型训练中的实现; 世界模型与分层规划在低精度、具身/多模态场景中的落地（包括FC-STOMP五步抽象）; 状态与时间的层级化抽象设计及其对计算负载和推理效率的影响; 面向Agentic与多模态应用的持续学习体系评估与验证框架; 计算架构与模型演进的协同预测：提前对硬件/算力需求的对齐与优化
计算,"AI Assistants in the Wild: Agents, Adaptation, and Memory-Augmented Deployment",Expo Workshop,WED 3 DEC,noon,0.50937325,结合边缘部署、持久记忆与代理式多模态负载，聚焦高效架构、低精度训推与记忆系统的持续适应要点，推动从实验到现场部署的落地。,持久记忆系统与检索增强生成的架构设计：如何高效存储、检索并更新用户记忆以实现长期个性化; 面向边缘设备的高效模型设计与低精度推理策略：量化、剪枝、硬件协同优化等在实际代理应用中的应用路径; 代理学习与持续适应：少样本泛化、在线/增量学习、真实场景中的任务推断与自适应能力; 具身-多模态情境下的可信生成与安全约束：降低幻觉、约束感知生成与不确定性安全性评估; 真实世界负载的评估、基线与落地路线：从实验室到现场的评估框架、基准设计与落地实施要点
计算,On Device/Edge AI,Expo Workshop,WED 3 DEC,noon,0.54779166,该团队在高效模型架构与训推新范式方面聚焦边缘计算。此Session聚焦低精度训推、硬件协同、分布式学习与隐私保护等前沿议题，帮助把握计算系统需求的演进与产品化路径。,边缘端轻量化模型架构与软硬件协同设计（量化、剪枝、稀疏性、ExecuTorch/TensorRT优化、iOS优化等）; 低精度训推范式的演进与产品化，面向具身/多模态/RL场景的精度-延迟权衡与应用落地（MXFP6/NVFP4等进展、量化感知训练）; 分布式学习与跨设备协同推理在异构边缘硬件中的架构与实现; 边缘隐私保护训练与安全聚合机制的落地方案; Agentic与多模态前沿工作负载的评估、基准与鲁棒性保障
计算,The Art of (Artificial) Reasoning,Invited Talk,THU 4 DEC,8:30 a.m.,0.5263412,结合大模型推理与小模型提升的对比，聚焦低精度训推对架构的影响、RL在推理中的边界、多模态/具身任务对硬件的新负载，以指引团队在高效架构与训推范式上的设计方向。,小模型推理能力提升与域适应策略的有效性评估（蒸馏/微调/RLHF/领域微调等在具体任务中的对比）; 在推理任务中RL的边界与局限，探索适用于小模型的强化/自监督推理增强设计; 低精度训推对计算架构的影响及硬件友好算法设计（量化、剪枝、训练推理的协同优化）; 多模态/具身AI前沿负载的特征及对存储带宽、并行度与异构计算的需求; 对未来模型结构演进的预测与对接：如何在软硬件栈中建立可迁移的训推范式与系统设计
计算,  → Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies,Oral Paper,THU 4 DEC,10:00-11:00,0.5344502,该团队专注高效模型架构与训推新范式，研讨聚焦通过执行阶段的推理策略突破多智能体强化学习性能天花板，能为低精度推理与资源优化在复杂负载中的应用提供直接启发。,研究执行阶段推理策略在多智能体强化学习中的预算-性能权衡及对比分析; 探索低精度推理对鲁棒性与协作控制的影响，并设计面向异构硬件的实现方案; 评估面向前沿负载（具身、多模态、Agentic”等）推理策略的迁移性与计算架构需求; 基于公开的大规模实验数据与代码，构建可重复性强的推理策略评估基准与基准任务集合
计算,  → Memory Mosaics at scale,Oral Paper,FRI 5 DEC,10:00-11:00,0.52243584,Memory Mosaics大规模可扩展性与新任务推理能力，与团队关注的高效架构和低精度训推需求高度契合，提供记忆增强与软硬件协同的关键技术切入点。,Memory Mosaics v2的架构要点与大规模实现细节（10B规模、1万亿token训练、与Transformer的对比）; 低精度训练与推理的技术路径与硬件影响（量化、混合精度、带宽/内存权衡）; 知识存储评估框架与指标设计（训练知识存储、新知识存储、在上下文中的学习能力的测量）; 真实世界数据集下的扩展与数据效率分析（与8T级Transformer的对比，数据质量与覆盖的影响）; 面向前沿应用负载的场景化研究（Agentic/多模态/具身任务的计算与系统需求）
计算,ML x OR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making,Workshop,SAT 6 DEC,8 a.m.,0.51679033,结合ML×OR在不确定性决策中的方法论，团队聚焦高效模型架构与训推新范式，连接OR建模、序列决策与可解释性，推动低精度推理与前沿负载协同研究。,将OR建模思想嵌入ML工作流的具体实现：随机建模、鲁棒优化、决策规则在神经网络训练和推理中的嵌入; 不确定性编码与量化：预测不确定性、置信区间、鲁棒性评估在数据-模型-决策接口的端到端实现; 面向在线/序列决策的ML方法：在OR视角下的在线学习、时序优化与在线再训练策略; 低精度训练/推理对决策性能的影响及加速策略：混合精度、量化感知训练、精度-延迟权衡分析; 多模态与Agentic负载对计算架构的需求：软硬件协同的资源调度、可解释性与可信性分析，驱动新芯片需求
计算,The First Workshop on Efficient Reasoning,Workshop,SAT 6 DEC,8 a.m.,0.6073207,该团队聚焦高效模型架构与训推新范式，Workshop聚焦低精度训推、数据-算法-系统协同及边缘部署，能直接对应挑战并获取前沿负载与硬件需求的实用洞见。,低精度训推范式对计算架构的影响与实现路径; 资源约束场景的数据、算法与系统协同设计（数据集构建、量化、动态KV-cache放置、量化图执行等）; 前沿负载（Agentic和多模态应用）对计算系统的新诉求及软硬件协同方案; On-device knowledge distillation、轻量化推理与边缘部署的落地策略与评估框架
计算,ML for Systems,Workshop,SAT 6 DEC,8 a.m.,0.5866854,该团队聚焦高效模型架构与训推新范式，Session聚焦将ML应用于系统挑战，尤其是大模型结构演进、低精度训推、以及对计算系统需求的预测，具备直接连接点。,低精度训练/推理与量化对计算架构的影响评估、混合精度策略与模型压缩方案; 面向Agentic与多模态工作负载的建模、预测与资源调度方法; LLM驱动的系统任务（程序合成、自适应优化）中的软硬件协同设计与工作流优化; 可持续计算的能源/功耗/碳效益优化方法、监控与基准体系建设; 软硬件协同设计与系统级基准：新数据结构、内存管理、调度/编译优化，以及对未来芯片需求的前瞻性分析
计算,AI for Science: The Reach and Limits of AI for Scientific Discovery,Workshop,SUN 7 DEC,8 a.m.,0.5168639,该团队专注高效模型架构与新训推范式，能直接支撑跨领域科学推理与高保真仿真器的算力需求，在数据稀缺场景下的实验设计与数据协作也可获益。,跨领域LLM推理评估框架：设计可验证的跨物理、化学、生物领域假设生成与推理指标，促进科学发现的可重复性。; 高保真仿真器的算力需求分析：比较全原子与力场近似在训练与推理中的成本-精度权衡，明确不同尺度的硬件需求。; 数据稀缺与偏差缓解：推动数据协作、联合数据集建设、主动学习与lab-in-the-loop策略，提升极少数据场景的鲁棒性。; 低精度训练推理范式对架构的影响：研究量化、剪枝、混合精度在多模态和具身/强化学习负载中的可用性与实现路径。; 前沿负载对硬件的需求对齐：建立Agentic与多模态应用的基准与测试，指导下一代芯片与系统架构设计。
计算,"Evaluating the Evolving LLM Lifecycle:  Benchmarks, Emergent Abilities, and Scaling",Workshop,SUN 7 DEC,8 a.m.,0.50458,本会聚焦LLM全生命周期评估、基准与扩展能力，与贵队对高效模型架构、低精度训推及前沿负载的研究高度契合，有助把握架构演进对计算系统需求及评估框架的衔接。,全生命周期评估框架设计与统一基准集（从预训练到微调/ RLHF 再到部署的评测指标与流程）。; 低精度训推对计算系统的评估指标与工具链（量化、混合精度、吞吐/功耗/热设计等在不同架构上的表现）。; 负载演化与 emergent 能力的监测与风险评估框架（跟踪新能力、稳定性、偏差与潜在风险的量化方法）。; 多模态/Agentic 负载对软硬件系统的需求对齐与评测（硬件资源分配、软件栈瓶颈、系统级评估指标）。; 数据污染、记忆与隐私风险的统一评估方法（数据污染检测、记忆风险量化、合规性评估）。
计算,Multimodal Algorithmic Reasoning Workshop,Workshop,SUN 7 DEC,8 a.m.,0.5287522,该Session聚焦多模态算法推理与跨模态任务，能帮助团队把握多模态推理对计算架构的负载特征、低精度训推需求，以及Agentic框架对硬件的潜在影响，促进软硬件协同与架构演进对接。,1) 多模态推理的计算/内存负载特征与数据流动分析; 2) 低精度训练与推理在多模态场景中的策略与实现; 3) Agentic与工具使用的推理链路、资源需求与安全性考量; 4) 认知模型在感知-语言-推理之间的评估框架与基准; 5) 面向未来硬件的软件/硬件协同设计路线与评估指标
计算,AI That Keeps Up: Workshop on Continual and Compatible Foundation Model Updates (CCFM),Workshop,SUN 7 DEC,8 a.m.,0.50629205,该团队专注高效架构与训推新范式，与CCFM强调成本可控更新、动态评估和一致用户体验的核心议题高度契合，能为理解模型演进对计算系统的影响提供前瞻性洞察。,成本可控的持续更新与遗忘抑制策略; 面向模型演进的动态评估框架与基准设计; 计算架构与训推范式的协同设计与低精度训练/推理对硬件影响分析（含多模态/具身应用场景）; 模型版本化与无缝更新流水线（版本管理、回滚、对比分析、用户体验一致性）; 对未来模型结构演进的负载预测与硬件规划的前瞻性研究
温哥华云,Who Needs Attention Anyway? Real-Time Control from Learned State Geometry,Expo Demonstration,TUE 2 DEC,noon,0.5003938,本演示将时序模型与几何规划结合的实时控制，强调低延迟、稳定性与安全性。对团队在强化微调与具身AI方向、将RL落地生产、提升样本效率的目标，提供明确的对接点与落地路径。,基于在线学习的状态空间几何建模：曲率估计、测地线更新与信赖域约束; 设备端实时控制的固定计算预算与延迟保障：在具身AI场景中的稳定性与自适应边界; 通过几何信息增强的强化学习安全性与稳定性：利用局部曲率约束动作以确保策略安全; 面向具身AI的生产落地实践：桥接理论与生产差距、提升样本效率与在华为云上的可扩展性; 在动态环境中的几何引导SSM-RL控制器的评估与基准测试
温哥华云,Agentic AI/RL,Expo Talk Panel,TUE 2 DEC,4 p.m.,0.54045904,该团队专注RFT与具身AI，旨在云端落地RL策略。Session围绕大规模环境框架、环境–训练器对接、样本效率与后训练工作流等议题，能提供生产化工具链、标准化接口与鲁棒性评估的直接对接点，助力华云落地环境–模型协同。,大规模环境框架与生态系统对接、标准化接口; 环境–训练器无缝集成与复现性; 样本效率提升与后训练工作流（奖励塑形、数据反馈循环）; 具身AI/多模态在云端的生产化落地路径; 高性能仿真器在异构硬件上的优化与可扩展性
温哥华云,The Art of (Artificial) Reasoning,Invited Talk,THU 4 DEC,8:30 a.m.,0.50011945,本场聚焦推理能力、分层规模与小模型提升策略，与团队的强化学习微调（RFT）及嵌入式AI在生产落地、样本效率与可扩展性方面的需求高度契合，便于理论到实践的对接。,针对小模型的强化学习微调（RFT）中的奖励设计、样本效率提升与鲁棒性训练策略（如自我一致性、链式推理）; 多模态/嵌入式环境中的推理加强与行为决策：将推理能力应用于 Embodied AI 任务; 离线/在线混合的样本高效学习框架，模型基于计划与模型预测的领域适应; 从仿真到生产的工程化管线：数据管控、监控、可观测性、部署与合规性; 对比分析规模化与小模型策略的优劣，制定 domain-specific 的鲁棒推理方法
温哥华云,"Evaluating the Evolving LLM Lifecycle:  Benchmarks, Emergent Abilities, and Scaling",Workshop,SUN 7 DEC,8 a.m.,0.50619805,本研讨会聚焦从预训练到后训练的评估、强化学习微调（RFT）与基线对比，能帮助团队将RFT落地云端，提升评估体系、样本效率与可扩展性，并探讨模态与实体AI的评估挑战。,RLFT评估设计与对齐：奖励建模、策略优化、离线-在线评估的一致性与样本效率; 数据治理与数据污染/记忆化评估框架：数据分割、对抗性测试、隐私与泛化; 生产化评估框架与云端落地：在华为云上的成本、延迟、可观测性与反馈回路监控; Embodied AI与跨模态评估基准：仿真到现实的评估、感知-控制耦合与鲁棒性
温哥华云,Workshop on Scaling Environments for Agents,Workshop,SUN 7 DEC,8 a.m.,0.5350335,SEA工作坊聚焦可扩展、丰富的环境对智能体学习的影响，与贵团队RFT与嵌入式AI目标直接相关，聚焦环境设计、样本效率、仿真到部署等关键议题，助力在华为云落地。,可扩展的仿真环境架构与云端集成，支持嵌入式AI/ RFT 在华为云上的规模化仿真与数据管线; 以样本效率为导向的 RL/LLM 结合策略（如世界模型、离线数据混合在线微调）在嵌入式环境中的应用; Sim2Real 与部署管线：从仿真到真实设备的迁移、延迟与成本优化，覆盖端到端工作流; 环境基准与评估框架：面向端到端自主性与长期规划的跨环境可重复评估
多伦多云,Planning in the Era of Language Models,Tutorial,TUE 2 DEC,9:30 a.m.,0.5368242,本次Session将规划原理融入LLM代理，直接对接团队在评估覆盖、写操作可靠性与持续优化的需求，提供可落地的多步执行与验证框架。,将自动化规划形式与LLM代理的任务分解、行动模型、约束条件对齐，形成可执行的代理架构; 为代理评估设计统一的子项与覆盖范围框架，覆盖通用性、领域专用性与可重复性; 在写操作与执行环节引入前置/后置条件、执行监控、异常回滚等验证机制以提升可靠性; 利用规划驱动的持续学习循环，建立Prompt与模型优化的协同“飞轮”以提升L3+代理的自我优化能力; 设计面向多步执行的鲁棒代理架构，包括计划-执行-监控-恢复的闭环与可解释性机制
多伦多云,BeeAI,Expo Demonstration,TUE 2 DEC,noon,0.5933649,BeeAI 的确定性代理设计与规则化执行框架，能直接映射到团队对评估覆盖、写操作可靠性和上线后持续优化的需求，尤其适合实现跨模型的一致执行与可验证性。,将 RequirementAgent 的确定性执行与规则约束整合到评估子项设计，定义跨领域的覆盖指标与测试用例; 建立面向写操作的可控性与可审计机制：声明性约束、行为校验、变更审计与回滚能力; 设计上线后的自主学习与持续优化机制，结合计划与多步执行能力的迭代与落地; 实现跨模型一致性与多步计划执行的对齐：统一推理差异处理、工具调用规范和可追溯的执行轨迹
多伦多云,Agentic AI/RL,Expo Talk Panel,TUE 2 DEC,4 p.m.,0.5417606,该团队可借助可扩展的 RL 环境、评估基准与环境–训练器一体化设计，提升评估覆盖、写操作可靠性，并建立上线后持续学习与优化闭环。,可扩展的高性能 RL 环境框架与跨硬件仿真优化（多任务/多智能体、异构硬件）; 安全性与鲁棒性评估基准的系统化设计，明确通用子项与领域知识子项的覆盖范围; 环境–训练器/推理引擎的一体化集成，关注写操作的原子性、可重复性与验证管线; 上线后的持续学习与自适应优化机制，整合奖励塑形、提示工程与多步规划能力的迭代
多伦多云,Multi-Agent Systems in Industry: From Research to Real-World Impact,Expo Workshop,WED 3 DEC,noon,0.60204893,该团队聚焦评估覆盖、可靠性与上线后优化，与Session的产业落地、可扩展性及人机协作主题高度契合，便于对接实际部署与评估框架。,人机协作设计与评估指标体系（包括任务分解、人机协同决策、透明度与可解释性评估）; 可扩展的多代理架构与协调/任务分配机制，面向大规模工业应用的可扩展性与鲁棒性; 安全性、可信性与可验证性：代理行为的监控、写操作的可靠性保障、治理与审计管线; 上线后自适应学习与持续优化：持续学习循环、提示优化飞轮与模型优化飞轮的耦合实现，L3+规划与多步执行能力; 面向领域的部署模式与评估框架：软件工程、科学研究、创意内容等的实际案例、度量标准与成功要点
多伦多云,Workshop on Scaling Environments for Agents,Workshop,SUN 7 DEC,8 a.m.,0.5375316,本Session聚焦可扩展、丰富交互的环境对代理学习与自我优化的作用，与贵团队在评估覆盖、写操作可靠性、持续优化与规划执行能力的关注点高度吻合，可为其提供评估基线与环境设计方向。,环境基线与评估框架设计：评估覆盖面、通用子项与领域知识子项的构建与基线指标; 环境工具箱与写操作鲁棒性：工具接口设计、原子性/幂等性、审计与可追溯性; 端到端强化学习的互动环境训练框架：高保真环境、长序列规划、奖励设计与自我改进机制; 在线学习与持续优化循环：在线学习机制、提示-模型优化轮回的耦合、持续性能提升; Sim2Real与部署鲁棒性：从仿真到实际部署的泛化能力、鲁棒性评估与安全性要求
诺亚,Beyond Benchmarks: Rethinking Reasoning in Language Models,Expo Talk Panel,TUE 2 DEC,8:30 a.m.,0.51037323,本场聚焦推理过程与评估偏差，与你们在大模型长序列推理、记忆更新与Latent Reasoning的研究方向高度契合，能启发推理策略、分解式求解及跨模态推理的落地方法。,长序列推理的高效架构演化与缓存/计算量优化（如高效自注意力、分段处理、按需记忆）; 测试时推理策略与内存更新机制的改进（自我校验、分步推理、动态记忆写入/清理策略）; 长序列图文多模态推理的输入范式与跨模态融合优化（提升长文本与图像/视频的协同推理能力）; 自博弈与经验学习框架在推理策略演化中的应用（Latent Reasoning、RL从经验学习）; 评估方法与基准设计（聚焦推理过程而非仅给出答案，验证鲁棒性与泛化）
诺亚,Recent developments in embodied AI,Expo Talk Panel,TUE 2 DEC,4 p.m.,0.5228103,团队在大模型长序列与多模态推理方面具备扎实积累，Session 的嵌入式AI、边缘推理、端到端训练与长期记忆议题，与其自博弈、经验学习及 Latent Reasoning 的研究方向高度契合，便于技术对接。,长序列多模态模型的高效架构与上下文管理（优化注意力、层次记忆、缓存机制）; 边缘端流式推理与记忆更新策略（内存更新机制、推理策略、缓存一致性）; 长序列数据的端到端训练与数据生成（视频-文本对齐、自监督与 RL 训练流程）; Latent Reasoning 与自博弈在嵌入式任务中的应用（隐变量规划、世界模型、因果推理）; 状态跟踪与长期记忆的稳健性及 grounding 的评估指标设计
诺亚,Ling 2.0 and Ling-1T: Scaling Knowledge-Enhanced Large Language Models for Reasoning and Efficiency,Expo Talk Panel,TUE 2 DEC,4 p.m.,0.5544546,该团队在大模型长序列与跨模态推理领域具前沿，Ling 2.0 的稀疏MoE、知识增强与高效训练体系能与其自博弈与学习经验框架直接对接，利于落地与方法对齐。,长序列下的稀疏MoE扩展与参数分布策略及对齐训练; FP8混合精度下的1F1B调度与缓存优化对吞吐与精度的影响分析; 跨模态长文本推理中的输入范式设计与长上下文记忆管理; 知识增强与跨域推理的知识源对齐、混合注意力与RL-based对齐策略; 自博弈与学习经验训练框架在长序列记忆更新与 Latent Reasoning 的应用与评估
诺亚,"AI Assistants in the Wild: Agents, Adaptation, and Memory-Augmented Deployment",Expo Workshop,WED 3 DEC,noon,0.57123876,该团队专注长序列与多模态推理，Session聚焦边缘部署中的持久记忆、检索增强与自我学习。可对接其内存更新、跨模态缓存与学习策略，提升代理在长期任务中适应性与稳健。,持久记忆架构与检索增强生成，支持长期个性化代理行为; 内存更新策略与持续学习在长时序多模态中的应用; 边缘设备长上下文建模：高效注意力、缓存与跨模态输入压缩; 约束下的安全性和可控性：去幻觉、约束感知生成与代理学习框架
诺亚,The Art of (Artificial) Reasoning,Invited Talk,THU 4 DEC,8:30 a.m.,0.51473135,团队专注长序列与多模态推理、后训练推理强化与 RL。聚焦推理边界与小模型对齐，能提供落地的推理策略、记忆更新与 Latent Reasoning 启发，契合度高。,长序列原生架构的精度/缓存/计算量优化策略（如分段推理、层次注意力、缓存设计、量化与剪枝）; 测试阶段推理策略与模型内置记忆更新机制（跨会话记忆、记忆对齐、可解释的推理过程）; 长文本图文多模态输入范式与跨模态长文本推理瓶颈突破（输入分块、跨模态对齐、长期依赖建模）; 自博弈与学习自经验训练框架在后训练中的推理能力提升（Latent Reasoning 融合、RL 在推理中的应用、评测标准）; 小模型对齐与鲁棒性提升及评测方法（对齐指标、跨域鲁棒性、与大模型推理对齐的验证）
诺亚,  → Learning to Learn with Contrastive Meta-Objective,Oral Paper,THU 4 DEC,3:30-4:30,0.50397974,该会议以任务身份对比监督的元学习目标为核心，能为诺亚团队在长序列/多模态模型的自博弈与经验学习框架中提供高效的任务区分信号与泛化提升路径，且实现成本较低。,将对比元目标与长序列多模态记忆/推理的结合点设计与实现; 在自博弈与经验学习框架中融入任务分布条件化的元训练; 优化记忆更新与缓存策略，使对比信号推动记忆/推理组件的改进; 跨模态对齐与表示一致性：利用任务身份对比提升文本-图像等模态的协同学习; 设计面向长序列/多模态任务的元训练评估基准、指标与数据分布，验证泛化与鲁棒性
诺亚,  → EvoLM: In Search of Lost Language Model Training Dynamics,Oral Paper,FRI 5 DEC,10:00-11:00,0.5806896,结合团队对长序列多模态和后训练的关注，EvoLM提供跨阶段的系统训练动态评估、遗忘缓解与跨阶段桥接策略，并提供可复现实验资源，便于优化推理能力与RL应用。,长序列多模态模型在跨阶段训练中的遗忘缓解与记忆更新策略研究; 跨阶段桥接：如何利用继续预训练和RL提升长序列推理能力，同时评估计算/缓存成本权衡; 自博弈与 Latent Reasoning 在大模型长序列任务中的应用设计、评估指标与可复现实验; 面向多模态长文本的推理计算瓶颈及输入范式改进，探索更高效的记忆与推理机制
诺亚,  → Large Language Diffusion Models,Oral Paper,FRI 5 DEC,10:00-11:00,0.5776237,结合团队对长序列与多模态的关注，LLaDA的扩散式语言建模提供新的推理与记忆更新路径，并与 Latent Reasoning、自博弈 等方向具直接技术连接。,长序列扩散LM的架构与优化：研究注意力、缓存和算力权衡，在不显著牺牲精度的前提下扩展序列长度; 测试时推理策略与记忆更新机制：设计高效的推理流程与内置历史记忆的更新规则; 长序列多模态对齐与推理：探讨输入范式下的图文跨模态对齐与长期文本推理瓶颈的突破方法; 自博弈与 learning from experience 在扩散LM中的实现：将自博弈与经验学习融入扩散LM训练与微调框架; Latent Reasoning 的整合与评估：在扩散框架中嵌入潜在推理路径，并建立可解释性与鲁棒性评估机制
诺亚,  → Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?,Oral Paper,FRI 5 DEC,10:00-11:00,0.5353041,"该团队专注大模型后训练推理与RL,Session深入探讨RLVR是否真正为LLM注入超越基座模型的推理能力,可为团队的自博弈与经验学习框架提供实证依据与理论验证,助力Latent Reasoning的落地。",RLVR对基座模型推理能力边界的影响评估与实证分析; 自博弈与learning from experience在RLVR中的作用机制与实现路径; Latent Reasoning在强化学习微调中的嵌入方式与性能提升; 数学与编程任务中推理能力的持续自我改进策略与评估框架; RLVR训练后的长序列推理稳定性与记忆更新机制的协同优化
诺亚,  → Memory Mosaics at scale,Oral Paper,FRI 5 DEC,10:00-11:00,0.62026626,"Memory Mosaics在大规模下的记忆存储与快速任务适应能力,与团队在长序列记忆更新机制、测试时推理策略的研究目标高度契合,可为长序列架构演进与多模态记忆管理提供新范式。",Memory Mosaics v2的大规模架构设计与长序列记忆存储优化策略; 测试时推理策略与内置记忆更新机制的协同设计与实现; 万亿token训练下的知识存储效率与在上下文学习能力评估; 多模态长序列记忆对齐与跨模态知识检索增强方案; 长序列推理中的缓存优化与计算量权衡分析
诺亚,  → Boosting Knowledge Utilization in Multimodal Large Language Models via Adaptive Logits Fusion and Attention Reallocation,Oral Paper,FRI 5 DEC,10:00-11:00,0.5671382,"该Session的自适应注意力重分配与知识融合机制,直接对应团队在多模态长序列推理与记忆更新的挑战,能为突破多模态长文本推理瓶颈提供可操作的技术路径。","无训练自适应注意力重分配在长序列多模态推理中的应用与评估; 参数知识与上下文知识的解耦融合策略,缓解知识冲突与提升检索增强效果; 多模态长文本输入范式的优化设计,降低计算瓶颈; 跨模态注意力权重的动态分配机制与长序列一致性保障; 检索增强生成在多模态大模型中的记忆更新与推理策略"
诺亚,  → HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models,Oral Paper,FRI 5 DEC,10:00-11:00,0.5531186,"HyperET在超球面空间实现跨模态多粒度对齐与参数高效训练,与团队在多模态长序列架构优化、计算量缓存维度的研究目标契合,能提供高效训练与跨模态对齐的新思路。",超球面空间中的跨模态多粒度对齐与层次化表征设计; 参数高效训练策略(对角、块对角、带状矩阵)在长序列多模态模型中的应用; 长序列图文多模态推理的输入范式优化与计算瓶颈突破; 超球面对齐与长序列记忆更新机制的协同设计; 多模态大模型训练成本与对齐质量的权衡分析
诺亚,The First Workshop on Efficient Reasoning,Workshop,SAT 6 DEC,8 a.m.,0.6212126,"该Workshop聚焦大型推理模型的训练与推理效率瓶颈,与团队在长序列架构优化、测试时推理策略及后训练推理强化的研究方向高度契合,能获取前沿的数据、算法与系统协同方案。","测试时推理缩放(test-time scaling)的效率优化策略与长序列适配; 数据、算法与系统协同设计,突破计算、内存、延迟与成本约束; 长序列原生架构在大型推理模型中的演进趋势与实现要点; 自博弈与learning from experience在高效推理训练中的应用; Latent Reasoning的落地路径与可部署性评估框架"
诺亚,Workshop on Multi-Turn Interactions in Large Language Models,Workshop,SAT 6 DEC,8 a.m.,0.56014985,"该Workshop聚焦LLM多轮交互中的长时序建模与动态决策,与团队在长序列记忆更新、测试时推理策略的挑战直接相关,能提供长期交互中的记忆管理与推理稳定性的实用方案。",多轮交互中的长序列记忆更新机制与状态跟踪策略; 长时序对话的测试时推理策略与上下文一致性保障; 多模态长序列交互的输入范式设计与计算优化; 跨轮次的记忆对齐与知识累积的鲁棒性评估; 长时序交互任务的评估基准与指标设计
诺亚,"Evaluating the Evolving LLM Lifecycle:  Benchmarks, Emergent Abilities, and Scaling",Workshop,SUN 7 DEC,8 a.m.,0.553464,"该Workshop覆盖LLM全生命周期评估与后训练技术(如RLHF),与团队在大模型后训练推理、RL及长序列架构演进的研究高度契合,能获取评估框架与方法论的前沿洞见。","后训练推理(RLHF/RLVR)的评估方法与基准设计,覆盖长序列与多模态场景; 长序列架构演进中的涌现能力监测与性能评估框架; 自博弈与learning from experience的评估指标与可重复性验证; 测试时推理策略与记忆更新机制的评估标准与工具链; 多模态大模型全生命周期的鲁棒性与泛化能力评估"
诺亚,Multimodal Algorithmic Reasoning Workshop,Workshop,SUN 7 DEC,8 a.m.,0.5654487,"该Workshop聚焦多模态算法推理与跨模态任务,与团队在多模态长序列推理、输入范式突破及后训练推理的研究方向契合,能获取跨模态推理的认知模型与评估框架。","多模态算法推理的认知模型与跨模态推理链路设计; 长序列图文多模态推理的输入范式优化与计算瓶颈突破; 感知-语言-推理的端到端建模与多粒度对齐策略; 多模态推理的评估基准与指标,覆盖长序列与复杂任务场景; 跨模态知识整合与记忆更新在算法推理中的应用"
诺亚,Workshop on Scaling Environments for Agents,Workshop,SUN 7 DEC,8 a.m.,0.517919,"该Workshop强调环境对智能体学习的关键作用,与团队在长序列推理、自博弈与经验学习框架的研究目标契合,能为基于环境交互的持续学习与推理优化提供新视角。","可扩展环境架构对长序列推理与记忆更新的支持设计; 自博弈与learning from experience在大规模环境中的训练框架与评估; 长时序决策任务的推理策略与环境交互的协同优化; Latent Reasoning在端到端自主性与长期规划中的应用; 环境基准与评估框架,覆盖多模态与长序列智能体任务"
