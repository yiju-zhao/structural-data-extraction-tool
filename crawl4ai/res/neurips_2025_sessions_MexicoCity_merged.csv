date,time,type,title,url,speaker,end_time,abstract,overview,matched_team,recommendation_reason,focus_area
"Sunday, Nov 30, 2025",11:00,Workshop,NeurIPS 2025 Workshop on Socially Responsible and Trustworthy Foundation Models,https://neurips.cc/virtual/2025/workshop/127834,,18:00,"The Socially Responsible and Trustworthy Foundation Models (ResponsibleFM) Workshop at NeurIPS 2025 Mexico City is envisioned as a vital interdisciplinary forum dedicated to advancing ethical, inclusive, and socially conscious research practices in the rapidly evolving field of foundation models, including language models and multimodal models. As foundation models are tremendously reshaping human communication, decision-making, and societal infrastructures, there is a growing recognition of the profound impacts these systems can have, both positive and negative, on individuals and communities. In particular, previous research has documented a wide range of risks and harms associated with foundation models, including but not limited to bias and discrimination, misinformation propagation, privacy violations, environmental concerns, and unintended social consequences.","Overview: The ResponsibleFM Workshop is an interdisciplinary forum focused on advancing ethical, inclusive, and socially responsible research in foundation models, including language and multimodal models. It aims to address fairness, accountability, transparency, and safety throughout model development and deployment, proactively tackling ethical and social risks. The workshop brings together researchers, practitioners, ethicists, policy-makers, and affected communities to catalyze methods and best practices ensuring foundation model research serves the common good. The event is scheduled to be held in hybrid mode, both virtually and at the Hilton Mexico City Reforma, during NeurIPS 2025. | Research Interests: Defining & Measuring Trustworthiness, Techniques to Enhance Trustworthiness, Deployment & Social Good, Datasets & Benchmarks, Interdisciplinary Perspectives & Governance",,,
"Sunday, Nov 30, 2025",11:00,Workshop,NeurIPS 2025 Workshop on Embodied and Safe-Assured Robotic Systems,https://neurips.cc/virtual/2025/workshop/127833,,18:00,"This workshop focuses on advancing safe and quality-assured embodied robotic systems. Embodied systems—including autonomous robots, self-driving vehicles, robotic arms, and humanoid robots—are increasingly deployed in safety-critical real-world scenarios. Ensuring their trustworthiness—encompassing safety, reliability, and predictable behavior—remains a pressing challenge. Despite notable progress in perception, reasoning, and control, many AI-based robotic systems still operate as “black boxes,” often exhibiting unpredictable behaviors. Failures can emerge from complex sensorimotor interactions, adversarial inputs, or novel environments, leading to safety incidents and diminished user trust.",,温哥华云,温哥华云: 该团队关注于2026年物理或具身AI领域的关键发展。NeurIPS 2025 Workshop强调具身机器人系统的安全性和可靠性，正契合该团队识别战略性增长领域的需求。通过参与，团队可深入了解安全核保证技术，助力关键研究方向的布局。,温哥华云: 具身机器人系统的安全性保障方法; 自动驾驶及自主机器人中的可靠性算法; 传感器和环境交互的复杂性处理; AI系统的可解释性与透明度提升; 应对对抗性输入及未知环境的鲁棒性技术
"Sunday, Nov 30, 2025",11:00,Workshop,NeurIPS2025 Workshop Research Development AI Mexico,https://neurips.cc/virtual/2025/workshop/127832,,18:00,"The Research Development of AI in Mexico: Main Applications workshop seeks to showcase, strengthen, and connect the most impactful developments in Artificial Intelligence (AI) and Data Science emerging from Mexico and the broader Latin American region. Over the past four decades, Mexico has cultivated a robust research community in AI through pioneering contributions in areas such as computational intelligence, autonomous robotics, fuzzy systems, and natural language processing, led by institutions including CIC–IPN, INAOE, UNAM, ITESM, CINVESTAV, and Universidad Veracruzana.Today, the region is undergoing a strategic transformation, shifting from foundational research to the development of applied AI technologies addressing real-world needs in healthcare, education, agriculture, smart cities, cybersecurity, and sustainability. This evolution has been further propelled by increased access to open data, advances in computing infrastructure, and growing collaborations between academia, government, and industry.Despite these advances, Latin America faces distinctive challenges in the development and deployment of AI. These include limited funding, underrepresentation in global AI initiatives, digital inequality, and the need for responsible, inclusive, and culturally relevant AI systems. Additionally, emerging concerns related to AI ethics, algorithmic bias, and regulatory frameworks must be addressed proactively to ensure equitable and trustworthy technology adoption.This workshop aims to create a forum for researchers, students, practitioners, and policymakers to engage in meaningful dialogue about the current landscape and future directions of AI in Mexico and Latin America. By promoting interdisciplinary collaboration, the workshop will highlight impactful case studies, emerging research trajectories, and opportunities for cross-border cooperation, while fostering a shared vision for AI that is ethical, sustainable, and aligned with regional priorities.",,温哥华云,温哥华云: 该Session聚焦拉美地区AI应用和技术发展，强调跨学科合作与实际应用，契合温哥华云对物理或具象AI关键研究领域的战略投资需求。通过参与，团队可探索具象AI在医疗、教育等地面应用的创新潜力。,温哥华云: 具象AI在医疗健康和教育领域的应用; 跨学科合作促进AI技术转化; 负责任且具文化相关性的AI系统设计; 数据开放与基础设施提升助力AI发展; 区域性AI伦理与算法偏见问题
"Sunday, Nov 30, 2025",11:00,Workshop,Vision Language Models: Challenges of Real World Deployment,https://neurips.cc/virtual/2025/workshop/127831,,18:00,"Vision language models (VLMs) have demonstrated remarkable capabilities in integrating visual perception with natural language understanding, powering applications such as multimodal assistants, robotics, autonomous systems, and accessibility tools. However, their real-world deployment faces significant challenges in efficiency, scalability, and reliability. This workshop will bring together researchers and practitioners from academia and industry to highlight cutting-edge research, systems-level optimizations, and evaluation methodologies that are often overlooked yet pivotal for robust real-world integration. Efficiency, robustness, and reliability will be emphasized as core design principles, essential to advancing VLMs from experimental systems to dependable deployed technologies. By convening researchers at the intersection of multimodal learning, efficient inference and training, robustness and uncertainty estimation, and large-scale systems design, the workshop aims to establish concrete pathways toward building VLMs that can operate reliably under practical constraints. We hope this workshop will serve as a venue for exchanging insights on model design, efficiency techniques, and robustness evaluation that bridge the gap between research and real-world systems.","Overview: The VLM4RWD NeurIPS 2025 Workshop focuses on the challenges of deploying Vision Language Models (VLMs) in real-world applications. It aims to bring together researchers and practitioners to discuss cutting-edge research, systems-level optimizations, and evaluation methodologies essential for the efficient, scalable, and reliable deployment of VLMs. The workshop emphasizes the importance of efficiency, robustness, and reliability in advancing VLMs from experimental systems to dependable technologies. | Research Interests: Data pipelines for efficient multimodal learning, Accelerating VLMs inference, Compression and distillation for VLMs deployment, Sparse, modular, and retrieval-augmented VLM architectures, Efficient training for complex reasoning tasks, Robust training and evaluation of VLMs, Benchmarks for deployment-oriented evaluation, Mitigating hallucination and improving multimodal grounding, Agentic VLMs for real-world integration",诺亚,诺亚: 该团队在长序列图文多模态模型演进方面深耕，正对应Session关注的高效、可靠的多模态模型部署需求。参与本Workshop有助于借鉴先进的输入范式优化及推理计算突破方案，提升实际系统适用性。,诺亚: 突破多模态长文本推理计算瓶颈的输入范式创新; 加速VLMs推理与训练效率的系统级优化; 压缩与蒸馏技术以适配部署资源限制; 增强模型鲁棒性与不确定性评估方法; 多模态推理中的错误缓解与多模态对齐
"Monday, Dec 1, 2025",06:00,Workshop,Centering Low-Resource Languages and Cultures in the Age of Large Language Models,https://neurips.cc/virtual/2025/workshop/127830,,15:00,"Large Language Models (LLMs) have transformed NLP research and applications, yet they are still predominantly trained on high-resource, globally dominant languages. This imbalance leads to poor performance and limited applicability for low-resource languages, which are rich in tone, morphology, and cultural meaning. As a result, current AI systems risk reinforcing linguistic inequality, cultural erasure, and lack of accessibility in critical domains like education and healthcare.This workshop aims to reframe language technology by centering low-resource languages, cultures, and epistemologies in the age of LLMs. We seek to bring together researchers, linguists, developers, healthcare professionals, and technologists to share insights and develop strategies for building inclusive, culturally grounded, and linguistically robust language models. The workshop emphasizes collaboration across disciplines and regions to ensure both technical advancement and social relevance.Key areas of focus include developing LLM architectures tailored to low-resource linguistic features, ethical and community-centered dataset collection, and multilingual benchmarks designed specifically for underrepresented languages. We also highlight the importance of healthcare and medical machine translation to support equitable access to information and improve public health outcomes. Ultimately, this workshop aims to advance responsible AI innovation that empowers low-resource language communities and shapes a more inclusive future for global language technologies.","Overview: The CLRLC-LLMs Workshop at NeurIPS 2025 focuses on the role of Large Language Models (LLMs) in promoting multilingual and culturally inclusive AI. It addresses the underrepresentation of low-resource languages and cultures in AI research and development. The workshop aims to reframe language technology discussions by centering low-resource languages and cultures in AI innovation. It brings together researchers, linguists, developers, and technologists to share insights, challenges, and strategies for developing LLMs that support linguistic diversity and cultural identity, particularly in Africa and parts of Asia. The workshop promotes global collaboration, scalable data creation, model alignment, and ethical evaluation of LLMs, inspiring interdisciplinary research across linguistics, computer science, and engineering. | Research Interests: LLMs for low-resource languages, Culturally grounded NLP and multilingual evaluation, Dataset creation, curation, and benchmarks for African, Indigenous, and marginalized languages, Cross-linguistic transfer and model adaptation, Ethical, social, and policy dimensions of language technologies, Community-based and participatory AI approaches, Speech, ASR, and translation in low-resource settings, Human–AI interaction for linguistic and cultural inclusivity, Cognitive or sociolinguistic perspectives on AI and language, Healthcare and Biomedical Machine Translation for Low-Resource Languages",,,
"Monday, Dec 1, 2025",06:00,Workshop,NORA: The First Workshop on Knowledge Graphs & Agentic Systems Interplay,https://neurips.cc/virtual/2025/workshop/127827,,15:00,"Agents have experienced significant growth in recent years, largely due to the rapid technological advancements of Large Language Models (LLMs). Although these agents benefit from LLMs' advanced generation proficiency, they still suffer from catastrophic forgetting and a limited context window size compared to the agents' needs in terms of contextual information.  Knowledge Graphs (KGs) are a powerful paradigm for structuring and managing connected pieces of information while unlocking deeper insights than traditional methods. Their value is immense for tasks that require context, integration, and reasoning. However, this power comes at the cost of significant upfront and ongoing investment in construction, curation, and specialized expertise.   The first version of this workshop aims at analyzing and discussing emerging and novel practices, ongoing research and validated or deployed innovative solutions that showcase the growing synergy between LLMs agents and KGs.","Overview: The NORA 2025 workshop focuses on the interplay between Knowledge Graphs (KGs) and agentic systems, particularly those enhanced by Large Language Models (LLMs). The workshop aims to explore emerging practices, research efforts, and innovative solutions that demonstrate the synergy between LLM agents and KGs. It addresses the challenges faced by agents, such as catastrophic forgetting and limited context window size, and highlights the potential of KGs in structuring and managing information for improved reasoning and integration. | Research Interests: Agentic and Knowledgeable Systems with Small Language Models, Agentic Information Extraction and Retrieval, Agentic KG Construction & Enrichment, Agents for Complex Reasoning over KGs, Agents and KGs for private and proactive personal assistants & Personalisation, Augmenting Agents with External Knowledge, Collaborative Agents for Knowledge Computing and Serving, Context Engineering enhanced by KGs, Efficient Reinforcement Learning for better performance, Graph Retrieval Augmented Generation in Agentic systems, KGs serving agents’ memories: episodic, semantic, and procedural, Multi-Lingual & Multi-modal integrations, On-Device or Hybrid (Device-Cloud) systems combining Agents and KGs, Personalisation via Agents and KGs, Personas and digital twins enabled by Agents and KGs, Theoretical and experimental analysis of close and open Domain applications scenarios",,,
"Monday, Dec 1, 2025",06:00,Workshop,7th International Workshop on Large Scale Holistic Video Understanding: Toward Video Foundation Models,https://neurips.cc/virtual/2025/workshop/127828,,15:00,"This workshop aims to advance the field of video understanding by fostering discussions around holistic and generalist video foundation models. Building upon the Holistic Video Understanding (HVU) initiative and dataset introduced in 2019, we have successfully organized eight HVU workshops and tutorials at top-tier venues such as CVPR and ICCV, uniting researchers, practitioners, and students from around the world. These efforts have played a central role in moving the community beyond narrow action recognition tasks toward multi-faceted, semantic, and generalist video understanding.With the emergence of large-scale foundation models and video large language models (Video-LLMs), the landscape of video understanding is rapidly evolving. These models enable unified reasoning across spatial, temporal, and multimodal dimensions, yet introduce new challenges in scalability, efficiency, interpretability, and responsible deployment.The HVU Workshop 2025 will provide a platform to explore these frontiers, discussing topics such as multimodal representation learning, long-context reasoning, evaluation of general-purpose video systems, efficient adaptation and scaling laws, and the ethical and societal implications of video AI. Our goal is to bring together a diverse and inclusive community to define the next chapter of holistic, generalist, and responsible video understanding.",,诺亚,诺亚: 本Session聚焦长序列多模态视频理解，与团队在长序列图文多模态模型推理计算瓶颈的挑战高度契合，能助力突破输入范式瓶颈，提升多模态推理能力。,诺亚: 多模态表示学习方法; 长序列视频与文本的联合建模; 视频与语言模型的扩展与适应技术; 多模态大规模基础模型的高效推理; 视频AI的伦理与责任问题
"Monday, Dec 1, 2025",06:00,Workshop,First Workshop on LLM Persona Modeling,https://neurips.cc/virtual/2025/workshop/127829,,15:00,"Large language models (LLMs) are increasingly used to simulate human-like personas for applications in research, education, healthcare, and interactive AI systems. While such persona modeling creates opportunities for interdisciplinary innovation, it raises challenges around authenticity, consistency, bias, and ethical deployment. This workshop brings together perspectives from AI, psychology, cognitive science, and human–computer interaction to advance robust methods, standardized evaluation frameworks, and responsible practices for persona modeling in LLMs. Through invited talks, panels, posters, and discussions, the event will chart a roadmap for interdisciplinary collaboration and future research in this emerging area.","Overview: The PersonaLLM workshop, part of NeurIPS 2025, focuses on the modeling of personas using large language models (LLMs). It aims to explore the creation of human-like personas with consistent traits and behaviors, leveraging LLMs' adaptability across diverse contexts. The workshop seeks to provide an interdisciplinary forum for discussing the conceptualization, evaluation, and ethical implications of LLM persona modeling, with applications in marketing, social science, product development, and healthcare. | Research Interests: LLM persona modeling, Instruction-following capabilities of LLMs, Personification and human-like personas, Interdisciplinary approaches in AI, psychology, and cognitive science, Evaluation methods for persona consistency and effectiveness, Social and ethical implications of anthropomorphism in LLMs, Technical innovations in LLMs, Real-world applications of LLM personas",,,
"Tuesday, Dec 2, 2025",09:30,Tutorial,"Efficient Transformers: State of the art in pruning, sparse attention, and transformer funneling",https://neurips.cc/virtual/2025/128790,,12:00,"""Transformer architectures consume the lionshare of computational budgets associated with today’s most powerful language and vision models, making research into greater computational efficiency a hot and essential direction. Our proposed tutorial surveys the bleeding edge of three complementary research threads that together comprise a significant part of the current industrial toolkit for achieving computational efficiency in Transformers: (1) pruning, the structured or unstructured removal of weights, layers and heads; (2) sparse attention & routing, including block, sliding-window, locality-sensitive hashing; and (3) funneling, which pools intermediate representations to shorten sequences through depth. We will then feature an expert industrial and academic panel of speakers from Caltech, MIT, Anthropic, Google Deepmind, and Microsoft, hearing about the latest trends seen in top industrial labs. Attendees will leave with actionable recipes for building sub-10 B-parameter models that match or exceed dense baselines on language, vision and multi-modal benchmarks.The tutorial targets researchers and practitioners who build or deploy Transformer models and assumes familiarity with basic deep-learning concepts but not with any specific efficiency method. All slides and publication materials will be released under a permissive license.""",,,,
"Tuesday, Dec 2, 2025",09:30,Tutorial,"Geospatial Foundation Models: Overview, Application and Benchmarking",https://neurips.cc/virtual/2025/128793,,12:00,"Geospatial foundation models (GeoFMs) are a class of large-scale deep learning models, typically based on the transformer architecture, that are pre-trained on vast, diverse datasets of Earth Observation data to learn a general, transferable understanding of the Earth’s surface. These models help address long-standing challenges in Earth Observation by dramatically reducing the need for manually labeled data, handling vast and diverse data streams (e.g., optical, SAR, multispectral, LiDAR), and enabling robust performance across time, space, and sensor types. In this tutorial, we will give an overview of the recent advancements in GeoFMs, highlighting the main challenges in developing these models and differences from foundation models developed for other domains. We will also show practical examples of fine-tuning and inferencing GeoFMs for different downstream tasks using the TerraTorch open-source framework, which facilitates the use to publicly available GeoFMs such as SatMAE, Prithvi-EO, DOFA, Galileo and TerraMind. Finally, we will introduce best practices for systematic and reproducible benchmarking of GeoFMs using the TerraTorch Iterate plug-in and its integration with GEO-Bench.",,,,
"Tuesday, Dec 2, 2025",09:30,Tutorial,From Tuning to Guarantees: Statistically Valid Hyperparameter Selection,https://neurips.cc/virtual/2025/128794,,12:00,"""The performance and reliability of modern machine learning systems depend critically on hyperparameter selection. Whether tuning a large language model, configuring a vision pipeline, or deploying AI in safety-critical environments, the choice of hyperparameters is decisive. Current tuning strategies such as grid or random search and Bayesian optimization are powerful for empirical optimization but they do not provide statistical guarantees on the reliability of the selected configuration after deployment. This gap becomes critical when models must satisfy strict performance, safety, or fairness requirements.This tutorial introduces a rigorous and practical framework that treats hyperparameter selection as a statistical testing problem. By constructing valid p- or e-values for candidate configurations and applying multiple hypothesis testing (MHT) procedures, practitioners can control deployment risk with finite-sample guarantees. We begin with the Learn-Then-Test (LTT) methodology for average-risk control and build up to multiple key extensions, such as controlling the quantile risk using quantile LTT (QLTT), multi-objective optimization through Pareto Testing (PT), incorporating prior information through the concept of reliability graphs, and data-efficient selection through adaptive LTT (aLTT). Throughout the tutorial, we emphasize conceptual clarity, plain-language explanations of assumptions, and hands-on demonstrations with minimal, reproducible notebooks.Attendees will gain a drop-in toolkit for augmenting existing tuning workflows with statistically valid selection. They will learn how to formalize relevant risk functions, generate valid evidence, choose appropriate error-rate controls (FWER/FDR), and navigate the trade-offs between statistical conservatism and power under limited data. No prior expertise in multiple hypothesis testing is required.""",,,,
"Tuesday, Dec 2, 2025",13:30,Tutorial,How to Build Agents to Generate Kernels for Faster LLMs (and Other Models!),https://neurips.cc/virtual/2025/128792,,16:00,"The compute demanded by modern AI has been exploding since 2016; the FLOPs used to train frontier models have grown at a rate of 2.4x per year [0], and the inference side is growing even faster—already an estimated 80% of total AI electricity use [1]. Large language models and other deep networks rely on highly tuned GPU kernels to achieve state-of-the-art performance; these efficient kernels directly translate to cost and energy savings. In this 2.5-hour in-person tutorial, we demonstrate how LLM-powered agents can generate and optimize GPU kernels for CUDA, HIP/ROCm, and Triton. We begin with a unified primer on GPU‐programming fundamentals and common tooling (memory hierarchy, occupancy, profilers), then introduce an agentic loop: prompt engineering, compiler/profiler feedback as tools, iterative kernel refinement, correctness validation, and automated benchmarking. We will provide additional benchmarking examples on HIP and Triton, on top of Stanford’s KernelBench that covers CUDA [2], KernelBot as reliable source of human curated dataset for heterogenous GPU code [3], and show how to turn runtime and profiler metrics into reward signals that drive kernel optimizations. On top of this loop, we build an inference-scaling framework in which the LLM proposes candidate kernels, compiles them, measures latency/throughput/energy, and feeds those signals back as rewards. By combining test-time scaling techniques the agent iteratively discovers increasingly accurate and efficient kernels. Attendees will compare generated code against expert kernels, inspect wins and losses. By the end, participants will walk away with a reproducible pipeline for LLM-driven GPU‐kernel optimization.",,计算,计算: 本Session通过LLM驱动的GPU内核生成与优化，精准对接低精度训推模型（挑战点2）与多模态Agentic负载快速演进（挑战点4）的计算需求，助力团队提升芯片算力定义及软硬件系统适配能力。,计算: 基于LLM的GPU内核自动生成与迭代优化流程; 跨平台GPU编程技术（CUDA、HIP/ROCm、Triton）; 利用编译器和性能分析器的反馈机制进行内核优化; 设计测试时伸缩性系统以提升推理效率和准确性; 基于运行时和性能指标的奖励信号推动优化Agent学习
"Tuesday, Dec 2, 2025",13:30,Tutorial,"Positional Encoding: Past, Present, and Future",https://neurips.cc/virtual/2025/128797,,16:00,"""Positional Encoding is a foundational yet often opaque component of Transformerarchitectures, underpinning how self-attention mechanisms capture sequence orderin language, vision, and multimodal models. Despite its centrality to the successof modern LLMs, and other attention-reliant architectures, the mathematical in-tuition behind positional encoding remains challenging and inaccessible to manyresearchers and practitioners. This workshop aims to demystify positional encodingby bridging formal theory with intuitive understanding and practical experimen-tation. Through a series of guided lectures, visual demonstrations, and hands-oncoding sessions, participants will explore the operational principles behind ef-fective positional representations, the evolution of key methods (from sinusoidaland learned embeddings to rotary and relative encodings), and open challengesthat motivate current research directions. We will also provide open-source codeimplementations, mathematical visualizations, and collaborative ideation sessionsfor fostering new positional encoding concepts. By easing the barrier to entry forthis mathematically intensive, yet crucial topic, the workshop seeks to foster deeperunderstanding, interdisciplinary exchange, and novel contributions to the future ofPositional Encoding, and Transformer design""",,,,
"Tuesday, Dec 2, 2025",13:30,Tutorial,Science of Trustworthy Generative Foundation Models,https://neurips.cc/virtual/2025/128795,,16:00,"We are living through a moment that once belonged to science fiction: generative foundation models can write, reason, design, diagnose, and increasingly, decide. They are no longer just predicting the next word — they are shaping knowledge, influencing choices, and becoming collaborators in science, medicine, education, and daily life. But here's the tension: as their capabilities accelerate, our ability to trust them has not kept pace.Trustworthiness can't remain a ""patch after the failure"" or a moral hope layered on top of engineering. It must evolve into a science—a discipline as rigorous as the one that created these models in the first place. In this tutorial, we explore what that science looks like: how we understand model behaviors, measure and stress-test trust, and design systems that earn it. We'll build the foundations together, then step into the frontier—where models begin to exhibit human-like cognitive behaviors that inspire wonder, but also demand responsibility and new forms of alignment.This session is an invitation: to move beyond building models that impress us, toward building models we can trust with what matters.",,,,
"Wednesday, Dec 3, 2025",08:30,Invited Talk,The Oak Architecture: A Vision of SuperIntelligence from Experience,https://neurips.cc/virtual/2025/invited-talk/129132,Rich Sutton,09:30,"As AI has become a huge industry, to an extent it has lost its way. What is needed to get us back on track to true intelligence? We need agents that learn continually. We need world models and planning. We need knowledge that is high-level and learnable. We need to meta-learn how to generalize. The Oak architecture is one answer to all these needs. It is a model-based RL architecture with three special features: 1) all of its components learn continually, 2) each learned weight has a dedicated step-size parameter that is meta-learned using online cross-validation, and 3) abstractions in state and time are continually created in a five-step progression: Feature Construction, posing a SubTask based on the feature, learning an Option to solve the subtask, learning a Model of the option, and Planning using the option’s model (the FC-STOMP progression). The Oak architecture is rather meaty; in this talk we give an outline and point to the many works, prior and contemporaneous, that are contributing to its overall vision of how superintelligence can arise from an agent’s experience.",,计算,计算: 该Session深入探讨模型架构如何通过持续学习和元学习推动智能演进，直接对应挑战点中对模型结构演进趋势影响计算系统的需求。团队参与将有助于理解模型架构与计算系统的交互，降低未来架构变化带来的计算冲击。,计算: 持续学习机制在模型架构中的应用; 元学习步长参数优化方法; 模型状态和时间抽象的五步进展（FC-STOMP）; 基于模型的强化学习策略规划; 模型架构演进对计算架构需求的影响
"Wednesday, Dec 3, 2025",14:30,Invited Talk,Are We Having the Wrong Nightmares About AI?,https://neurips.cc/virtual/2025/invited-talk/129136,Zeynep Tufekci,15:30,"Though seemingly opposite, doom and optimism regarding generative AI's spectacular rise both center on AGI or even superintelligence as a pivotal moment. But generative AI operates in a distinct manner from human intelligence, and it’s not a less intelligent human on a chip slowly getting smarter anymore than cars were mere horseless carriages. It must be understood on its own terms. And even if Terminator isn’t coming to kill us or superintelligence isn’t racing to save us, generative AI does bring profound challenges, well-beyond usual worries such as employment effects.  Technology facilitates progress by transforming the difficult into easy, the rare into ubiquitous, the scarce into abundant, the manual into automated, and the artisan into mass-produced. While potentially positive long-term, these inversions are extremely destabilizing during the transition, shattering the correlations and assumptions of our social order that relied on superseded difficulties as mechanisms of proof, filtering, sorting and signaling. For example, while few would dispute the value of the printing press or books, their introduction led to such destructive upheaval that the resulting religious wars caused proportionally more deaths than all other major wars and pandemics since combined. Historically, a new technology's revolutionary impact comes from making what's already possible and desired cheap, easy, fast, and large-scale, not from outdated or ill-fitting benchmarks that technologists tend to focus on. As such, Artificial Good-Enough Intelligence can unleash chaos and destruction long before, or if ever, AGI is reached. Existing AI is good enough to blur or pulverize our existing mechanisms of proof of accuracy, effort, veracity, authenticity, sincerity, and even humanity. The tumult from such a transition will require extensive technological, regulatory, and societal effort to counter. But the first step to getting started is having the right nightmares.",,,,
"Thursday, Dec 4, 2025",08:30,Invited Talk,The Art of (Artificial) Reasoning,https://neurips.cc/virtual/2025/invited-talk/129134,Yejin Choi,09:30,"Scaling laws suggest that “more is more” — brute-force scaling of data and compute leads to stronger AI capabilities. However, despite rapid progress on benchmarks, state-of-the-art models still exhibit ""jagged intelligence,"" indicating that current scaling approaches may have limitations in terms of sustainability and robustness. Additionally, while the volume of papers on arXiv continues to grow rapidly, our scientific understanding of artificial intelligence hasn't kept pace with engineering advances, and the current literature presents seemingly contradictory findings that can be difficult to reconcile. In this talk, I will discuss key insights into the strengths and limitations of LLMs, examine when reinforcement learning succeeds or struggles in reasoning tasks, and explore methods for enhancing reasoning capabilities in smaller language models to help them close the gap against their larger counterparts in specific domains.",,诺亚,诺亚: 该Session深入探讨大规模语言模型的推理能力及其局限性，特别关注增强小型模型推理能力的技术策略，直接契合团队在多模态长文本推理瓶颈突破的挑战点。参与此Session有助于获得前沿思路与方法。,诺亚: 大型语言模型的推理能力与局限性分析; 强化学习在推理任务中的应用成效与挑战; 提升小型语言模型推理性能的方法; 多模态长文本推理的输入范式创新; 科学理解与工程实践间的差距及其弥合策略
"Thursday, Dec 4, 2025",14:30,Invited Talk,"On the Science of “Alien Intelligences”: Evaluating Cognitive Capabilities in Babies, Animals, and AI",https://neurips.cc/virtual/2025/invited-talk/129137,Melanie Mitchell,15:30,"Today’s generative AI systems—termed by some researchers as “alien intelligences”—have exceeded human performance on many benchmarks meant to test humanlike cognitive capabilities.  However, these systems still struggle in unhumanlike ways on real-world tasks requiring these capabilities.  This disconnect may be due in part to neglect in the AI community of well-founded experimental protocols for evaluating cognition.  In this talk I will summarize several recommendations on experimental methods from developmental and comparative psychology—fields that study the “alien intelligences” of babies and non-human animals—and demonstrate the application of such methods in two case studies of cognitive abilities in LLMs: analogical reasoning and visual abstraction.",,,,
"Friday, Dec 5, 2025",08:30,Invited Talk,From Benchmarks to Problems - A Perspective on Problem Finding in AI,https://neurips.cc/virtual/2025/invited-talk/129135,Kyunghyun Cho,09:30,"During the past 15 years or so, I have worked on a series of seemingly distinct but eventually related problems, including machine learning algorithms, generative modeling with neural networks, machine translation, language modeling, medical imaging, a bit of healthcare, protein modeling and a bit of drug discovery. I chose to work on some of these problems intentionally, while it was pure serendipity that I worked on some others. It was only in hindsight that these seemingly different problems turned out to be closely related to each other from both technical, social and personal perspectives. In this talk, I plan to do my own retrospective on my own choices, be them intentional or not, on these problems and share with you my thoughts what our own discipline, which is sometimes called computer science, data science, machine learning or artificial intelligence, is.",,,,
"Friday, Dec 5, 2025",14:30,Invited Talk,Demystifying depth: Principles of learning in deep neural networks,https://neurips.cc/virtual/2025/invited-talk/129133,Andrew Saxe,15:30,"Deep neural networks have revolutionized artificial intelligence, yet their inner workings remain poorly understood. This talk presents mathematical analyses of the nonlinear dynamics of learning in several solvable deep network models, offering theoretical insights into the role of depth. These models reveal how learning algorithms, data structure, initialization schemes, and architectural choices interact to produce hidden representations that afford complex generalization behaviors. A recurring theme across these analyses is a neural race: competing pathways within a deep network vie to explain the data, with an implicit bias toward shared representations. These shared representations in turn shape the network’s capacity for systematic generalization, multitasking, and transfer learning. I will show how such principles manifest across diverse architectures—including feedforward, recurrent, and linear attention networks. Together, these results provide analytic foundations for understanding how environmental statistics, network architecture, and learning dynamics jointly structure the emergence of neural representations and behavior.",,计算,计算: 本次演讲深入分析深度神经网络的学习动态，揭示训练算法、架构选择与学习表现的内在联系，恰与团队关注训推范式负载特征演进机理相契合，有助精准理解和预测负载演变。,计算: 深度神经网络的非线性学习动态解析; 训练算法与数据结构的相互作用; 网络架构对表示学习和泛化能力的影响; 共享表示在多任务和迁移学习中的角色; 不同网络类型（前馈、循环、线性注意力）的比较分析
