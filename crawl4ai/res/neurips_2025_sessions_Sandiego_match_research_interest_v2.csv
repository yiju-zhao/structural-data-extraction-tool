bu_name,session_title,session_type,session_date,session_time,base_cosine,rel,tech_overlap,novelty,actionability,confidence,final_score,scoring_reason,recommendation_reason,focus_areas
中软,"PRIME Guardrails in Action: A Live Demonstration of an Agentic, Multi-Layered Safety Framework for Generative AI",Expo Demonstration,TUE 2 DEC,noon,0.5918214321136475,0.75,0.65,0.58,0.7,0.76,0.6098399999999999,"Defense-in-depth, modality-agnostic guardrails with agentic orchestration align with BU’s runtime security, policy enforcement, and monitoring needs. Demonstration offers patterns like early-exit filtering and heterogeneous model routing. Limited coverage of stateful memory, transactional semantics, orchestration primitives, and uncertainty calibration reduces overlap.",该团队专注于多模态AI系统的安全与分布式框架建设，正与Session中介绍的PRIME多层安全防护框架高度契合。Session展示的高效、多模态威胁检测与防御机制，能有效助力团队解决对抗性输入和隐私保护的系统级难题。,PRIME框架中的多层防护机制和‘Defense in Depth’策略; 结合大模型深度语义理解与开源分类器快速过滤的混合安全方案; 多模态输入（文本与图像）的实时威胁检测技术; 代理式流程管理与异步编排以提升系统可靠性; 对抗输入攻击的实时识别与中和方法
中软,ContextForge,Expo Demonstration,TUE 2 DEC,noon,0.5454860925674438,0.72,0.6,0.58,0.82,0.8,0.6066,"Directly addresses BU’s runtime security and governance needs with LSM-style hooks, policy enforcement, PII redaction, and standards-aligned agent tooling (MCP). Limited coverage of memory, orchestration primitives, transactional semantics, and uncertainty handling. Open-source plugins make near-term adoption actionable.",该团队的挑战强调分布式AI系统的安全性和状态管理，Session提供了基于插件的安全中间件架构，能精准解决多模态流水线中的安全防护及权限控制难题，助力实现统一、标准化的安全策略执行。,基于Linux安全模块的插件架构设计; 细粒度安全策略实施与扩展; 多轮对话状态的可回放性和一致性保障; 恶意输入检测与数据泄露防护; 跨异构运行时的策略执行与监控
可信,"AI Assistants in the Wild: Agents, Adaptation, and Memory-Augmented Deployment",Expo Workshop,WED 3 DEC,noon,0.6019790172576904,0.92,0.85,0.75,0.78,0.83,0.7910175,"Strong match on agentic memory, continual adaptation, task inference, and trustworthy generation under uncertainty; includes edge deployment constraints. Less coverage of probabilistic intent fusion, runtime risk control/rollback, and observability/telemetry specifics. Likely offers applicable designs and algorithms with moderate novelty.",该团队在可信AI领域聚焦于意图推断、长期记忆管理及安全适应，恰好对应Session中关于个性记忆系统、长期适应与可信生成的核心议题，能深化其在多模态意图识别和安全自学习机制的研究。,个性化记忆架构及持久化策略; 多模态、多轮意图检测与不确定性量化; 在线自学习与避免灾难性遗忘的机制; 风险感知的异常检测及回滚策略; 部署在边缘设备的高效生成模型设计
可信,Workshop on Multi-Turn Interactions in Large Language Models,Workshop,SAT 6 DEC,8 a.m.,0.4764305353164673,0.9,0.75,0.78,0.65,0.8,0.72945,"Strong match on multi-turn agentic tasks, alignment over extended interactions, and long-horizon evaluation. Some gaps on uncertainty calibration, runtime risk controls, and memory/telemetry specifics. Likely to provide methods, benchmarks, and frameworks useful for trustworthy multi-turn agents but fewer deployment-ready practices.",该团队专注可信代理AI，涵盖用户意图推断、多轮对话状态管理和安全适应，与多轮交互中的意图检测、记忆管理及安全自学习等关键挑战高度契合，能深度参与Session核心议题。,Multi-Turn RL Learning for Agentic Tasks; Maintaining Alignment over Multi-Turn Interactions; Memory and Context Management: selective retention and summarization; Safe Online Policy Improvement and Catastrophic Forgetting Prevention; Calibrated Uncertainty Monitoring and Risk-aware Intervention
可信,"PRIME Guardrails in Action: A Live Demonstration of an Agentic, Multi-Layered Safety Framework for Generative AI",Expo Demonstration,TUE 2 DEC,noon,0.5637615919113159,0.82,0.68,0.55,0.76,0.79,0.66051,"Defense-in-depth guardrails with agentic orchestration map to BU’s runtime safety, monitoring, intervention, and composable architecture goals. Less coverage of probabilistic intent inference, long-term memory, and continual learning. Demo likely offers practical patterns (early-exit, multimodal filtering) with actionable takeaways.",该团队关注可信Agentic AI的多模态意图识别、状态管理及风险干预，正与Session展示的PRIME多层安全框架密切契合。两者均强调实时性、上下文管理及多模型协同，为打造稳健、安全的生成式AI提供互补方案。,多模态多轮意图检测与冲突解析; 多层次安全框架中的策略与风险管理; 利用大模型和轻量分类器的混合过滤机制; 实时异常检测与风险感知干预; 构建可组合、可观测、可测试的系统架构
可信,Reliable ML from Unreliable Data,Workshop,SAT 6 DEC,8 a.m.,0.4838853180408478,0.82,0.62,0.75,0.7,0.8,0.6579,"Strong thematic fit on reliability under distribution shift, adversarial/strategic manipulation, and LLM safety. Overlaps with BU’s uncertainty calibration, OPE, robust interactive agents. Less coverage of agent memory, multimodal intent, and architectural observability. Likely to yield practical robustness techniques and evaluation protocols.",该团队专注于构建可信AI代理，关注意图推断、多模态信号融合及安全适应，契合Workshop聚焦的分布偏移、鲁棒性和策略行为挑战，为开发可靠机器学习系统提供理论与实践支持。,分布偏移与迁移学习技术; 对抗鲁棒性及防御机制; 多模态意图检测与不确定性量化; 记忆管理与因果保持策略; 在线学习与自我改进的安全机制
可信,ContextForge,Expo Demonstration,TUE 2 DEC,noon,0.5304814577102661,0.82,0.55,0.6,0.85,0.82,0.6429149999999999,"Security-focused middleware with hookable plugins aligns with BU’s trustworthy agent architecture and governance needs (policy enforcement, injection/PII controls, provenance). Strong actionable OSS. Limited overlap with BU’s probabilistic intent, long-horizon memory, and uncertainty/continual learning.","Context Forge's open-source, security-focused middleware aligns closely with the BU's challenge in building trustworthy AI agents, particularly in managing contextual policies, intent detection, and safe adaptability through modular security hooks and plugin architecture.",Plugin architecture for embedding security hooks; Contextual policy enforcement at scale; Prompt injection detection techniques; Selective retention and forgetting policies in memory management; Calibration of uncertainty and anomaly detection mechanisms
可信,Planning in the Era of Language Models,Tutorial,TUE 2 DEC,9:30 a.m.,0.48068737983703613,0.82,0.64,0.7,0.58,0.74,0.6272699999999999,"Planning with LLMs aligns with trustworthy agent design, offering principled goal reasoning, search, plan validation, and evaluation practices. However, it likely undercovers uncertainty calibration, multimodal intent inference, memory policies, and safe continual learning. Expect methodological insights and benchmarks more than immediate, production-ready mechanisms.",本团队挑战关注可信智能体的意图推断、多模态信息整合及安全适应，与Session对规划方法及长期状态管理的深入探讨高度契合，有助于提升LLM驱动规划系统的鲁棒性与可靠性。,规划中多模态意图推断与冲突解决技术; 长期状态管理中的选择性记忆与信息遗忘策略; 在线自学习机制中的安全增益与灾难性遗忘防范; 基于规划的风险感知与异常检测方法; 规划系统的组合式架构设计与可测试性保障
可信,BeeAI,Expo Demonstration,TUE 2 DEC,noon,0.5843484401702881,0.8,0.58,0.55,0.72,0.77,0.61065,"BeeAI’s declarative, rule-based control for deterministic agent behavior aligns with trustworthy, controllable agent architecture and production deployment. However, it lacks emphasis on probabilistic intent inference, uncertainty calibration, long-term memory, and continual learning. Still offers actionable design patterns and tooling for safe orchestration.",该团队关注可信任AI代理的多模态意图检测、状态管理与安全适应，正契合BeeAI通过声明式规则确保代理行为可控、可预测的核心理念，两者在保证代理可靠性和安全性上具备直接技术共鸣。,基于声明式规则的代理行为约束和执行一致性; 多模态、多轮交互中的用户意图推断与不确定性量化; 长期记忆管理：选择性保留、总结与遗忘策略; 运行时的不确定性校准、异常检测及风险干预机制; 结构化、可观测且可测试的AI系统设计与反馈机制
