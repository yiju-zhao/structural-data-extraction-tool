{
  "存储": {
    "challenge_sumary": "AI training and inference impose heterogeneous, bursty I/O and memory access patterns that must be mapped onto a tiered hierarchy spanning GPU HBM, host DRAM, CXL-extended memory, NVMe, and object storage. During training, shuffled, parallel dataloaders demand high-throughput mixes of sequential and random reads; in multi-model inference, dynamic KV cache growth/eviction and model swapping create latency-sensitive demand spikes. Agentic RAG and vector databases generate small, concurrent, read-heavy workloads with strict tail-latency SLOs, while agent memory systems (e.g., MemOS) require schedulable persistence and recall. Evolving data layouts and dataset formats complicate zero-copy pipelines and compression. The core challenge is workload-aware placement, prefetch, eviction, and scheduling across tiers, with minimal CPU mediation (e.g., GPUDirect/Storage-Next), topology awareness, consistent semantics, and reproducible evaluation.",
    "key_points_en": [
      "Characterize and simulate IO/memory access patterns for training, RAG, and multi-model inference.",
      "Cost-aware placement across HBM, DRAM, CXL memory, NVMe, and object storage.",
      "Adaptive prefetch, eviction, and throttling under bursty, multi-tenant tail-latency constraints.",
      "KV cache and model artifact load/unload scheduling with NUMA and PCIe topology awareness.",
      "Vector DB and MemOS access paths with concurrency control and durability guarantees.",
      "Data layout/format evolution enabling zero-copy, compression, and columnar-to-row transformations.",
      "Benchmarks for NVIDIA Storage-Next and GPUDirect Storage under realistic agentic workloads."
    ],
    "keywords_en": [
      "I/O access patterns",
      "heterogeneous memory hierarchy",
      "HBM",
      "DRAM",
      "CXL memory",
      "NVMe",
      "object storage",
      "GPUDirect Storage",
      "NVIDIA Storage-Next",
      "KV cache",
      "multi-model inference",
      "vector database",
      "RAG",
      "MemOS",
      "prefetching",
      "eviction policy",
      "scheduling",
      "data layout",
      "dataset formats",
      "NUMA"
    ],
    "candidate_queries_en": [
      "learned prefetch and eviction for CXL–NVMe tiers",
      "topology-aware KV cache scheduling across GPU, DRAM, and CXL",
      "measure vector DB access patterns under agentic RAG workloads",
      "evaluation protocols for NVIDIA Storage-Next in multi-model inference",
      "data layout strategies enabling zero-copy dataloading and GPUDirect pipelines"
    ],
    "meta": {
      "source_md_hash": "cf9a209c6ef8e0431e0cd63b6e1fe622",
      "generated_at": "2025-11-11T21:39:29.619178+00:00"
    }
  },
  "CBG": {
    "challenge_sumary": "CBG’s 3D AIGC goals demand closing the loop between dynamic scene understanding, controllable 3D reasoning, and generative video synthesis. Core needs include fast, accurate motion segmentation in unconstrained videos with occlusions and complex backgrounds; monocular 3D/4D reconstruction that resolves scale ambiguity and yields temporally coherent sparse structures, poses, and trajectories; and video generation conditioned on explicit, user-defined camera paths while respecting physical geometry and photometric consistency. Achieving long-horizon temporal consistency of identity, shape, lighting, and backgrounds under viewpoint changes requires 3D-aware representations, trajectory-aware attention, and differentiable rendering. The system must balance fidelity and latency, leverage SLAM/NeRF/Gaussian priors, quantify uncertainty, and provide robust evaluation metrics for pose, reconstruction quality, and perceptual consistency across minutes-long sequences.",
    "key_points_en": [
      "Streaming motion segmentation with occlusion reasoning, fine boundaries, and minimal drift in cluttered scenes.",
      "Monocular 3D/4D sparse reconstruction resolving scale ambiguity via priors, multi-frame constraints, and learned depth.",
      "Robust pose estimation and bundle adjustment under motion blur, rolling shutter, and dynamic objects.",
      "Camera-trajectory-conditioned video generation enforcing geometric consistency through 3D-aware guidance and differentiable rendering.",
      "Long-horizon temporal consistency of identity, lighting, and background via trajectory-aware attention and scene representations.",
      "Throughput-latency optimization and memory-efficient training/inference for minutes-long sequences on commodity GPUs."
    ],
    "keywords_en": [
      "3D AIGC",
      "video segmentation",
      "moving object segmentation",
      "monocular reconstruction",
      "4D reconstruction",
      "SLAM",
      "structure from motion",
      "scene flow",
      "neural radiance fields",
      "3D Gaussian splatting",
      "diffusion video generation",
      "camera path conditioning",
      "bundle adjustment",
      "pose estimation",
      "point cloud",
      "temporal consistency",
      "identity preservation",
      "lighting consistency",
      "differentiable rendering",
      "real-time inference"
    ],
    "candidate_queries_en": [
      "geometry-aware diffusion models with camera trajectory conditioning",
      "monocular 4D reconstruction under scale ambiguity and occlusions",
      "online motion segmentation using joint optical flow and foreground priors",
      "maintaining long-horizon temporal consistency of identity, geometry, and lighting",
      "evaluation metrics for pose accuracy and perceptual consistency in long videos"
    ],
    "meta": {
      "source_md_hash": "c9da63fe4b8bd427ccbb373d26905bf7",
      "generated_at": "2025-11-11T21:40:21.476666+00:00"
    }
  },
  "DCN": {
    "challenge_sumary": "Training and inference at scale stress data-center and inter-datacenter networks with bursty, synchronized, and topology-sensitive traffic. The challenge is to co-design compute, storage, and fabric so collective communication and parameter exchange complete with minimal tail latency, predictable throughput, and high utilization. This requires advances in congestion control, lossless transports without PFC pathologies, topology- and job-aware routing/scheduling, NIC and switch offloads, and in-network aggregation. Across WANs, we must characterize and forecast the fraction and evolution of AI-driven flows (synchronization, checkpoints, model distribution) and adapt traffic engineering accordingly. Finally, AI4Network calls for robust use of large models and ML for telemetry, anomaly detection, configuration synthesis, and closed-loop control with verifiability, data governance, and safety.",
    "key_points_en": [
      "Cross-layer co-design of compute, storage, and fabric to minimize end-to-end training time and SLOs.",
      "Optimize collective communication (all-reduce, all-to-all) via topology-aware routing, in-network aggregation, and NIC offload.",
      "Robust congestion control and lossless transports (RoCE) without PFC pathologies; control tail latency and head-of-line blocking.",
      "Fine-grained scheduling: bandwidth, NUMA, placement, and job-aware admission for multi-tenant AI clusters.",
      "WAN traffic engineering for inter-DC AI synchronization, checkpoints, and model distribution; forecast AI traffic evolution.",
      "Telemetry, digital twins, and ML/LLM-driven operations for anomaly detection, routing, and configuration synthesis with provable safety.",
      "Energy- and cost-aware fabric design using optics, programmable switches, in-network compute, and disaggregation."
    ],
    "keywords_en": [
      "AI networking",
      "cross-layer co-design",
      "collective communication",
      "all-reduce",
      "RDMA",
      "RoCE",
      "congestion control",
      "ECN",
      "PFC mitigation",
      "in-network aggregation",
      "P4 programmable switches",
      "NIC offload",
      "topology-aware routing",
      "flow scheduling",
      "tail latency",
      "inter-datacenter WAN",
      "traffic engineering",
      "telemetry and observability",
      "digital twin",
      "LLM for networking",
      "optical interconnects"
    ],
    "candidate_queries_en": [
      "learning-based congestion control for collective communication workloads",
      "quantifying AI training traffic share in inter-datacenter WANs",
      "LLM-driven network configuration synthesis and safe automation",
      "topology-aware all-reduce via in-network aggregation and NIC offload",
      "scheduling coflows and bandwidth for multi-tenant AI clusters"
    ],
    "meta": {
      "source_md_hash": "f7e030fbaec64d670a6890db48db4714",
      "generated_at": "2025-11-11T21:41:15.541053+00:00"
    }
  },
  "海思": {
    "challenge_sumary": "The BU targets end-to-end acceleration of large language models and conditional diffusion while preserving dialog quality and cross-turn consistency. Bottlenecks arise from token-serial decoding, quadratic attention growth with long contexts, and heterogeneous multimodal encoders that induce feature translation and synchronization latency. A principled solution requires near-linear attention via sparsity and blockwise KV caching, robust speculative or multi-path decoding to cut compute without semantic drift, and a unified latent space that amortizes text/image/sketch/depth conditioning. Kernel and memory co-design—FlashAttention-style kernels, quantized KV/weights, fused ops, and bandwidth-aware layouts—must shrink memory traffic. At the system level, tail-latency-aware batching, prefill/stream separation, admission control, and cache residency policies are needed to guarantee jitter-bounded real-time responses under variable load.",
    "key_points_en": [
      "Implement sparse or linearized attention with chunked KV caches and paged memory to scale long-context inference near linearly.",
      "Build a unified multimodal latent space to replace heterogeneous encoders and reduce cross-modal conditioning latency.",
      "Use speculative decoding with adaptive draft lengths and calibrated acceptance to lower latency without degrading response quality.",
      "Apply quantization-aware kernels, fused operators, and FlashAttention-like implementations to cut memory bandwidth and kernel launch overhead.",
      "Separate prefill and streaming phases; schedule micro-batches for tail-latency SLAs under bursty loads.",
      "Cache and reuse cross-modal condition embeddings; maintain locality to minimize synchronization and PCIe/NVLink transfer costs."
    ],
    "keywords_en": [
      "low-latency inference",
      "streaming decoding",
      "speculative decoding",
      "sparse attention",
      "linear attention",
      "chunked KV cache",
      "paged attention",
      "long-context reasoning",
      "FlashAttention",
      "quantization",
      "fused kernels",
      "unified multimodal latent space",
      "conditional diffusion",
      "cross-modal encoders",
      "caching",
      "dynamic batching",
      "admission control",
      "jitter"
    ],
    "candidate_queries_en": [
      "sparse attention with chunked KV cache for long-context LLMs",
      "unified latent space for low-latency multimodal conditional diffusion",
      "real-time conversational decoding with speculative sampling and quality constraints",
      "latency-aware batching and scheduling for streaming LLM and diffusion workloads",
      "evaluation of end-to-end jitter and tail latency under mixed multimodal loads"
    ],
    "meta": {
      "source_md_hash": "766fd2e44a9aca48320dfb23c5821630",
      "generated_at": "2025-11-11T21:42:02.203988+00:00"
    }
  },
  "计算": {
    "challenge_sumary": "AI computation is constrained by tight co-evolution between model architectures and the hardware–software stack. Anticipating shifts—MoE routing, longer contexts, multimodal fusion, and agentic loops—requires first-principles workload forecasting rather than backward-looking benchmarks. Precision is pivotal: extending FP6/FP4-like formats into training and inference demands provable numerical stability, calibrated dynamic range, error-compensated accumulations, and full ecosystem enablement in kernels, compilers, and tooling. Evolving train/infer paradigms—speculative decoding, retrieval, parallel sampling, and reinforcement fine-tuning—re-balance compute, memory bandwidth, interconnect traffic, and tail latency, especially in embodied and streaming scenarios. The central challenge is coordinated model–runtime–hardware co-design that defines future loads early, so memory hierarchies, interconnects, scheduling policies, and libraries can absorb architectural shocks with predictable efficiency and quality-of-service guarantees.",
    "key_points_en": [
      "Build predictive workload models linking algorithmic features to compute, memory, and interconnect demands.",
      "Validate FP6/FP4 training with stable accumulations, calibration, stochastic rounding, and error compensation.",
      "Standardize low-precision formats and kernels across compilers and libraries for reproducible performance.",
      "Optimize runtimes for MoE, sparsity, long-context KV caches, and sequence/activation partitioning.",
      "Design benchmarks and traces that capture speculative decoding, RAG, multi-agent loops, and parallel sampling.",
      "Provision memory hierarchy and network topology to meet real-time SLOs in multimodal and embodied workloads."
    ],
    "keywords_en": [
      "model-system co-design",
      "workload forecasting",
      "low-precision training",
      "FP6",
      "FP4",
      "stochastic rounding",
      "mixed-precision accumulators",
      "KV cache",
      "MoE",
      "sparsity",
      "HBM bandwidth",
      "interconnect topology",
      "runtime scheduling",
      "speculative decoding",
      "retrieval-augmented generation",
      "agentic workloads",
      "multimodal inference",
      "embodied RL"
    ],
    "candidate_queries_en": [
      "Stability techniques for FP4/FP6 mixed-precision training and inference",
      "Forecasting compute needs of agentic, multimodal, and retrieval-augmented workloads",
      "Compiler/runtime co-design for MoE, sparsity, and speculative decoding",
      "Trace-driven benchmarks to define future LLM training and inference loads",
      "Meeting real-time SLOs for embodied RL and sensor-stream multimodal inference"
    ],
    "meta": {
      "source_md_hash": "98468e4ac172fe86f8d9cf93f5cd9604",
      "generated_at": "2025-11-11T21:43:19.103262+00:00"
    }
  },
  "温哥华云": {
    "challenge_sumary": "Deploying reinforcement fine-tuning (RFT) for VLMs/LLMs and embodied agents requires resolving core RL deficiencies under real-world constraints. Key gaps include data-efficient preference/reward learning; stable off-policy optimization over long horizons with sparse, delayed signals; principled credit assignment across multimodal token–action trajectories; and rigorous, scalable evaluation beyond proxy rewards. Productionization further demands distributed training with elastic fault tolerance, reproducibility, and cost/latency-aware serving, while enabling safe online adaptation without catastrophic drift. In embodied settings, limited interaction budgets, partial observability, and hardware variability exacerbate sim-to-real gaps; reliable sensor fusion, calibration, and safety-aware control are essential. Unifying simulation, dataset curation, and online feedback with standardized metrics is required to improve performance, generalization, and scalability for practical deployment.",
    "key_points_en": [
      "Sample-efficient preference and reward modeling for long-horizon, sparse-feedback VLM/LLM policies.",
      "Stable off-policy RFT with variance reduction and credit assignment across multimodal sequences.",
      "Scalable distributed RL training: replay, prioritization, synchronization, and elastic fault tolerance.",
      "Latency- and cost-aware serving for stochastic policies with online safety constraints.",
      "Reproducible, task-grounded evaluation beyond proxy rewards; uncertainty and regression monitoring.",
      "Embodied AI sim-to-real transfer via system identification, domain randomization, and selective real-world data.",
      "Robust multimodal sensor fusion, calibration, and safety-certified control under partial observability."
    ],
    "keywords_en": [
      "reinforcement fine-tuning",
      "RFT",
      "reward modeling",
      "preference learning",
      "off-policy RL",
      "variance reduction",
      "credit assignment",
      "distributed training",
      "replay buffers",
      "scalability",
      "sim-to-real",
      "domain randomization",
      "system identification",
      "sensor fusion",
      "partial observability",
      "safety constraints",
      "evaluation protocols",
      "continual learning",
      "latency-aware serving",
      "embodied AI"
    ],
    "candidate_queries_en": [
      "Efficient off-policy RFT for long-horizon VLMs",
      "Robust reward modeling from multimodal preferences at scale",
      "Sim-to-real transfer for manipulation with limited real-world data",
      "Online evaluation and monitoring of RL-tuned language agents in production",
      "Safety-constrained control and perception under partial observability"
    ],
    "meta": {
      "source_md_hash": "3261ae57607f012bb12870b63d8c9ef4",
      "generated_at": "2025-11-11T21:44:01.093490+00:00"
    }
  },
  "多伦多云": {
    "challenge_sumary": "Delivering robust AI Agents requires a principled framework that spans evaluation, reliability, and continuous learning. First, define a hierarchical competency taxonomy that separates general abilities (reasoning, planning, tool-use, memory) from domain-specific knowledge, coupled with representative task distributions, strong oracles, and precise success, safety, latency, and cost metrics. Second, make agent actions, especially writes, trustworthy via transactional semantics, dry-run diffs, pre/post-conditions, idempotency, capability gating, authorization, sandboxing, invariant monitors, and automatic rollback. Third, design online improvement loops that unify prompt and model optimization: rigorous logging, feedback extraction, counterfactual/off-policy evaluation, trace distillation, and targeted fine-tuning, with reproducibility and regression safeguards. Finally, for L3+ agents with multi-step plans, tackle credit assignment, long-horizon validation, and distribution shift using structured traces, causal analysis, and continuous coverage tracking.",
    "key_points_en": [
      "Build a hierarchical evaluation taxonomy separating general competencies from domain knowledge, with task distributions and success, safety, latency, and cost metrics.",
      "Construct reliable oracles via programmatic tests, simulators, and human review; define error taxonomies and coverage metrics to expose blind spots and regressions.",
      "Guarantee write safety with transactional semantics, dry-run diffs, pre/post-conditions, idempotency, canaries, and automatic rollback.",
      "Enforce behavioral control through policy guardrails, capability gating, tool authorization, sandboxed execution, and runtime monitors with invariant checks.",
      "Unify prompt and model optimization loops via logging, feedback extraction, counterfactual evaluation, off-policy learning, and trace distillation.",
      "Address multi-step planning credit assignment and drift with structured traces, causal attribution, and continuous regression testing."
    ],
    "keywords_en": [
      "agent evaluation",
      "competency taxonomy",
      "domain-specific benchmarks",
      "task distribution design",
      "tool-use reliability",
      "transactional writes",
      "idempotency and rollback",
      "policy guardrails",
      "authorization and sandboxing",
      "pre/post-condition checks",
      "invariant monitoring",
      "error taxonomy",
      "counterfactual evaluation",
      "off-policy learning",
      "prompt optimization",
      "trace distillation",
      "credit assignment",
      "planning and multi-step execution",
      "drift detection",
      "reproducibility and versioning"
    ],
    "candidate_queries_en": [
      "counterfactual off-policy evaluation for agent policies with tool calls",
      "ensuring transactional safety of agent-initiated write operations",
      "evaluation protocols for domain-specific L3 planning agents in production",
      "pre/post-condition checking and invariant synthesis for agent tool executions",
      "credit assignment in multi-step plans with delayed rewards"
    ],
    "meta": {
      "source_md_hash": "fbf996274bd39443d6cd5b9d3c2dc151",
      "generated_at": "2025-11-11T21:45:52.595141+00:00"
    }
  },
  "诺亚": {
    "challenge_sumary": "Enabling native long-sequence and multimodal long-sequence reasoning requires rethinking attention, memory, and post-training. Architectures must maintain accuracy across 100k+ tokens while bounding compute and cache, via stable positional schemes, sparse/linear attention, recurrence, and lossy/lossless KV compression. At inference, the model should allocate compute adaptively: selective expansion, speculative decoding, tree-based deliberation, and dynamic scratchpad usage, coupled with principled memory write/evict policies for persistent internal memory. For vision-language, input paradigms must hierarchically tokenize frames and pages, perform early summarization, and restrict cross-modal attention without losing cross-reference fidelity. Post-training must produce strong reasoning through self-play and learning-from-experience, combining RL with preference/model-based signals and latent reasoning objectives, with robust evaluation under production latency and cost.",
    "key_points_en": [
      "Design stable 100k–1M token models using NTK-aware RoPE, ALiBi, recurrence, and sparse/linear attention.",
      "Develop lossless/lossy KV-cache compression, eviction, and retrieval policies with accuracy–latency trade-off guarantees.",
      "Optimize test-time reasoning via adaptive routing, speculative decoding, self-consistency, and limited-width tree search.",
      "Build write/read/forget mechanisms for persistent internal memory supporting continual long-session inference.",
      "Create hierarchical tokenization and early summarization for video–document inputs with sparse cross-modal alignment.",
      "Unify self-play, learning-from-experience, and RL/DPO objectives to elicit latent reasoning without revealing chain-of-thought."
    ],
    "keywords_en": [
      "long-context transformers",
      "1M-token context",
      "linear attention",
      "sparse attention",
      "recurrence",
      "RoPE scaling",
      "ALiBi",
      "KV cache compression",
      "eviction policy",
      "adaptive routing",
      "speculative decoding",
      "self-consistency",
      "tree search",
      "persistent memory",
      "hierarchical tokenization",
      "multimodal reasoning",
      "video-text",
      "cross-modal alignment",
      "self-play RL",
      "latent reasoning"
    ],
    "candidate_queries_en": [
      "KV-cache compression with adaptive eviction for million-token transformers",
      "Robust long-context memory updates in continual inference",
      "Efficient multimodal video-document reasoning under strict latency and GPU budgets",
      "Test-time computation allocation for reasoning with self-consistency",
      "Self-play and learning-from-experience to elicit latent reasoning"
    ],
    "meta": {
      "source_md_hash": "da39f8a77f39658499779476bde7196a",
      "generated_at": "2025-11-11T21:47:03.133635+00:00"
    }
  }
}