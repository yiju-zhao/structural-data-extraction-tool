title,authors,date,time,location,abstract,website
Vision Language Models: Challenges of Real World Deployment,"Mozhgan Nasr Azadani, Yimu Wang, Krzysztof Czarnecki, Negar Arabzadeh, Richard H Bai, Lukas Schmid",Sun 30 Nov,1 p.m. PST — 8 p.m. PST,Don Alberto 4,"Vision language models (VLMs) have demonstrated remarkable capabilities in integrating visual perception with natural language understanding, powering applications such as multimodal assistants, robotics, autonomous systems, and accessibility tools. However, their real-world deployment faces significant challenges in efficiency, scalability, and reliability. This workshop will bring together researchers and practitioners from academia and industry to highlight cutting-edge research, systems-level optimizations, and evaluation methodologies that are often overlooked yet pivotal for robust real-world integration. Efficiency, robustness, and reliability will be emphasized as core design principles, essential to advancing VLMs from experimental systems to dependable deployed technologies. By convening researchers at the intersection of multimodal learning, efficient inference and training, robustness and uncertainty estimation, and large-scale systems design, the workshop aims to establish concrete pathways toward building VLMs that can operate reliably under practical constraints. We hope this workshop will serve as a venue for exchanging insights on model design, efficiency techniques, and robustness evaluation that bridge the gap between research and real-world systems.",https://mozhgan91.github.io/vlm4rwd-neurips25-ws/
NeurIPS2025 Workshop Research Development AI Mexico,"Ponciano Jorge Escamilla-Ambrosio, Jose Martinez-Carranza, MIGUEL GONZALEZ-MENDOZA",Sun 30 Nov,1 p.m. PST — 8 p.m. PST,Don Alberto 3,"The Research Development of AI in Mexico: Main Applications workshop seeks to showcase, strengthen, and connect the most impactful developments in Artificial Intelligence (AI) and Data Science emerging from Mexico and the broader Latin American region. Over the past four decades, Mexico has cultivated a robust research community in AI through pioneering contributions in areas such as computational intelligence, autonomous robotics, fuzzy systems, and natural language processing, led by institutions including CIC–IPN, INAOE, UNAM, ITESM, CINVESTAV, and Universidad Veracruzana.Today, the region is undergoing a strategic transformation, shifting from foundational research to the development of applied AI technologies addressing real-world needs in healthcare, education, agriculture, smart cities, cybersecurity, and sustainability. This evolution has been further propelled by increased access to open data, advances in computing infrastructure, and growing collaborations between academia, government, and industry.Despite these advances, Latin America faces distinctive challenges in the development and deployment of AI. These include limited funding, underrepresentation in global AI initiatives, digital inequality, and the need for responsible, inclusive, and culturally relevant AI systems. Additionally, emerging concerns related to AI ethics, algorithmic bias, and regulatory frameworks must be addressed proactively to ensure equitable and trustworthy technology adoption.This workshop aims to create a forum for researchers, students, practitioners, and policymakers to engage in meaningful dialogue about the current landscape and future directions of AI in Mexico and Latin America. By promoting interdisciplinary collaboration, the workshop will highlight impactful case studies, emerging research trajectories, and opportunities for cross-border cooperation, while fostering a shared vision for AI that is ethical, sustainable, and aligned with regional priorities.",
NeurIPS 2025 Workshop on Embodied and Safe-Assured Robotic Systems,"Hu Cao, Derui Zhu, Alois Knoll, Shangding Gu, Costas J Spanos, Yiming Tang, Qiang Hu, Jiahui Geng, Xingcheng Zhou",Sun 30 Nov,1 p.m. PST — 8 p.m. PST,Don Alberto 2,"This workshop focuses on advancing safe and quality-assured embodied robotic systems. Embodied systems—including autonomous robots, self-driving vehicles, robotic arms, and humanoid robots—are increasingly deployed in safety-critical real-world scenarios. Ensuring their trustworthiness—encompassing safety, reliability, and predictable behavior—remains a pressing challenge. Despite notable progress in perception, reasoning, and control, many AI-based robotic systems still operate as “black boxes,” often exhibiting unpredictable behaviors. Failures can emerge from complex sensorimotor interactions, adversarial inputs, or novel environments, leading to safety incidents and diminished user trust.",https://neurips.cc/virtual/2025/workshop/127833
NeurIPS 2025 Workshop on Socially Responsible and Trustworthy Foundation Models,"Canyu Chen, Yue Huang, Xiangliang Zhang, Mohit Bansal, Yejin Choi, Dawn Song, Manling Li",Sun 30 Nov,1 p.m. PST — 8 p.m. PST,Don Alberto 1,"The Socially Responsible and Trustworthy Foundation Models (ResponsibleFM) Workshop at NeurIPS 2025 Mexico City is envisioned as a vital interdisciplinary forum dedicated to advancing ethical, inclusive, and socially conscious research practices in the rapidly evolving field of foundation models, including language models and multimodal models. As foundation models are tremendously reshaping human communication, decision-making, and societal infrastructures, there is a growing recognition of the profound impacts these systems can have, both positive and negative, on individuals and communities. In particular, previous research has documented a wide range of risks and harms associated with foundation models, including but not limited to bias and discrimination, misinformation propagation, privacy violations, environmental concerns, and unintended social consequences.",https://workshop-responsible-fm.github.io/
NORA: The First Workshop on Knowledge Graphs & Agentic Systems Interplay,"Btissam Er-Rahmadi, Sebastien Montella, Damien Graux, Hajira Jabeen",Mon 1 Dec,8 a.m. PST — 5 p.m. PST,Don Alberto 4,"Agents have experienced significant growth in recent years, largely due to the rapid technological advancements of Large Language Models (LLMs). Although these agents benefit from LLMs' advanced generation proficiency, they still suffer from catastrophic forgetting and a limited context window size compared to the agents' needs in terms of contextual information. Knowledge Graphs (KGs) are a powerful paradigm for structuring and managing connected pieces of information while unlocking deeper insights than traditional methods. Their value is immense for tasks that require context, integration, and reasoning. However, this power comes at the cost of significant upfront and ongoing investment in construction, curation, and specialized expertise. The first version of this workshop aims at analyzing and discussing emerging and novel practices, ongoing research and validated or deployed innovative solutions that showcase the growing synergy between LLMs agents and KGs.",https://nora-workshop.github.io/2025/
7th International Workshop on Large Scale Holistic Video Understanding: Toward Video Foundation Models,"Mohsen Fayyaz, Vivek Sharma, Ali Diba, Shyamal Buch, Anurag Arnab, Luc V Gool, Jürgen Gall, Joao Carreira, David Ross, Ehsan Adeli, Manohar Paluri",Mon 1 Dec,8 a.m. PST — 5 p.m. PST,Don Alberto 3,"This workshop aims to advance the field of video understanding by fostering discussions around holistic and generalist video foundation models. Building upon the Holistic Video Understanding (HVU) initiative and dataset introduced in 2019, we have successfully organized eight HVU workshops and tutorials at top-tier venues such as CVPR and ICCV, uniting researchers, practitioners, and students from around the world. These efforts have played a central role in moving the community beyond narrow action recognition tasks toward multi-faceted, semantic, and generalist video understanding.With the emergence of large-scale foundation models and video large language models (Video-LLMs), the landscape of video understanding is rapidly evolving. These models enable unified reasoning across spatial, temporal, and multimodal dimensions, yet introduce new challenges in scalability, efficiency, interpretability, and responsible deployment.The HVU Workshop 2025 will provide a platform to explore these frontiers, discussing topics such as multimodal representation learning, long-context reasoning, evaluation of general-purpose video systems, efficient adaptation and scaling laws, and the ethical and societal implications of video AI. Our goal is to bring together a diverse and inclusive community to define the next chapter of holistic, generalist, and responsible video understanding.",https://neurips.cc/virtual/2025/workshop/127828
First Workshop on LLM Persona Modeling,"Yunze Xiao, Shu Yang, Zhuang Li, Lucio La Cava, Jen-Tse Huang, Andrea Tagarelli, Xintao Wang, Marco Guerini, Jiarui Liu, Jindong Wang, Mona Diab, Maarten Sap",Mon 1 Dec,8 a.m. PST — 5 p.m. PST,Don Alberto 2,"Large language models (LLMs) are increasingly used to simulate human-like personas for applications in research, education, healthcare, and interactive AI systems. While such persona modeling creates opportunities for interdisciplinary innovation, it raises challenges around authenticity, consistency, bias, and ethical deployment. This workshop brings together perspectives from AI, psychology, cognitive science, and human–computer interaction to advance robust methods, standardized evaluation frameworks, and responsible practices for persona modeling in LLMs. Through invited talks, panels, posters, and discussions, the event will chart a roadmap for interdisciplinary collaboration and future research in this emerging area.",https://personallmworkshop.github.io/
Centering Low-Resource Languages and Cultures in the Age of Large Language Models,"Joy Olusanya, Mary Salami",Mon 1 Dec,8 a.m. PST — 5 p.m. PST,Don Alberto 1,"Large Language Models (LLMs) have transformed NLP research and applications, yet they are still predominantly trained on high-resource, globally dominant languages. This imbalance leads to poor performance and limited applicability for low-resource languages, which are rich in tone, morphology, and cultural meaning. As a result, current AI systems risk reinforcing linguistic inequality, cultural erasure, and lack of accessibility in critical domains like education and healthcare. This workshop aims to reframe language technology by centering low-resource languages, cultures, and epistemologies in the age of LLMs. We seek to bring together researchers, linguists, developers, healthcare professionals, and technologists to share insights and develop strategies for building inclusive, culturally grounded, and linguistically robust language models. The workshop emphasizes collaboration across disciplines and regions to ensure both technical advancement and social relevance. Key areas of focus include developing LLM architectures tailored to low-resource linguistic features, ethical and community-centered dataset collection, and multilingual benchmarks designed specifically for underrepresented languages. We also highlight the importance of healthcare and medical machine translation to support equitable access to information and improve public health outcomes. Ultimately, this workshop aims to advance responsible AI innovation that empowers low-resource language communities and shapes a more inclusive future for global language technologies.",https://clrlcllms.github.io/CLRLCLLMs-workshop.github.io-NeurIPS-2025
Embodied World Models for Decision Making,"Yunbo Wang, Qi Wang, Mengyue Yang, Shenyuan Gao, Huazhe Xu, Xin Jin, Mingqi Yuan, Nedko Savov, Guozheng Ma, Bo Liu, Siheng Chen, Yongquan Hu, Jenny Zhang, Nicklas Hansen, Minting Pan, Luc V Gool",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 30A-E,"World models infer and predict real-world dynamics by modeling the external environment, and have become a cornerstone of embodied artificial intelligence. They have powered recent progress in decision-making and planning for interacting agents. This workshop aims to bring together researchers working at the intersection of generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models—models that enable agents to understand, predict, and interact with the world through learned models. By focusing on embodiment and decision-making, this workshop seeks to advance world models beyond passive prediction, toward active, goal-driven interaction with the physical and virtual world. By emphasizing embodiment and decision-making, we aim to move beyond passive sequence prediction toward goal-directed interaction with both physical and simulated worlds.",https://embodied-world-models.github.io/
Differentiable Learning of Combinatorial Algorithms: From Theory To Practice,"Cathy Wu, Nikolaos Karalias, Yusu Wang, Indradyumna Roy, Abir De",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 25ABC,,
ML for Systems,"Dan Zhang, Xinlei XU, Mangpo Phothilimthana, Divya Mahajan, Haoran Qiu, Patrick Musau",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 5AB,"The 9th Machine Learning for Systems (ML for Systems) workshop brings together researchers and practitioners applying machine learning to core computer systems challenges. This year, we focus on three themes: (1) using LLMs and agentic workflows for systems tasks such as program synthesis and adaptive optimization; (2) applying ML to manage the complexity of large-scale training and serving of multimodal and reasoning models; and (3) leveraging ML for sustainable computing, including energy-, power-, and carbon-aware optimization. The workshop will feature invited talks, contributed presentations, and discussions aimed at advancing the frontier of ML for Systems research.",https://mlforsystems.org/
AI4Mat-NeurIPS-2025: NeurIPS 2025 Workshop on AI for Accelerated Materials Design,"Santiago Miret, ALEXANDRE DUVAL, Rocío Mercado, Emily Jin, N M Anoop Krishnan, Kevin Maik Jablonka, Marta Skreta, Stefano Martiniani",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 29A-D,"AI4Mat-NeurIPS-2025 explores applications of artificial intelligence (AI) to materials via: 1. AI-Guided Materials Design; 2. Automated Chemical Synthesis; 3. Automated Material Characterization. AI4MatNeurIPS-2025 emphasizes structured, expert-driven dialogue on making advanced machine learning more impactful for real-world materials discovery. To that end, AI4Mat-RLSF (Research Learning from Speaker Feedback) creates a new structured discussion format where spotlight presenters receive curated, in-depth feedback from invited discussants. Further, the AI4Mat Frontiers & Benchmarking session brings together a diverse and distinguished set of speakers to critically examine current benchmarks, present state-of-the-art methods, and identify emerging opportunities and current limitations in AI-driven materials design.",https://sites.google.com/view/ai4mat
Workshop on Multi-Turn Interactions in Large Language Models,"Simon Yu, Bo Liu, Yifei Zhou, Mickel Liu, Kai Zhang, Hanxu Hu, Leon Guertler, Leshem Choshen, Weiyan Shi",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 11AB,"The field of AI is entering a new era of interaction, profoundly shaped by the capabilities of Large Language Models (LLMs). While multi-turn interaction has been a long-standing pursuit in AI—from dialogue systems to multi-agent coordination—the advent of LLMs has radically transformed this landscape. These models now engage in complex, long-horizon interactions, process diverse data, and make crucial decisions in dynamic, human-centric scenarios. This leap forward, however, brings forth critical new research questions and challenges that demand immediate attention: Multi-Turn RL Learning for Agentic Tasks Learning from complex, interactive environments like GUI agents and tool-use scenarios, given the challenges of sparse rewards. Maintaining Alignment Understanding human values over extended, multi-turn interactions, preventing ""loss of alignment"" seen in current models. Human-AI Interaction Over time, ensuring models adapt to user goals without compromising safety or fairness. Long-horizon Evaluation For LLMs' long-term capabilities, consistency, and strategic abilities in complex, multi-turn tasks. The Workshop on Multi-Turn Interactions in LLMs is designed to be the central forum for addressing these pivotal questions. We invite researchers to contribute to defining the next generation of interactive AI, tackling these core challenges, and charting the course for future advancements in AI reasoning and planning. This workshop will concentrate on key areas where the extended use of LLMs presents both new challenges and opportunities, serving as a platform to discuss and refine methods for future improvements and evaluation for practical LLM use cases.",https://workshop-multi-turn-interaction.github.io/
"Dynamics at the Frontiers of Optimization, Sampling, and Games","Tatjana Chavdarova, Dilsad ER, Niao He, Michael Jordan, Eric Moulines, Michael Muehlebach, Molei Tao, Andre Wibisono",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 7,,https://sites.google.com/view/dynafrontneurips25
Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET),"Marco Mussi, Till Freihaut, Antoine Moulin, Giorgia Ramponi, Dirk van der Hoeven, Alberto Maria Metelli, Felix Berkenkamp, Francesco Trovò, Csaba Szepesvari",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 31ABC,"Recent progress in reinforcement learning (RL) has powered breakthroughs in various real-world problems, gathering considerable attention and investment. However, it has also exposed a significant gap between theoretical and experimental developments. RL theory has grown significantly in the past two decades. Research has characterized the inherent difficulty of various settings and has designed a wide variety of algorithms to reach optimal performances. Furthermore, a huge leap has been made in understanding how to handle large state spaces using function approximation techniques, identifying key structural properties that enable efficient learning. Despite theoretical guarantees, applying RL algorithms to complex problems faces challenges. Theoretical algorithms often focus on simplified settings, making them hard to apply to real-world complexities. Furthermore, optimizing for worst-case scenarios, which include unlikely situations, can lead to algorithms that perform poorly on practical tasks. Yet, while specialized algorithms offer empirical success, they might not translate to other problems due to their specific design, and the reliance on heuristics and engineering fixes further widens the gap between theory and practice. A prominent area that has seen a surge of interest in RL is generative language modeling. Pre-training these models can be viewed as a form of imitation learning, while post-training typically implements RL algorithms for purposes like instruction tuning with RL from human feedback or enhancing reasoning capabilities. While these successes make the practical utility of RL undeniable, the RL community finds itself at a crossroads. The algorithms employed are frequently variants of classical methods, and exploring beyond these presents a key challenge. Conversely, the success of these models prompts new questions for RL theory, suggesting that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions. Following the success of the ICML 2024 edition, the Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) aims to bridge this discrepancy and promote collaboration. By bringing together experts from both sides, we want to facilitate meaningful discussions and draw a path for future RL research. Motivated by the take-home messages from the previous edition, we seek to encourage: (i) theorists to ask experimentalists for concrete problems to solve, and (ii) experimentalists to seek theoretical guidance on how to approach these problems.",https://arlet-workshop.github.io
AI Virtual Cells and Instruments: A New Era in Drug Discovery and Development,"Quanquan Gu, Michelle Li, Chong Liu, Xuefeng Liu, Abhishek Pandey, Nataša Tagasovska, Marinka Zitnik",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 28A-E,"As the US FDA phases out animal testing requirements for drug discovery and development, AI tools will become widely adopted to simulate the effects of candidate drugs. We posit that building virtual cells and instruments with AI is poised to transform drug discovery and development by enabling large-scale simulation and interrogation of molecules, cells, and tissues. In our workshop, we will collaboratively define and promote this emerging scientific paradigm of AI to accelerate the drug discovery and development process in this new era.",https://ai4d3.github.io/2025/index.html
GenProCC: 1st Workshop on Generative and Protective AI for Content Creation,"Wei-Yao Wang, Takashi Shibuya, vali lalioti, Wei Wang, Shusuke Takahashi, Yuki Mitsufuji",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 23ABC,"Recent advancements in generative AI (GenAI) have empowered machines to create high-quality content across diverse modalities - text, image, audio, and video - with impressive fluency and creativity. From GPT-4o and Stable Diffusion to Sora and MMAudio, the explosion of X-to-X generation (e.g., text-to-image, video-to-audio) is unlocking new frontiers in science, education, entertainment, and art. While GenAI has shown significant potential in creative applications (e.g., music, films, arts), these breakthroughs also raise pressing concerns related to safety, copyright, and ethical use. Generative models can be exploited to spread misinformation, violate intellectual property rights, or diminish human agency in creative processes. As such, there is an increasing need to balance innovation with protection, ensuring that AI-powered creative tools are used responsibly and ethically. This workshop, GenProCC: Generative and Protective AI for Content Creation, brings together researchers, creators, and practitioners at the intersection of content generation and IP protection. By uniting the generative AI and creator communities, the GenProCC workshop aims to explore the latest advances, challenges, and opportunities in the rapidly evolving field.",https://genprocc.github.io/
What Makes a Good Video: Next Practices in Video Generation and Evaluation,"Xinting Hu, Yongliang Wu, Anna Kukleva, Zhicai Wang, Chenyang Si, Li Jiang, Gang Yu, Xu Yang, Ziwei Liu, Bernt Schiele",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 6B,"This workshop aims to explore how real-world advances in video generation increasingly rely on forwardlooking evaluation frameworks and to collaboratively shape the next generation of high-quality video synthesis. Through a combination of invited talks, academic presentations, and expert discussions featuring leading voices from both academia and industry, the workshop bridges academic foundations and industrial insights across the modeling, evaluation, and deployment of video generation. We welcome contributions from computer vision, generative modeling, video-language learning, evaluation methodology, and human-centered AI to shape the next generation of high-quality video synthesis collaboratively.",https://what-makes-good-video.github.io/
CauScien: Uncovering Causality in Science,"Dingling Yao, Jiaqi Zhang, Piersilvio De Bartolomeis, Ying Jin, Alexander D\'Amour, Caroline Uhler, Kun Zhang, Francesco Locatello",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 8,,https://sites.google.com/view/causcien
UniReps: Unifying Representations in Neural Models,"Marco Fumero, Zorah Laehner, Irene Cannistraci, Clémentine Dominé, Bo Zhao, Alex Williams",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 20D,"When, how and why do different neural models learn the same representations? New findings in neuroscience and artificial intelligence reveal a shared pattern: whether in biological brains or artificial models, different learning systems tend to create similar representations when subject to similar stimuli. The emergence of these similar representations is igniting a growing interest in the fields of neuroscience and artificial intelligence, with both fields offering promising directions for their theoretical understanding. These include analyzing the learning dynamics in neuroscience and studying the problem of identifiability in the functional and parameter space in artificial intelligence. While the theoretical aspects already demand investigation, the practical applications are equally compelling: aligning representations allows for model merging, stitching and reuse, while also playing a crucial role in multi-modal scenarios. Furthermore, studying the features that are universally highlighted by different learning processes brings us closer to pinpoint the invariances that naturally emerge from learning models, possibly suggesting ways to enforce them. The objective of the workshop is to discuss theoretical findings, empirical evidence and practical applications of this phenomenon, benefiting from the cross-pollination of different fields (ML, Neuroscience, Cognitive Science) to foster the exchange of ideas and encourage collaborations. In conclusion, our primary focus is to delve into the underlying reasons, mechanisms, and extent of similarity in internal representations across distinct neural models, with the ultimate goal of unifying them into a single cohesive whole.",https://unireps.org/2025/
ML x OR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making,"Jose Blanchet, Jing Dong, Henry Lam, Min-hwan Oh, Qiaomin Xie, Yao Xie, Assaf Zeevi, Enlu Zhou",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 26AB,"Much of traditional decision-making science is grounded in the mathematical formulations and analyses of structured systems to recommend decisions that are optimized, robust, and uncertainty-aware. This scientific approach, rooted in the field of Operations Research (OR), has evolved through decades of advancements in stochastic modeling, computational simulation and optimization, and exhibits key strengths in methodological rigor and uncertainty encoding. On the other hand, recent advances in the AI/ML space have eschewed this model-based paradigm and increasingly embraced, to great success, model-free algorithmic design frameworks. This workshop, which is the first NeurIPS workshop explicitly themed and structured on ML-OR synergization, aspires to present recent developments, challenges and emerging research to accelerate ML-OR synthesis. By integrating ML into established OR methodologies, we have the opportunities to produce more data-centric and adaptive solutions for complex decision-making tasks that could propel, in a much faster-paced manner, the frontier of ""optimality"" across many relevant applications. Concomitantly, the goal is also to explore how model-based principled OR approaches can help alleviate issues revolving around ""black box"" systems, and provide paths to enhance interpretability, trust, and performance analysis.",https://mlxor-workshop.github.io/
The First Workshop on Efficient Reasoning,"cheng Luo, Xinyu Yang, Simran Arora, Weijia Shi, Hanshi Sun, Songlin Yang, Luca Zancato, Jiawei Zhao",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Exhibit Hall F,"Recent progress in large reasoning models (LRMs), like OpenAI o1 and Deepseek R1, has been pivotal for tackling complex applications, from mathematical and code reasoning to advanced symbolic and agentic planning. Their success often relies on test-time scaling, which involves increasing the generation length or depth. However, these approaches incur significant efficiency bottlenecks during training and inference. To overcome these limitations, further advancements are needed in data, algorithms, and systems applicable across various domains, as exemplified by work such as s1, Z1, and verl. The proposed workshop will bring together researchers and practitioners to rethink efficient reasoning under tight compute, memory, latency, throughput, and cost budgets, with the goal of translating theoretical breakthroughs into practical, deployable solutions.",https://efficient-reasoning.github.io/
Imageomics: Discovering Biological Knowledge from Images Using AI,"Jianyang Gu, Sam Stevens, Zheda Mai, Kaiya Provost, Lily Weng, Sara Beery, Subhransu Maji, Anuj Karpatne, Ben Weinstein",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 32AB,"Imageomics is an emerging interdisciplinary field at the crossroads of machine learning (ML), computer vision (CV), and biological sciences. It leverages visual data—from microscopic images of single-cell species to videos of megafauna—to extract and analyze biological information, specifically traits. By grounding ML models in existing scientific knowledge, Imageomics aims to make traits computable from images, facilitating insights into the evolution and function of living organisms. Imageomics poses research problems that resonate with the broad machine-learning community: multimodal representation learning, object detection and tracking, few-shot learning, imbalanced-class learning, video understanding, 3D modeling, hierarchical learning, etc. When people leverage ML tools to solve biological questions, the foundational bridges between ML and biological sciences also provide opportunities to address key challenges in ML, creating a virtuous cycle between the two fields.",https://imageomics.github.io/Imageomics-NeurIPS-2025/
Deep Learning for Code in the Agentic Era,"Zijian Wang, Giovanni Zappella, Qian Liu, Zora Wang, Wen-Ding Li, Wasi Uddin Ahmad, Binyuan Hui",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,"Exhibit Hall G,H","Deep learning for code has progressed from focused tasks—such as completion, repair, synthesis, and explanation to tackling complex, end-to-end software–engineering problems. A key recent breakthrough is the rise of coding agents. Unlike single-shot models, these systems plan, reason, explore, and invoke external tools to assist throughout the software-development lifecycle: adding features, refactoring, debugging, finding vulnerabilities, optimizing performance, summarizing code, and answering repository-level questions. Their growing versatility demands rigorous evaluation and a deeper understanding of their capabilities, limits, risks, and broader social impact. Building on momentum from both academia and industry (e.g. Google, OpenAI, Anthropic, SWE-Agent, OpenHands), we propose the 4th Deep Learning for Code (DL4C) workshop with a dedicated focus on coding agents. This workshop will provide a timely forum where researchers and practitioners can design and stress-test robust coding agents, discover novel applications and emergent behaviors, establish principled benchmarks and evaluation methods, study human–agent collaboration at scale, and advance the responsible, safe deployment of autonomous coding tools.",https://dl4c.github.io
Generative AI in Finance,"Renyuan Xu, Randall Balestriero, Jiawei He, Yongjae Lee, Zhangyang ""Atlas"" Wang, Yu Yu, Yinbin Han",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 3,"This workshop aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance, a high-stakes domain where the integration of domain expertise is essential to the safe and effective deployment of machine learning technologies. Recent advances in generative models—ranging from large language models to diffusion and score-based generative architectures—have opened new frontiers for applications in finance, such as financial modeling, stress testing, scenario generation, automated financial services, and decision-making under uncertainty. The workshop will highlight theoretical advances, practical implementations, new opportunities, and open challenges that arise when adapting generative AI to financial systems under unique constraints, such as data sparsity, regulatory requirements, and highly non-stationary and adversarial environments. By bringing together the computer science community, financial researchers, industry practitioners, and regulators, we aim to catalyze interdisciplinary dialogue and accelerate the responsible development of generative AI tailored to the needs of finance and risk management.",https://sites.google.com/view/neurips-25-gen-ai-in-finance/home
MATH-AI: The 5th Workshop on Mathematical Reasoning and AI,"Kaiyu Yang, Sophia S. Han, Pan Lu, Wei Xiong, Eric Zelikman, Yong Lin, Zhizhen Qin, Soonho Kong, He He, Dawn Song, Sanjeev Arora",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 6A,,https://mathai2025.github.io/
"The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance","Jiawei Xu, Tiange Xiang, Pranav Rajpurkar, Junyuan Hong, Changan Chen, Ehsan Adeli, Xiaoxiao Li, Georgios Pavlakos, Scott Delp, Fei-Fei Li, Ying Ding",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 33ABC,"Generative AI (GenAI) has emerged as a transformative force in healthcare, yet public trust remains limited due to safety concerns and policy misalignment. Building on last year’s successful GenAI4Health workshop, the field has rapidly evolved from exploratory research to real-world clinical deployments, accompanied by FDA regulatory involvement and expanding global governance frameworks. This second workshop convenes machine learning researchers, healthcare professionals, and policy experts to address the critical intersection of GenAI innovation and regulatory compliance in health applications. We will examine trustworthiness challenges in large language models and multimodal foundation models, explore mitigation strategies, and foster dialogue between technical and policy communities. Our goal is to advance safe, effective, and ethically-compliant GenAI integration in healthcare systems, improving patient outcomes and clinical research capabilities.",https://genai4health.github.io/
Algorithmic Collective Action,"Elliot Creager, Nicholas Vincent, Celestine Mendler-Dünner, William Agnew, Hanlin Li, Ulrich Aïvodji",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 4,"The study of collective action has a long history in economics and sociology as a way for groups of people to impact markets and the political arena. Algorithmic collective action focuses on the study of such coordinated efforts in algorithmically-mediated sociotechnical systems. How can participants of AI systems coordinate towards socially beneficial outcomes? We offer a platform to discuss new ideas and help define the foundational research directions for this emerging topic through interdisciplinary discussions between core ML researchers, scholars from the social sciences, community stakeholders and advocates.",https://acaworkshop.github.io/
"Lock-LLM Workshop: Prevent Unauthorized Knowledge Use from Large Language Models - Deep Dive into Un-Distillate, Un-Finetunable, Un-Compressible, Un-Editable, and Un-Usable","Tianlong Chen, Ang Li, Furong Huang, Avi Schwarzschild, Neil Gong, Bo Li, Yuxiong He",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 1AB,"Large Language Models (LLMs) have emerged as transformative tools across research and industry, revolutionizing how we interact with information. However, their immense capabilities bring critical security challenges—the same features that drive innovation can be exploited for malicious purposes through unauthorized distillation, fine-tuning, compression, or editing. These vulnerabilities pose severe threats, including intellectual property theft, the generation of sophisticated disinformation, the bypass of safety alignments, and the erosion of user trust in AI systems. This workshop aims to bring together researchers and practitioners from academia and industry who are advancing the frontiers of LLM security and protection. We seek to confront the unauthorized use of LLMs head-on by exploring novel and robust mechanisms designed to make these models inherently resistant to exploitation while maintaining their beneficial capabilities. The workshop also hosts the 2025 TrustAI Rising Star Award. Topics of interest include, but are not limited to: 1. Un-Distillable LLMs: Preventing unauthorized model replication and intellectual property theft 2. Un-Finetunable LLMs: Resisting malicious parameter updates and behavior alterations 3. Un-Compressible LLMs: Maintaining model integrity against unauthorized compression 4. Un-Editable LLMs: Safeguarding against knowledge tampering and misinformation injection 5. Un-Usable LLMs: Ensuring traceability and preventing misuse through watermarking and verification",https://lock-llm.github.io/
Structured Probabilistic Inference and Generative Modeling,"Yuanqi Du, Dinghuai Zhang, Jiajun He, Heli Ben-Hamu, Francisco Vargas, Yunan Yang, Animashree Anandkumar, Arnaud Doucet, José Miguel Hernández-Lobato",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 20C,,https://spigmworkshopv3.github.io/
Foundation Models for the Brain and Body Workshop,"Mehdi Azabou, Cole Hurwitz, Sophia Sanborn, Sana Tonekaboni, Paul Scotti, Nanda H Krishna, Pierre Guetschel",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 24ABC,,https://brainbodyfm-workshop.github.io
Biosecurity Safeguards for Generative AI,"ZAIXI ZHANG, Amrit Singh Bedi, Mengdi Wang, Ruofan Jin, Le Cong, Souradip Chakraborty, Alvaro Velasquez",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 27AB,,
AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG @ NeurIPS’25),"Cong Shen, Christopher Brinton, Gauri Joshi, Hyeji Kim, Osvaldo Simeone, Shiqiang Wang, Taesang Yoo, Jun Zhang",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 10,"The field of wireless communications and networking is undergoing a paradigm shift, driven by the growing potential of Artificial Intelligence (AI) and Machine Learning (ML) to redefine traditional system design principles. This workshop aims to catalyze interest and foster collaboration between the AI/ML and wireless communications communities. The timing of this workshop is especially significant, as the next-generation (NextG) wireless standardization efforts (such as 6G and WiFi 9) are just getting started, with AI-native technologies expected to play a central role across all aspects of the wireless ecosystem – from radio access to network management and edge intelligence. NextG represents a foundational shift in global infrastructure, enabling ultra-fast, low-latency, and intelligent connectivity that will power future applications in AI, robotics, immersive environments, and autonomous systems. These technologies offer unprecedented opportunities to both drive and benefit many applications, from healthcare and transportation to industrial automation and environmental monitoring. The economic and societal implications are vast: NextG networks will underlie trillions in global GDP impact, bridge digital divides, and shape how billions of people interact with technology and each other in the decades to come. Despite the clear promise, a significant disconnect exists between the AI/ML and wireless research communities. AI/ML experts often lack an understanding of the unique physical, algorithmic, and architectural constraints inherent in wireless systems, while wireless researchers tend to adopt generic, off-the-shelf AI/ML models that are not optimized for the intricacies of wireless environments. Wireless environments are inherently dynamic, high-dimensional, and partially observable. These unique characteristics make them ideal testbeds for developing robust learning algorithms, particularly in areas like online learning, reinforcement learning, and in-context learning. At the same time, AI/ML techniques are becoming essential for managing the growing complexity of modern wireless networks, including resource allocation, interference mitigation, and cross-layer optimization. Bridging the gap between the two communities is not only necessary for meaningful technological advances but also critical for realizing the full societal impact of intelligent wireless systems. This workshop aims to bring together researchers and practitioners at the intersection of artificial intelligence (AI), machine learning (ML), and wireless to address the unique challenges and opportunities posed by Next-Generation (NextG) wireless systems. As the 6G era begins to take shape, AI-native designs have emerged as a cornerstone of wireless innovation, with the potential to transform the performance, efficiency, and adaptability of communication systems. The integration of AI/ML is poised to influence every layer of the network stack, from physical-layer signal processing to network control and resource management.",https://ai4nextg.github.io/
Machine Learning and the Physical Sciences,"Nicole Hartman, Garrett Merz, Vinicius Mikuni, Mariel Pettee, Sebastian Wagner-Carena, Antoine Wehenkel, Atilim Gunes Baydin, Kyle Cranmer, Siddharth Mishra-Sharma, Benjamin Nachman, Brian Nord, Savannah Thais",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 6CF,"The Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS is a unique gathering space for the growing community spearheading cross-cutting research topics at the intersection of machine learning (ML) and the physical sciences (PS). This includes the applications of ML to problems in the physical sciences (ML for PS) as well as developments in ML motivated by physical insights (PS for ML). The physical sciences are defined inclusively, including but not limited to physics, astronomy, cosmology, chemistry, biophysics, materials science, and Earth science. Join us to discuss the latest research at the convergence of these fields!",https://ml4physicalsciences.github.io/
Reliable ML from Unreliable Data,"Andrew Ilyas, Alkis Kalavasis, Anay Mehrotra, Manolis Zampetakis",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 2,"Distributions shift, chatbots get jail‑broken, users game algorithms — how do we build reliable machine learning when data are missing, corrupted, or strategically manipulated? This workshop bridges theory and practice to tackle these challenges, bringing together researchers working on distribution shift, adversarial robustness, and strategic behaviour to chart principled yet deployable solutions for Reliable ML from Unreliable Data.",https://reliablemlworkshop.github.io/
OPT 2025: Optimization for Machine Learning,"Cristóbal Guzmán, Courtney Paquette, Misha Belkin, Zakaria Mhammedi, Frederik Kunstner, Sebastian Stich",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 20A,"Optimization lies at the heart of many machine learning algorithms and enjoys great interest in our community. Indeed, this intimate relation of optimization with ML is the key motivation for the OPT series of workshops. We aim to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to ML. The focus of OPT 2025 is on ""Statistics Meets Optimization"". Since its inception, stochastic optimization has been grounded in statistical principles. Today, many of the most pressing challenges in machine learning—such as generalization bounds, the training dynamics of overparameterized models, and the development of generative models—are directly inspired by statistical thinking. At the same time, the scale and complexity of modern datasets, along with the increasingly rich model classes used to represent them, pose new questions about how optimization algorithms interact with these structures—both computationally and statistically. For example, what role do data symmetries play in shaping optimization trajectories? How do statistical properties of the data affect the adaptivity and efficiency of learning algorithms? And how can optimization approaches be designed to scale with data while still preserving desirable statistical behavior? OPT 2025 will explore these questions with the goal of building bridges between the statistics and optimization communities, and highlighting their shared impact on the theory and practice of machine learning. We are looking forward to seeing you all at OPT 2025, which will take place at the San Diego Convention Center!",https://opt-ml.org
AI for non-human animal communication,"Ellen Gilsenan-McMahon, Brittany Solano",Sat 6 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 9,"The past few years have seen an unprecedented surge in both the availability of bioacoustic data and the sophistication of AI/machine learning models. This convergence presents a unique window of opportunity to revolutionize our understanding of animal communication and biodiversity. However, achieving this requires a conscious effort to integrate the disciplines of AI/Machine Learning and Ethology. This workshop will explore the intersection of artificial intelligence (AI) and bioacoustics, aiming to address challenges in processing complex bioacoustic data and interpreting animal signals in order to advance our understanding of non-human animal communication. Join us for a poster session, keynote talks and a panel discussion as we explore key opportunities to use AI to decipher animal languages and thus deepen our understanding of the natural world.",https://aiforanimalcomms.org/
Constrained Optimization for Machine Learning,"Juan Ramirez, Meraj Hashemizadeh, Ignacio Hounie, Juan Elenter, Katya Scheinberg, Alejandro Ribeiro, Simon Lacoste-Julien",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 6DE,"As AI systems are increasingly deployed in safety-critical domains—including credit scoring, medical diagnosis, and autonomous systems—there is a growing demand to ensure their fairness, safety, robustness, and interpretability, alongside stronger calls for regulation. Constrained optimization offers an accountable framework for enforcing these requirements by embedding them directly into the training process, steering models to satisfy explicit constraints. This framework facilitates compliance with regulatory, industry, or ethical standards, which can be easily verified by checking constraint satisfaction. This workshop explores constrained optimization as a principled method for enforcing desirable properties in machine learning models. It brings together experts in optimization, machine learning, and trustworthy AI to address the algorithmic and practical challenges of scaling constrained methods to modern deep learning settings, which are often large-scale, non-convex, and stochastic.",https://constrained-opt-ml.github.io/
Artificial Intelligence for Music: Where Creativity Meets Computation,"Hao-Wen Dong, Zachary Novack, Yung-Hsiang Lu, Kristen Yeon-Ji Yun, Benjamin Chou",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 27AB,"This workshop explores the dynamic intersection of AI and music, a rapidly evolving field where creativity meets computation. The goal of this workshop is twofold: First, we aim to explore the latest advancements of AI’s applications for music, from analysis, creation, performance, production, retrieval to music education and therapy. Second, we aim to discuss the impacts and implications of AI in music, including AI’s impacts on the music industry, musician community, and music education as well as ethical, legal and societal implications of AI music and AI’s implications for future musicians.",https://aiformusicworkshop.github.io/
2nd Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences,"Pengtao Xie, James Zou, Le Song, Ruishan Liu, Aidong Zhang, Eran Segal, Wei Wang, Li Zhang",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 31ABC,,https://nips2025fm4ls.github.io/index.html
Workshop on Scaling Environments for Agents,"Yuan He, Guohao Li, Yi R. (May) Fung, Qingyun Wang, Fangru Lin, Xingyue Huang, Alisia Lupidi, Yusheng Su, Ziyu Ye, Da Yin, Ziyi Yang, Jialin Yu, Sunando Sengupta, Rishabh Agarwal, Bernard Ghanem, Animashree Anandkumar, Philip Torr",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 23ABC,"The development of intelligent agents – particularly those powered by large language models (LLMs) – has emphasized the critical role of environments in shaping agent behavior and capabilities, especially for achieving end-to-end autonomy. Environments are not merely testing grounds; they are dynamic, interactive contexts that serve as the essential ""data"" for agents to learn adaptive behavior, complex reasoning, and long-term decision-making skills. Just as scaling the model size, dataset size, and training computation has led to emergent capabilities in LLMs, scaling the structure, fidelity, and diversity of environments is one of the crucial dimensions in advancing agent intelligence. Moreover, recent advances in end-to-end reinforcement learning (RL), particularly when paired with LLM-based agents, have made it increasingly viable to train agents through sustained interaction. These agents can now acquire skills, strategies, and planning abilities through environmental feedback, rather than relying solely on imitation learning or static prompt engineering. As we move toward more autonomous, general-purpose agents, the need for scalable, richly interactive, and diverse environments has become both urgent and foundational.",https://sea-workshop.github.io
CogInterp: Interpreting Cognition in Deep Learning Models,"Eric Bigelow, Jennifer Hu, Ekdeep S Lubana, Kanishk Gandhi, Laura Ruis, Thomas Fel, Ellie Pavlick, Noah Goodman",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 5AB,"Recent innovations in deep learning have produced models with impressive capabilities, achieving or even exceeding human performance in a wide range of domains. A timely and critical challenge in AI is understanding what behaviors these models are actually capable of, and the internal processes which support these behaviors. As interest continues to grow in models’ internal processes, the field of cognitive science is becoming increasingly useful for describing and understanding cognition in deep learning models: cognitive science, which seeks to describe the cognitive processes in human and animal minds, offers a rich body of theories, experiments, and frameworks which may be adopted to understand how deep learning models achieve complex behaviors in domains such as language, vision, and reasoning. The workshop will focus on Cognitive Interpretability (“CogInterp”), which involves the systematic interpretation of high-level cognition in deep learning models. Similar to how cognitive science describes the intermediate representations and algorithms (or cognition) between behavior and neurons in biological systems, the goal of Cognitive Interpretability is to describe the cognitive processes which lie between the levels of behavioral evaluations and mechanistic interpretability in deep learning models. Practically speaking, this means that Cognitive Interpretability does not just ask whether a model can perform task X or has a certain ability Y , but additionally (or instead) how a model performs X or learns and implements Y . These kinds of inferences—from observable behavior to latent “mental” processes—are the bread and butter of cognitive science, but many of the theoretical and empirical tools developed to tackle these problems have not yet been widely adopted in AI research, in part because of the separation between the fields and communities. To address the gap above, our goal is to bring together researchers in cognitive science and AI interpretability to discuss new empirical results and theories about the inner workings of deep learning models. We hope to gather perspectives from various disciplines, including machine learning, psychology, linguistics, vision science, neuroscience, philosophy of mind, and law.",https://coginterp.github.io/neurips2025/
"NeurIPS 2025 Workshop on Space in Vision, Language, and Embodied AI","Ziqiao Ma, Freda Shi, Jiayuan Mao, Jiafei Duan, Manling Li, David Hsu, Parisa Kordjamshidi",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 29A-D,,https://space-in-vision-language-embodied-ai.github.io/
Workshop on Mechanistic Interpretability,"Neel Nanda, Martin Wattenberg, Sarah Wiegreffe, Atticus Geiger, Julius Adebayo, Kayo Yin, Fazl Barez, Lawrence Chan",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 30A-E,,https://mechinterpworkshop.com
"Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling","Berivan Isik, Beyza Ermis, Nithya Attaluri, Rishi Bommasani, Marius Hobbhahn, Yangjun Ruan, Diyi Yang",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 2,,https://sites.google.com/corp/view/llm-eval-workshop
Symmetry and Geometry in Neural Representations,"Francisco Acosta, Chase van de Geijn, Simone Azeglio, Christian A Shewmake, Sophia Sanborn, Nina Miolane",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 6A,"The fields of biological and artificial intelligence are increasingly converging on a shared principle: the geometry and topology of real-world structure play a central role in building efficient, robust, and interpretable representations. In neuroscience, mounting evidence suggests that neural circuits encode task and environmental structure through low-dimensional manifolds, conserved symmetries, and structured transformations. In deep learning, principles such as sparsity, equivariance, and compositionality are guiding the development of more generalizable and interpretable models, including new approaches to foundation model distillation. The NeurReps workshop brings these threads together, fostering dialogue among machine learning researchers, neuroscientists, and mathematicians to uncover unifying geometric principles of neural representation. Just as geometry and symmetry once unified the models of 20th-century physics, we believe they may now illuminate the computational foundations of intelligence.",https://www.neurreps.org/
"LAW 2025: Bridging Language, Agent, and World Models for Reasoning and Planning","Zhen Wang, Ziqiao Ma, Jessy Lin, Melanie Sclar, Jianwen Xie, Kelsey Allen, Alane Suhr, Jacob Andreas, Tianmin Shu, Zhiting Hu",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 20D,,https://sites.google.com/view/law-2025
GPU-Accelerated and Scalable Optimization (ScaleOpt),"Parth Nobel, Fangzhao Zhang, Maximilian Schaller, Alexandre Amice, Tobia Marcucci, Tetiana Parshakova, Stephen Boyd",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 9,"Recent advancements in GPU-based large-scale optimization have been remarkable. Recognizing the revolution in optimizing neural network weights via large-scale GPU-accelerated algorithms, the optimization community has been interested in developing general purpose GPU-accelerated optimizers for various families of classic optimization problems, including linear programming, general conic optimization, combinatorial optimization, and more specific problem families such as flow optimization and optimal transport. Beyond deploying GPUs directly at classical problems, current frontier AI tools—including large language models (LLMs)—are being deployed to solve optimization problem. Various works have used neural networks to solve mixed integer problems, linear or quadratic programs, general combinatorial optimization problems, and more specific optimization problems such as LASSO and robust PCA. In this workshop, we aim to provide a platform for interested researchers to engage with each other on recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems.",https://cvxgrp.org/scaleopt
Data on the Brain and Mind,"Catherine Ji, Vivek Myers, Archer Wang, Benjamin Eysenbach, Jenelle Feather, Erin Grant",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 10,,https://data-brain-mind.github.io/
Foundations of Reasoning in Language Models,"Audrey Huang, Adam Block, Sadhika Malladi, Will Merrill, Tatsunori Hashimoto, Dylan J Foster, Akshay Krishnamurthy, Pavel Izmailov",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 33ABC,"Our workshop’s goal is to advance foundational understanding, principled innovations, and rigorous scientific evaluations for reasoning in language models. These advancements are built upon theoretical analyses and controlled empirical studies that illuminate how reasoning emerges, where it fails, and how it can be systematically improved. We want to foster dialogue between communities with complementary strengths---those building theoretical models of reasoning phenomena, those designing experiments that reveal its emergence or failure in practice, and those proposing algorithmic developments that advance reasoning---around three primary questions: 1. How are language models able to solve complex tasks, and what do they still struggle with? 2. What fundamental challenges stand in the way of advancing reasoning capabilities? 3. What algorithmic innovations can overcome these obstacles?",https://reasoning-workshop.github.io/
Learning from Time-Series for Health,"Max Xu, Hyewon Jeong, Wanting Mao, Girish Narayanswamy, Sujay Nagaraj, Tom Hartvigsen, Xin Liu, Sana Tonekaboni, James Rehg",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 28A-E,"Time-series data underpin modern healthcare, spanning electronic health records, physiological waveforms, wearables, and population trends, yet their unique characteristics—including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints—demand specialized machine learning approaches. While recent advances in foundation models, multimodal learning, and generative methods show promise, significant challenges remain in causality, interpretability, and deployment. This workshop unites researchers across health time-series domains (from wearables to clinical systems) to address shared challenges through: (1) cross-domain discussion, (2) diverse industry/academic perspectives (featuring Google, Oura, Apple and 5 institutions), and (3) community engagement via posters, talks, and panels. By fostering cross-domain collaboration on physiological-aware methods, we aim to bridge the gap between cutting-edge ML and real-world healthcare impact.",https://timeseries4health.github.io/
Multimodal Algorithmic Reasoning Workshop,"Anoop Cherian, Kuan-Chuan Peng, Suhas Lohit, Honglu Zhou, Kevin Smith, Josh Tenenbaum",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 11AB,"Large AI frameworks have been increasing in their data modeling abilities at an ever more vigor in recent times, with compelling applications emerging frequently, many of which may even appear to challenge human intelligence. Yet despite such impressive performance, there remain open questions about whether these models include the foundations of general intelligence, or whether they perform these tasks without human-like understanding. This necessitates development of better tools for assessing these models in tandem with developing the models themselves. This workshop focuses on the topic of multimodal algorithmic reasoning, where an agent needs to assimilate information from multiple modalities towards deriving reasoning algorithms for complex problem solving. In the last year, we have seen rapid advances in AI capabilities that better bridge across modalities, bringing both optimism about superhuman capabilities and skepticism about the limits of current approaches. Through talks from outstanding researchers and faculty, we hope to dive deep into this exciting topic at the intersection of theory, multimodal learning and cognitive science to understand what we have achieved thus far in machine intelligence and what we are lacking in relation to the human way of thinking, towards finding the missing rungs on the ladder to truly intelligent reasoning.",https://marworkshop.github.io/neurips25/
Learning to Sense (L2S),"Shashank Agnihotri, Mishal Fatima, Marius Bock, Kanchana Vaishnavi Gandikota, Jovita Lukasik, Margret Keuper, Michael Moeller",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 32AB,"The workshop explores the joint optimization of sensors and machine learning models, pushing beyond traditional paradigms of data acquisition and processing. We aim to rethink the foundations of how machines sense the world by replacing hand-crafted ISPs, leveraging learnable sensor layouts, and adopting task-driven sensing strategies. We welcome original contributions and position papers on the following topics (non-exhaustive): * Sensor optimization for e.g. computer vision (bit-depth, pixel layouts, color filter design) * RAW-to-task or RAW-to-label approaches for visual tasks * Co-design of neural networks and sensor hardware * Low-bit and energy-efficient sensing for embedded or mobile devices * Benchmarks, datasets, and metrics for evaluating sensor-model pipelines * Generalization and robustness of sensor-model systems in real-world conditions * Failure case studies and negative results in joint optimization pipelines Join us to engage with cutting-edge research and cross-disciplinary discussions that are shaping the future of sensor systems for real-world deployment across mobile, embedded, and autonomous platforms.",https://sites.google.com/view/l2s-workshop/home
What Can(\'t) Transformers Do?,"Tobias Schnabel, Kiran Tomlinson, Lena Strobl, Michael Hahn",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 4,"With most advances in large foundation models (LFMs) being empirical, our theoretical understanding of what transformers can compute, express, and learn still lags behind. This workshop will convene theorists and empiricists to chart a rigorous agenda for the next generation of LFMs, asking “What _can_ and _can’t_ transformers do?” We welcome both formal analyses and empirically grounded studies that shed light on theoretical questions, aiming to close the gap between proofs and practice while fostering new, interdisciplinary collaborations.",https://transformerstheory.github.io/
Frontiers in Probabilistic Inference: Learning meets Sampling,"Tara Akhound-Sadegh, Michael Albergo, Joey Bose, Marylou Gabrié, Louis Grenioux, Guan-Horng Liu, Kirill Neklyudov, Grant Rotskoff, Eva Smorodina, Alexander Tong",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 7,,http://fpiworkshop.org
Tackling Climate Change with Machine Learning,"Hari Prasanna Das, Raluca Georgescu, Joaquin Salas, Salva Rühling Cachay, Nadia Ahmed, Yoshua Bengio",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 24ABC,"Many in the ML community wish to take action on climate change, but are unsure how to have the most impact. This workshop will highlight work that demonstrates that, while ML is no silver bullet, it can be an invaluable tool in reducing greenhouse gas emissions and in helping society adapt to the effects of climate change. Climate change is a complex problem for which action takes many forms, from advancing theory to deploying new technology. Many of these actions represent high-impact opportunities for real-world change, and simultaneously pose interesting academic research problems. The theme of this workshop, “Roots to Routes: A Dialogue on Different Machine Learning Methods for Climate Impact,” invites submissions that explore the strengths of diverse machine learning approaches in climate-related contexts. We particularly encourage work that demonstrates the effectiveness of classical ML methods under real-world constraints, such as limited data availability, privacy concerns, or restricted computational resources. At the same time, we welcome contributions that showcase how scaling up data and computing resources combined with modern tools and techniques can unlock new possibilities for tackling global-scale climate prediction challenges. This workshop is part of a series that aims to bring together those applying ML to climate change challenges and facilitate cross-pollination between ML researchers and experts in climate-relevant fields.",https://www.climatechange.ai/events/neurips2025
Regulatable ML: Towards Bridging the Gaps between Machine Learning Research and Regulations,"Chirag Agarwal, Jiaqi Ma, Sarah Tan, Himabindu Lakkaraju, Junwei Deng, Pingbang Hu, Eileanor LaRocco, Karolina Naranjo, Shichang (Ray) Zhang",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 1AB,,https://regulatableml.github.io/
AI for Science: The Reach and Limits of AI for Scientific Discovery,"Ada Fang, Marinka Zitnik, Max Welling, Carla Gomes, Yuanqi Du, Sanjeev Raja, Lixue Cheng, Lijing Wang, Michael Albergo",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Ballroom 20A,"Through our proposed AI for Science workshop, we will bring together experimentalists, domain scientists, and ML researchers to discuss the reach and limits of AI for scientific discovery. We will center our discussion on three challenges that are essential to progress across scientific domains: **LLM reasoning across scientific domains** – can present-day LLMs generate rigorously testable hypotheses and reason over experimental results that span scientific domains such as physics, chemistry, and biology? **Fidelity of generative and surrogate simulators** – In biology, we see a shift towards all-atom models with increasingly powerful capabilities, in chemistry machine learning force fields are increasing in accuracy and generalizability, and in climate modeling we can now accurately predict weather 15 days out. How far can we push this limit? What spatial or temporal scales remain intractable? **Experimental data scarcity and bias**. We see modern examples of large-scale dataset generation such as the Protein Data Bank, Human Cell Atlas, and the Materials Project. Are there other fields where AI can benefit most from consortium efforts to generate large-scale datasets? How far can models trained on limited experimental datasets take us and where are lab-in-the-loop strategies essential? To address this, we additionally introduce a **dataset proposal competition**. Our workshop will highlight common bottlenecks in developing AI methods across scientific application domains, and delve into solutions that can unlock progress across all of these domains.",https://ai4sciencecommunity.github.io/neurips25
New Perspectives in Graph Machine Learning,"Zhiyang Wang, Juan Cervino, Luana Ruiz, Alejandro Ribeiro, Stefanie Jegelka, Charilaos Kanatsoulis",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Exhibit Hall F,,https://newgraphperspectives.com/
Non-Euclidean Foundation Models and Geometric Learning: Advancing AI Beyond Euclidean Frameworks,"Menglin Yang, Neil He, Yifei Zhang, Weikang Qiu, Ngoc Bui, Jiahong Liu, Melanie Weber, Rex Ying",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 8,"In the era of foundation models and Large Language Models (LLMs), Euclidean space is the de facto geometric setting of our machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. Non-Euclidean learning is quickly gaining traction. Non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, have been shown to provide more efficient and effective representations for data with intrinsic geometric properties, like hierarchy, symmetry, and heterogeneity. Integrating foundation models with non-Euclidean spaces has great potential to enhance their ability to capture and model the underlying structures and relationships in complex real-world data, leading to better performance, generalization, and interpretability. This workshop focuses on the intersection of Non-Euclidean representation learning and Foundation Models, exploring its potential benefits, challenges, and future directions.",https://hyperboliclearning.github.io/events/neurips2025negelworkshop
UrbanAI: Harnessing Artificial Intelligence for Smart Cities,"Judah Goldfeder, Na Li, Donna Vakalis, Bianca Howard, Philippe Wyder, Bing Dong, Yoshua Bengio",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 26AB,,
AI That Keeps Up: Workshop on Continual and Compatible Foundation Model Updates (CCFM),"Fartash Faghri, Jessica Echterhoff, Jeffrey Li, Saurabh Garg, Amal Rannen-Triki, Sayna Ebrahimi",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 25ABC,"Foundation models, despite their impressive capabilities, face a critical challenge: they naturally become outdated. Trained on vast datasets, frequently updating these models is expensive. Crucially, these challenges extend beyond the scope of studies in traditional continual learning, as foundation models require rapid and scalable adaptation to dynamic global changes and the emergence of both generalized and specialized tasks. This workshop addresses the urgent need for up-to-date foundation models. We invite researchers to explore cost-effective methods for frequent updates and adaptation, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve.",https://sites.google.com/view/ccfm-neurips2025
Recent Advances in Time Series Foundation Models: Have We Reached the ‘BERT Moment’?,"Thomas Moreau, Romain Tavenard, Valentina Zantedeschi, Vasilii Feofanov, Ievgen Redko, Ambroise Odonnat",Sun 7 Dec,8 a.m. PST — 5 p.m. PST,Upper Level Room 3,"Foundation models (FMs) have achieved great success in NLP and vision, inspiring over 20 new time series FMs (TSFMs) in the past year. Despite promising results, studies show that carefully designed lightweight supervised baselines often match TSFM performance. Unlike NLP’s “BERT Moment,” TSFMs still require full fine-tuning to be competitive in real-world scenarios. Additionally, some tabular FMs rival TSFMs without being time series-specific. Recent benchmarks also provide mixed evidence: GIFT-Eval favors TSFMs, OpenTS shows statistical models outperforming deep learning on univariate data, and FoundTS finds supervised baselines on par with TSFMs. This workshop aims to bring together researchers to examine the gap between TSFM potential and real-world utility, and to identify benchmarks and applications where TSFMs can truly excel. The key topics of this workshop include, but are not limited to: - Benchmarking Foundation Models in Time Series, - Scaling Laws and Efficiency in Time Series Models, - Evaluating Transferability and Adaptability of Foundation Models, - Leveraging Foundation Models of Other Modalities for Time Series, - Unsupervised performance estimation of TSFMs, - Industrial Benchmarking of Time Series Foundation Models",https://berts-workshop.github.io/
