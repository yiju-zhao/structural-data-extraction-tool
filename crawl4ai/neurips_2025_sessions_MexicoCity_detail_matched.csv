date,time,type,title,url,speaker,end_time,abstract,overview,matched_teams,relevance_scores,team_research_focus,matching_reasons
"Sunday, Nov 30, 2025",11:00,Workshop,NeurIPS 2025 Workshop on Socially Responsible and Trustworthy Foundation Models,https://neurips.cc/virtual/2025/workshop/127834,,18:00,"The Socially Responsible and Trustworthy Foundation Models (ResponsibleFM) Workshop at NeurIPS 2025 Mexico City is envisioned as a vital interdisciplinary forum dedicated to advancing ethical, inclusive, and socially conscious research practices in the rapidly evolving field of foundation models, including language models and multimodal models. As foundation models are tremendously reshaping human communication, decision-making, and societal infrastructures, there is a growing recognition of the profound impacts these systems can have, both positive and negative, on individuals and communities. In particular, previous research has documented a wide range of risks and harms associated with foundation models, including but not limited to bias and discrimination, misinformation propagation, privacy violations, environmental concerns, and unintended social consequences.","Overview: The ResponsibleFM Workshop is an interdisciplinary forum focused on advancing ethical, inclusive, and socially responsible research in foundation models, including language and multimodal models. It aims to address fairness, accountability, transparency, and safety throughout model development and deployment, proactively tackling ethical and social risks. The workshop brings together researchers, practitioners, ethicists, policy-makers, and affected communities to catalyze methods and best practices ensuring foundation model research serves the common good. The event is scheduled to be held in hybrid mode, both virtually and at the Hilton Mexico City Reforma, during NeurIPS 2025. | Research Interests: Defining & Measuring Trustworthiness, Techniques to Enhance Trustworthiness, Deployment & Social Good, Datasets & Benchmarks, Interdisciplinary Perspectives & Governance","多伦多云, 计算","多伦多云:65, 计算:55",多伦多云:AI Agent可靠性与行为管控; 计算:高效模型架构的社会影响,多伦多云:Workshop关注trustworthy和accountability机制，直接对应Agent行为可靠性评估与管控需求; 计算:Foundation model的安全设计与模型架构演进趋势相关
"Sunday, Nov 30, 2025",11:00,Workshop,NeurIPS 2025 Workshop on Embodied and Safe-Assured Robotic Systems,https://neurips.cc/virtual/2025/workshop/127833,,18:00,"This workshop focuses on advancing safe and quality-assured embodied robotic systems. Embodied systems—including autonomous robots, self-driving vehicles, robotic arms, and humanoid robots—are increasingly deployed in safety-critical real-world scenarios. Ensuring their trustworthiness—encompassing safety, reliability, and predictable behavior—remains a pressing challenge. Despite notable progress in perception, reasoning, and control, many AI-based robotic systems still operate as “black boxes,” often exhibiting unpredictable behaviors. Failures can emerge from complex sensorimotor interactions, adversarial inputs, or novel environments, leading to safety incidents and diminished user trust.",,"温哥华云, 计算, 多伦多云, CBG","温哥华云:95, 计算:75, 多伦多云:70, CBG:60",温哥华云:Embodied AI战略重点领域; 计算:Agentic和多模态前沿应用负载; 多伦多云:具身Agent的可靠性与安全保证; CBG:3D环境感知与重建,温哥华云:Workshop完全对应其Embodied/Physical AI战略投资方向; 计算:具身机器人是典型的Agentic多模态前沿负载; 多伦多云:具身系统的安全保证与Agent行为管控高度相关; CBG:机器人需要3D场景理解和重建能力
"Sunday, Nov 30, 2025",11:00,Workshop,NeurIPS2025 Workshop Research Development AI Mexico,https://neurips.cc/virtual/2025/workshop/127832,,18:00,"The Research Development of AI in Mexico: Main Applications workshop seeks to showcase, strengthen, and connect the most impactful developments in Artificial Intelligence (AI) and Data Science emerging from Mexico and the broader Latin American region. Over the past four decades, Mexico has cultivated a robust research community in AI through pioneering contributions in areas such as computational intelligence, autonomous robotics, fuzzy systems, and natural language processing, led by institutions including CIC–IPN, INAOE, UNAM, ITESM, CINVESTAV, and Universidad Veracruzana.Today, the region is undergoing a strategic transformation, shifting from foundational research to the development of applied AI technologies addressing real-world needs in healthcare, education, agriculture, smart cities, cybersecurity, and sustainability. This evolution has been further propelled by increased access to open data, advances in computing infrastructure, and growing collaborations between academia, government, and industry.Despite these advances, Latin America faces distinctive challenges in the development and deployment of AI. These include limited funding, underrepresentation in global AI initiatives, digital inequality, and the need for responsible, inclusive, and culturally relevant AI systems. Additionally, emerging concerns related to AI ethics, algorithmic bias, and regulatory frameworks must be addressed proactively to ensure equitable and trustworthy technology adoption.This workshop aims to create a forum for researchers, students, practitioners, and policymakers to engage in meaningful dialogue about the current landscape and future directions of AI in Mexico and Latin America. By promoting interdisciplinary collaboration, the workshop will highlight impactful case studies, emerging research trajectories, and opportunities for cross-border cooperation, while fostering a shared vision for AI that is ethical, sustainable, and aligned with regional priorities.",,,,,区域性AI应用展示workshop，与所有团队的技术研究方向相关度均低于50分阈值
"Sunday, Nov 30, 2025",11:00,Workshop,Vision Language Models: Challenges of Real World Deployment,https://neurips.cc/virtual/2025/workshop/127831,,18:00,"Vision language models (VLMs) have demonstrated remarkable capabilities in integrating visual perception with natural language understanding, powering applications such as multimodal assistants, robotics, autonomous systems, and accessibility tools. However, their real-world deployment faces significant challenges in efficiency, scalability, and reliability. This workshop will bring together researchers and practitioners from academia and industry to highlight cutting-edge research, systems-level optimizations, and evaluation methodologies that are often overlooked yet pivotal for robust real-world integration. Efficiency, robustness, and reliability will be emphasized as core design principles, essential to advancing VLMs from experimental systems to dependable deployed technologies. By convening researchers at the intersection of multimodal learning, efficient inference and training, robustness and uncertainty estimation, and large-scale systems design, the workshop aims to establish concrete pathways toward building VLMs that can operate reliably under practical constraints. We hope this workshop will serve as a venue for exchanging insights on model design, efficiency techniques, and robustness evaluation that bridge the gap between research and real-world systems.","Overview: The VLM4RWD NeurIPS 2025 Workshop focuses on the challenges of deploying Vision Language Models (VLMs) in real-world applications. It aims to bring together researchers and practitioners to discuss cutting-edge research, systems-level optimizations, and evaluation methodologies essential for the efficient, scalable, and reliable deployment of VLMs. The workshop emphasizes the importance of efficiency, robustness, and reliability in advancing VLMs from experimental systems to dependable technologies. | Research Interests: Data pipelines for efficient multimodal learning, Accelerating VLMs inference, Compression and distillation for VLMs deployment, Sparse, modular, and retrieval-augmented VLM architectures, Efficient training for complex reasoning tasks, Robust training and evaluation of VLMs, Benchmarks for deployment-oriented evaluation, Mitigating hallucination and improving multimodal grounding, Agentic VLMs for real-world integration","海思, 计算, 诺亚, 存储, 多伦多云","海思:85, 计算:80, 诺亚:75, 存储:70, 多伦多云:60",海思:多模态条件融合加速与低延迟推理; 计算:多模态模型架构优化与前沿负载; 诺亚:图文多模态长序列处理; 存储:VLM部署中的模型与KV Cache调度; 多伦多云:Agentic VLM系统集成,海思:Workshop聚焦VLM高效推理部署，直接对应多模态融合延迟和实时响应挑战; 计算:VLM是前沿多模态负载，效率优化对计算架构有明确诉求; 诺亚:VLM的长上下文图文推理与多模态长序列技术相关; 存储:VLM部署涉及大模型和KV Cache的加载调度优化; 多伦多云:Workshop明确涵盖Agentic VLM的实际应用
"Monday, Dec 1, 2025",06:00,Workshop,Centering Low-Resource Languages and Cultures in the Age of Large Language Models,https://neurips.cc/virtual/2025/workshop/127830,,15:00,"Large Language Models (LLMs) have transformed NLP research and applications, yet they are still predominantly trained on high-resource, globally dominant languages. This imbalance leads to poor performance and limited applicability for low-resource languages, which are rich in tone, morphology, and cultural meaning. As a result, current AI systems risk reinforcing linguistic inequality, cultural erasure, and lack of accessibility in critical domains like education and healthcare.This workshop aims to reframe language technology by centering low-resource languages, cultures, and epistemologies in the age of LLMs. We seek to bring together researchers, linguists, developers, healthcare professionals, and technologists to share insights and develop strategies for building inclusive, culturally grounded, and linguistically robust language models. The workshop emphasizes collaboration across disciplines and regions to ensure both technical advancement and social relevance.Key areas of focus include developing LLM architectures tailored to low-resource linguistic features, ethical and community-centered dataset collection, and multilingual benchmarks designed specifically for underrepresented languages. We also highlight the importance of healthcare and medical machine translation to support equitable access to information and improve public health outcomes. Ultimately, this workshop aims to advance responsible AI innovation that empowers low-resource language communities and shapes a more inclusive future for global language technologies.","Overview: The CLRLC-LLMs Workshop at NeurIPS 2025 focuses on the role of Large Language Models (LLMs) in promoting multilingual and culturally inclusive AI. It addresses the underrepresentation of low-resource languages and cultures in AI research and development. The workshop aims to reframe language technology discussions by centering low-resource languages and cultures in AI innovation. It brings together researchers, linguists, developers, and technologists to share insights, challenges, and strategies for developing LLMs that support linguistic diversity and cultural identity, particularly in Africa and parts of Asia. The workshop promotes global collaboration, scalable data creation, model alignment, and ethical evaluation of LLMs, inspiring interdisciplinary research across linguistics, computer science, and engineering. | Research Interests: LLMs for low-resource languages, Culturally grounded NLP and multilingual evaluation, Dataset creation, curation, and benchmarks for African, Indigenous, and marginalized languages, Cross-linguistic transfer and model adaptation, Ethical, social, and policy dimensions of language technologies, Community-based and participatory AI approaches, Speech, ASR, and translation in low-resource settings, Human–AI interaction for linguistic and cultural inclusivity, Cognitive or sociolinguistic perspectives on AI and language, Healthcare and Biomedical Machine Translation for Low-Resource Languages","计算, 海思","计算:55, 海思:50",计算:适应低资源语言的LLM架构设计; 海思:低资源语言LLM的推理加速,计算:Workshop涉及针对语言特性的LLM架构定制，与模型架构演进趋势相关; 海思:低资源语言LLM同样需要低延迟高效推理支持
"Monday, Dec 1, 2025",06:00,Workshop,NORA: The First Workshop on Knowledge Graphs & Agentic Systems Interplay,https://neurips.cc/virtual/2025/workshop/127827,,15:00,"Agents have experienced significant growth in recent years, largely due to the rapid technological advancements of Large Language Models (LLMs). Although these agents benefit from LLMs' advanced generation proficiency, they still suffer from catastrophic forgetting and a limited context window size compared to the agents' needs in terms of contextual information.  Knowledge Graphs (KGs) are a powerful paradigm for structuring and managing connected pieces of information while unlocking deeper insights than traditional methods. Their value is immense for tasks that require context, integration, and reasoning. However, this power comes at the cost of significant upfront and ongoing investment in construction, curation, and specialized expertise.   The first version of this workshop aims at analyzing and discussing emerging and novel practices, ongoing research and validated or deployed innovative solutions that showcase the growing synergy between LLMs agents and KGs.","Overview: The NORA 2025 workshop focuses on the interplay between Knowledge Graphs (KGs) and agentic systems, particularly those enhanced by Large Language Models (LLMs). The workshop aims to explore emerging practices, research efforts, and innovative solutions that demonstrate the synergy between LLM agents and KGs. It addresses the challenges faced by agents, such as catastrophic forgetting and limited context window size, and highlights the potential of KGs in structuring and managing information for improved reasoning and integration. | Research Interests: Agentic and Knowledgeable Systems with Small Language Models, Agentic Information Extraction and Retrieval, Agentic KG Construction & Enrichment, Agents for Complex Reasoning over KGs, Agents and KGs for private and proactive personal assistants & Personalisation, Augmenting Agents with External Knowledge, Collaborative Agents for Knowledge Computing and Serving, Context Engineering enhanced by KGs, Efficient Reinforcement Learning for better performance, Graph Retrieval Augmented Generation in Agentic systems, KGs serving agents’ memories: episodic, semantic, and procedural, Multi-Lingual & Multi-modal integrations, On-Device or Hybrid (Device-Cloud) systems combining Agents and KGs, Personalisation via Agents and KGs, Personas and digital twins enabled by Agents and KGs, Theoretical and experimental analysis of close and open Domain applications scenarios","多伦多云, 存储, 计算, 诺亚","多伦多云:90, 存储:75, 计算:65, 诺亚:55",多伦多云:Agent记忆系统与知识图谱集成; 存储:Agent记忆系统(MemOS)的存储访问模式; 计算:KG增强Agentic系统的计算负载; 诺亚:模型内置记忆更新机制,多伦多云:Workshop核心议题Agentic系统完全对应其研究方向，KG作为Agent记忆的方案直接相关; 存储:Workshop明确讨论KGs作为agents' memories，对应MemOS等记忆系统的存储优化; 计算:KG-Agent协同系统是新型Agentic前沿负载; 诺亚:知识图谱的更新维护与模型记忆机制相关
"Monday, Dec 1, 2025",06:00,Workshop,7th International Workshop on Large Scale Holistic Video Understanding: Toward Video Foundation Models,https://neurips.cc/virtual/2025/workshop/127828,,15:00,"This workshop aims to advance the field of video understanding by fostering discussions around holistic and generalist video foundation models. Building upon the Holistic Video Understanding (HVU) initiative and dataset introduced in 2019, we have successfully organized eight HVU workshops and tutorials at top-tier venues such as CVPR and ICCV, uniting researchers, practitioners, and students from around the world. These efforts have played a central role in moving the community beyond narrow action recognition tasks toward multi-faceted, semantic, and generalist video understanding.With the emergence of large-scale foundation models and video large language models (Video-LLMs), the landscape of video understanding is rapidly evolving. These models enable unified reasoning across spatial, temporal, and multimodal dimensions, yet introduce new challenges in scalability, efficiency, interpretability, and responsible deployment.The HVU Workshop 2025 will provide a platform to explore these frontiers, discussing topics such as multimodal representation learning, long-context reasoning, evaluation of general-purpose video systems, efficient adaptation and scaling laws, and the ethical and societal implications of video AI. Our goal is to bring together a diverse and inclusive community to define the next chapter of holistic, generalist, and responsible video understanding.",,"CBG, 诺亚, 计算, 海思, 存储","CBG:85, 诺亚:80, 计算:75, 海思:70, 存储:60",CBG:视频物体分割与长视频生成一致性; 诺亚:视频多模态长序列推理; 计算:视频基础模型架构演进; 海思:Video-LLM长上下文推理加速; 存储:大规模视频训练的IO优化,CBG:Workshop的holistic video understanding与3DAIGC的视频理解需求高度匹配; 诺亚:Video-LLM的长上下文多模态推理是其核心研究方向; 计算:Video foundation models对计算架构提出新挑战; 海思:长视频多模态推理需要高效加速; 存储:大规模视频数据的训练访问模式优化
"Monday, Dec 1, 2025",06:00,Workshop,First Workshop on LLM Persona Modeling,https://neurips.cc/virtual/2025/workshop/127829,,15:00,"Large language models (LLMs) are increasingly used to simulate human-like personas for applications in research, education, healthcare, and interactive AI systems. While such persona modeling creates opportunities for interdisciplinary innovation, it raises challenges around authenticity, consistency, bias, and ethical deployment. This workshop brings together perspectives from AI, psychology, cognitive science, and human–computer interaction to advance robust methods, standardized evaluation frameworks, and responsible practices for persona modeling in LLMs. Through invited talks, panels, posters, and discussions, the event will chart a roadmap for interdisciplinary collaboration and future research in this emerging area.","Overview: The PersonaLLM workshop, part of NeurIPS 2025, focuses on the modeling of personas using large language models (LLMs). It aims to explore the creation of human-like personas with consistent traits and behaviors, leveraging LLMs' adaptability across diverse contexts. The workshop seeks to provide an interdisciplinary forum for discussing the conceptualization, evaluation, and ethical implications of LLM persona modeling, with applications in marketing, social science, product development, and healthcare. | Research Interests: LLM persona modeling, Instruction-following capabilities of LLMs, Personification and human-like personas, Interdisciplinary approaches in AI, psychology, and cognitive science, Evaluation methods for persona consistency and effectiveness, Social and ethical implications of anthropomorphism in LLMs, Technical innovations in LLMs, Real-world applications of LLM personas",多伦多云,多伦多云:55,多伦多云:Agent的persona一致性与行为管理,多伦多云:Workshop关注LLM persona的一致性和可靠性，与Agent行为可靠性管理有关联
"Tuesday, Dec 2, 2025",09:30,Tutorial,"Efficient Transformers: State of the art in pruning, sparse attention, and transformer funneling",https://neurips.cc/virtual/2025/128790,,12:00,"""Transformer architectures consume the lionshare of computational budgets associated with today’s most powerful language and vision models, making research into greater computational efficiency a hot and essential direction. Our proposed tutorial surveys the bleeding edge of three complementary research threads that together comprise a significant part of the current industrial toolkit for achieving computational efficiency in Transformers: (1) pruning, the structured or unstructured removal of weights, layers and heads; (2) sparse attention & routing, including block, sliding-window, locality-sensitive hashing; and (3) funneling, which pools intermediate representations to shorten sequences through depth. We will then feature an expert industrial and academic panel of speakers from Caltech, MIT, Anthropic, Google Deepmind, and Microsoft, hearing about the latest trends seen in top industrial labs. Attendees will leave with actionable recipes for building sub-10 B-parameter models that match or exceed dense baselines on language, vision and multi-modal benchmarks.The tutorial targets researchers and practitioners who build or deploy Transformer models and assumes familiarity with basic deep-learning concepts but not with any specific efficiency method. All slides and publication materials will be released under a permissive license.""",,"海思, 计算, 诺亚, 存储","海思:90, 计算:85, 诺亚:75, 存储:55",海思:稀疏注意力与分块缓存优化; 计算:高效Transformer架构演进; 诺亚:长序列架构的效率优化; 存储:稀疏注意力的内存访问模式,海思:Tutorial的sparse attention核心技术完全对应其稀疏注意力与分块缓存研究; 计算:Efficient Transformers直接影响模型架构演进和计算系统设计; 诺亚:Sparse attention和funneling是长序列模型的关键优化方向; 存储:稀疏模式改变内存访问特性
"Tuesday, Dec 2, 2025",09:30,Tutorial,"Geospatial Foundation Models: Overview, Application and Benchmarking",https://neurips.cc/virtual/2025/128793,,12:00,"Geospatial foundation models (GeoFMs) are a class of large-scale deep learning models, typically based on the transformer architecture, that are pre-trained on vast, diverse datasets of Earth Observation data to learn a general, transferable understanding of the Earth’s surface. These models help address long-standing challenges in Earth Observation by dramatically reducing the need for manually labeled data, handling vast and diverse data streams (e.g., optical, SAR, multispectral, LiDAR), and enabling robust performance across time, space, and sensor types. In this tutorial, we will give an overview of the recent advancements in GeoFMs, highlighting the main challenges in developing these models and differences from foundation models developed for other domains. We will also show practical examples of fine-tuning and inferencing GeoFMs for different downstream tasks using the TerraTorch open-source framework, which facilitates the use to publicly available GeoFMs such as SatMAE, Prithvi-EO, DOFA, Galileo and TerraMind. Finally, we will introduce best practices for systematic and reproducible benchmarking of GeoFMs using the TerraTorch Iterate plug-in and its integration with GEO-Bench.",,,,,地理空间基础模型是垂直领域应用，与所有团队的核心研究方向相关度低
"Tuesday, Dec 2, 2025",09:30,Tutorial,From Tuning to Guarantees: Statistically Valid Hyperparameter Selection,https://neurips.cc/virtual/2025/128794,,12:00,"""The performance and reliability of modern machine learning systems depend critically on hyperparameter selection. Whether tuning a large language model, configuring a vision pipeline, or deploying AI in safety-critical environments, the choice of hyperparameters is decisive. Current tuning strategies such as grid or random search and Bayesian optimization are powerful for empirical optimization but they do not provide statistical guarantees on the reliability of the selected configuration after deployment. This gap becomes critical when models must satisfy strict performance, safety, or fairness requirements.This tutorial introduces a rigorous and practical framework that treats hyperparameter selection as a statistical testing problem. By constructing valid p- or e-values for candidate configurations and applying multiple hypothesis testing (MHT) procedures, practitioners can control deployment risk with finite-sample guarantees. We begin with the Learn-Then-Test (LTT) methodology for average-risk control and build up to multiple key extensions, such as controlling the quantile risk using quantile LTT (QLTT), multi-objective optimization through Pareto Testing (PT), incorporating prior information through the concept of reliability graphs, and data-efficient selection through adaptive LTT (aLTT). Throughout the tutorial, we emphasize conceptual clarity, plain-language explanations of assumptions, and hands-on demonstrations with minimal, reproducible notebooks.Attendees will gain a drop-in toolkit for augmenting existing tuning workflows with statistically valid selection. They will learn how to formalize relevant risk functions, generate valid evidence, choose appropriate error-rate controls (FWER/FDR), and navigate the trade-offs between statistical conservatism and power under limited data. No prior expertise in multiple hypothesis testing is required.""",,计算,计算:50,计算:训练范式中的超参数优化,计算:超参数选择影响训练效率和模型性能，与训推新范式相关
"Tuesday, Dec 2, 2025",13:30,Tutorial,How to Build Agents to Generate Kernels for Faster LLMs (and Other Models!),https://neurips.cc/virtual/2025/128792,,16:00,"The compute demanded by modern AI has been exploding since 2016; the FLOPs used to train frontier models have grown at a rate of 2.4x per year [0], and the inference side is growing even faster—already an estimated 80% of total AI electricity use [1]. Large language models and other deep networks rely on highly tuned GPU kernels to achieve state-of-the-art performance; these efficient kernels directly translate to cost and energy savings. In this 2.5-hour in-person tutorial, we demonstrate how LLM-powered agents can generate and optimize GPU kernels for CUDA, HIP/ROCm, and Triton. We begin with a unified primer on GPU‐programming fundamentals and common tooling (memory hierarchy, occupancy, profilers), then introduce an agentic loop: prompt engineering, compiler/profiler feedback as tools, iterative kernel refinement, correctness validation, and automated benchmarking. We will provide additional benchmarking examples on HIP and Triton, on top of Stanford’s KernelBench that covers CUDA [2], KernelBot as reliable source of human curated dataset for heterogenous GPU code [3], and show how to turn runtime and profiler metrics into reward signals that drive kernel optimizations. On top of this loop, we build an inference-scaling framework in which the LLM proposes candidate kernels, compiles them, measures latency/throughput/energy, and feeds those signals back as rewards. By combining test-time scaling techniques the agent iteratively discovers increasingly accurate and efficient kernels. Attendees will compare generated code against expert kernels, inspect wins and losses. By the end, participants will walk away with a reproducible pipeline for LLM-driven GPU‐kernel optimization.",,"计算, 海思, 多伦多云","计算:80, 海思:75, 多伦多云:60",计算:GPU kernel优化与计算架构; 海思:LLM推理的kernel加速; 多伦多云:Agent自动代码生成能力,计算:Kernel优化是计算架构的核心，直接影响芯片设计和算力效率; 海思:优化的GPU kernel直接提升LLM推理速度; 多伦多云:展示Agent在专业编程任务中的能力
"Tuesday, Dec 2, 2025",13:30,Tutorial,"Positional Encoding: Past, Present, and Future",https://neurips.cc/virtual/2025/128797,,16:00,"""Positional Encoding is a foundational yet often opaque component of Transformerarchitectures, underpinning how self-attention mechanisms capture sequence orderin language, vision, and multimodal models. Despite its centrality to the successof modern LLMs, and other attention-reliant architectures, the mathematical in-tuition behind positional encoding remains challenging and inaccessible to manyresearchers and practitioners. This workshop aims to demystify positional encodingby bridging formal theory with intuitive understanding and practical experimen-tation. Through a series of guided lectures, visual demonstrations, and hands-oncoding sessions, participants will explore the operational principles behind ef-fective positional representations, the evolution of key methods (from sinusoidaland learned embeddings to rotary and relative encodings), and open challengesthat motivate current research directions. We will also provide open-source codeimplementations, mathematical visualizations, and collaborative ideation sessionsfor fostering new positional encoding concepts. By easing the barrier to entry forthis mathematically intensive, yet crucial topic, the workshop seeks to foster deeperunderstanding, interdisciplinary exchange, and novel contributions to the future ofPositional Encoding, and Transformer design""",,"诺亚, 计算, 海思","诺亚:75, 计算:70, 海思:60",诺亚:长序列位置编码优化; 计算:位置编码对模型架构的影响; 海思:位置编码的计算效率,诺亚:Positional encoding是长序列建模的关键，不同编码方式直接影响长序列性能; 计算:位置编码演进(sinusoidal→RoPE等)是模型架构重要变化; 海思:位置编码计算影响推理效率
"Tuesday, Dec 2, 2025",13:30,Tutorial,Science of Trustworthy Generative Foundation Models,https://neurips.cc/virtual/2025/128795,,16:00,"We are living through a moment that once belonged to science fiction: generative foundation models can write, reason, design, diagnose, and increasingly, decide. They are no longer just predicting the next word — they are shaping knowledge, influencing choices, and becoming collaborators in science, medicine, education, and daily life. But here's the tension: as their capabilities accelerate, our ability to trust them has not kept pace.Trustworthiness can't remain a ""patch after the failure"" or a moral hope layered on top of engineering. It must evolve into a science—a discipline as rigorous as the one that created these models in the first place. In this tutorial, we explore what that science looks like: how we understand model behaviors, measure and stress-test trust, and design systems that earn it. We'll build the foundations together, then step into the frontier—where models begin to exhibit human-like cognitive behaviors that inspire wonder, but also demand responsibility and new forms of alignment.This session is an invitation: to move beyond building models that impress us, toward building models we can trust with what matters.",,多伦多云,多伦多云:60,多伦多云:生成式Agent的可信赖性评估,多伦多云:Tutorial关注generative models的trustworthiness，与Agent行为可靠性和评估准确性相关
"Wednesday, Dec 3, 2025",08:30,Invited Talk,The Oak Architecture: A Vision of SuperIntelligence from Experience,https://neurips.cc/virtual/2025/invited-talk/129132,Rich Sutton,09:30,"As AI has become a huge industry, to an extent it has lost its way. What is needed to get us back on track to true intelligence? We need agents that learn continually. We need world models and planning. We need knowledge that is high-level and learnable. We need to meta-learn how to generalize. The Oak architecture is one answer to all these needs. It is a model-based RL architecture with three special features: 1) all of its components learn continually, 2) each learned weight has a dedicated step-size parameter that is meta-learned using online cross-validation, and 3) abstractions in state and time are continually created in a five-step progression: Feature Construction, posing a SubTask based on the feature, learning an Option to solve the subtask, learning a Model of the option, and Planning using the option’s model (the FC-STOMP progression). The Oak architecture is rather meaty; in this talk we give an outline and point to the many works, prior and contemporaneous, that are contributing to its overall vision of how superintelligence can arise from an agent’s experience.",,"温哥华云, 诺亚, 多伦多云, 计算, 存储","温哥华云:85, 诺亚:75, 多伦多云:70, 计算:65, 存储:50",温哥华云:强化学习架构与RFT; 诺亚:Learning from experience训练框架; 多伦多云:Agent持续学习与自主优化; 计算:RL训推新范式的计算需求; 存储:持续学习的经验数据管理,温哥华云:Rich Sutton的model-based RL架构与RFT研究直接相关; 诺亚:Oak的learning from experience核心理念完全对应其研究方向; 多伦多云:持续学习和planning机制是Agent自主优化的关键; 计算:RL范式对计算系统有独特需求; 存储:持续学习需要高效经验管理
"Wednesday, Dec 3, 2025",14:30,Invited Talk,Are We Having the Wrong Nightmares About AI?,https://neurips.cc/virtual/2025/invited-talk/129136,Zeynep Tufekci,15:30,"Though seemingly opposite, doom and optimism regarding generative AI's spectacular rise both center on AGI or even superintelligence as a pivotal moment. But generative AI operates in a distinct manner from human intelligence, and it’s not a less intelligent human on a chip slowly getting smarter anymore than cars were mere horseless carriages. It must be understood on its own terms. And even if Terminator isn’t coming to kill us or superintelligence isn’t racing to save us, generative AI does bring profound challenges, well-beyond usual worries such as employment effects.  Technology facilitates progress by transforming the difficult into easy, the rare into ubiquitous, the scarce into abundant, the manual into automated, and the artisan into mass-produced. While potentially positive long-term, these inversions are extremely destabilizing during the transition, shattering the correlations and assumptions of our social order that relied on superseded difficulties as mechanisms of proof, filtering, sorting and signaling. For example, while few would dispute the value of the printing press or books, their introduction led to such destructive upheaval that the resulting religious wars caused proportionally more deaths than all other major wars and pandemics since combined. Historically, a new technology's revolutionary impact comes from making what's already possible and desired cheap, easy, fast, and large-scale, not from outdated or ill-fitting benchmarks that technologists tend to focus on. As such, Artificial Good-Enough Intelligence can unleash chaos and destruction long before, or if ever, AGI is reached. Existing AI is good enough to blur or pulverize our existing mechanisms of proof of accuracy, effort, veracity, authenticity, sincerity, and even humanity. The tumult from such a transition will require extensive technological, regulatory, and societal effort to counter. But the first step to getting started is having the right nightmares.",,,,,社会学和人文视角的AI影响讨论，与技术研究团队相关度低
"Thursday, Dec 4, 2025",08:30,Invited Talk,The Art of (Artificial) Reasoning,https://neurips.cc/virtual/2025/invited-talk/129134,Yejin Choi,09:30,"Scaling laws suggest that “more is more” — brute-force scaling of data and compute leads to stronger AI capabilities. However, despite rapid progress on benchmarks, state-of-the-art models still exhibit ""jagged intelligence,"" indicating that current scaling approaches may have limitations in terms of sustainability and robustness. Additionally, while the volume of papers on arXiv continues to grow rapidly, our scientific understanding of artificial intelligence hasn't kept pace with engineering advances, and the current literature presents seemingly contradictory findings that can be difficult to reconcile. In this talk, I will discuss key insights into the strengths and limitations of LLMs, examine when reinforcement learning succeeds or struggles in reasoning tasks, and explore methods for enhancing reasoning capabilities in smaller language models to help them close the gap against their larger counterparts in specific domains.",,"诺亚, 温哥华云, 计算, 海思","诺亚:85, 温哥华云:75, 计算:70, 海思:55",诺亚:后训练Reasoning与RL方法; 温哥华云:RL for LLMs的实践问题; 计算:Reasoning训练范式的计算特征; 海思:推理任务的加速优化,诺亚:Yejin Choi讨论的reasoning+RL完全是其核心研究领域; 温哥华云:Talk分析RL在reasoning中的成功与挑战，对RFT有直接指导; 计算:Reasoning范式影响训练负载特征; 海思:推理任务的加速优化对推理加速有意义
"Thursday, Dec 4, 2025",14:30,Invited Talk,"On the Science of “Alien Intelligences”: Evaluating Cognitive Capabilities in Babies, Animals, and AI",https://neurips.cc/virtual/2025/invited-talk/129137,Melanie Mitchell,15:30,"Today’s generative AI systems—termed by some researchers as “alien intelligences”—have exceeded human performance on many benchmarks meant to test humanlike cognitive capabilities.  However, these systems still struggle in unhumanlike ways on real-world tasks requiring these capabilities.  This disconnect may be due in part to neglect in the AI community of well-founded experimental protocols for evaluating cognition.  In this talk I will summarize several recommendations on experimental methods from developmental and comparative psychology—fields that study the “alien intelligences” of babies and non-human animals—and demonstrate the application of such methods in two case studies of cognitive abilities in LLMs: analogical reasoning and visual abstraction.",,多伦多云,多伦多云:65,多伦多云:Agent认知能力评估方法学,多伦多云:Talk提出的认知评估方法论可应用于Agent评估，对应其'提升Agent评估准确性'的研究需求
"Friday, Dec 5, 2025",08:30,Invited Talk,From Benchmarks to Problems - A Perspective on Problem Finding in AI,https://neurips.cc/virtual/2025/invited-talk/129135,Kyunghyun Cho,09:30,"During the past 15 years or so, I have worked on a series of seemingly distinct but eventually related problems, including machine learning algorithms, generative modeling with neural networks, machine translation, language modeling, medical imaging, a bit of healthcare, protein modeling and a bit of drug discovery. I chose to work on some of these problems intentionally, while it was pure serendipity that I worked on some others. It was only in hindsight that these seemingly different problems turned out to be closely related to each other from both technical, social and personal perspectives. In this talk, I plan to do my own retrospective on my own choices, be them intentional or not, on these problems and share with you my thoughts what our own discipline, which is sometimes called computer science, data science, machine learning or artificial intelligence, is.",,,,,研究方法论和问题选择的元讨论，与具体技术研究方向相关度低
"Friday, Dec 5, 2025",14:30,Invited Talk,Demystifying depth: Principles of learning in deep neural networks,https://neurips.cc/virtual/2025/invited-talk/129133,Andrew Saxe,15:30,"Deep neural networks have revolutionized artificial intelligence, yet their inner workings remain poorly understood. This talk presents mathematical analyses of the nonlinear dynamics of learning in several solvable deep network models, offering theoretical insights into the role of depth. These models reveal how learning algorithms, data structure, initialization schemes, and architectural choices interact to produce hidden representations that afford complex generalization behaviors. A recurring theme across these analyses is a neural race: competing pathways within a deep network vie to explain the data, with an implicit bias toward shared representations. These shared representations in turn shape the network’s capacity for systematic generalization, multitasking, and transfer learning. I will show how such principles manifest across diverse architectures—including feedforward, recurrent, and linear attention networks. Together, these results provide analytic foundations for understanding how environmental statistics, network architecture, and learning dynamics jointly structure the emergence of neural representations and behavior.",,计算,计算:65,计算:深度网络学习动力学与架构演进,计算:深度学习理论有助于理解模型架构演进的根本驱动力，支持计算架构的前瞻性设计
