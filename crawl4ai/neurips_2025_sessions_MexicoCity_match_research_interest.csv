bu_name,session_title,session_type,session_date,session_time,base_cosine,rel,tech_overlap,novelty,actionability,confidence,final_score,scoring_reason,recommendation_reason,focus_areas
CBG,7th International Workshop on Large Scale Holistic Video Understanding: Toward Video Foundation Models,Workshop,"Monday, Dec 1, 2025",06:00,0.5220636129379272,0.7,0.6,0.75,0.6,0.9,0.6270000000000001,"The workshop focuses on holistic video understanding and foundation models relevant to CBG's video synthesis and 3D reasoning goals, but less emphasis on explicit 3D reconstruction or differentiable rendering; still, strong overlap with temporal and multimodal understanding offers useful learnings.",该会议聚焦大规模视频基础模型，正好覆盖了CBG对复杂视频动态解析与3D一致性的需求，能带来多模态表示和长时序关系的最新技术思路。,多模态视频表示学习; 长时序推理; 高效模型适应与扩展; 视频大语言模型; 视频AI伦理与责任
海思,"Efficient Transformers: State of the art in pruning, sparse attention, and transformer funneling",Tutorial,"Tuesday, Dec 2, 2025",09:30,0.6048277020454407,0.9,0.85,0.8,0.85,0.9,0.8241249999999999,"The session covers sparse attention, pruning, and funneling, directly aligned with BU goals for efficient large model acceleration; it offers advanced techniques and industrial insights, providing novel, actionable methods for optimizing attention mechanisms and model efficiency.",海思关注长上下文的稀疏注意和计算加速，该讲座中的稀疏注意和融合中间表示技术直接契合，实现更高效模型部署。多路径解码和量化技巧也有助提升性能同,稀疏注意机制; 剪枝技术; 序列融合技术; 多路径解码; 权重量化
海思,Vision Language Models: Challenges of Real World Deployment,Workshop,"Sunday, Nov 30, 2025",11:00,0.5568771362304688,0.85,0.75,0.8,0.7,0.9,0.75525,"The session focuses on deploying vision-language models emphasizing efficiency and robustness, matching BU's focus on multimodal latency and scalability. Shared methods like sparse attention and efficient inference align well, promising actionable insights and novelty in deployment challenges.",海思BU关注多模态模型的异构编码同步和内存带宽优化，这与会中强调的系统级效率和低延时响应策略高度契合，有助于提升实际部署中VLM的性能和稳定,多模态编码同步; 内存与带宽优化; 低延时推理; 系统级调度策略; 模型压缩与加速
海思,How to Build Agents to Generate Kernels for Faster LLMs (and Other Models!),Tutorial,"Tuesday, Dec 2, 2025",13:30,0.5311927199363708,0.8,0.7,0.75,0.7,0.9,0.7124999999999999,Session focuses on GPU kernel generation and optimization which aligns with BU's need for efficient kernels like FlashAttention and fused ops. It offers substantial learning and actionable insights for kernel-level acceleration and optimization relevant to the BU's challenges.,本次教程聚焦用LLM智能生成GPU核函数，实现性能与能效双提升，正好契合海思在加速大模型时需降低计算和内存瓶颈的需求。,GPU核函数自动生成; 性能与能效优化; 内存层次结构管理; 异构加速框架; 自动化性能反馈循环
海思,7th International Workshop on Large Scale Holistic Video Understanding: Toward Video Foundation Models,Workshop,"Monday, Dec 1, 2025",06:00,0.42701035737991333,0.7,0.6,0.7,0.5,0.9,0.61275,"Both focus on large-scale multimodal models and long-context reasoning, but BU leans towards optimization of inference and memory for LLMs with multimodal inputs, while session emphasizes video foundation models and holistic understanding, providing complementary but not exact overlap or immediate actionable techniques.",海思BU关注高效处理长上下文和多模态信息，这正好契合工作坊讨论的视频多模态表征和长距离推理，能借鉴视频大模型的规模化与效率策略提升终端性能。,多模态表示学习; 长距离上下文推理; 模型效率与扩展; 统一潜空间设计; 实时低延迟处理
计算,How to Build Agents to Generate Kernels for Faster LLMs (and Other Models!),Tutorial,"Tuesday, Dec 2, 2025",13:30,0.6936999559402466,0.8,0.7,0.75,0.7,0.9,0.7124999999999999,"The session focuses on LLM-driven GPU kernel optimization relevant to the BU's challenge of co-designing hardware-runtime-model stacks and benchmarking. Technical methods like iterative kernel refinement and runtime feedback overlap with BU goals, yielding actionable insights and learning potential for workload forecasting and runtime optimizations.",这场教程技术聚焦GPU核生成与优化，直接提升推理效率和能耗控制，契合计算BU对硬件—软件协同设计和动态负载预测的需求。通过实战演练，掌握循环,GPU编程基础; 自动化内核优化; 性能与能耗评测; 基于LLM的代码生成; 编译器与分析工具
计算,Vision Language Models: Challenges of Real World Deployment,Workshop,"Sunday, Nov 30, 2025",11:00,0.5293007493019104,0.8,0.65,0.7,0.6,0.9,0.681625,"Session focuses on deployment challenges of multimodal models including efficiency and robustness, well aligned with BU's focus on co-design and workload forecasting, but BU emphasizes hardware-software stack and FP6/FP4 precisions less discussed in session.",计算BU关注模型与硬件软件栈协同优化，能借助该研讨会探讨多模态融合、稀疏架构及推理效率，推动VLM在实际硬件环境下高效稳定落地。,多模态融合技术; 模型推理加速; 稀疏与模块化架构; 稳健训练与评测; 系统级联合优化
计算,"Efficient Transformers: State of the art in pruning, sparse attention, and transformer funneling",Tutorial,"Tuesday, Dec 2, 2025",09:30,0.5015974044799805,0.75,0.7,0.65,0.6,0.9,0.672125,"Session focuses on efficient Transformer techniques including sparse attention and pruning, aligning well with BU's concern on model-hardware co-design and efficient runtimes. While not addressing low-precision formats or all co-design aspects, it offers relevant knowledge on computational efficiency and actionable methods.",这场教程深入讲解了Transformer计算效率提升的核心技术，与计算BU面对的模型—硬件协同优化及计算资源约束紧密关联，助力预见未来计算负,Transformer剪; 稀疏注意力机制; 序列压缩技术; 模型-硬件共设计; 计算资源优化
温哥华云,Vision Language Models: Challenges of Real World Deployment,Workshop,"Sunday, Nov 30, 2025",11:00,0.4307093024253845,0.9,0.85,0.8,0.75,0.9,0.8146249999999999,"The session directly addresses real-world deployment challenges of VLMs, aligning well with BU's focus on reinforcement fine-tuning, scalability, multimodal credit assignment, and safety. The workshop's emphasis on efficiency, robustness, and evaluation matches BU needs, promising valuable insights and practical methods.",云BU面临多模态强化学习中数据效率和稳定优化挑战，该Session聚焦真实场景下VLM高效推理与鲁棒性，正好提供解决多模态在线学习和系统容错,多模态强化学习; 高效推理技术; 鲁棒训练策略; 系统级优化; 部署评测指标
温哥华云,NeurIPS 2025 Workshop on Embodied and Safe-Assured Robotic Systems,Workshop,"Sunday, Nov 30, 2025",11:00,0.5860496759414673,0.85,0.75,0.8,0.7,0.9,0.75525,"The session on embodied robotic systems safety aligns closely with the BU's focus on embodied AI, sim-to-real challenges, and safety-aware control, providing relevant technical insights and potential practical takeaways.",我们关注强化学习在实际约束下的数据效率和安全适应性，而该Workshop聚焦机器人系统的安全性与可预测行为，正好补充了解决复杂环境中的安全和,强化学习数据效率; 安全感知控制; 多模态信用分配; 仿真与在线反馈融合; 安全在线自适应
温哥华云,7th International Workshop on Large Scale Holistic Video Understanding: Toward Video Foundation Models,Workshop,"Monday, Dec 1, 2025",06:00,0.33464276790618896,0.7,0.5,0.6,0.4,0.9,0.5605,"The workshop focuses on video foundation models and multimodal understanding, overlapping with the BU's interest in reinforcement fine-tuning of VLMs/LLMs. However, session emphasis is more on general video understanding than specialized RL challenges, limiting direct actionable insights.",这个研讨会关注多模态视频基础模型的长时推理和多维度融合，正好触及我们在强化学习中对跨模态轨迹信用分配和高效适应的需求。能借此探索视频理解系统,多模态表示学习; 长时上下文推理; 高效适应与扩展; 多模态信用分配; 视频系统评估
多伦多云,Science of Trustworthy Generative Foundation Models,Tutorial,"Tuesday, Dec 2, 2025",13:30,0.3992655873298645,0.9,0.7,0.8,0.75,0.9,0.7647499999999999,"The session targets trustworthy generative models, aligning closely with the BU's focus on AI agent trustworthiness, evaluation, and reliability. Techniques like measuring trust and designing aligned systems overlap, offering significant novel insights and actionable knowledge for the BU's challenges.",该BU强调AI代理的可信执行与持续优化，会议内容聚焦于构建严谨的信任度科学，有助于解决代理行为的信任验证和多步骤决策的责任分配问题。,模型行为理解; 信任度测量与压力测试; 事务语义保障; 在线持续改进; 长程决策信用分配
多伦多云,The Oak Architecture: A Vision of SuperIntelligence from Experience,Invited Talk,"Wednesday, Dec 3, 2025",08:30,0.6181996464729309,0.8,0.7,0.75,0.6,0.9,0.703,"Session addresses continual learning, planning, and state abstractions, aligning well with BU's focus on agent competency, evaluation, and improvement loops. Technical approaches partially overlap in model-based RL and continual meta-learning. While conceptual, it offers novel insights but fewer direct actionable details for immediate BU application.",这个Oak框架强调持续学习和元学习，正好对应多伦多云关注的在线改进循环和连续学习机制，能增强智能体的稳健性和泛化能力。,持续学习能力; 元学习参数调优; 抽象层次建模; 模型规划策略; 在线改进反馈
多伦多云,NeurIPS 2025 Workshop on Socially Responsible and Trustworthy Foundation Models,Workshop,"Sunday, Nov 30, 2025",11:00,0.2822287082672119,0.8,0.5,0.7,0.6,0.9,0.63175,"The workshop addresses trustworthiness and ethical issues overlapping BU's focus on reliable and safe AI agents. While BU emphasizes technical frameworks, the session brings interdisciplinary governance insights, offering novel perspectives and actionable ethical methods to enhance agent robustness.",Session探讨基础模型的可信性与社会责任，正好衔接多伦多云对可信AI和安全执行的需求，有助强化模型评估与多源反馈机制。,模型可信度提升; 伦理与社会责任; 多模态基础模型; 模型评测指标; 多方反馈优化
多伦多云,From Tuning to Guarantees: Statistically Valid Hyperparameter Selection,Tutorial,"Tuesday, Dec 2, 2025",09:30,0.5205050706863403,0.7,0.6,0.8,0.7,0.85,0.624375,"Session focus on statistically valid hyperparameter tuning complements BU's need for reliable AI agent evaluation and optimization, offering new rigorous methods to control deployment risk with finite-sample guarantees, relevant for their evaluation and improvement loops.",多伦多云关注AI代理的可靠性和持续学习，而本教程提供统计验证的超参数选择方法，有助于严格控制模型性能和安全风险，实现更可信的部署与优化。,超参数统计验证; 多重假设检验; 风险控制机制; 模型性能保障; 有限样本理论
多伦多云,NeurIPS 2025 Workshop on Embodied and Safe-Assured Robotic Systems,Workshop,"Sunday, Nov 30, 2025",11:00,0.5550625324249268,0.7,0.6,0.6,0.5,0.9,0.60325,"Session addresses safety and trustworthiness of embodied systems, aligning with BU's focus on robust AI agent evaluation and safe operations. Some shared themes in reliability and safety, but BU's detailed framework and continuous learning aspects are more advanced than session focus.",本Session强调机器人系统的安全和可预测性，与多伦多云BU中对AI代理安全性验证、行为可信度及在线改进机制的需求高度契合，有助优化安全关,安全保障机制; 行为可信验证; 在线学习与优化; 多步规划验证; 回滚与事务控制
多伦多云,NORA: The First Workshop on Knowledge Graphs & Agentic Systems Interplay,Workshop,"Monday, Dec 1, 2025",06:00,0.40384048223495483,0.7,0.5,0.6,0.5,0.9,0.5700000000000001,"Session focuses on the synergy between LLM agents and knowledge graphs, relevant to the BU's agent reliability and evaluation aspects. Technical overlap modest since BU's main focus is on evaluation and safety mechanisms rather than KG construction. Good potential for novel insights on KG augmentation and reasoning.",多伦多云关注AI Agent的可靠性和持续学习，NORA工作坊探讨知识图谱对Agent记忆与推理能力的增强，能为构建稳健、具备长序列计划和上,知识图谱与Agent记忆; 上下文窗口扩展技术; Agent的持续学习机制; Agent行动可信保障; 多步计划执行分析
多伦多云,Vision Language Models: Challenges of Real World Deployment,Workshop,"Sunday, Nov 30, 2025",11:00,0.3656275272369385,0.65,0.5,0.7,0.6,0.9,0.5676249999999999,"Both focus on AI agents and reliability, with the session emphasizing deployment challenges in VLMs relevant to the BU's concerns on evaluation and robustness. Methods overlap moderately in evaluation and robustness, providing novel insights and actionable deployment strategies for the BU.",多伦多云关注代理可信操作和在线优化，与该Workshop强调的VLM高效、稳健部署和持续学习高度契合，可借鉴事务语义和因果分析提升系统可靠性,代理可信操作框架; 在线反馈与持续优化; 事务语义保障; 长程规划验证; 多模态稳健训练
诺亚,"Positional Encoding: Past, Present, and Future",Tutorial,"Tuesday, Dec 2, 2025",13:30,0.5571724772453308,0.9,0.85,0.8,0.75,0.95,0.8360624999999999,"The session focuses on positional encoding, a core aspect of the BU's challenge in stable long-sequence modeling using RoPE, ALiBi, etc. The tutorial offers foundational knowledge and open-source tools, likely benefiting BU's technical needs and enabling near-term application improvements.",诺亚业务关注长序列推理与跨模态处理，精准理解和设计位置编码有助于优化序列表示和计算效率，提升模型的长距离依赖捕捉和多模态融合能力。,位置编码原理; 长序列注意力机制; 跨模态序列处理; 可扩展编码方法; 代码实现与实验
诺亚,"Efficient Transformers: State of the art in pruning, sparse attention, and transformer funneling",Tutorial,"Tuesday, Dec 2, 2025",09:30,0.6146764755249023,0.9,0.85,0.75,0.8,0.9,0.8146250000000002,"Session covers pruning, sparse attention, and funneling directly relevant to long-sequence efficiency challenges. Techniques overlap well with BU's focus on sparse/linear attention and token compression. Tutorial includes actionable recipes, supporting strong relevance and applicability.",Noah BU关注内存管理与长序列推理，该教程覆盖稀疏注意力与序列压缩技术，有助提升模型对超长序列的高效处理能力。借鉴工业界最新实践，能帮助,稀疏注意力机制; 序列压缩与漏斗结构; 内存写入与驱逐策略; 多模态长序列编码; 工业前沿效率方法
诺亚,Vision Language Models: Challenges of Real World Deployment,Workshop,"Sunday, Nov 30, 2025",11:00,0.6404716372489929,0.8,0.75,0.7,0.65,0.9,0.7196250000000001,"The BU's focus on efficient, scalable vision-language models with adaptive compute matches well with the session's emphasis on deployment challenges and efficiency in VLMs. Techniques like sparse attention and memory management overlap. The workshop offers novel insights and actionable strategies for real-world VLM deployment.",诺亚BU关注高效管理超长多模态序列与推理，和会议强调的VLM高效推理与可靠性高度契合，可借鉴会议优化多模态输入与自主计算调度方法。,多模态长序列推理; 高效注意力机制; 动态计算分配; 多模态输入分层处理; VLM鲁棒性评估
诺亚,7th International Workshop on Large Scale Holistic Video Understanding: Toward Video Foundation Models,Workshop,"Monday, Dec 1, 2025",06:00,0.5774131417274475,0.8,0.7,0.75,0.65,0.9,0.7077499999999999,"The workshop focuses on holistic video foundation models and multimodal reasoning, aligning well with BU's focus on long-sequence multimodal reasoning and hierarchical tokenization. Some technical overlap exists around multimodal alignment and efficient scaling. Novel methods and discussions could yield actionable insights.",这个Workshop聚焦多模态视频中高效的长序列推理和多维度语义理解，正好契合BU对100k+ tokens的稳定注意力机制和层次化帧页编码,长序列推理; 多模态表示学习; 层次化帧编码; 计算资源调度; 多模态跨模态注意力
诺亚,The Art of (Artificial) Reasoning,Invited Talk,"Thursday, Dec 4, 2025",08:30,0.5840483903884888,0.7,0.5,0.8,0.6,0.9,0.5985,"The session addresses reasoning capabilities and challenges in AI, overlapping broadly with the BU's interest in scaling and reasoning methods. Specific techniques like reinforcement learning and reasoning enhancement are relevant, though detailed methods (KV compression, long-sequence architectures) are not deeply covered, limiting overlap and immediate actionability.",这个专题深入探讨了在有限计算资源下如何通过改进模型结构和训练策略增强小模型的推理能力，正好契合我们BU对长序列多模态推理的高效架构设计与鲁棒,长序列推理架构; 稀疏与线性注意力; 动态计算分配; 持久内存管理; 跨模态输入策略
诺亚,The Oak Architecture: A Vision of SuperIntelligence from Experience,Invited Talk,"Wednesday, Dec 3, 2025",08:30,0.40184980630874634,0.7,0.5,0.8,0.6,0.9,0.5985,"Both focus on continual learning, model-based RL, and planning which overlaps with BU's post-training and reasoning goals. Oak's meta-learned step sizes and abstractions offer novel insight. However, BU's detailed long-sequence, memory, and multimodal methods differ technically, limiting direct overlap and actionability.",Oak架构强调持续学习和高级抽象，与BU在多模态和长序列推理中需要的适应性计算策略高度契合，特别是其元学习和规划机制有助提升长期推理的准确性,持续学习机制; 元学习调参; 状态与时间抽象; 模型规划策略; 多模态长序列推理
中软,Vision Language Models: Challenges of Real World Deployment,Workshop,"Sunday, Nov 30, 2025",11:00,0.5634012222290039,0.7,0.6,0.75,0.6,0.9,0.6270000000000001,"Session focuses on real-world deployment challenges of multimodal VLMs, overlapping BU needs in uncertainty handling, robustness, and systems optimizations, but BU's emphasis on distributed AI primitives and stateful orchestration is less covered, yielding moderate-high relevance and value.",该Session聚焦于提高视觉语言模型在效率、鲁棒性和系统级部署的可靠性，正好对中软构建分布式AI框架和多模态管道中的不确定性处理、安全防护,高效推理加速; 多模态不确定性处理; 系统级鲁棒性设计; 分布式流水线整合; 安全隐私防御
中软,Science of Trustworthy Generative Foundation Models,Tutorial,"Tuesday, Dec 2, 2025",13:30,0.35232967138290405,0.7,0.5,0.8,0.6,0.9,0.5985,"Session focuses on trustworthy generative models, aligning with BU's emphasis on security, privacy, and reliability. However, BU needs system-level orchestration and multimodal fusion not directly addressed. Strong potential for learning about trust and model alignment.",多轮对话与异步编排对模型的信任和一致性提出了高要求，本教程针对模型行为理解与信任测试，助力构建可靠的分布式AI系统。,模型行为理解; 信任度量与测试; 异步编排机制; 多轮长上下文管理; 安全隐私防护
中软,NORA: The First Workshop on Knowledge Graphs & Agentic Systems Interplay,Workshop,"Monday, Dec 1, 2025",06:00,0.5269882678985596,0.7,0.6,0.7,0.5,0.85,0.5966250000000001,"Session focuses on agents and knowledge graphs enhancing contextual memory and reasoning, aligning well with BU's interest in long-context memory and agent orchestration, though session is broader and less system-primitives focused, limiting immediate actionable specifics for BU's tooling and security challenges.",这个Workshop探讨了知识图谱辅助解决多轮对话中的长期记忆和信息整合问题，正好契合中软对统一长上下文存储和状态一致性的需求，同时关注异步,统一长上下文记忆模型; 知识图谱构建与增强; 智能体异步调度机制; 多模态信息融合; 安全隐私保护
可信,The Oak Architecture: A Vision of SuperIntelligence from Experience,Invited Talk,"Wednesday, Dec 3, 2025",08:30,0.5383872985839844,0.8,0.7,0.85,0.6,0.9,0.7124999999999999,"The session discusses continual learning, meta-learning, and hierarchical planning closely related to BU's safety and agent architecture challenges, offering innovative methods with moderate direct application potential.",Oak架构重视持续学习与元学习，正好对应可信BU对持续适应与在线策略改进的需求，特别是通过分层抽象和模型规划提升内存与上下文管理能力。,持续学习机制; 元学习步长调整; 分层状态与时间抽象; 模型规划策略; 安全适应与风险控制
可信,Science of Trustworthy Generative Foundation Models,Tutorial,"Tuesday, Dec 2, 2025",13:30,0.39355090260505676,0.85,0.65,0.75,0.6,0.9,0.7077500000000001,"The session covers trustworthy generative foundation models with emphasis on trust science, aligning well with the BU's focus on trustworthy AI agents. However, BU's detailed agent architecture and runtime mechanisms are more specific than the tutorial scope, reducing actionability slightly.",这场教程深入探讨了如何科学地评估和设计可信生成模型，正好契合构建可信智能体中对不确定性量化和行为校准的核心需求。,不确定性量化方法; 多模态意图识别; 模型行为解释; 在线自我学习机制; 风险监控与干预
可信,NORA: The First Workshop on Knowledge Graphs & Agentic Systems Interplay,Workshop,"Monday, Dec 1, 2025",06:00,0.4888514280319214,0.8,0.7,0.75,0.65,0.9,0.7077499999999999,"Session focuses on knowledge graphs enhancing agent systems, addressing catastrophic forgetting and context limitations aligned with BU's trust and memory challenges. Overlap in architectures and memory management is strong; novelty and actionable insights on knowledge graph integration are likely useful for BU.",该Session强调利用知识图增强语言模型代理的记忆和推理能力，与可信BU中多模态意图识别和长期状态管理技术密切相关，有助提升代理的在线自学,知识图增强记忆管理; 多模态意图识别; 长期状态保持机制; 在线自学习安全; 风险感知与干预
可信,NeurIPS 2025 Workshop on Socially Responsible and Trustworthy Foundation Models,Workshop,"Sunday, Nov 30, 2025",11:00,0.26214104890823364,0.85,0.6,0.7,0.65,0.9,0.691125,"Session focuses on trustworthy foundation models and ethical risks, aligning well with BU's trust challenges. While methods overlap moderately, BU can gain novel insights on responsible deployment and governance applicable soon.",该BU关注在多模态环境中推断用户意图及动态适应，与Workshop中跨学科提升模型透明度、公平性和安全性的主题高度契合，有助推动可信机制和风,多模态意图识别; 不确定性量化; 记忆与上下文管理; 自我学习与防护; 风险监测与干预
可信,Vision Language Models: Challenges of Real World Deployment,Workshop,"Sunday, Nov 30, 2025",11:00,0.44952192902565,0.75,0.65,0.7,0.6,0.9,0.6602499999999998,"Both focus on multimodal agents and robustness under real-world constraints; session addresses uncertainty estimation and modular architectures relevant to BU's trustworthiness challenge. Some BU specifics like continual self-learning and long-horizon memory are less emphasized, yielding moderate but meaningful overlap and actionable insights.",可信BU强调在非稳定环境中安全自适应与多模态意图检测，正好呼应这个研讨会中关于VLM高效推理和鲁棒训练的核心挑战。可以借鉴其中对不确定性量化,多模态意图识别; 不确定性量化; 高效推理技术; 鲁棒训练方法; 持续在线学习策略
可信,NeurIPS 2025 Workshop on Embodied and Safe-Assured Robotic Systems,Workshop,"Sunday, Nov 30, 2025",11:00,0.6145504713058472,0.8,0.6,0.7,0.6,0.8,0.63,"Session targets safety and trustworthiness in embodied robotic systems, aligning well with BU's focus on trustworthy agentic AI. Both address safety and uncertainty, but BU emphasizes agent architectures and continual learning beyond robotics.",该Session聚焦于机器人系统的安全和行为可预测性，正好契合BU对不确定性量化和风险干预的需求，有助推进自学习策略中安全性和异常检测技术发,不确定性量化; 异常检测机制; 多模态意图推断; 在线自学习安全; 风险感知干预
