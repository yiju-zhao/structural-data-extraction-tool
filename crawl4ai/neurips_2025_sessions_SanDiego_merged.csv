date,time,type,title,url,speaker,end_time,abstract,overview,matched_team,recommendation_reason,focus_area
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Telling Stories at Scale: Multimodal ML in the Global Media Landscape,https://neurips.cc/virtual/2025/128652,,9:30 AM,"Netflix has long been recognized as a pioneer in personalization, leveraging member preference data to recommend the most engaging shows, movies, and games. In recent years, we have expanded our use of machine learning and data-driven approaches to support a wide array of upstream creative and operational workflows. In this talk, we will discuss how modern AI methods – contrastive learning, transformers, cross-modal retrieval, graph neural networks, etc. – are transforming the curation, localization, promotion, and launch of stories on a global scale. A distinctive aspect of our work is the integration of highly creative assets—text, images, video, and speech—alongside traditional tabular datasets. We will highlight unique challenges that arise at the intersection of multimedia, personalization, and web-scale products, and share how advanced ML/AI techniques are addressing these challenges to connect great stories with our worldwide audience.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Data Scout: “From Prompt to Corpus: Accelerating Domain-Specific Data Collection with LLMGuided Discovery”,https://neurips.cc/virtual/2025/128656,,9:30 AM,"Training large language models for specialized disciplines such as advanced mathematics, molecular biology, or legal reasoning is limited by the scarcity of large, high quality, domain specific corpora. Most publicly available datasets are dominated by general purpose web text. When available, specialized data are fragmented across diverse sources such as preprints, conference papers, forums, lecture notes, and digitized books. No single source offers comprehensive real-world coverage across scientific domains. Consequently, scaling up authentic domain data remains a bottleneck: collecting a subset of relevant tokens often requires downloading and filtering hundreds of terabytes of raw web material, a process that is both time consuming and costly.x000Dx000DWe introduce Data Scout, a modular, LLM powered pipeline that turns a high-level user intent (e.g., “I need data for advanced mathematics”) into a vetted, list of seed URLs in minutes. The system first expands the original intent using an LLM that generates a hierarchical subgraph of related concepts; this taxonomy drives a diversified set of search queries that systematically cover the target domain while respecting known licensing signals. Candidate URLs are then filtered by the same LLM using chain of thought prompting based on topical relevance, licensing clarity, and crawlability. Our results show that that the list of selected candidate URLs when crawled can yield a high percentage of relevant pages (40%+) related to the user’s intended topic or query, compared to less than 1 percent in general web-scale corpora. Data Scout is available with both CLI and GUI front ends. By democratizing domain specific data acquisition, Data Scout enables researchers without dedicated crawling infrastructure to bootstrap large, high-fidelity corpora, accelerating the development of specialized LLMs across various niche domains fields.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Multimodal Data Foundation at Industry-Scale,https://neurips.cc/virtual/2025/128659,,9:30 AM,"Pre-training is fundamental to foundation models, enabling them to acquire broad knowledge that gives rise to emerging capabilities at later training stages, and scaling is the key for pre-training. In this talk, we present a recipe for building and curating pre-training, multimodal image-text paired data from scratch on a global scale, enabling mutual benefits between English and non-English data. We would like to share our key observations and insights with the community on: (1) why scaling matters, including the foundational role of data and key principles to hold for scaling; (2) how to design simple yet scalable data algorithms that enable industry-scale data collection and training without data filters, serving both research and production needs; (3) how the scaling improves Meta’s products at conventional and frontier machine learning areas. Submission is facilitated by Cogs & Marvel but is entirely organized, executed, and implemented by Meta.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Toward General Full Autonomy: Open Research Challenges in Scalable Self-Driving,https://neurips.cc/virtual/2025/128661,,9:30 AM,"Speaker: Ben Snyder, Director of AI Research for Autonomous Vehicles, General Motorsx000Dx000DGM’s driver-assistance systems now power millions of vehicles across North America, logging over half a billion hands-free miles with zero reported crashes—demonstrating the safety and scalability of autonomy at unprecedented consumer scale. Following GM’s acquisition of Cruise earlier this year, the combined teams now bring together a decade of experience to accelerate progress toward full, generalized autonomy. This talk will dive into the open research challenges ahead—from model architecture and the balance between imitation and reinforcement learning, to leveraging vision-language models for long-tail, common-sense reasoning, and advancing the training, deployment, and simulation infrastructure needed to scale truly generalized autonomy.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Beyond Benchmarks: Rethinking Reasoning in Language Models,https://neurips.cc/virtual/2025/128665,,9:30 AM,"Reasoning is often described as the next frontier for AI, but what does it really mean for a model to “reason”, and how should we measure it? Popular benchmarks like GSM8K suggest steady progress, yet controlled studies reveal that models can fail dramatically under small changes—such as swapping numbers or adding irrelevant details. Large Reasoning Models (LRMs), which generate explicit chains of thought, raise new optimism but also expose clear limits: they often underperform standard models on simple tasks, improve briefly at medium complexity, and then collapse on harder ones despite having unused compute. Crucially, reasoning is not the same as knowledge recall, tool use, or agent-like behavior. True reasoning involves solving novel problems, decomposing them into steps, generalizing to new contexts, recombining partial results, and finally generating novel hypotheses—capabilities current systems largely lack. Today’s evaluations, focused on final answers and contaminated benchmarks, risk giving a misleading sense of progress. This talk will provide a critical review of reasoning in language models, highlight why current evaluations can be deceptive, and emphasize that reasoning is not just about “what"" models answer, but “how"" they solve problems.",,计算; 诺亚,计算: 该Session深入探讨语言模型推理的本质及其评测方法，契合计算团队面对训推范式演进负载特征变化的挑战。理解推理机制有助于精准把握未来训练与推理负载走向，促进模型智能水平提升。; 诺亚: 本Session深入探讨语言模型的推理本质与评估误区，契合团队关于多模态长文本推理计算瓶颈的挑战。通过理解推理能力的内涵及其限制，有助于指导长序列图文模型在输入范式上的创新突破。,计算: 语言模型推理的定义与特征解析; 现有推理评测的局限性及改进方法; 连锁思维（Chain-of-Thought）生成与应用; 训练与推理范式演进对负载特征的影响; 解决复杂问题时模型的分解和泛化能力; 诺亚: 推理过程的分步解构及链式思维生成方法; 推理能力与知识召回的区别及影响; 现有推理评估方法的局限性及改进策略; 多模态长文本中的复杂推理计算瓶颈分析; 如何基于推理机制优化输入范式提升模型性能
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Foundational Generative Recommendations for E-Commerce,https://neurips.cc/virtual/2025/128667,,9:30 AM,"Modern commerce platforms face the challenge of delivering personalized recommendations across billions of items to users with diverse intents, temporal dynamics, and cold-start scenarios. We present a generative foundation model for commerce built on Hierarchical Sequential Transduction Units (HSTU) that integrates Liquid Foundation Models (LFM) for rich textual product representations and custom CUDA kernels developed in collaboration with Nvidia for efficient training and online serving. Our approach demonstrates that generative methods unlock substantial gains through three key innovations: (1) large-scale contrastive learning with hard negative sampling; (2) temporal mechanisms that fuse multi-scale time signals (session, day, season) with commerce-specific features; and (3) optimized training and inference kernels. By treating LFM embeddings as auxiliary features rather than end-to-end fine-tuning, we maintain modularity while capturing semantic relationships. While results are promising, significant challenges remain in handling non-stationary preferences, multi-objective optimization, and ensuring fairness in generative retrieval—we discuss our roadmap toward truly foundational commerce models that generalize across domains and market conditions.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,From Research to Markets: Applying Cutting-Edge Machine Learning in Quantitative Finance,https://neurips.cc/virtual/2025/128670,,9:30 AM,"In modern quantitative finance, the boundaries between academic machine learning research and real-world trading strategies are rapidly dissolving. In this talk, we will share how researchers at G-Research apply advances in deep learning, probabilistic modelling, reinforcement learning, and large-scale optimization to some of the most challenging problems in global financial markets. Our work transforms vast, noisy, and non-stationary data into predictive signals, demanding innovations that extend the state of the art in both theory and practice. This includes sequence modelling for high-frequency data, scalable Bayesian inference for uncertainty quantification, generative modelling for scenario analysis, and reinforcement learning for adaptive portfolio construction. Operating at the intersection of rigorous science and high-performance computing, we thrive in an environment where milliseconds matter and model generalization is paramount.x000Dx000DCome and see how cutting-edge machine learning meets the realities of global financial markets at G-Research.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection,https://neurips.cc/virtual/2025/128668,,9:30 AM,"The rapid integration of LLMs for synthetic data generation offers a powerful solution for data scarcity, a critical issue for training machine learning models. However, the resulting data quality is often questionable, requiring costly and time-consuming manual review. This oversight is especially challenging in the crucial domain of trustworthy and safe AI.x000Dx000DA significant need here is the automated identification of adversarial and harmful inputs, a process known as red-teaming, to improve guardrailing systems before deployment. Developing an effective, fully automated red-teaming approach capable of generating diverse, out-of-domain harmful content has been a long-standing challenge.x000Dx000DTo address data scarcity in harmful text detection & the challenge of automated red-teaming, we introduce GRAID (Geometric & Reflective AI-Driven Data Augmentation), a novel, versatile, & dynamic multi-agent framework.x000Dx000DGRAID operates in two stages:x000D1) Geometric Generation: A constrained, fine-tuned LLM generates geometrically controlled examples to diversify content within the original embedding space.x000D2) Reflective Augmentation: A multi-agentic reflective process promotes stylistic diversity & uncovers difficult edge cases.x000Dx000DThis combination ensures both reliable coverage of the input space & nuanced exploration of harmful content. We demonstrate that augmenting a harmful text classification dataset with GRAID significantly improves the performance of downstream real-world guardrail models. Furthermore, GRAID captures data variability in new geometric domains while preserving data relationships.x000Dx000DWhile initially focused on harmful text detection, GRAID’s modular design makes it an inherently domain-agnostic framework adaptable to various applications beyond classification. In this talk, we will detail how GRAID distinguishes itself from existing solutions, discuss its building blocks, & share insights on its easy adaptation for diverse synthetic data generation needs.",,,,
TUE 2 DEC,9:30 a.m.,Tutorial,Planning in the Era of Language Models,https://neurips.cc/virtual/2025/109596,,12:00 PM,"For over six decades, the field of automated planning has been at the heart of AI, empowering intelligent systems to reason, act, and achieve goals in complex, dynamic environments. From robotics and logistics to space exploration, planning research has fueled autonomous decision-making in real-world applications.Today, as large language models redefine what’s possible in AI, the principles and methodologies of planning are more vital than ever. The planning community brings decades of experience in designing, benchmarking, and interpreting intelligent behavior; expertise that can accelerate the development of powerful, trustworthy, and general-purpose LLM-based agents.Participants will gain a clear understanding of what planning truly entails, what has been learned (and sometimes forgotten) in the shift toward LLM-based approaches, and how foundational insights from the planning community can inform the creation of stronger, more reliable, and more scalable LLM-powered planners.","Overview: The webpage presents a tutorial titled 'Planning in the Era of Language Models' scheduled for December 2nd, 2025, at NeurIPS in San Diego, CA. The tutorial focuses on the integration of automated planning with large language models (LLMs). It highlights the importance of planning in AI, especially as LLMs redefine AI capabilities. The tutorial aims to provide participants with insights into planning methodologies and how these can enhance the development of LLM-based agents. | Research Interests: Automated planning, Large language models, AI reasoning and decision-making, Planning formalisms and languages, Evaluation of planning tools, Human-aware AI systems",温哥华云; 多伦多云,温哥华云: 本Session聚焦自动化规划与大型语言模型的结合，契合温哥华云在物理或具身AI关键领域的战略发展需求。通过学习规划原理与LLM融合技术，有助于深入理解和推动温哥华云在具身AI研究中的创新和应用。; 多伦多云: 该团队面临多步执行能力Agent的持续优化挑战，Session聚焦于规划与LLM结合的智能决策机制，能助力设计自主学习和优化机制，直接契合其多轮优化飞轮问题。,温哥华云: 自动化规划原理及方法; 大型语言模型与规划的融合技术; 基于规划的智能决策与推理; 具身AI系统中的规划应用; 规划工具的评估与应用; 多伦多云: 自动规划技术在LLM中的应用与集成; 多步执行能力的规划方法; 基于规划的Agent持续优化策略; 规划与Prompt优化飞轮的结合方式; 评估与解释LLM驱动的规划系统性能
TUE 2 DEC,9:30 a.m.,Tutorial,Foundations of Tensor/Low-Rank Computations for AI,https://neurips.cc/virtual/2025/109591,,12:00 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Human-AI Alignment: Foundations, Methods, Practice, and Challenges",https://neurips.cc/virtual/2025/109592,,12:00 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Model Merging: Theory, Practice and Applications",https://neurips.cc/virtual/2025/109593,,12:00 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,New Frontiers of Hyperparameter Optimization: Recent advances and open challenges in theory and practice,https://neurips.cc/virtual/2025/109594,,12:00 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Explain AI Models: Methods and Opportunities in Explainable AI, Data-Centric AI, and Mechanistic Interpretability",https://neurips.cc/virtual/2025/109599,,1:30 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,Energy and Power as First-Class ML Design Metrics,https://neurips.cc/virtual/2025/109589,,12:00 PM,,"Overview: The tutorial titled 'Energy and Power as First-Class ML Design Metrics' at NeurIPS 2025 focuses on addressing energy as a critical bottleneck in machine learning. It provides practical measurements, a primer on power and energy as computing resources, and optimizations from kernels to clusters. The event is a collaboration between The ML.ENERGY Initiative at the University of Michigan and NVIDIA, featuring a series of sessions and an industry panel discussion. | Research Interests: Energy efficiency in machine learning, Power and energy as computing resources, Performance optimization under power constraints, Energy optimization with performance considerations, Industry applications of power and energy in ML",计算,计算: 该团队关注低精度训练推理对计算架构的影响，而本Session深入探讨能量与功率作为关键性能指标，涵盖从计算核到集群的性能优化，契合团队在低精度模型及其硬件需求的研究和应用，促进下一代芯片设计的能效提升。,计算: 能量与功率作为计算资源的基础度量方法; 在功率约束下的性能优化技术; 低精度模型训练与推理的能效优化策略; 硬件架构设计中能效与性能的平衡; 面向多模态及强化学习的新型能效计算方案
TUE 2 DEC,noon,Expo Demonstration,Multimodal AI Forensic Search for Video Surveillance,https://neurips.cc/virtual/2025/128632,,3:00 PM,"Video surveillance often requires searching for specific targets from long-duration videos using multiple cameras. Traditional tracking‑and‑detection pipelines demand heavy manual filtering, and even recent multimodal approaches such as using CLIP remain limited to shallow visual attributes (e.g., clothing color) and weak temporal reasoning. This makes forensic search labor‑intensive.x000Dx000DWe present ForeSea, a novel AI forensic search system that supports rich multimodal queries (text + image) and returns timestamped evidence of key events. ForeSea is organized as a multi‑stage pipeline that couples tracking and retrieval with time‑aware VideoLLM reasoning: (1) uses tracking model to filter out irrelevant segments (e.g., frames without people) and produces person‑centric clips; (2) retrieval constructs an index over tracked clips to form a searchable database; and (3) during inference, the multimodal query is embedded to retrieve the top N candidate clips, which are then fed into a time-aware VideoLMM that performs temporal grounding and generates precise answers from concise input. Through ForeSea's multi-stage pipeline, we can search for targets using both image and text queries (e.g., asking 'When does this person get involved in a fight?' with an image of the person). This approach eliminates the need for detailed textual descriptions and enables effective temporal understanding across long videos.x000Dx000DTo evaluate LMM based forensic search, we introduce AI Forensic‑QA, a benchmark for multimodal video question answering with temporal grounding. On this benchmark, ForeSea achieves an 8.6 % accuracy improvement and a 6.9 (IoU) gain over strong baselines. To the best of our knowledge, this is the first benchmark in this domain to support multimodal queries evaluation. Our live demo showcases multimodal search, timestamped evidence visualization, and side‑by‑side comparisons with SOTA models.",,,,
TUE 2 DEC,noon,Expo Demonstration,Efficient LiDAR Processing with AI Models Leveraging Heterogeneous Compute,https://neurips.cc/virtual/2025/128633,,3:00 PM,"This demo showcases heterogeneous compute execution of a LiDAR model running in real time on an edge device. The LiDAR processing, specifically 3D sparse convolution (spconv3d) network, runs on the Qualcomm Adreno GPU, while the Region Proposal Network (RPN) executes on the Qualcomm Hexagon NPU.  This division of labor across specialized processors reduces on-device inference latency and maximizes overall efficiency. Additionally, a lightweight, learnable voxel removal layer that hierarchically prunes redundant voxels further reduces inference time without compromising detection accuracy.x000Dx000D""This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.""x000Dx000DImplementation challenge that we tacklex000Dx000DLiDAR models often combine different types of operations: irregular, sparse computations (e.g., SpConv3D) and dense convolutional layers (e.g., CNNs). These operations have distinct hardware affinities—SpConv3D is better suited for SIMT-style GPUs, while CNNs benefit from SIMD-style NPUs. Efficient execution requires mapping each part of the model to the most appropriate compute unit.x000Dx000DAnother challenge is the variability in voxel density across LiDAR frames. Not all voxels contribute meaningfully to object detection, many represent ground planes or distant background and can be safely discarded. However, identifying and removing these in a lightweight, learnable way is non-trivial.",,,,
TUE 2 DEC,noon,Expo Demonstration,Parallel generation with verification on device,https://neurips.cc/virtual/2025/128634,,3:00 PM,"In this work, we address the challenges of efficiently generating and verifying multiple responses from large language models (LLMs) directly on device. While sampling with non-zero temperature often yields improved responses compared to greedy approaches, selecting the best response requires generating several candidates and evaluating them without incurring significant latency or resource overhead. Cloud-based solutions often rely on separate verification models, which are impractical for on-device deployment due to resource constraints. Our proposed solution leverages multi-stream execution graphs and parallel LLM generation, enabling joint generation and verification within a unified framework. Combined with post-processing techniques such as majority voting, this approach minimizes latency and optimizes the selection of high-quality responses, paving the way for more effective on-device LLM inference.x000Dx000DSpecific challenge that we tackle (research/implementation-wise)x000Dx000DUsing non-zero temperature sampling with language models can result in higher-quality responses compared to greedy sampling, although this is not always assured. Achieving optimal output often requires generating multiple candidate responses and selecting the most suitable one for the user. This technique is widely adopted to enhance inference-time performance. When implemented on device, however, it presents two primary challenges: minimizing the latency associated with generating several responses and determining a resource-efficient method for selecting the best response from the generated set.",,,,
TUE 2 DEC,noon,Expo Demonstration,Soft Prompts for On-Device Content Moderation,https://neurips.cc/virtual/2025/128635,,3:00 PM,"We demonstrate the first on-device integration of a safety-aligned large language model (LLM) using soft prompt distillation, powered by our proposed TV-DiSP framework. Our system showcases how a mobile device can run a quantized LLM equipped with learned soft prompts to moderate harmful or toxic content in real-time. The demo highlights the difference in LLM outputs with and without our soft prompts when subjected to adversarial or unsafe inputs, enabling efficient and safe deployment of LLMs on edge devices.x000Dx000DLLMs are known to produce unsafe or toxic outputs when prompted harmfully. Traditional safety mechanisms rely on dual-model architectures—pairing a base LLM with a separate guard model—which are memory and computationally expensive and unsuitable for deployment on resource-constrained devices like smartphones. The challenge is to achieve robust safety alignment without compromising latency, memory, or model utility in edge environments.",,,,
TUE 2 DEC,noon,Expo Demonstration,Generating group photos of multiple people from text and reference images,https://neurips.cc/virtual/2025/128636,,3:00 PM,"Reference-based multi-human image generation is emerging as a critical capability for personalization, synthetic data creation, and benchmarking generative models. Unlike single-subject generation, this task requires compositional reasoning to place multiple individuals—each with distinct identities—into a coherent scene guided by a text prompt. Existing models often fail to preserve identities or maintain spatial fidelity, which limits their applicability for real-world scenarios such as social content creation or training vision systems.x000Dx000DOur demo addresses these challenges by showcasing a state-of-the-art system for reference-based multi-human generation. The system takes reference images of multiple individuals and a text description of the desired scene, then produces a high-quality image featuring all participants in context. Built on the Flux-Kontext backbone and trained using synthetic data from DisCo (arXiv:2510.01399), our RL-based approach optimizes multiple rewards including Human Preference Score (HPS3) and Average ID Similarity. Evaluation on MultiHuman-Testbench (arXiv:2506.20879) confirms state-of-the-art performance.x000Dx000DThis demo showcases fast generation on a laptop powered by a Snapdragon processor, highlighting the efficiency and scalability of our solution.",,诺亚,诺亚: 该Session展示了基于文本和多个人物参考图像生成高质量合成图像的最新技术，直接关联长序列图文多模态模型的推理挑战，契合团队对多模态长文本推理计算瓶颈的突破需求。,诺亚: 参考图像与文本的多模态融合技术; 多人人物身份保持与空间关系建模; 基于强化学习的多目标优化策略; 高效长序列多模态推理方法; 移动端实时图像生成实现方案
TUE 2 DEC,noon,Expo Demonstration,Reasoning through Multimodal End-to-End Decision Transformer Networks and Vision Language Action (VLA) models,https://neurips.cc/virtual/2025/128637,,3:00 PM,"This demonstration showcases the live output and visualization capabilities of an edge-integrated VLA model for path planning in automated driving scenarios. By harnessing raw multimodal sensor inputs, including visual and voice data, the VLA model processes information in real time to generate safe, explainable, and repeatable driving trajectories. The system operates on a Snapdragon Ride Elite SoC platform and incorporates safety guardrails, enabling robust decision-making and transparent reasoning. Attendees will observe how end-to-end AI networks interpret complex environmental cues to deliver actionable driving paths, with a special focus on complex use cases involving vulnerable road users and other actors on the road. This demonstration highlights advances in multimodal reasoning and edge deployment for next-generation intelligent mobility solutions.",,,,
TUE 2 DEC,noon,Expo Demonstration,Disaggregated LLM Serving on AI Accelerators,https://neurips.cc/virtual/2025/128638,,3:00 PM,"This demo showcases disaggregated serving on Qualcomm Cloud AI 100 Ultra Card, a power-efficient AI inference accelerator purpose-built for large language models (LLMs) serving. The accelerator has been deployed across multiple cloud service providers (CSPs) globally and is actively serving state-of-the-art LLMs and other generative AI workloads.x000Dx000DLLM inference typically involves two distinct stages: prefill and decode. The prefill stage is compute bound, while the decode stage is memory bound. Applying uniform parallelism strategies across both stages often results in suboptimal performance, particularly in key metrics such as Time to First Token (TTFT) and Requests Per Minute (RPM) at the cluster level.x000Dx000DThis demo highlights the performance benefits of disaggregated parallelism strategies tailored to the unique characteristics of each stage. By optimizing the execution of prefill and decode independently, we demonstrate significant improvements in TTFT and overall throughput.x000Dx000DKey benefits:x000Dx000DImproved TTFT: Faster initial response times for LLM queries.x000Dx000DHigher throughput: Increased number of requests served per minute at the cluster level.x000Dx000DOptimized resource utilization: Efficient mapping of compute and memory resources to match workload characteristics.x000Dx000DSLA-adherent performance: Maintains service quality and responsiveness within strict latency and throughput requirements.",,,,
TUE 2 DEC,noon,Expo Demonstration,SwiftEdit: Fast Text-guided Image Editing via One-step Diffusion on a Mobile Device,https://neurips.cc/virtual/2025/128639,,3:00 PM,"In this demo, we show an on-device inference of our one-step diffusion image editing model (SwiftEdit) [1] that performs interactive image editing based on the user’s source image and text prompt, running on an Android smartphone powered by Qualcomm Technologies’ latest Snapdragon Mobile Platform. On A100 GPUs, this technique can run in real-time with 0.23s per single edit operation. We expect SwiftEdit to perform each edit operation in seconds on the smartphone, demonstrating efficient and responsive on-device diffusion inference.x000Dx000DScientific Challenge that we tacklex000Dx000DExisting text-guided image editing methods fell short of the speed demands required for real-world and on-device applications due to the costly multi-step inversion and sampling process involved. In response to this, we developed SwiftEdit that performed image editing using just one-step inversion and one-step image reconstruction.x000Dx000DEfficiently running SwiftEdit requires concurrently on-boarding multiple deep models, including IP-Adapter (Vision Encoder and Image Projection), SwiftBrush (U-Net, VAE, Text Encoder), and SwiftBrush-based Inversion Network. This poses significant challenges for efficient execution and inter-module communication, while enabling an interactive image editing experience for the user — with all computation performed entirely on the edge device.",,,,
TUE 2 DEC,noon,Expo Demonstration,Mobile Video Diffusion Transformers,https://neurips.cc/virtual/2025/128640,,3:00 PM,"We demonstrate Neogradon, the first video diffusion transformer (DiT) designed to run on low-power NPUs in mobile devices, such as phones and laptops. Despite DiTs huge memory and computation cost due to the quadratic attention over thousands of video tokens, we show that mobile devices can run these models when being designed for efficiency. To achieve this level of efficiency:x000Dx000DWe replace the original large text encoder with a much smaller one with minimal quality loss through our novel distillation framework, which doesn’t require any image or video data.x000Dx000DWe propose an asymmetric decoder distillation approach, which allows us to replace the native codec-latent-VAE decoder with a more efficient one, without disturbing the generative latent-space of the video generation pipeline.x000Dx000DWith our block pruning strategy, we remove entire blocks from the MMDiT denoiser based on their relative importance and recover the original performance through a two-stage distillation process.x000Dx000DWe reduce the diffusion sampling cost using our novel extended version of DMD (distribution matching distillation) for the pyramidal flow-matching objective.x000Dx000DNeodragon generates 49 frames of 640x1024 resolution within 7.6 seconds on the Qualcomm Hexagon NPU with the VBench total score of 81.61, setting a new state of the art for mobile video generation.x000Dx000D""This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.""",,,,
TUE 2 DEC,noon,Expo Demonstration,Pushing the boundaries of chemical synthesis with RetroChimera,https://neurips.cc/virtual/2025/128641,,3:00 PM,"Retrosynthesis - the task of planning chemical reaction recipes to synthesize complex molecules - remains a bottleneck in the discovery of novel pharmaceuticals. We recently released RetroChimera - a model for predicting chemical reactions - which demonstrated robustness well outside of training distribution by transferring zero-shot to internal reaction data at a major pharmaceutical company. We also found that industrial organic chemists prefer predictions from RetroChimera over real patented reactions in terms of quality, revealing a high degree of alignment. In this demo, we will showcase the model, let attendees query it live, and show them how to interpret the results.",,,,
TUE 2 DEC,noon,Expo Demonstration,BeeAI,https://neurips.cc/virtual/2025/128642,,3:00 PM,"The BeeAI Framework is an open-source project for building reliable AI agents that combine autonomy with control. Current agent frameworks focus primarily on prompting and orchestration, leaving critical questions of predictability and safety unaddressed. BeeAI fills this gap with a lightweight framework that enables developers to build agents whose reasoning abilities are preserved while execution is constrained by declarative, rule-based requirements. At the core of the framework is the RequirementAgent, a novel agent design that enforces deterministic, controlled behaviors across heterogeneous language models. With RequirementAgent, developers can ensure consistent and reliable execution patterns regardless of differences in model reasoning, tool-calling abilities, or stochastic variation. This approach provides practitioners with a unified abstraction layer that simplifies the deployment of complex AI systems into production settings. As an incubating Linux Foundation AI project, BeeAI is gaining adoption in open source and enterprise contexts as organizations seek robust ways to operationalize AI agents at scale. At NeurIPS EXPO, we will showcase BeeAI’s architecture, real-world use cases, and lessons learned from applying declarative control to agent autonomy.",,计算; 多伦多云,计算: BeeAI框架专注于构建具有确定性和控制性的AI代理，正对应挑战点中对Agentic和多模态模型负载快速演进所带来的计算架构新需求。通过BeeAI的声明式控制机制，团队可提前探索软硬件系统的适应性及稳定性，助力应对未来计算负载挑战。; 多伦多云: BeeAI框架专注于通过声明性规则保障AI Agent的可控性和可靠性，直接响应多伦多云关于提升AI Agent评估准确性和覆盖范围及自主学习与持续优化机制的挑战点。参与此Session，有助团队深入理解统一控制层设计，推动Agent评估和优化机制创新。,计算: RequirementAgent设计与实现，确保推理能力和执行确定性的统一; 结合多模态模型的执行控制与负载管理策略; 声明式、规则驱动的代理行为规范与安全性保障机制; 在复杂异构系统中跨模型的一致执行模式; 面向生产环境稳定部署的框架架构与性能优化; 多伦多云: RequirementAgent设计与实现; 声明性规则对Agent行为的约束机制; 多模型异构环境下的统一执行保障; Agent评估指标的确定与划分; Agent自主学习与持续优化策略的结合
TUE 2 DEC,noon,Expo Demonstration,ContextForge,https://neurips.cc/virtual/2025/128643,,3:00 PM,"The rapid rise of autonomous AI agents across enterprises is creating a new class of security and governance challenges that are not adequately addressed with today’s technology. Context Forge MCP Gateway is an open-source, security-focused middleware that provides fine-grained control and extensibility for agent operations. With over 2.6k GitHub stars and a rapidly growing user community, Context Forge addresses emerging threat classes including prompt injection, data leakage, and misuse of sensitive resources. At its core, Context Forge introduces a plugin architecture modeled after Linux Security Modules, embedding reusable security hooks at critical points in agent execution (e.g., prompt handling, tool invocation, data transformation). This modular foundation enables organizations to enforce contextual policies at scale—ranging from PII redaction and provenance tagging to prompt injection detection and policy-based access control. With 39 plugins already available, Context Forge is establishing a standards-aligned ecosystem for securing agent workflows in real-world enterprise deployments. By blending research-driven design with open-source adoption it creates a practical path for organizations to advance agent trustworthiness, safety, and compliance.",,,,
TUE 2 DEC,noon,Expo Demonstration,LLM-Powered Intelligent Data Engineering: From Workflow Design to Ingestion andQuality Assurance,https://neurips.cc/virtual/2025/128644,,3:00 PM,"Modern enterprises depend on efficient data engineering pipelines to unlock value from diverse and large-scale datasets. Yet, current processes for workflow design, schema ingestion, and data quality validation remain complex, error-prone, and dependent on technical expertise. This creates barriers for non-expert users, slows down development, and introduces risks of data inconsistency.x000Dx000DWe present a suite of LLM-powered frameworks that reimagine enterprise data engineering across three critical dimensions: (i) From Natural Language to Executable ETL Flows, enabling intuitive pipeline creation with natural language specifications and automatic operator/property inference, (ii) All You Can Ingest, an end-to-end schema mapping and transformation framework that unifies semantic alignment, code synthesis, and robust validation, and (iii) Quality Assessment of Tabular Data, a scalable approach for auto-generating interpretable quality rules and executable validators tailored to specific datasets.x000Dx000DTogether, these innovations demonstrate how Large Language Models (LLMs), augmented with retrieval, code synthesis, reasoning, and guardrails, can transform the data engineering lifecycle into a more accessible, adaptive, and trustworthy process, reducing manual effort, accelerating time-to-value, and ensuring data fidelity at enterprise scale.",,,,
TUE 2 DEC,noon,Expo Demonstration,ALICE: Agentic Logic for Incident and Codebug Elimination,https://neurips.cc/virtual/2025/128646,,3:00 PM,"Modern incident root-cause analysis (RCA) is constrained by partial observability, symptom-centric signals, and the overwhelming noise present in logs, traces, and metrics. Diagnosing production failures often depends on instrumentation quality and human expertise, while latent software defects, configuration errors, and zero-day failure modes remain difficult to pinpoint. To address these challenges, we demonstrate a multi-agent system for incident diagnostics that augments observability data with application source code and static analysis signals.x000Dx000DOur system introduces two cooperating agents: the Code Context Agent (COCOA), which builds a knowledge graph of program dependencies, control/data flows, and caller–callee relationships; and the Incident Diagnostics Agent (IDA), which performs agentic reasoning over an entity topology graph enriched with observability streams. Together, these agents extend topology-aware planning (TAP) to simultaneously operate on program dependency graphs and infrastructure entity graphs, thereby linking runtime symptoms with underlying code-level causes.x000Dx000DThis demo showcases how multi-agent collaboration enables deeper, context-sensitive RCA. We walk through real-world inspired scenarios—including incidents where critical log lines are hidden in noisy observability streams or where latent defects emerge only after system updates—illustrating how the system surfaces root causes that would otherwise remain invisible. By bridging program analysis with runtime observability, our approach moves beyond symptom-driven diagnostics toward a more reliable, automated framework for incident management.",,多伦多云,多伦多云: 本Session介绍的多智能体协作系统通过结合代码上下文与运行时拓扑，实现了对复杂故障的自动诊断，切实提升了Agent行为的可靠性和管控能力。与多伦多云团队关注的Agent写操作可靠性和行为校验挑战紧密相关，值得深入参与。,"多伦多云: 多智能体协作机制; 程序依赖关系知识图构建; 拓扑感知规划（Topology-aware Planning, TAP）; 结合源代码静态分析与运行时观测数据; Agent行为校验与管控策略"
TUE 2 DEC,noon,Expo Demonstration,AI or Human,https://neurips.cc/virtual/2025/128647,,3:00 PM,"This demo from Sound Patrol will ask the audience to guess whether content is AI or Human, challenging the limits of human perception while showcasing an audio foundation model with multiple task heads, fine-tuned to classify and attribute the source of AI content",,,,
TUE 2 DEC,noon,Expo Demonstration,Who Needs Attention Anyway? Real-Time Control from Learned State Geometry,https://neurips.cc/virtual/2025/128648,,3:00 PM,"Large language models changed how we reason with data, not how we act under constraints. Their latency grows with context, adaptation depends on retraining, and safety is emergent rather than measurable. For robots, simulators, and industrial systems that must react now, this compute model is the wrong fit.CurvOS offers an alternative: a real-time operating layer where streaming state-space models (SSMs) meet geometry and reinforcement learning to deliver stable, on-device intelligence. At its core, CurvOS runs a fast streaming SSM coupled to a local Riemannian planner derived from decoder sensitivities. Each step predicts the next state, estimates local curvature (how small perturbations bend predicted dynamics), and moves a short distance along a geodesic within a trust radius.Compute per step stays fixed, so latency and adaptation remain bounded. Unlike streaming SSMs such as Mamba, CurvOS learns geometry online to steer predictions safely without retraining. The result is a compact, measurable control stack that reasons in real time, adapts continuously, and meets physical or chemical objectives under fixed budgets. CurvOS turns sequence models into predictable decision engines for systems where timing and safety matter most.",,,,
TUE 2 DEC,noon,Expo Demonstration,"PRIME Guardrails in Action: A Live Demonstration of an Agentic, Multi-Layered Safety Framework for Generative AI",https://neurips.cc/virtual/2025/128650,,3:00 PM,"The rapid proliferation of large-scale Generative AI systems has created an urgent need for safety frameworks that are both robust and performant. Existing solutions often present a false dichotomy: simple, low-latency filters that are easily circumvented by adversarial inputs, or powerful, semantically-aware models that introduce prohibitive latency for real-time applications. This demonstration introduces a live, practical instantiation of the PRIME (Policy, Risk, Intervention, Monitoring, Evaluation) framework, a novel, modality-agnostic architecture designed to resolve this trade-off. We will showcase a production-grade, multi-layered “Defense in Depth” safety system that utilizes an agentic workflow to intelligently orchestrate heterogeneous guardrail models. The system combines the deep contextual reasoning of large proprietary models (e.g., Google’s Gemini) for nuanced threat assessment with the speed of specialized, open-source classifiers for rapid, early-exit filtering of common violations. Through a series of live, interactive examples, we will demonstrate the system's ability to detect and neutralize a range of adversarial inputs in real-time across both text and image modalities. Attendees will witness the framework successfully identifying and blocking prompt injection attacks, harmful content requests, and policy violations, thereby proving the efficacy of a hybrid, agentic approach to building safer, more trustworthy Generative AI experiences at scale.",,,,
TUE 2 DEC,noon,Expo Workshop,Creative and Protective AI for Music and Entertainment,https://neurips.cc/virtual/2025/128679,,1:30 PM,"Generative AI is reshaping how we create, experience, and safeguard music and entertainment. This workshop presents technologies that expand creative expression while honoring responsibility. On the creative side, we share collaborative artworks with leading sound artists, neural engines for sound design and performance, and automatic mixing that adapts to musical intent. We also present a large multimodal dataset for multishot speech video that supports research on coherent and controllable speech, together with specialized language models that orchestrate camera transitions, gestures, vocal cues, and sound effects. On the protective side, we advance AI methods for data attribution, traceability, and responsible model behavior that safeguard creative data and prevent unintended memorization, ensuring fairness, transparency, and respect for creators’ rights. Together, these threads outline an ecosystem in which AI amplifies artistic practice while preserving the integrity of human contribution.",,,,
TUE 2 DEC,noon,Expo Workshop,Large-Scale Real-World Physical AI Systems,https://neurips.cc/virtual/2025/128672,,1:30 PM,"Motivation and Scopex000Dx000DPhysical AI systems comprise of four things: namely sensors like cameras and lidar, mechanical and electronic control unit, AI models to reason about the environment, and actuators to convert decisions to physical actions. It marries multiple domains like sensor design, perception, low-power real-time hardware design, and control loop action design. Autonomous driving is the most mature physical AI domain deployed for over 10 years, but it still has many open challenges. Humanoid robots are an emerging physical AI domain with potential for near term commercial deployment. One of the major challenges in physical AI is to scale to all real-world scenarios including corner cases in a safe manner. A scalable AI data flywheel is the most critical module to achieve this. Traditional physical AI models have a modular decomposition of perception and action tasks, but the community is increasingly moving towards a single end-to-end AI model.  Furthermore, recent advancements in LLMs and VLMs are leading to VLA (Vision-Language-Action) based end-to-end models. In the future, there will likely be a convergence of physical AI models across different domains like driving and robotics.  The proposed workshop covers the latest research and best practices in industrial research of physical AI by leaders in the domain. It also covers emerging technologies like VLA based foundation models, AI data flywheel, and cross-embodiment learning focused on Physical AI.",,温哥华云,温哥华云: 该Session聚焦大规模物理AI系统，涵盖传感器、AI模型及动作控制等核心技术，与团队需识别和投资关键物理AI研究领域的挑战点高度契合。参会能助力团队把握2026战略增长的技术前沿。,温哥华云: 物理AI系统的传感器设计与集成; 端到端AI模型在感知与动作任务中的应用; 基于视觉-语言-动作(VLA)的多模态模型发展; AI数据飞轮机制实现规模化安全部署; 跨表现形学习与物理AI模型的融合
TUE 2 DEC,noon,Expo Workshop,Checkmate: Fine-tune your own small language model for real-time chess reasoning and gameplay on AWS Trainium,https://neurips.cc/virtual/2025/128680,,1:30 PM,"In this hands-on workshop, participants will leverage AWS Trainium to fine-tune and deploy their own chess-playing language models. Building on recent research showing language models' effectiveness in reasoning, attendees will work with various chess datasets to create AI models that not only play chess but explain their strategic thinking through natural language. The 90-minute session will cover model fine-tuning techniques, optimization strategies specific to Trainium's architecture, and real-time deployment to a chess engine. The workshop culminates in a live tournament where participants' models compete against each other, providing immediate feedback on their implementations. Participants will leave with a working chess reasoning model, practical experience in fine-tuning language models on Trainium, and transferable skills for similar tasks. Python programming experience and familiarity with LLM concepts are required, in addition to a basic understanding of the rules of chess. Workshop materials and AWS credits will be provided.",,,,
TUE 2 DEC,noon,Expo Workshop,Workshop on multimodal Superintelligence,https://neurips.cc/virtual/2025/128681,,1:30 PM,"Multimodal machine learning is among the most promising directions of artificial intelligence. With remarkable progress in academia and industry on this topic, we are at the cusp of building next-generation multimodal models, i.e. multimodal superintelligence. These models can be defined as being able to observe, think, and act across several modalities. At this important junction, our workshop provides a forum for researchers to align and cross-polinate ideas. The Workshop on Multimodal Superintelligence will provide a venue where the community can gather to discuss the current state of multimodal machine learning science. Together, we will attempt to overcome the current barriers of modeling several modalities at once. We will also focus on topics such as cross-modal reasoning, alignment, fusion and co-learning.",,诺亚,诺亚: 该团队面临的多模态长序列图文模型推理计算瓶颈，契合Workshop对跨模态推理和多模态模型输入范式突破的探讨，有助于解决挑战点，提高模型性能和效能。,诺亚: 多模态长序列建模与推理技术; 跨模态融合与协同学习方法; 多模态模型的输入范式创新; 跨模态推理与对齐机制; 多模态模型的计算效率优化
TUE 2 DEC,noon,Expo Demonstration,Interpretable AI for Risk-Based Human Rights Assessment in Global Supply Chains,https://neurips.cc/virtual/2025/128649,,3:00 PM,"Amazon’s responsible sourcing efforts aim to protect people across its global supply chain. Yet detecting human rights risks such as forced labor or unsafe conditions across hundreds of thousands of suppliers is challenging. Auditing every site is costly and impractical, making a risk-based approach essential focusing resources where the likelihood and severity of issues are greatest. To address this, Amazon developed PRISM AI (Predictive Risk Intelligence for Supplier Management), an interpretable machine learning system that predicts and explains supplier-level risk across global supply chains. Trained on over 70,000 internal and third-party audit records, PRISM integrates signals from self-assessment questionnaires, grievance reports, adverse media, and geo-sector risk indices. These inputs help detect both documented and emerging risks in near real time. The model supports three supplier types: those with audit histories, limited data, or none. It adapts using transfer learning, rule-based heuristics, and domain-specific indicators. Each prediction includes transparent attribution, showing which factors such as safety violations or country-sector exposure, most influenced the score. Built with monotonic constraints, the system ensures logically consistent, explainable outputs for regulatory and operational use.x000DThis demo gives NeurIPS participants a hands-on view of how AI research can be operationalized for real-world impact. Already in production at Amazon, PRISM helps compliance teams prioritize audits, onboard suppliers, and escalate risks thereby reducing review time and improving oversight. For researchers, it highlights methods for building interpretable models under data imbalance and integrating structured and unstructured signals. For practitioners, PRISM shows how AI can scale responsible business practices and drive innovation across environmental and social sustainability domains.",,,,
TUE 2 DEC,noon,Expo Demonstration,Build verifiable apps using Generative AI and Automated Reasoning,https://neurips.cc/virtual/2025/128651,,3:00 PM,"Recent advancements in Generative AI have enabled customers to use LLMs to generate infrastructure code using AWS CLI commands. Because humans can make mistakes, when deployed such LLM-generated infrastructure code can have negative impacts, including on security.x000DMotivated by this challenge, this demonstration introduces participants to automated reasoning tooling that enhanced security in production for Amazon Q chat.x000DAWS Q Chat enables natural language interaction with AWS resources while employing automated reasoning to verify every generated API call against comprehensive semantic logic models. This prevents potentially harmful operations before execution and suggests corrections, creating a feedback loop that iterates until verifiably correct code is produced. Through this work, we demonstrate how organizations can leverage GenAI's efficiency while maintaining the rigorous verification standards required for production environments and participants will learn how to integrate these tools into their workflows to prevent security regressions and ensure reliable infrastructure management. This tutorial Scientists, Engineers, Security professionals and anyone interested in applying formal verification to their infrastructure.",,,,
TUE 2 DEC,noon,Expo Workshop,CausalFairness: An Open-Source Python Library for Causal Fairness Analysis,https://neurips.cc/virtual/2025/128677,,1:30 PM,"As machine learning (ML) systems are increasingly deployed in high-stakes domains, the need for robust methods to assess fairness has become more critical. While statistical fairness metrics are widely used due to their simplicity, they are limited in their ability to explain why disparities occur, as they rely on associative relationships in the data. In contrast, causal fairness metrics aim to uncover the underlying data-generating mechanisms that lead to observed disparities, enabling a deeper understanding of the influence of sensitive attributes and their proxies. Despite their promise, causal fairness metrics have seen limited adoption due to their technical and computational complexity. To address this gap, we present CausalFairness, the first open-source Python package designed to compute a diverse set of causal fairness metrics at both the group and individual levels. The metrics implemented are broadly applicable across classification and regression tasks (with easy extensions for intersectional analysis) and were selected for their significance in the fairness literature. We also demonstrate how standard statistical fairness metrics can be decomposed into their causal components, providing a complementary view of fairness grounded in causal reasoning. In this active learning talk participants will learn how to quantify bias using CausalFairness at the group (Counterfactual Equalized Odds , Counterfactual Effects) and individual (Counterfactual Fairness) levels by applying each method to three datasets - 1) the Adult Income dataset, 2) the COMPAS dataset, 3) Law School Admission Council (LSAC) Dataset. The session will elucidate on the intuition for computing and interpreting each metric, and conclude with a discussion of their limitations.",,,,
TUE 2 DEC,noon,Expo Demonstration,Learning to Steer LLMs with AI Steerability 360 and In-Context Explainability 360,https://neurips.cc/virtual/2025/128645,,3:00 PM,"Current algorithms for aligning LLM behavior are often implemented for narrow settings, making it difficult for researchers and developers to understand their effectiveness across model architectures, datasets, and tasks. To help provide a more informed and principled approach to steering model behavior, we present the AI Steerability 360 (AISteer360) and In-Context Explainability 360 (ICX360) toolkits. Participants will first be guided through a conceptual overview for how model behavior can be influenced across four model control surfaces: input (prompting), structural (weights/architecture), state (activations/attentions), and output (decoding). After the conceptual overview, we will guide attendees through how to apply some recently developed explainability tools (from ICX360) for understanding why models produce given, potentially undesirable, outputs and how this information is used to design targeted steering inventions (via AISteer360). Closing the loop, we will evaluate if the baseline behavior (of the original, unsteered model) was successfully mitigated by the selected steering inventions and investigate if steering introduced any unintended behavioral side-effects. All of the experiments throughout the demonstration will be facilitated solely by the tools in the two toolkits, illustrating their power to design end-to-end steering workflows. Attendees will come away with a practical understanding of how to apply these toolkits to their own alignment challenges.",,,,
TUE 2 DEC,noon,Expo Workshop,Introduction to Generative Computing,https://neurips.cc/virtual/2025/128678,,1:30 PM,"This hands-on workshop introduces a proposal that treats LLMs as computing elements governed by established software development principles—particularly task decomposition and modularization—at both the programming model (Mellea) and model level (LLM intrinsics).x000Dx000DLLM outputs are often unpredictable and incorrect. Agentic frameworks and prompt optimization libraries attempt to manage this by giving control to the LLM, but this leads to systems that are hard to debug, maintain, and scale. Mellea offers an alternative: a programming model that restores developer control through modular design, information hiding, and compositional contracts. This enables predictable fault models, better portability, and lower inference costs. Attendees will gain hands-on experience building applications using the Melleaic approach.x000Dx000DExtending these principles to the model level, the workshop introduces a modularization framework for LLMs using activated LoRAs. These produce components—LLM intrinsics—that match fine-tuned model accuracy for specific tasks but with significantly lower inference costs and latency, thanks to KV cache reuse. Participants will build applications using a pre-built library of RAG LLM intrinsics and learn how to train their own.x000Dx000DPresented by the creators of Mellea and the inventors of LLM intrinsics and aLoRA, this workshop equips attendees with foundational skills for scalable model/application co-design.",,计算; 温哥华云,计算: 该Session聚焦于通过模块化设计和任务分解提升大型语言模型(LLM)的可控性与效率，直接回应了计算团队面临的前沿Agentic及多模态模型负载快速演进带来的软硬件适配需求，有助提前优化计算体系结构。; 温哥华云: 该Session介绍了基于模块化设计和任务分解的生成式计算新范式，特别针对LLM的可靠性和推理成本问题，能有效支持温哥华云在提升视觉语言模型及大型语言模型强化微调性能的需求。,计算: 基于Mellea的模块化编程模型及其在LLM中的应用; LLM内在模块化框架及激活LoRA技术; 任务分解与模块化设计提升模型可预测性与可维护性; 低推理成本及延迟优化方法，如KV缓存复用; 多模态及Agentic框架在计算架构中的集成需求与挑战; 温哥华云: 任务分解与模块化编程模型Mellea; LLM内在模块化及激活LoRAs应用; 降低推理延迟与成本的KV缓存重用; 生成式模型可预测性与错误容忍机制; 联合模型-应用协同设计与调优
TUE 2 DEC,noon,Expo Workshop,Exploring Trust and Reliability in LLM Evaluation,https://neurips.cc/virtual/2025/128673,,1:30 PM,"The current paradigm of Large Language Model (LLM) evaluation faces a crisis of reliability. Traditional leaderboards—built on static benchmarks and surface-level metrics—have become increasingly distorted by benchmark contamination, prompt overfitting, and evaluation methodologies that fail to reflect model behavior in real-world use. As reasoning models emerge that generate detailed internal thought processes (e.g.,traces) before producing answers, existing evaluation practices—especially for multiple-choice and generation tasks—have become fundamentally inadequate.x000Dx000DThis lack of rigor not only undermines scientific progress and cross-model comparability, but also poses significant enterprise and societal risks, as evaluation results inform model selection, deployment safety, and governance in high-stakes environments.x000Dx000DThis workshop aims to reassert rigor in LLM evaluation by convening researchers and practitioners to address three intertwined challenges: (1) developing fair and consistent evaluation methods for reasoning and non-reasoning models, (2) confronting widespread contamination across public benchmarks and open-weight models, and (3) defining robust data curation and validation practices to prevent future contamination in both pretraining and post-training pipelines.x000Dx000DBy combining empirical findings, methodological advances, and practical case studies, this session—led by Capital One in collaboration with leading AI labs—seeks to chart a concrete path toward trustworthy, contamination-proof, and utility-aligned LLM evaluation frameworks.x000Dx000DThis 1.5-hour workshop will be structured around three highly focused, 25-minute talks, followed by a moderated discussion aimed at forging actionable paths forward for the community:x000Dx000DTalk 1: Robust Evaluation for Reasoning & Non-Reasoning Modelsx000Dx000DTalk 2: Benchmark Contamination — Detection, Measurement, & Findingsx000Dx000DTalk 3: Preventing Contamination — Building Clean & Reliable Data Pipelines",,,,
TUE 2 DEC,1:30 p.m.,Tutorial,Foundations of Imitation Learning: From Language Modeling to Continuous Control,https://neurips.cc/virtual/2025/109590,,4:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,Scale Test-Time Compute on Modern Hardware,https://neurips.cc/virtual/2025/109595,,3:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,Autoregressive Models Beyond Language,https://neurips.cc/virtual/2025/109587,,3:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,"Recent Developments in Geometric Machine Learning: Foundations, Models, and More",https://neurips.cc/virtual/2025/109600,,3:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,Theoretical Insights on Training Instability in Deep Learning,https://neurips.cc/virtual/2025/109597,,3:00 PM,,"Overview: The NeurIPS 2025 tutorial titled 'Theoretical Insights on Training Instability in Deep Learning' explores the oscillatory, spiky, and unstable nature of the optimization process in deep learning. This tutorial aims to provide theoretical insights into the benign nature of these training instabilities, offering perspectives from both optimization and statistical learning. The work challenges classical optimization theory by demonstrating that the best training configurations often operate in unstable regimes. | Research Interests: Gradient-based optimization, Training instability in deep learning, Large stepsizes in optimization, Statistical learning perspectives, Benign nature of instabilities, Optimization efficiency, Overfitting prevention, Implicit bias in optimization, Edge of stability in gradient descent | Key Findings: The tutorial highlights that large stepsizes can accelerate optimization and prevent overfitting, providing a new understanding of the implicit bias and stability in deep learning models. It also discusses the role of training at the edge of stability and how it can lead to efficient optimization and generalization.",,,
TUE 2 DEC,1:30 p.m.,Tutorial,"The Science of Benchmarking: What’s Measured, What’s Missed, and What’s Next",https://neurips.cc/virtual/2025/109598,,3:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,"Data Privacy, Memorization, & Legal Implications in  Generative AI: A Practical Guide",https://neurips.cc/virtual/2025/109588,,3:00 PM,,,,,
TUE 2 DEC,4 p.m.,Expo Talk Panel,Recent developments in embodied AI,https://neurips.cc/virtual/2025/128653,,5:00 PM,"Embodied AI is the study of systems that can perceive and interact with the physical world in real time. Real-world interactions pose unique challenges for AI systems since they naturally require a deep understanding of the physical world and/or its inhabitants. This understanding is often taken for granted in humans, where it is typically labelled as “intuitive physics” or “common sense”.x000Dx000DIt is widely agreed that solving this challenge would be as rewarding as it is hard, since it would be equivalent to creating truly capable “world models”, with countless applications in robotics, human-computer interaction, and even in advancing language modeling through concept grounding. Like other areas in AI, embodied AI has seen dramatic advances in recent years, fueled by the success of using pre-trained large language models as a central ingredient to allow for end-to-end training. While this development stands as one of many examples of the power of pre-trained language models, recently the converse has come true as well: embodied AI is increasingly being drawn on to understand real-world common sense and concept grounding in language models themselves, bringing back its early vision as a way to understand human-like cognition and world models.x000Dx000DThis talk will provide an in-depth discussion of embodied AI, with a focus on recent advances based on multi-modal large language models. It will discuss how end-to-end training has made it possible to instill key aspects of real-world common sense in a model and how this had enabled highly ambitious use-cases, such as generalist (“common sense”) robot control and real-world visual interaction (“chatbots that can see and hear you”). The talk will also discuss practical considerations, such as streaming inference at the edge, end-to-end training data generation and the role of reinforcement learning, as well as open challenges in state tracking and long-term memory.",,温哥华云; 诺亚,温哥华云: 该Session深入探讨了基于多模态大语言模型的Embodied AI前沿进展，契合温哥华云团队在2026年重点物理或具身AI研究领域的战略布局需求，有助于捕捉行业热点，指导关键技术投入布局。; 诺亚: 本Session深入探讨基于多模态大语言模型的内嵌AI前沿技术，直接契合诺亚团队在长序列图文多模态模型推理计算瓶颈突破的挑战点，可助力优化多模态长文本推理能力。,温哥华云: 基于多模态大语言模型的端到端训练方法; 物理世界常识和直觉物理建模; 通用智能机器人控制及实际应用; 边缘设备上的流式推理技术; 强化学习在具身AI中的应用及挑战; 诺亚: 多模态大语言模型的端到端训练方法; 长序列多模态输入范式创新; 实时边缘设备推理技术; 强化学习在多模态模型训练中的应用; 状态追踪与长期记忆机制
TUE 2 DEC,4 p.m.,Expo Talk Panel,Distributed Orthonormal Updates for Large-Scale Training,https://neurips.cc/virtual/2025/128655,,5:00 PM,"We propose a 50-minute technical talk on recent advances in orthonormal update methods for large-scale AI model training. This topic is rapidly gaining attention in the community, emerging as a strong successor to AdamW following the success of orthonormal optimizers in training production-scale models such as Kimi-K2 and GLM-4.5.x000DThe talk will center on the design and practice of orthonormal updates, focusing on optimizers such as Muon and Dion. While we will briefly discuss their theoretical foundations, the emphasis will be on practical usage: how to integrate these optimizers into modern training pipelines, interpret their algorithmic components, and leverage the implementation guidelines provided in our open-source codebase at github.com/microsoft/dion.x000DThe talk is designed to engage both researchers and practitioners in the NeurIPS community:x000DAcademic perspective: presents a new class of optimizers grounded in theory along with how they interact with distributed training.x000DIndustrial perspective: highlights how orthonormal updates are implemented in practice and what best practices are.x000DThis topic lies   at the intersection of optimization theory, scalable systems, and large-model training—an area of growing importance for both the research and applied machine learning communities.",,计算,计算: 本Session聚焦正交更新及其在分布式大规模训练中的应用，紧密对应计算团队在低精度计算架构及训练推理新范式演进方面的挑战。通过深入探讨MuOn和Dion优化器的实用集成，助力解决低精度算力需求及未来负载定义难题。,计算: 正交优化器MuOn和Dion的算法设计与实现; 分布式训练中正交更新的集成实践; 低精度训练对计算架构的影响分析; 训练推理新范式下负载特征的理解与预测; 开源代码库（github.com/microsoft/dion）使用与应用指南
TUE 2 DEC,4 p.m.,Expo Talk Panel,Ling 2.0 and Ling-1T: Scaling Knowledge-Enhanced Large Language Models for Reasoning and Efficiency,https://neurips.cc/virtual/2025/128657,,5:00 PM,"The Ling 2.0 series represents a new generation of large language models designed around knowledge enhancement, reasoning efficiency, and scalable architecture innovation. Built upon trillion-scale sparse MoE foundations, Ling-1T achieves ~50B active parameters per token with FP8 mixed-precision pipelines and 1F1B interleaved scheduling, realizing over 40% training-throughput gains with negligible accuracy loss (<0.1%).x000DThis talk presents the technical journey behind Ling-mini, Ling-flash, and Ling-1T, focusing on (1) efficient large-scale training systems for trillion-parameter models; (2) the Ling Scaling Law and its implications for cross-domain reasoning; (3) hybrid attention and RL-based alignment strategies that enable both concise reasoning and long-context understanding; and (4) how these architectural and algorithmic advances empower industrial applications such as financial risk modeling and knowledge-grounded agents.x000DWe will conclude with open-sourced implementations (inclusionAI on Hugging Face and ModelScope) and future research directions toward trustworthy, efficient, and domain-enhanced LLMs.",,海思; 计算; 诺亚,海思: 该Session深入探讨了基于稀疏MoE架构和混合精度技术的高效大型语言模型训练，尤其关注长上下文推理中注意力复杂度的优化，正好对应海思团队关于长上下文推理注意力复杂度过高的挑战点。参与此会有助于探索线性或次线性复杂度的注意力机制实现方案。; 计算: 该Session深入探讨了基于低精度混合精度FP8训练架构的超大规模模型Ling-1T，针对高效大规模训推系统与低精度计算的应用挑战，直接对标计算团队对低精度训推算力架构和产品化的需求。; 诺亚: 该Session聚焦于高效大规模训练和混合注意力机制，直接对应诺亚团队在多模态长文本推理计算瓶颈的挑战点，有助突破输入范式和推理效率限制，实现跨模态长序列处理能力。,海思: 稀疏MoE架构与超大规模模型训练系统; 基于FP8混合精度和交错调度的训练效率提升; 长上下文下的混合注意力机制和分块缓存技术; 基于强化学习的模型对齐与精简推理策略; 跨域推理的Ling Scaling Law及其应用; 计算: FP8混合精度训练流水线设计及优化; 1F1B交织调度机制提升吞吐量; 大规模稀疏MoE模型的扩展性与效率; 混合注意力机制与增强推理能力; 低精度算力定义与未来芯片架构需求; 诺亚: 高效的大规模训练系统设计与实现; 混合注意力机制及其在长上下文推理中的应用; 基于RL的模型对齐策略提升推理准确性与简洁性; 跨域推理和知识增强技术的扩展可能性; 工业级应用，如金融风险建模中的模型部署与优化
TUE 2 DEC,4 p.m.,Expo Talk Panel,Agentic AI/RL,https://neurips.cc/virtual/2025/128662,,5:00 PM,"The transition from static language models to agentic AI systems driven by reinforcement learning (RL) places environments at the center of research and deployment. Environments provide the substrate where agents act, learn, and are evaluated—ranging from lightweight simulators and synthetic tasks to rich multi-agent ecosystems and real-world interfaces. Building and scaling these environments requires specialized tools and systems: standardized hubs for discovery and sharing, interfaces for reproducibility, and infrastructure that connects environments seamlessly to trainers, inference engines, and evaluation pipelines.x000Dx000DThis workshop will highlight the tools, environments, and system innovations enabling the next generation of agentic AI. Topics will include scalable RL environment frameworks, benchmarks for safety and robustness, high-performance simulators optimized for heterogeneous hardware, and environment–trainer integration at scale. We will also explore how environments interface with large-model post-training workflows, providing the data and feedback loops necessary for reward shaping, alignment, and deployment in production systems.x000Dx000DBy convening researchers, environment developers, and systems engineers, the workshop will create a venue to examine how environments, tools, and infrastructure together shape the future of agentic AI.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DPyTorch native RL and agentic development at scalex000DEnvironments for everyone - how open environments can democratize RL post training at scalex000DSafety in the new era of Agents",,计算; 多伦多云,计算: 本Session聚焦于Agentic AI及强化学习环境的系统搭建与优化，正对应挑战点中前沿负载对计算架构的新诉求。通过参加，团队能深入了解环境与软硬件系统的综合集成，提升多模态模型部署效率。; 多伦多云: 该Session聚焦构建和优化agentic AI系统及其环境，契合多伦多云团队关于Agent上线后自主学习与持续优化机制的挑战，特别是Prompt与模型优化飞轮结合及多步执行能力的持续提升。通过参与，可获取前沿工具和系统创新，助力实现L3+ agent持续优化。,计算: 可扩展的强化学习环境框架设计; 环境与训练器的高效集成技术; 针对异构硬件优化的高性能模拟器; 强化学习环境中的安全性与鲁棒性基准; 多模态代理模型的负载管理与计算资源调度; 多伦多云: 可扩展的强化学习环境框架设计; agent与环境的高效接口集成; 自主学习与模型、Prompt优化飞轮结合机制; L3+ agent的planning与多步执行优化; 安全性与鲁棒性基准测试方法
TUE 2 DEC,4 p.m.,Expo Talk Panel,"Neural Arms Race: Authenticity, Infringement Analysis, and Attribution in the Age of AI Music",https://neurips.cc/virtual/2025/128669,,5:00 PM,"The same neural architectures powering music generation have become critical infrastructure for content moderation—creating a technological arms race where AI both threatens and protects creative rights. This talk presents Sound Patrol's production-scale response across three dimensions: (1) Authenticity Detection: Analyzing AI content in the wild begins with binary classification—was a given song created by AI or humans? Using MuQ and ResNet backbones with auxiliary task heads, we show how careful dataset construction and model ensembling enables attribution of when AI was used, where in a track (vocal vs instrumental), and which genAI platform generated it. (2) Infringement Analysis: Once identified as AI, content requires infringement screening. We combine singer deepfake detection via RawNet3, Burrows-Wheeler alignment-derived comparisons of MIDI transcripts, lyrics analysis via a combination of neural embeddings and LLMs, and neural fingerprinting achieving 88%+ accuracy under adversarial transforms. These analyses are orchestrated through dynamic expert routing, enabling sophisticated tagging and automated musicology reports. (3) Attribution Framework: We end with a pragmatic discussion of what it means for a piece of training data to influence a model output. We propose a set of principles guiding how fractional royalty models could be derived by examining prompts, training sets, and model outputs. Drawing from production deployments and industry evaluations, we offer the NeurIPS community technical blueprints for turning this arms race into equitable innovation—exploring how the same AI enabling infringement might ensure fair compensation to the artists whose work powers it all.",,,,
TUE 2 DEC,4 p.m.,Expo Talk Panel,Building an AI Ecosystem for Multiscale Biological Discovery,https://neurips.cc/virtual/2025/128658,,5:00 PM,"Understanding biological systems requires resolving their structure and organization across scales, from tissues to individual molecules. Advances in imaging and molecular profiling now generate vast multimodal datasets that capture biological architecture and dynamics with unprecedented fidelity. Unlocking insights from this data demands computational approaches capable of linking observations across spatial, temporal, and molecular dimensions.At the Chan Zuckerberg Imaging Institute (CZII), we are building the infrastructure, datasets, and community connections to enable this transformation. Our cryo-electron tomography (cryoET) processing pipeline supports high-throughput reconstruction and standardized metadata integration, forming the foundation for reproducible, machine-learning–ready datasets. The CryoET Data Portal (cryoetdataportal.czscience.com) provides open access to raw data, reconstructions, and curated annotations contributed by leading structural biology labs worldwide. Its programmatic API tools support segmentation, particle picking, and model benchmarking, creating a foundation for AI-driven structural discovery.To catalyze progress in automated molecular identification, the CZ Imaging Institute recently organized a Kaggle challenge inviting participants to develop models for detecting and labeling macromolecular complexes in real-world cryoET data. Building on this success, upcoming challenges organized by the CZI & CZ Biohub Network will extend this approach to datasets spanning different biological scales, from tissue architecture and cellular organization to subcellular and molecular structure.Together, these efforts form an open, interoperable ecosystem for machine learning in biological imaging. By combining standardized data infrastructure, scalable computation, and community-driven innovation, we aim to bridge the worlds of imaging and AI and accelerate the discovery of life’s organization across all scales.",,,,
TUE 2 DEC,4 p.m.,Expo Talk Panel,Building Foundational Models for Robotics at Tesla,https://neurips.cc/virtual/2025/128654,,5:00 PM,"Tesla's robots, both wheeled and legged, are developed with the goal of achieving general-purpose capability, analogous to the versatility observed in humans and animals. These systems rely primarily on scalable sensing modalities such as vision, audio etc, enabling robust performance within stringent power and cost constraints.x000Dx000DThis talk will describe the principles and methodology behind constructing foundation models for robotics at Tesla. We will discuss the architecture, data and training of large-scale multimodal models that control these robots in an end-to-end pixels-to-actuation fashion. We will also examine evaluation protocols, safety considerations, and strategies for reliable real-world deployment. Finally, we project the transformational benefits to society that widespread deployment of such advanced robotic systems can deliver.",,,,
WED 3 DEC,8:30 a.m.,Invited Talk,Rich Sutton_The Oak Architecture: A Vision of SuperIntelligence from Experience,https://neurips.cc/virtual/2025/invited-talk/109601,Rich Sutton,9:30 AM,"As AI has become a huge industry, to an extent it has lost its way. What is needed to get us back on track to true intelligence? We need agents that learn continually. We need world models and planning. We need knowledge that is high-level and learnable. We need to meta-learn how to generalize. The Oak architecture is one answer to all these needs. It is a model-based RL architecture with three special features: 1) all of its components learn continually, 2) each learned weight has a dedicated step-size parameter that is meta-learned using online cross-validation, and 3) abstractions in state and time are continually created in a five-step progression: Feature Construction, posing a SubTask based on the feature, learning an Option to solve the subtask, learning a Model of the option, and Planning using the option’s model (the FC-STOMP progression). The Oak architecture is rather meaty; in this talk we give an outline and point to the many works, prior and contemporaneous, that are contributing to its overall vision of how superintelligence can arise from an agent’s experience.",,计算; 多伦多云,计算: Session深入探讨Oak架构中持续学习与模型规划机制，契合团队对AI计算架构变革及训练推理新范式演进的关键挑战，有助于理解前沿模型结构对计算系统需求的影响，推动智能模型负载特征的精准预测。; 多伦多云: 该Session深入介绍了Oak架构中的持续学习和规划能力，契合多伦多云团队关于Agent上线后自主学习及持续优化机制的挑战点，尤其是具备planning与多步执行能力的L3+ agent优化需求。,计算: 持续学习机制及其对计算资源的影响; 基于模型的强化学习结构设计; Meta-学习与在线交叉验证优化步长; 多层次抽象的特征构建及任务分解; 利用选择性模型进行规划的FC-STOMP方法; 多伦多云: 持续学习机制实现; 专用步长参数的元学习方法; 状态与时间的抽象构建（FC-STOMP流程）; 基于模型的强化学习架构设计; Agent多步规划与策略执行
WED 3 DEC,noon,Expo Workshop,"AI Assistants in the Wild: Agents, Adaptation, and Memory-Augmented Deployment",https://neurips.cc/virtual/2025/128671,,1:30 PM,"Motivation and Scopex000Dx000DGenerative AI is evolving from offline, single modality models into interactive agentic systems that perceive, decide, and act in the real world. This shift marks a transition from static generation to dynamic, context-aware interaction. As these systems move toward deployment on edge devices such as mobile phones, augmented reality glasses, and robots, they face constraints in compute, memory, and latency. Beyond efficiency and responsiveness, a new frontier is emerging: agents equipped with persistent memory that enables long-term adaptation and personalization.x000Dx000DThis workshop explores a timely and focused question. How do we build generative agents that are not only efficient and responsive but also able to accumulate, recall, and adapt based on personal memory over time? We aim to bring together perspectives from generative modeling, agentic learning, efficient model design, and memory systems to close the gap between lab scale prototypes and real-world deployment.x000Dx000DKey Themesx000DPersonal Memory Systems for AI Assistants: Architectures for persistent memory, retrieval-augmented generation, and long-term personalization.x000DReal-World Adaptation Few-shot generalization, continual learning, and task inference for evolving agent behavior.x000DGrounded and Trustworthy Generation: Techniques for hallucination mitigation, constraint-aware generation, and safety under uncertainty.x000DDeployment on Edge Platforms: Challenges and solutions for deploying generative agents on mobile, AR, and robotics platforms.x000Dx000DThis focused workshop aligns with emerging themes at NeurIPS including agentic learning, trustworthy AI, efficient multimodal generation, and embodied intelligence. It will spotlight the systems, algorithms, and design decisions needed to make generative AI truly adaptive and persistent, outside the data center and into the wild.",,,,
WED 3 DEC,noon,Expo Workshop,On Device/Edge AI,https://neurips.cc/virtual/2025/128674,,1:30 PM,"From smartphones and wearables to autonomous vehicles, robots, and AR/VR systems, the demand for models that are efficient, private, and adaptive in real-time has never been higher. Yet deploying state-of-the-art AI at the edge remains challenging: researchers and practitioners must navigate heterogeneous hardware, memory and power constraints, compression and distillation trade-offs, as well as privacy, safety, and reliability requirements.x000Dx000DThis workshop will bring together researchers, practitioners, and industry leaders to explore the frontiers of Edge AI. Topics will include lightweight model architectures, compiler/toolchain optimizations (e.g., quantization, pruning, sparsity), advances in frameworks such as ExecuTorch and TensorRT, distributed learning across devices, privacy-preserving training, and emerging applications where latency and trust are critical. Beyond technical advances, we will examine the broader implications for democratizing AI—enabling billions of devices to act as intelligent, personalized agents while reducing dependence on the cloud.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DOptimized AI on iOSx000DLeveraging ExecuTorch as a platform for mixed reality at scalex000DReal-time reasoning at the edgex000DMamba and SSM running at the edge",,计算,计算: 该团队关注低精度训练推理对计算架构的影响，而本Session深入探讨轻量模型及低精度技术优化，契合其对下一代芯片算力和精度需求的研究，有助于推动具身、多模态及强化学习应用的进步。,计算: 轻量级模型架构设计与优化; 低精度量化技术及其在推理中的应用; 模型剪枝与稀疏性优化; 边缘设备上的实时推理与推断加速; 隐私保护及安全的分布式边缘学习
WED 3 DEC,noon,Expo Workshop,Multi-Agent Systems in Industry: From Research to Real-World Impact,https://neurips.cc/virtual/2025/128675,,1:30 PM,"This workshop will bridge the gap between the theoretical advancements in multi-agent systems and their practical applications in industry. The session will feature a series of poster presentations showcasing state-of-the-art, real-world multi-agent systems that are driving innovation across various sectors. We will delve into the challenges and opportunities of deploying these systems at scale, covering topics such as:x000DHuman-in-the-loop collaboration: Designing systems where AI agents and human experts work in synergy.x000DScalability and efficiency: Architecting multi-agent systems for large-scale industrial applications.x000DSafety and reliability: Ensuring the robustness and predictability of autonomous agents in critical systems.x000DDomain-specific applications: Highlighting successful implementations in areas such as software engineering, scientific research, and creative content generation.x000DThe goal of this workshop is to foster a discussion on the practical challenges and future directions of multi-agent systems, providing attendees with actionable insights and a deeper understanding of how these technologies are shaping the future of industry.",,计算; 多伦多云,计算: 该Session聚焦于多智能体系统在工业中的实际应用，与挑战点中对Agentic和多模态模型的快速演进对计算架构的新诉求高度契合。团队可借此洞察软硬件系统如何适应前沿计算需求，实现技术创新转化。; 多伦多云: 该Session深入探讨多Agent系统在工业中的可靠性和优化，正契合多伦多云团队关于Agent行为可靠性及自主学习与持续优化的挑战点。参与会议可助力解决写操作安全与持续演进方案。,计算: 人机协作设计，推动人与AI智能体协同工作; 多智能体系统的可扩展架构设计，提升工业应用效率; 安全性与可靠性保障，确保关键系统运行稳健; 面向特定领域（软件工程、科研、创意内容）的多智能体应用; 软硬件计算架构适应Agentic和多模态模型的前沿需求; 多伦多云: Agent行为的可靠性设计与校验机制; 自主学习与持续优化的算法架构; 结合Prompt优化与模型优化的飞轮机制; 多步规划与执行能力的提升; 实际工业应用中的多Agent系统部署与安全保障
WED 3 DEC,noon,Expo Workshop,Using the Virtual Cell Platform to Accelerate Machine Learning in Biology,https://neurips.cc/virtual/2025/128676,,1:30 PM,"Biology presents some of the most complex and high-impact challenges for machine learning, and single-cell transcriptomics is at the frontier of this work. In this workshop, we introduce the Virtual Cell Platform (VCP), a unified environment designed to accelerate model development and evaluation in biology. Using single-cell transcriptomics as a case study, we will demonstrate how the VCP enables researchers to train, benchmark, and interpret models in a reproducible and biologically meaningful way.    Participants will gain a primer on single-cell transcriptomics and learn how to evaluate models with cz-benchmarks, an open-source Python package providing standardized, community-driven tasks and metrics. Through the VCP CLI, attendees will pull datasets, run packaged models, and compare results programmatically. Hands-on exercises will guide participants through interactive visualizations, side-by-side model comparisons, and deep dives into model behavior using VCP’s no-code interface and BYOD (Bring Your Own Data) module.    By the end of the session, attendees will understand how to use the VCP to actively test and refine models during development, ensure biological relevance, and contribute models and benchmarks back to the community. This workshop highlights how the Virtual Cell Platform transforms ML infrastructure into a one-stop, researcher-friendly ecosystem, empowering the NeurIPS community to push the boundaries of AI in biology.",,,,
WED 3 DEC,2:30 p.m.,Invited Talk,Are We Having the Wrong Nightmares About AI?,https://neurips.cc/virtual/2025/invited-talk/109606,Zeynep Tufekci,3:30 PM,"Though seemingly opposite, doom and optimism regarding generative AI's spectacular rise both center on AGI or even superintelligence as a pivotal moment. But generative AI operates in a distinct manner from human intelligence, and it’s not a less intelligent human on a chip slowly getting smarter anymore than cars were mere horseless carriages. It must be understood on its own terms. And even if Terminator isn’t coming to kill us or superintelligence isn’t racing to save us, generative AI does bring profound challenges, well-beyond usual worries such as employment effects.  Technology facilitates progress by transforming the difficult into easy, the rare into ubiquitous, the scarce into abundant, the manual into automated, and the artisan into mass-produced. While potentially positive long-term, these inversions are extremely destabilizing during the transition, shattering the correlations and assumptions of our social order that relied on superseded difficulties as mechanisms of proof, filtering, sorting and signaling. For example, while few would dispute the value of the printing press or books, their introduction led to such destructive upheaval that the resulting religious wars caused proportionally more deaths than all other major wars and pandemics since combined. Historically, a new technology's revolutionary impact comes from making what's already possible and desired cheap, easy, fast, and large-scale, not from outdated or ill-fitting benchmarks that technologists tend to focus on. As such, Artificial Good-Enough Intelligence can unleash chaos and destruction long before, or if ever, AGI is reached. Existing AI is good enough to blur or pulverize our existing mechanisms of proof of accuracy, effort, veracity, authenticity, sincerity, and even humanity. The tumult from such a transition will require extensive technological, regulatory, and societal effort to counter. But the first step to getting started is having the right nightmares.",,,,
WED 3 DEC,4:30 p.m.,Expo Talk Panel,"Juries, Not Judges! Industry-Scale Evaluation of Trustworthy AI via Dynamic LLM Panels",https://neurips.cc/virtual/2025/128660,,5:30 PM,"As Large Language Models (LLMs) become central to high-stakes applications, the reliability of their evaluation systems is under intense scrutiny, especially in the financial industry. Traditional approaches - human annotation, single LLM judges, and static model juries - struggle to balance scalability, cost, and trustworthiness. We will discuss a promising framework: LLM Jury-on-Demand, a dynamic, learning-based framework that assembles an optimal panel of LLM evaluators for each task instance, leveraging predictive modeling to select and weight judges based on context-specific reliability. Our system adapts in real time, outperforming static ensembles and single judges in alignment with human expert judgment across summarization and retrieval-augmented generation benchmarks. This talk will showcase how adaptive LLM juries can transform evaluation of AI systems, offering robust, scalable, and context-aware solutions for industry and research. Attendees will gain practical insights into building trustworthy LLM evaluation pipelines, see live demos, and discuss future directions for reliable AI assessment in critical domains.",,,,
WED 3 DEC,4:30 p.m.,Expo Talk Panel,"Frontier Open-Weight Models: Building Transparent, Secure, and Sovereign AI",https://neurips.cc/virtual/2025/128664,,5:30 PM,"The next generation of AI will be defined not just by scale, but by openness. As the frontier in model capabilities accelerates, researchers and enterprises alike face a critical question: how do we advance state-of-the-art intelligence while preserving transparency, control, and security?x000Dx000DThis panel brings together leaders from open research, industry, and infrastructure to explore the emerging ecosystem of open-weight frontier models—systems that can be fully run, audited, and customized within private or sovereign environments. Discussion topics will include the research challenges behind training and aligning open models at scale, implications for reproducibility and safety, and how open access can enable new forms of collaboration between academia, government, and enterprise.x000Dx000DAttendees will gain insight into how the open frontier movement is reshaping AI research culture, infrastructure design, and deployment strategy worldwide.",,计算; 温哥华云,计算: 该团队关注模型架构对计算系统的影响，本Session聚焦开放权重模型在透明度与安全上的挑战，提供前沿大模型架构演进趋势及其对计算需求的深入讨论，契合团队识别计算系统需求、降低模型结构冲击的核心挑战。; 温哥华云: 本Session深入探讨开放权重模型的透明性、安全性和主权控制，契合温哥华云对关键物理或具身AI研究领域的战略投资需求，有助于推动前沿AI模型相关技术的理解与落地。,计算: 开放权重模型的架构设计与演进趋势; 大规模模型训练中的计算资源优化; 模型安全性与透明度保障机制; 开放模型在私有与主权环境中的部署策略; 开放模型对计算系统需求的影响与适配; 温哥华云: 开放权重模型的训练与对齐技术; 模型透明性与可审计机制; 主权环境下的模型部署与安全策略; 开放访问促进的跨领域协作模式; 提升AI研究的可复现性与安全性
WED 3 DEC,4:30 p.m.,Expo Talk Panel,The Co-X Framework: Versatile AI Agents for Automating and Augmenting Professional Workflows,https://neurips.cc/virtual/2025/128666,,5:30 PM,"Beyond monolithic models, the future of AI in industry lies in specialized agents that collaborate with human experts. This talk introduces the ""Co-X"" framework, a novel approach for creating a diverse ecosystem of collaborative agents tailored to specific professional domains. We will present four key agents built on this framework: the Co-AI Researcher, the Co-ML Engineer for automating software development cycles, the Co-Data Scientist for automating data analysis and insight generation, and the Co-Director for augmenting creative content generation. We will discuss the foundational technologies that enable this versatility—including long-term memory, tool use, and human-in-the-loop feedback—and demonstrate how the Co-X framework is poised to redefine productivity and innovation across industries.",,,,
WED 3 DEC,4:30 p.m.,Expo Talk Panel,Cosmos World Foundation Model Platform for Physical AI,https://neurips.cc/virtual/2025/128663,,5:30 PM,"Abstract: In this talk, I will introduce NVIDIA Cosmos, our World Foundation Model platform designed to advance Physical AI. Cosmos is built around three core pillars: Predict, Transfer, and Reason. I will provide updates on the latest releases—Predict 2.5 and Transfer 2.5—highlighting key improvements in generalization, efficiency, and scalability. In addition, I will share a preview of ongoing research directions that extend Cosmos toward richer world modeling and reasoning capabilities. Together, these developments aim to push the boundaries of how AI perceives, simulates, and interacts with complex real-world environments.",,温哥华云,温哥华云: 该Session详细介绍了NVIDIA Cosmos平台在Physical AI中的核心技术，包括预测、迁移和推理的最新升级，紧密契合了团队在物理及具身AI领域的战略成长挑战点。通过参与，团队可获取前沿技术洞见，助力战略规划。,温哥华云: Physical AI的核心技术架构与发展趋势; Predict 2.5和Transfer 2.5的技术改进和应用; 多任务泛化与模型效率提升方法; 复杂环境中的世界建模与推理技术; 基于物理交互的AI模拟与仿真
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1A,https://neurips.cc/virtual/2025/session/122546,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference,https://neurips.cc/virtual/2025/oral/118170,,11:00 AM,"Large Language Models (LLMs) are now integral across various domains and have demonstrated impressive performance. Progress, however, rests on the premise that benchmark scores are both accurate and reproducible. We demonstrate that the reproducibility of LLM performance is fragile: changing system configuration, such as evaluation batch size, GPU count, and GPU version, can introduce significant differences in the generated responses. This issue is especially pronounced in reasoning models, where minor rounding differences in early tokens can cascade into divergent chains of thought, ultimately affecting accuracy. For instance, under bfloat16 precision with greedy decoding, a reasoning model like DeepSeek-R1-Distill-Qwen-7B can exhibit up to 9\% variation in accuracy and 9,000 tokens difference in response length due to differences in GPU count, type, and evaluation batch size.We trace the root cause of this variability to the non-associative nature of floating-point arithmetic under limited numerical precision. This work presents the first systematic investigation into how numerical precision affects reproducibility in LLM inference. Through carefully controlled experiments across various hardware, software, and precision settings, we quantify when and how model outputs diverge.Our analysis reveals that floating-point precision—while critical for reproducibility—is often neglected in evaluation practices.Inspired by this, we develop a lightweight inference pipeline, dubbed LayerCast, that stores weights in 16-bit precision but performs all computations in FP32, balancing memory efficiency with numerical stability. Code is available at https://github.com/nanomaoli/llm_reproducibility.",,计算; 诺亚,"计算: 该Session针对低精度计算导致的数值不确定性问题进行深入分析，贴合团队在低精度训推对计算架构影响的挑战点，助力理解低精度模型训推的精度稳定性与硬件需求，推动下一代芯片算力精度优化。; 诺亚: 该Session深入探讨了数值精度对LLM推理结果的不确定性影响，直接关联到团队在""测试时推理策略及模型内置记忆更新机制改进""的挑战。参与该会议将助力团队优化推理策略，提升模型推理的稳定性和准确性。",计算: 低精度浮点运算对LLM推理结果的影响; 数值精度对模型推理可复现性的作用机制; 浮点非结合性导致的结果差异分析; 结合FP16权重和FP32计算的推理架构设计; 针对多硬件环境的推理稳定性测试方案; 诺亚: 浮点数数值精度及其对推理稳定性的影响; 推理过程中不同系统配置（GPU数量、批量大小）对结果波动的分析; 推理策略中数值舍入误差的传播机制; LayerCast轻量级推理管线及其内存与精度权衡; 提升模型推理结果可复现性的方法与实践
WED 3 DEC,10:00-11:00,Oral Paper,→ Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond),https://neurips.cc/virtual/2025/oral/121422,,11:00 AM,"Large language models (LMs) often struggle to generate diverse, human-like creative content, raising concerns about the long-term homogenization of human thought through repeated exposure to similar outputs. Yet scalable methods for evaluating LM output diversity remain limited, especially beyond narrow tasks such as random number or name generation, or beyond repeated sampling from a single model. To address this gap, we introduce Infinity-Chat, a large-scale dataset of 26K diverse, real-world, open-ended user queries that admit a wide range of plausible answers with no single ground truth. We introduce the first comprehensive taxonomy for characterizing the full spectrum of open-ended prompts posed to LMs, comprising 6 top-level categories (e.g., creative content generation, brainstorm & ideation) that further breaks down to 17 subcategories. Using Infinity-Chat, we present a large-scale study of mode collapse in LMs, revealing a pronounced Artificial Hivemind effect in open-ended generation of LMs, characterized by (1) intra-model repetition, where a single model consistently generates similar responses, and more so (2) inter-model homogeneity, where different models produce strikingly similar outputs. Infinity-Chat also includes 31,250 human annotations, across absolute ratings and pairwise preferences, with 25 independent human annotations per example. This enables studying collective and individual-specific human preferences in response to open-ended queries. Our findings show that state-of-the-art LMs, reward models, and LM judges are less well calibrated to human ratings on model generations that elicit differing idiosyncratic annotator preferences, despite maintaining comparable overall quality. Overall, INFINITY-CHAT presents the first large-scale resource for systematically studying real-world open-ended queries to LMs, revealing critical insights to guide future research for mitigating long-term AI safety risks posed by the Artificial Hivemind.",,诺亚,诺亚: 本Session聚焦大型语言模型生成多样性与长文本推理的挑战，契合团队在“长序列图文多模态模型演进及输入范式优化”上的研究需求，有助突破多模态长文本推理的计算瓶颈。,诺亚: 大型语言模型的开放式多样性生成及模式崩溃现象分析; 多模态长序列输入的范式设计与优化方法; 基于大规模真实开放式查询的数据集构建方法; 结合人类偏好标注优化模型生成输出的技术; 评估和缓解语言模型间同质化的机制与策略
WED 3 DEC,10:00-11:00,Oral Paper,→ SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing,https://neurips.cc/virtual/2025/oral/115002,,11:00 AM,"3D spatial reasoning in dynamic, audio-visual environments is a cornerstone of human cognition yet remains largely unexplored by existing Audio-Visual Large Language Models (AV-LLMs) and benchmarks, which predominantly focus on static or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D spatial reasoning in dynamic scenes with synchronized spatial audio. SAVVY-Bench is comprised of thousands of carefully curated question–answer pairs probing both directional and distance relationships involving static and moving objects, and requires fine-grained temporal grounding, consistent 3D localization, and multi-modal annotation. To tackle this challenge, we propose SAVVY, a novel training-free reasoning pipeline that consists of two stages: (i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as other audio-visual methods to track the trajectories of key objects related to the query using both visual and spatial audio cues, and (ii) Dynamic Global Map Construction, which aggregates multi-modal queried object trajectories and converts them into a unified global dynamic map. Using the constructed map, a final QA answer is obtained through a coordinate transformation that aligns the global map with the queried viewpoint. Empirical evaluation demonstrates that SAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a new standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.",,诺亚,诺亚: SAVVY通过融合视觉和空间音频线索，实现动态3D空间推理，有效突破多模态模型在长序列推理中的计算瓶颈，契合诺亚团队在长序列图文多模态模型演进方向的挑战点。,诺亚: 融合多模态音视频信息的长序列空间轨迹估计方法; 动态三维全局地图构建及其与局部视角的坐标变换; 结合空间音频实现动态环境中对象定位与跟踪; 无训练推理管线设计与应用潜力评估; 提升多模态长文本推理效率的输入范式创新
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1B,https://neurips.cc/virtual/2025/session/122547,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Optimal Mistake Bounds for Transductive Online Learning,https://neurips.cc/virtual/2025/oral/119099,,11:00 AM,"We resolve a 30-year-old open problem concerning the power of unlabeled data in online learning by tightly quantifying the gap between transductive and standard online learning. We prove that for every concept class $\mathcal{H}$ with Littlestone dimension $d$, the transductive mistake bound is at least $\Omega(\sqrt{d})$. This establishes an exponential improvement over previous lower bounds of $\Omega(\log \log d)$, $\Omega(\sqrt{\log d})$, and $\Omega(\log d)$, respectively due to Ben-David, Kushilevitz, and Mansour (1995, 1997) and Hanneke, Moran, and Shafer (2023). We also show that our bound is tight: for every $d$, there exists a class of Littlestone dimension $d$ with transductive mistake bound $O(\sqrt{d})$. Our upper bound also improves the previous best known upper bound of $(2/3) \cdot d$ from Ben-David et al. (1997). These results demonstrate a quadratic gap between transductive and standard online learning, thereby highlighting the benefit of advanced access to the unlabeled instance sequence. This stands in stark contrast to the PAC setting, where transductive and standard learning exhibit similar sample complexities.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ High-Dimensional Calibration from Swap Regret,https://neurips.cc/virtual/2025/oral/117761,,11:00 AM,"We study the online calibration of multi-dimensional forecasts over an arbitrary convex set $\mathcal{P} \subset \mathbb{R}^d$ relative to an arbitrary norm $\Vert\cdot\Vert$. We connect this with the problem of external regret minimization for online linear optimization, showing that if it is possible to guarantee $O(\sqrt{\rho T})$ worst-case regret after $T$ rounds when actions are drawn from $\mathcal{P}$ and losses are drawn from the dual $\Vert \cdot \Vert_*$ unit norm ball, then it is also possible to obtain $\epsilon$-calibrated forecasts after $T = \exp(O(\rho /\epsilon^2))$ rounds. When $\mathcal{P}$ is the $d$-dimensional simplex and $\Vert \cdot \Vert$ is the $\ell_1$-norm, the existence of $O(\sqrt{T\log d})$ algorithms for learning with experts implies that it is possible to obtain $\epsilon$-calibrated forecasts after $T = \exp(O(\log{d}/\epsilon^2)) = d^{O(1/\epsilon^2)}$ rounds, recovering a recent result of Peng 2025.Interestingly, our algorithm obtains this guarantee without requiring access to any online linear optimization subroutine or knowledge of the optimal rate $\rho$ -- in fact, our algorithm is identical for every setting of $\mathcal{P}$ and $\Vert \cdot \Vert$. Instead, we show that the optimal regularizer for the above OLO problem can be used to upper bound the above calibration error by a swap regret, which we then minimize by running the recent TreeSwap algorithm with Follow-The-Leader as a subroutine. The resulting algorithm is highly efficient and plays a distribution over simple averages of past observations in each round.Finally, we prove that any online calibration algorithm that guarantees $\epsilon T$ $\ell_1$-calibration error over the $d$-dimensional simplex requires $T \geq \exp(\mathrm{poly}(1/\epsilon))$ (assuming $d \geq \mathrm{poly}(1/\epsilon)$). This strengthens the corresponding $d^{\Omega(\log{1/\epsilon})}$ lower bound of Peng 2025, and shows that an exponential dependence on $1/\epsilon$ is necessary.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Does Stochastic Gradient really succeed for bandits?,https://neurips.cc/virtual/2025/oral/116754,,11:00 AM,"Recent works of Mei et al. (2023, 2024) have deepened the theoretical understanding of the *Stochastic Gradient Bandit* (SGB) policy, showing that using a constant learning rate guarantees asymptotic convergence to the optimal policy, and that sufficiently *small* learning rates can yield logarithmic regret. However, whether logarithmic regret holds beyond small learning rates remains unclear. In this work, we take a step towards characterizing the regret *regimes* of SGB as a function of its learning rate. For two--armed bandits, we identify a sharp threshold, scaling with the sub-optimality gap $\Delta$, below which SGB achieves *logarithmic* regret on all instances, and above which it can incur *polynomial* regret on some instances. This result highlights the necessity of knowing (or estimating) $\Delta$ to ensure logarithmic regret with a constant learning rate.For general $K$-armed bandits, we further show the learning rate must scale inversely with $K$ to avoid polynomial regret. We introduce novel techniques to derive regret upper bounds for SGB, laying the groundwork for future advances in the theory of gradient-based bandit algorithms.",,,,
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1C,https://neurips.cc/virtual/2025/session/122548,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Adjoint Schrödinger Bridge Sampler,https://neurips.cc/virtual/2025/oral/115787,,11:00 AM,"Computational methods for learning to sample from the Boltzmann distribution—where the target distribution is known only up to an unnormalized energy function—have advanced significantly recently. Due to the lack of explicit target samples, however, prior diffusion-based methods, known asdiffusion samplers, often require importance-weighted estimation or complicated learning processes. Both trade off scalability with extensive evaluations of the energy and model, thereby limiting their practical usage. In this work, we proposeAdjoint Schrödinger Bridge Sampler (ASBS), a new diffusion sampler that employs simple and scalable matching-based objectives yet without the need to estimate target samples during training. ASBS is grounded on a mathematical model—the Schrödinger Bridge—which enhances sampling efficiency via kinetic-optimal transportation. Through a new lens of stochastic optimal control theory, we demonstrate how SB-based diffusion samplers can be learned at scale via Adjoint Matching and prove convergence to the global solution. Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to arbitrary source distributions by relaxing the so-called memoryless condition that largely restricts the design space. Through extensive experiments, we demonstrate the effectiveness of ASBS on sampling from classical energy functions, amortized conformer generation, and molecular Boltzmann distributions. Codes are available at https://github.com/facebookresearch/adjoint_samplers",,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Rethinking Joint Maximum Mean Discrepancy for Visual Domain Adaptation,https://neurips.cc/virtual/2025/oral/117477,,11:00 AM,"In domain adaption (DA), joint maximum mean discrepancy (JMMD), as a famous distribution-distance metric, aims to measure joint probability distribution difference between the source domain and target domain, while it is still not fully explored and especially hard to be applied into a subspace-learning framework as its empirical estimation involves a tensor-product operator whose partial derivative is difficult to obtain. To solve this issue, we deduce a concise JMMD based on the Representer theorem that avoids the tensor-product operator and obtains two essential findings. First, we reveal the uniformity of JMMD by proving that previous marginal, class conditional, and weighted class conditional probability distribution distances are three special cases of JMMD with different label reproducing kernels. Second, inspired by graph embedding, we observe that the similarity weights, which strengthen the intra-class compactness in the graph of Hilbert Schmidt independence criterion (HSIC), take opposite signs in the graph of JMMD, revealing why JMMD degrades the feature discrimination. This motivates us to propose a novel loss JMMD-HSIC by jointly considering JMMD and HSIC to promote discrimination of JMMD. Extensive experiments on several cross-domain datasets could demonstrate the validity of our revealed theoretical results and the effectiveness of our proposed JMMD-HSIC.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Class-wise Balancing Data Replay for Federated Class-Incremental Learning,https://neurips.cc/virtual/2025/oral/117265,,11:00 AM,"Federated Class Incremental Learning (FCIL) aims to collaboratively process continuously increasing incoming tasks across multiple clients. Among various approaches, data replay has become a promising solution, which can alleviate forgetting by reintroducing representative samples from previous tasks. However, their performance is typically limited by class imbalance, both within the replay buffer due to limited global awareness and between replayed and newly arrived classes. To address this issue, we propose a class-wise balancing data replay method for FCIL (FedCBDR), which employs a global coordination mechanism for class-level memory construction and reweights the learning objective to alleviate the aforementioned imbalances. Specifically, FedCBDR has two key components: 1) the global-perspective data replay module reconstructs global representations of prior task knowledge in a privacy-preserving manner, which then guides a class-aware and importance-sensitive sampling strategy to achieve balanced replay; 2) Subsequently, to handle class imbalance across tasks, the task-aware temperature scaling module adaptively adjusts the temperature of logits at both class and instance levels based on task dynamics, which reduces the model’s overconfidence in majority classes while enhancing its sensitivity to minority classes. Experimental results verified that FedCBDR achieves balanced class-wise sampling under heterogeneous data distributions and improves generalization under task imbalance between earlier and recent tasks, yielding a 2%-15% Top-1 accuracy improvement over six state-of-the-art methods.",,,,
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1D,https://neurips.cc/virtual/2025/session/122549,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think,https://neurips.cc/virtual/2025/oral/116345,,11:00 AM,"REPA and its variants effectively mitigate training challenges in diffusion models by incorporating external visual representations from pretrained models, through alignment between the noisy hidden projections of denoising networks and foundational clean image representations. We argue that the external alignment, which is absent during the entire denoising inference process, falls short of fully harnessing the potential of discriminative representations. In this work, we propose a straightforward method called \textit{\textbf{R}epresentation \textbf{E}ntanglement for \textbf{G}eneration} (\textbf{REG}), which entangles low-level image latents with a single high-level class token from pretrained foundation models for denoising. REG acquires the capability to produce coherent image-class pairs directly from pure noise, substantially improving both generation quality and training efficiency.This is accomplished with negligible additional inference overhead, requiring only one single additional token for denoising (<0.5\% increase in FLOPs and latency).The inference process concurrently reconstructs both image latents and their corresponding global semantics, where the acquired semantic knowledge actively guides and enhances the image generation process.On ImageNet 256$\times$256, SiT-XL/2 + REG demonstrates remarkable convergence acceleration, achieving $\textbf{63}\times$ and $\textbf{23}\times$ faster training than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively, SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA trained for 4M iterations ($\textbf{10}\times$ longer). Code is available at: https://github.com/Martinser/REG.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity,https://neurips.cc/virtual/2025/oral/116379,,11:00 AM,"Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods, such as diffusion and flow matching techniques, generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the noisy nature of the loss as a key factor driving generalization in flow matching.First, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Why Diffusion Models Don’t Memorize:  The Role of Implicit Dynamical Regularization in Training,https://neurips.cc/virtual/2025/oral/119373,,11:00 AM,"Diffusion models have achieved remarkable success across a wide range of generative tasks. A key challenge is understanding the mechanisms that prevent their memorization of training data and allow generalization. In this work, we investigate the role of the training dynamics in the transition from generalization to memorization. Through extensive experiments and theoretical analysis, we identify two distinct timescales: an early time $\tau_\mathrm{gen}$ at which models begin to generate high-quality samples, and a later time $\tau_\mathrm{mem}$ beyond which memorization emerges. Crucially, we find that $\tau_\mathrm{mem}$ increases linearly with the training set size $n$, while $\tau_\mathrm{gen}$ remains constant. This creates a growing window of training times with $n$ where models generalize effectively, despite showing strong memorization if training continues beyond it. It is only when $n$ becomes larger than a model-dependent threshold that overfitting disappears at infinite training times.These findings reveal a form of implicit dynamical regularization in the training dynamics, which allow to avoid memorization even in highly overparameterized settings. Our results are supported by numerical experiments with standard U-Net architectures on realistic and synthetic  datasets, and by a theoretical analysis using a tractable random features model studied in the high-dimensional limit.",,,,
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1E,https://neurips.cc/virtual/2025/session/122550,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation,https://neurips.cc/virtual/2025/oral/115716,,11:00 AM,"Vision-and-Language Navigation (VLN) is a core task where embodied agents leverage their spatial mobility to navigate in 3D environments toward designated destinations based on natural language instructions. Recently, video-language large models (Video-VLMs) with strong generalization capabilities and rich commonsense knowledge have shown remarkable performance when applied to VLN tasks. However, these models still encounter the following challenges when applied to real-world 3D navigation: 1) Insufficient understanding of 3D geometry and spatial semantics; 2) Limited capacity for large-scale exploration and long-term environmental memory; 3) Poor adaptability to dynamic and changing environments.To address these limitations, we propose Dynam3D, a dynamic layered 3D representation model that leverages language-aligned, generalizable, and hierarchical 3D representations as visual input to train 3D-VLM in navigation action prediction. Given posed RGB-D images, our Dynam3D projects 2D CLIP features into 3D space and constructs multi-level 3D patch-instance-zone representations for 3D geometric and semantic understanding with a dynamic and layer-wise update strategy.  Our Dynam3D is capable of online encoding and localization of 3D instances, and dynamically updates them in changing environments to provide large-scale exploration and long-term memory capabilities for navigation. By leveraging large-scale 3D-language pretraining and task-specific adaptation, our Dynam3D sets new state-of-the-art performance on VLN benchmarks including R2R-CE, REVERIE-CE and NavRAG-CE under monocular settings. Furthermore, experiments for pre-exploration, lifelong memory, and real-world robot validate the effectiveness of practical deployment.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Perception Encoder: The best visual embeddings are not at the output of the network,https://neurips.cc/virtual/2025/oral/118806,,11:00 AM,"We introduce Perception Encoder (PE), a family of state-of-the-art vision encoders for image and video understanding. Traditionally, vision encoders have relied on a variety of pretraining objectives, each excelling at different downstream tasks. Surprisingly, after scaling a carefully tuned image pretraining recipe and refining with a robust video data engine, we find that contrastive vision-language training alone can produce strong, general embeddings for all of these downstream tasks. There is only one caveat: these embeddings are hidden within the intermediate layers of the network. To draw them out, we introduce two alignment methods: language alignment for multimodal language modeling, and spatial alignment for dense prediction. Together, our PE family of models achieves state-of-the-art results on a wide variety of tasks, including zero-shot image and video classification and retrieval; document, image, and video Q&A; and spatial tasks such as detection, tracking, and depth estimation. We release our models, code, and novel dataset of synthetically and human-annotated videos: https://github.com/facebookresearch/perception_models",,,,
WED 3 DEC,10:00-11:00,Oral Paper,→ Interactive Cross-modal Learning for Text-3D Scene Retrieval,https://neurips.cc/virtual/2025/oral/116803,,11:00 AM,"Text-3D Scene Retrieval (T3SR) aims to retrieve relevant scenes using linguistic queries. Although traditional T3SR methods have made significant progress in capturing fine-grained associations, they implicitly assume that query descriptions are information-complete. In practical deployments, however, limited by the capabilities of users and models, it is difficult or even impossible to directly obtain a perfect textual query suiting the entire scene and model, thereby leading to performance degradation. To address this issue, we propose a novel Interactive Text-3D Scene Retrieval Method (IDeal), which promotes the enhancement of the alignment between texts and 3D scenes through continuous interaction. To achieve this, we present an Interactive Retrieval Refinement framework (IRR), which employs a questioner to pose contextually relevant questions to an answerer in successive rounds that either promote detailed probing or encourage exploratory divergence within scenes. Upon the iterative responses received from the answerer, IRR adopts a retriever to perform both feature-level and semantic-level information fusion, facilitating scene-level interaction and understanding for more precise re-rankings. To bridge the domain gap between queries and interactive texts, we propose an Interaction Adaptation Tuning strategy (IAT). IAT mitigates the discriminability and diversity risks among augmented text features that approximate the interaction text domain, achieving contrastive domain adaptation for our retriever. Extensive experimental results on three datasets demonstrate the superiority of IDeal.",,诺亚,诺亚: 本Session提出的交互式文本-3D场景检索方法，解决多模态长文本推理中的交互和信息融合瓶颈，契合诺亚团队挑战点“长序列图文多模态模型演进方向”，有助突破输入范式和计算限制。,诺亚: 交互式检索细化框架(IRR)设计与实现; 多轮提问与应答机制以优化查询表达; 特征和语义层面信息融合策略; 交互适配调优策略(IAT)实现对域差的适应; 多模态长文本推理中的性能提升方法
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2A,https://neurips.cc/virtual/2025/session/122551,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ Agnostic Active Learning Is Always Better Than Passive Learning,https://neurips.cc/virtual/2025/oral/117512,,4:30 PM,"We sharply characterize the optimal first-order query complexity of agnostic active learning for all concept classes, and propose a new general active learning algorithm which achieves it. Remarkably, the optimal query complexity admits a leading term which is always strictly smaller than the sample complexity of passive supervised learning (by a factor proportional to the best-in-class error rate). This was not previously known to be possible in the agnostic setting. For comparison, in all previous general analyses, the leading term exhibits an additional factor, such as the disagreement coefficient or related complexity measure, and therefore only provides improvements over passive learning in restricted cases. The present work completely removes such factors from the leading term, implying that every concept class benefits from active learning in the non-realizable case. The results established in this work resolve an important long-standing open question central to the past two decades of research on the theory of agnostic active learning.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ Tighter CMI-Based Generalization Bounds via Stochastic Projection and Quantization,https://neurips.cc/virtual/2025/oral/117680,,4:30 PM,"In this paper, we leverage stochastic projection and lossy compression to establish new conditional mutual information (CMI) bounds on the generalization error of statistical learning algorithms. It is shown that these bounds are generally tighter than the existing ones. In particular, we prove that for certain problem instances for which existing MI and CMI bounds were recently shown in Attias et al. [2024] and Livni [2023] to become vacuous or fail to describe the right generalization behavior, our bounds yield suitable generalization guarantees of the order of $\mathcal{O}(1/\sqrt{n})$, where $n$ is the size of the training dataset. Furthermore, we use our bounds to investigate the problem of data ""memorization"" raised in those works, and which asserts that there are learning problem instances for which any learning algorithm that has good prediction there exist distributions under which the algorithm must ""memorize'' a big fraction of the training dataset. We show that for every learning algorithm, there exists an auxiliary algorithm that does not memorize and which yields comparable generalization error for any data distribution. In part, this shows that memorization is not necessary for good generalization.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks,https://neurips.cc/virtual/2025/oral/118768,,4:30 PM,"Understanding the inductive bias and generalization properties of large overparametrized machine learning models requires to characterize the dynamics of the training algorithm.  We study the learning dynamics of large two-layer neural networks via dynamical mean field theory, a well established technique of non-equilibrium statistical physics. We show that, for large network width $m$,and large number of samples per input dimension $n/d$, the training dynamics exhibits a separation of timescales which implies:$(i)$ The emergence of a slow time scale associated with the growth in Gaussian/Rademacher complexity of the network;$(ii)$ Inductive bias towards small complexity if the initialization has small enough complexity;$(iii)$ A dynamical decoupling between feature learning and overfitting regimes; $(iv)$ A non-monotone behavior of the test error, associated  `feature unlearning' regime at large times.",,,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2B,https://neurips.cc/virtual/2025/session/122552,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ PhySense: Sensor Placement Optimization for Accurate Physics Sensing,https://neurips.cc/virtual/2025/oral/115066,,4:30 PM,"Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered. Code is available at this repository: https://github.com/thuml/PhySense.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability,https://neurips.cc/virtual/2025/oral/117509,,4:30 PM,"Vehicle GPS trajectories provide valuable movement information that supports various downstream tasks and applications. A desirable trajectory learning model should be able to transfer across regions and tasks without retraining, avoiding the need to maintain multiple specialized models and subpar performance with limited training data. However, each region has its unique spatial features and contexts, which are reflected in vehicle movement patterns and are difficult to generalize. Additionally, transferring across different tasks faces technical challenges due to the varying input-output structures required for each task. Existing efforts towards transferability primarily involve learning embedding vectors for trajectories, which perform poorly in region transfer and require retraining of prediction modules for task transfer.To address these challenges, we propose $\textit{TransferTraj}$, a vehicle GPS trajectory learning model that excels in both region and task transferability. For region transferability, we introduce RTTE as the main learnable module within TransferTraj. It integrates spatial, temporal, POI, and road network modalities of trajectories to effectively manage variations in spatial context distribution across regions. It also introduces a TRIE module for incorporating relative information of spatial features and a spatial context MoE module for handling movement patterns in diverse contexts. For task transferability, we propose a task-transferable input-output scheme that unifies the input-output structure of different tasks into the masking and recovery of modalities and trajectory points. This approach allows TransferTraj to be pre-trained once and transferred to different tasks without retraining. We conduct extensive experiments on three real-world vehicle trajectory datasets under various transfer settings, including task transfer, zero-shot region transfer, and few-shot region transfer. Experimental results demonstrate that TransferTraj significantly outperforms state-of-the-art baselines in different scenarios, validating its effectiveness in region and task transfer. Code is available at https://github.com/wtl52656/TransferTraj.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata,https://neurips.cc/virtual/2025/oral/121612,,4:30 PM,"Accurate visual localization from aerial views is a fundamental problem with applications in mapping, large-area inspection, and search-and-rescue operations. In many scenarios, these systems require high-precision localization while operating with limited resources (e.g., no internet connection or GNSS/GPS support), making large image databases or heavy 3D models impractical. Surprisingly, little attention has been given to leveraging orthographic geodata as an alternative paradigm, which is lightweight and increasingly available through free releases by governmental authorities (e.g., the European Union). To fill this gap, we propose OrthoLoC, the first large-scale dataset comprising 16,425 UAV images from Germany and the United States with multiple modalities. The dataset addresses domain shifts between UAV imagery and geospatial data. Its paired structure enables fair benchmarking of existing solutions by decoupling image retrieval from feature matching, allowing isolated evaluation of localization and calibration performance. Through comprehensive evaluation, we examine the impact of domain shifts, data resolutions, and covisibility on localization accuracy. Finally, we introduce a refinement technique called AdHoP, which can be integrated with any feature matcher, improving matching by up to 95% and reducing translation error by up to 63%. The dataset and code are available at: https://deepscenario.github.io/OrthoLoC .",,,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2C,https://neurips.cc/virtual/2025/session/122553,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ A multiscale analysis of mean-field transformers in the moderate interaction regime,https://neurips.cc/virtual/2025/oral/117616,,4:30 PM,"In this paper, we study the evolution of tokens through the depth of encoder-only transformer models at inference time by modeling them as a system of particles interacting in a mean-field way and studying the corresponding dynamics. More specifically, we consider this problem in the moderate interaction regime, where the number $N$ of tokens is large and the inverse temperature parameter $\beta$ of the model scales together with $N$. In this regime, the dynamics of the system displays a multiscale behavior: a fast phase, where the token empirical measure collapses on a low-dimensional space, an intermediate phase, where the measure further collapses into clusters, and a slow one, where such clusters sequentially merge into a single one. We provide a rigorous characterization of the limiting dynamics in each of these phases and prove convergence in the above mentioned limit, exemplifying our results with some simulations.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ The emergence of sparse attention: impact of data distribution and benefits of repetition,https://neurips.cc/virtual/2025/oral/116475,,4:30 PM,"Emergence is a fascinating property of large language models and neural networks more broadly: as models scale and train for longer, they sometimes develop new abilities in sudden ways. Despite initial studies, we still lack a comprehensive understanding of how and when these abilities emerge. To address this gap, we study the emergence over training of sparse attention, a critical and frequently observed attention pattern in Transformers. By combining theoretical analysis of a toy model with empirical observations on small Transformers trained on a linear regression variant, we uncover the mechanics driving sparse attention emergence and reveal that emergence timing follows power laws based on task structure, architecture, and optimizer choice. We additionally find that repetition can greatly speed up emergence. Finally, we confirm these results on a well-studied in-context associative recall task. Our findings provide a simple, theoretically grounded framework for understanding how data distributions and model design influence the learning dynamics behind one form of emergence.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer Training Dynamics,https://neurips.cc/virtual/2025/oral/116706,,4:30 PM,"Although transformer-based models have shown exceptional empirical performance, the fundamental principles governing their training dynamics are inadequately characterized beyond configuration-specific studies. Inspired by empirical evidence showing improved reasoning capabilities under small initialization scales in language models, we employ the gradient flow analytical framework established in \cite{zhou2022towards} to systematically investigate linearized Transformer training dynamics. Our theoretical analysis dissects the dynamics of attention modules into two distinct stages. In the first stage, asymmetric weight perturbations from random initialization sustain non-degenerate gradient dynamics in parameter matrices, facilitating systematic escape from small initialization regimes. Subsequently, these matrices undergo condensation, progressively aligning toward the target orientation. In the second stage, the previously static key-query matrices actively participate in training, driving the normalized matrices toward asymptotic rank collapse. This two-stage framework generalizes classical directional convergence results.",,,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2D,https://neurips.cc/virtual/2025/session/122554,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models,https://neurips.cc/virtual/2025/oral/119904,,4:30 PM,"Preference-based reinforcement learning (PbRL) has emerged as a promising paradigm for teaching robots complex behaviors without reward engineering. However, its effectiveness is often limited by two critical challenges: the reliance on extensive human input and the inherent difficulties in resolving query ambiguity and credit assignment during reward learning. In this paper, we introduce PRIMT, a PbRL framework designed to overcome these challenges by leveraging foundation models (FMs) for multimodal synthetic feedback and trajectory synthesis. Unlike prior approaches that rely on single-modality FM evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy, integrating the complementary strengths of vision-language models (VLMs) and large language models (LLMs) in evaluating robot behaviors for more reliable and comprehensive feedback. PRIMT also incorporates foresight trajectory generation to warm-start the trajectory buffer with bootstrapped samples, reducing early-stage query ambiguity, and hindsight trajectory augmentation for counterfactual reasoning with a causal auxiliary loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6 manipulation tasks on various benchmarks, demonstrating superior performance over FM-based and scripted baselines. Website at https://primt25.github.io/.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks,https://neurips.cc/virtual/2025/oral/116055,,4:30 PM,"Neuromorphic computing systems are set to revolutionize energy-constrained robotics by achieving orders-of-magnitude efficiency gains, while enabling native temporal processing. Spiking Neural Networks (SNNs) represent a promising algorithmic approach for these systems, yet their application to complex control tasks faces two critical challenges: (1) the non-differentiable nature of spiking neurons necessitates surrogate gradients with unclear optimization properties, and (2) the stateful dynamics of SNNs require training on sequences, which in reinforcement learning (RL) is hindered by limited sequence lengths during early training, preventing the network from bridging its warm-up period.We address these challenges by systematically analyzing surrogate gradient slope settings, showing that shallower slopes increase gradient magnitude in deeper layers but reduce alignment with true gradients. In supervised learning, we find no clear preference for fixed or scheduled slopes. The effect is much more pronounced in RL settings, where shallower slopes or scheduled slopes lead to a $\times2.1$ improvement in both training and final deployed performance. Next, we propose a novel training approach that leverages a privileged guiding policy to bootstrap the learning process, while still exploiting online environment interactions with the spiking policy. Combining our method with an adaptive slope schedule for a real-world drone position control task, we achieve an average return of 400 points, substantially outperforming prior techniques, including Behavioral Cloning and TD3BC, which achieve at most –200 points under the same conditions. This work advances both the theoretical understanding of surrogate gradient learning in SNNs and practical training methodologies for neuromorphic controllers demonstrated in real-world robotic systems.",,计算,计算: 该Session深入探讨了低精度神经网络训练中的梯度调整策略及其在强化学习中对计算效率和性能的提升，契合挑战点中关于低精度训练推理对计算架构需求的研究，助力团队洞悉新兴低精度模型训推技术。,计算: 低精度代理梯度的设计与调优; 强化学习中序列训练的梯度表现优化; 基于指导策略的学习加速方法; 神经形态计算系统在实际机器人控制中的应用; 适应性梯度斜率调度策略
WED 3 DEC,3:30-4:30,Oral Paper,→ SAGE: A Unified Framework for Generalizable Object State Recognition with State-Action Graph Embedding,https://neurips.cc/virtual/2025/oral/116465,,4:30 PM,"Recognizing the physical states of objects and their transformations within videos is crucial for structured video understanding and enabling robust real-world applications, such as robotic manipulation. However, pretrained vision-language models often struggle to capture these nuanced dynamics and their temporal context, and specialized object state recognition frameworks may not generalize to unseen actions or objects. We introduce SAGE (State-Action Graph Embeddings), a novel framework that offers a unified model of physical state transitions by decomposing states into fine-grained, language-described visual concepts that are sharable across different objects and actions. SAGE initially leverages Large Language Models to construct a State-Action Graph, which is then multimodally refined using Vision-Language Models. Extensive experiments show that our method significantly outperforms baselines, generalizes effectively to unseen objects and actions in open-world settings. SAGE improves the prior state-of-the-art by as much as 14.6% on novel state recognition with less than 5% of its inference time.",,,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2E,https://neurips.cc/virtual/2025/session/122555,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,→ Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing,https://neurips.cc/virtual/2025/oral/121634,,4:30 PM,"Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats. To study this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE). RISEBench focuses on four key reasoning categories: Temporal, Causal, Spatial, and Logical Reasoning. We curate high-quality test cases for each category and propose an robust evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and the LMM-as-a-judge approach. We conducted experiments evaluating nine prominent visual editing models, comprising both open-source and proprietary models. The evaluation results demonstrate that current models face significant challenges in reasoning-based editing tasks.  Even the most powerful model evaluated, GPT-image-1, achieves an accuracy of merely 28.8%. RISEBench effectively highlights the limitations of contemporary editing models, provides valuable insights,  and indicates potential future directions for the field of reasoning-aware visual editing. Our code and data have been released at https://github.com/PhoenixZ810/RISEBench.",,诺亚,诺亚: 该团队关注长序列图文多模态模型演进，与Session中对视觉编辑中复杂指令和推理的挑战高度契合。参与本Session有助于探索突破多模态长文本推理计算瓶颈的新思路和方法。,诺亚: 多模态长文本推理技术; 复杂指令下的视觉编辑算法; 图像与文本的时序因果空间逻辑推理; 编辑中外观一致性维护策略; 基于推理的视觉编辑评测框架
WED 3 DEC,3:30-4:30,Oral Paper,→ CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding,https://neurips.cc/virtual/2025/oral/121509,,4:30 PM,"Coral reefs are vital yet vulnerable ecosystems that require continuous monitoring to support conservation. While coral reef images provide essential information in coral monitoring, interpreting such images remains challenging due to the need for domain expertise. Visual Question Answering (VQA), powered by Large Vision-Language Models (LVLMs), has great potential in user-friendly interaction with coral reef images. However, applying VQA to coral imagery demands a dedicated dataset that addresses two key challenges: domain-specific annotations and multidimensional questions. In this work, we introduce CoralVQA, the first large-scale VQA dataset for coral reef analysis. It contains 12,805 real-world coral images from 67 coral genera collected from 3 oceans, along with 277,653 question-answer pairs that comprehensively assess ecological and health-related conditions. To construct this dataset, we develop a semi-automatic data construction pipeline in collaboration with marine biologists to ensure both scalability and professional-grade data quality. CoralVQA presents novel challenges and provides a comprehensive benchmark for studying vision-language reasoning in the context of coral reef images. By evaluating several state-of-the-art LVLMs, we reveal key limitations and opportunities. These insights form a foundation for future LVLM development, with a particular emphasis on supporting coral conservation efforts.",,诺亚,诺亚: 该Session聚焦于基于大规模视觉语言模型的 coral reef 图像理解，涉及长序列多模态数据的处理挑战，契合诺亚团队关于长序列图文多模态模型输入范式创新的研究方向，有助攻克多模态长文本推理瓶颈。,诺亚: 大规模视觉问答数据集构建与质量保障技术; 多模态长序列数据的高效编码与推理方法; 针对生态类图像的领域特定特征提取与表示; 视觉语言模型在环境监测任务中的应用和优化; 半自动数据标注流程与专家协同机制
WED 3 DEC,3:30-4:30,Oral Paper,→ OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model,https://neurips.cc/virtual/2025/oral/120304,,4:30 PM,"Understanding and synthesizing realistic 3D hand-object interactions (HOI) is critical for applications ranging from immersive AR/VR to dexterous robotics. Existing methods struggle with generalization, performing well on closed-set objects and predefined tasks but failing to handle unseen objects or open-vocabulary instructions. We introduce OpenHOI, the first framework for open-world HOI synthesis, capable of generating long-horizon manipulation sequences for novel objects guided by free-form language commands. Our approach integrates a 3D Multimodal Large Language Model (MLLM) fine-tuned for joint affordance grounding and semantic task decomposition, enabling precise localization of interaction regions (e.g., handles, buttons) and breakdown of complex instructions (e.g., “Find a water bottle and take a sip”) into executable sub-tasks. To synthesize physically plausible interactions, we propose an affordance-driven diffusion model paired with a training-free physics refinement stage that minimizes penetration and optimizes affordance alignment.Evaluations across diverse scenarios demonstrate OpenHOI’s superiority over state-of-the-art methods in generalizing to novel object categories, multi-stage tasks, and complex language instructions.",,,,
THU 4 DEC,8:30 a.m.,Invited Talk,The Art of (Artificial) Reasoning,https://neurips.cc/virtual/2025/invited-talk/109603,Yejin Choi,9:30 AM,"Scaling laws suggest that “more is more” — brute-force scaling of data and compute leads to stronger AI capabilities. However, despite rapid progress on benchmarks, state-of-the-art models still exhibit ""jagged intelligence,"" indicating that current scaling approaches may have limitations in terms of sustainability and robustness. Additionally, while the volume of papers on arXiv continues to grow rapidly, our scientific understanding of artificial intelligence hasn't kept pace with engineering advances, and the current literature presents seemingly contradictory findings that can be difficult to reconcile. In this talk, I will discuss key insights into the strengths and limitations of LLMs, examine when reinforcement learning succeeds or struggles in reasoning tasks, and explore methods for enhancing reasoning capabilities in smaller language models to help them close the gap against their larger counterparts in specific domains.",,诺亚,诺亚: 该Session深入探讨了提升推理能力的方法，特别关注小型语言模型的性能提升，这与团队在突破多模态长文本推理计算瓶颈的挑战点高度契合。参与此Session有助于团队获得最新算法与模型优化思路。,诺亚: 长序列多模态数据的输入范式创新; 提升小型语言模型推理能力的技术; 强化学习在复杂推理任务中的应用与限制; 分析当前大模型扩展的可持续性问题; 融合多模态信息以优化推理效果
THU 4 DEC,2:30 p.m.,Invited Talk,"On the Science of “Alien Intelligences”: Evaluating Cognitive Capabilities in Babies, Animals, and AI",https://neurips.cc/virtual/2025/invited-talk/109607,Melanie Mitchell,3:30 PM,"Today’s generative AI systems—termed by some researchers as “alien intelligences”—have exceeded human performance on many benchmarks meant to test humanlike cognitive capabilities.  However, these systems still struggle in unhumanlike ways on real-world tasks requiring these capabilities.  This disconnect may be due in part to neglect in the AI community of well-founded experimental protocols for evaluating cognition.  In this talk I will summarize several recommendations on experimental methods from developmental and comparative psychology—fields that study the “alien intelligences” of babies and non-human animals—and demonstrate the application of such methods in two case studies of cognitive abilities in LLMs: analogical reasoning and visual abstraction.",,,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3A,https://neurips.cc/virtual/2025/session/122556,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ Identifiability of Deep Polynomial Neural Networks,https://neurips.cc/virtual/2025/oral/118427,,11:00 AM,"Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability-a key property for ensuring interpretability-remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly compared to the activation degrees. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. We also settle an open conjecture on the dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach the expected dimension.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ Depth-Bounds for Neural Networks via the Braid Arrangement,https://neurips.cc/virtual/2025/oral/117519,,11:00 AM,"We contribute towards resolving the open question of how many hidden layers are required in ReLU networks for exactly representing all continuous and piecewise linear functions on $\mathbb{R}^d$. While the question has been resolved in special cases, the best known lower bound in general is still 2. We focus on neural networks that are compatible with certain polyhedral complexes, more precisely with the braid fan.  For such neural networks, we prove a non-constant lower bound of $\Omega(\log\log d)$ hidden layers required to exactly represent the maximum of $d$ numbers. Additionally, we provide a combinatorial proof that neural networks satisfying this assumption require three hidden layers to compute the maximum of 5 numbers; this had only been verified with an excessive computation so far.Finally, we show that a natural generalization of the best known upper bound to maxout networks is not tight, by demonstrating that a rank-3 maxout layer followed by a rank-2 maxout layer is sufficient to represent the maximum of 7 numbers.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ Learning Linear Attention in Polynomial Time,https://neurips.cc/virtual/2025/oral/118143,,11:00 AM,"Previous research has explored the expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the efficient learnability of Transformers from data has remained an open question.  Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention.  We show that learning the optimal multi head linear attention can be recast as finding the optimal kernel predictor in a suitably defined RKHS.  Moving to generalization, we construct an algorithm that, given a dataset, checks in polynomial time whether the set of best fit multi head linear attention networks on this data all perform an identical computation--a powerful notion for out of distribution generalization.  We empirically validate our theoretical findings on several canonical tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformer models.",,,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3B,https://neurips.cc/virtual/2025/session/122557,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts,https://neurips.cc/virtual/2025/oral/117276,,11:00 AM,"Current image fusion methods struggle with real-world composite degradations and lack the flexibility to accommodate user-specific needs. To address this, we propose ControlFusion, a controllable fusion network guided by language-vision prompts that adaptively mitigates composite degradations. On the one hand, we construct a degraded imaging model based on physical mechanisms, such as the Retinex theory and atmospheric scattering principle, to simulate composite degradations and provide a data foundation for addressing realistic degradations. On the other hand, we devise a prompt-modulated restoration and fusion network that dynamically enhances features according to degradation prompts, enabling adaptability to varying degradation levels. To support user-specific preferences in visual quality, a text encoder is incorporated to embed user-defined degradation types and levels as degradation prompts. Moreover, a spatial-frequency collaborative visual adapter is designed to autonomously perceive degradations from source images, thereby reducing complete reliance on user instructions. Extensive experiments demonstrate that ControlFusion outperforms SOTA fusion methods in fusion quality and degradation handling, particularly under real-world and compound degradations.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables,https://neurips.cc/virtual/2025/oral/118251,,11:00 AM,"Recently, deep learning-based pan-sharpening algorithms have achieved notable advancements over traditional methods. However, deep learning-based methods incur substantial computational overhead during inference, especially with large images. This excessive computational demand limits the applicability of these methods in real-world scenarios, particularly in the absence of dedicated computing devices such as GPUs and TPUs. To address these challenges, we propose Pan-LUT, a novel learnable look-up table (LUT) framework for pan-sharpening that strikes a balance between performance and computational efficiency for large remote sensing images. Our method makes it possible to process 15K$\times$15K remote sensing images on a 24GB GPU. To finely control the spectral transformation, we devise the PAN-guided look-up table (PGLUT) for channel-wise spectral mapping. To effectively capture fine-grained spatial details, we introduce the spatial details look-up table (SDLUT). Furthermore, to adaptively aggregate channel information for generating high-resolution multispectral images, we design an adaptive output look-up table (AOLUT). Our model contains fewer than 700K parameters and processes a 9K$\times$9K image in under 1 ms using one RTX 2080 Ti GPU, demonstrating significantly faster performance compared to other methods. Experiments reveal that Pan-LUT efficiently processes large remote sensing images in a lightweight manner, bridging the gap to real-world applications. Furthermore, our model surpasses SOTA methods in full-resolution scenes under real-world conditions, highlighting its effectiveness and efficiency.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution,https://neurips.cc/virtual/2025/oral/117604,,11:00 AM,"Accurate, high-resolution ocean forecasting is crucial for maritime operations and environmental monitoring. While traditional numerical models are capable of producing sub-daily, eddy-resolving forecasts, they are computationally intensive and face challenges in maintaining accuracy at fine spatial and temporal scales. In contrast, recent data-driven approaches offer improved computational efficiency and emerging potential, yet typically operate at daily resolution and struggle with sub-daily predictions due to error accumulation over time.We introduce FuXi-Ocean, the first data-driven global ocean forecasting model achieving six-hourly predictions at eddy-resolving 1/12° spatial resolution, reaching depths of up to 1500 meters. The model architecture integrates a context-aware feature extraction module with a predictive network employing stacked attention blocks. The core innovation is the Mixture-of-Time (MoT) module, which adaptively integrates predictions from multiple temporal contexts by learning variable-specific reliability, mitigating cumulative errors in sequential forecasting. Through comprehensive experimental evaluation, FuXi-Ocean demonstrates superior skill in predicting key variables, including temperature, salinity, and currents, across multiple depths.",,,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3C,https://neurips.cc/virtual/2025/session/122558,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ Auto-Compressing Networks,https://neurips.cc/virtual/2025/oral/116934,,11:00 AM,"Deep neural networks with short residual connections have demonstrated remarkable success across domains, but increasing depth often introduces computational redundancy without corresponding improvements in representation quality. We introduce Auto-Compressing Networks (ACNs), an architectural variant where additive long feedforward connections from each layer to the output replace traditional short residual connections. By analyzing the distinct dynamics induced by this modification, we reveal a unique property we coin asauto-compression—the ability of a network to organically compress information during training with gradient descent, through architectural design alone. Through auto-compression, information is dynamically ""pushed"" into early layers during training, enhancing their representational quality and revealing potential redundancy in deeper ones. We theoretically show that this property emerges from layer-wise training patterns found only in ACNs, where layers are dynamically utilized during training based on task requirements. We also find that ACNs exhibit enhanced noise robustness compared to residual networks, superior performance in low-data settings, improved transfer learning capabilities, and  mitigate catastrophic forgetting suggesting that they learn representations that generalize better despite using fewer parameters. Our results demonstrate up to 18\% reduction in catastrophic forgetting and 30-80\% architectural compression while maintaining accuracy across vision transformers, MLP-mixers, and BERT architectures. These findings establish ACNs as a practical approach to developing efficient neural architectures that automatically adapt their computational footprint to task complexity, while learning robust representations suitable for noisy real-world tasks and continual learning scenarios.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks,https://neurips.cc/virtual/2025/oral/119732,,11:00 AM,"Deployment of neural networks on resource-constrained devices demands models that are both compact and robust to adversarial inputs. However, compression and adversarial robustness often conflict. In this work, we introduce a dynamical low-rank training scheme enhanced with a novel spectral regularizer that controls the condition number of the low-rank core in each layer. This approach mitigates the sensitivity of compressed models to adversarial perturbations without sacrificing clean accuracy. The method is model- and data-agnostic, computationally efficient, and supports rank adaptivity to automatically compress the network at hand. Extensive experiments across standard architectures, datasets, and adversarial attacks show the regularized networks can achieve over 94 compression while recovering or improving adversarial accuracy relative to uncompressed baselines.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression,https://neurips.cc/virtual/2025/oral/116595,,11:00 AM,"The hypothesis that Convolutional Neural Networks (CNNs) are inherently texture-biased has shaped much of the discourse on feature use in deep learning. We revisit this hypothesis by examining limitations in the cue-conflict experiment by Geirhos et al. To address these limitations, we propose a domain-agnostic framework that quantifies feature reliance through systematic suppression of shape, texture, and color cues, avoiding the confounds of forced-choice conflicts. By evaluating humans and neural networks under controlled suppression conditions, we find that CNNs are not inherently texture-biased but predominantly rely on local shape features. Nonetheless, this reliance can be substantially mitigated through modern training strategies or architectures (ConvNeXt, ViTs). We further extend the analysis across computer vision, medical imaging, and remote sensing, revealing that reliance patterns differ systematically: computer vision models prioritize shape, medical imaging models emphasize color, and remote sensing models exhibit a stronger reliance on texture. Code is available at https://github.com/tomburgert/feature-reliance.",,,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3D,https://neurips.cc/virtual/2025/session/122559,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ State Entropy Regularization for Robust Reinforcement Learning,https://neurips.cc/virtual/2025/oral/115740,,11:00 AM,"State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ A Clean Slate for Offline Reinforcement Learning,https://neurips.cc/virtual/2025/oral/119623,,11:00 AM,"Progress in offline reinforcement learning (RL) has been impeded by ambiguous problem definitions and entangled algorithmic designs, resulting in inconsistent implementations, insufficient ablations, and unfair evaluations. Although offline RL explicitly avoids environment interaction, prior methods frequently employ extensive, undocumented online evaluation for hyperparameter tuning, complicating method comparisons. Moreover, existing reference implementations differ significantly in boilerplate code, obscuring their core algorithmic contributions. We address these challenges by first introducing a rigorous taxonomy and a transparent evaluation protocol that explicitly quantifies online tuning budgets. To resolve opaque algorithmic design, we provide clean, minimalistic, single-file implementations of various model-free and model-based offline RL methods, significantly enhancing clarity and achieving substantial speed-ups. Leveraging these streamlined implementations, we propose Unifloral, a unified algorithm that encapsulates diverse prior approaches and enables development within a single, comprehensive hyperparameter space. Using Unifloral with our rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR (model-free) and MoBRAC (model-based) - which substantially outperform established baselines. Our implementation is publicly available at https://github.com/EmptyJackson/unifloral.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,→ Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies,https://neurips.cc/virtual/2025/oral/117976,,11:00 AM,"Reinforcement learning (RL) systems have countless applications, from energy-grid management to protein design. However, such real-world scenarios are often extremely difficult, combinatorial in nature, and require complex coordination between multiple agents. This level of complexity can cause even state-of-the-art RL systems, trained until convergence, to hit a performance ceiling which they are unable to break out of with zero-shot inference. Meanwhile, many digital or simulation-based applications allow for an inference phase that utilises a specific time and compute budget to explore multiple attempts before outputting a final solution. In this work, we show that such an inference phase employed at execution time, and the choice of a corresponding inference strategy, are key to breaking the performance ceiling observed in complex multi-agent RL problems. Our main result is striking: we can obtain up to a 126% and, on average, a 45% improvement over the previous state-of-the-art across 17 tasks, using only a couple seconds of extra wall-clock time during execution. We also demonstrate promising compute scaling properties, supported by over 60k experiments, making it the largest study on inference strategies for complex RL to date. We make all of our experimental data and code available.",,计算,计算: 该Session深入探讨了通过推理策略突破强化学习性能瓶颈，正契合挑战点中对低精度训练推理在多模态与强化学习应用中的算力与架构需求，助力团队推动低精度模型训推研究与芯片定义。,计算: 推理阶段对强化学习性能提升的具体方法; 多智能体强化学习中的推理策略应用; 低精度计算对训练与推理性能的影响; 推理时间与算力资源的权衡策略; 实验数据驱动的性能优化方法
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3E,https://neurips.cc/virtual/2025/session/122560,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,"→ Position: If Innovation in AI systematically Violates Fundamental Rights, Is It Innovation at All?",https://neurips.cc/virtual/2025/oral/126305,,11:00 AM,"Artificial intelligence (AI) now permeates critical infrastructures and decisionmaking systems where failures produce social, economic, and democratic harm. This position paper challenges the entrenched belief that regulation and innovation are opposites. As evidenced by analogies from aviation, pharmaceuticals, and welfare systems and recent cases of synthetic misinformation, bias and unaccountable decision-making, the absence of well-designed regulation has already created immeasurable damage. Regulation, when thoughtful and adaptive, is not a brake on innovation—it is its foundation. The present position paper examines the EU AI Act as a model of risk-based, responsibility-driven regulation that addresses the Collingridge Dilemma: acting early enough to prevent harm, yet flexibly enough to sustain innovation. Its adaptive mechanisms—regulatory sandboxes, small and medium enterprises (SMEs) support, real-world testing, fundamental rights impact assessment (FRIA)—demonstrate how regulation can accelerate responsibly, rather than delay, technological progress. The position paper summarises how governance tools transform perceived burdens into tangible advantages: legal certainty, consumer trust, and ethical competitiveness. Ultimately, the paper reframes progress: innovation and regulation advance together. By embedding transparency, impact assessments, accountability, and AI literacy into design and deployment, the EU framework defines what responsible innovation truly means—technological ambition disciplined by democratic values and fundamental rights.",,温哥华云,温哥华云: 该Session围绕AI创新与基础权利保护的规范框架展开，强调风险评估与责任驱动的监管机制，与温哥华云团队关注的物理或具身AI关键研究领域的战略发展相契合，为推动技术与合规创新提供理论与实践指引。,温哥华云: 风险基础的AI监管模式及其对创新的促进作用; 基础权利影响评估（FRIA）在AI设计中的应用; 监管沙盒机制及中小企业支持策略; AI透明度与责任机制的实现路径; 促进技术进步与民主价值平衡的治理工具
THU 4 DEC,10:00-11:00,Oral Paper,→ More effort is needed to protect pedestrian privacy in the era of AI,https://neurips.cc/virtual/2025/oral/126301,,11:00 AM,"In the era of artificial intelligence (AI), pedestrian privacy is increasingly at risk. In research areas such as autonomous driving, computer vision, and surveillance, large datasets are often collected in public spaces, capturing pedestrians without consent or anonymization. These datasets are used to train systems that can identify, track, and analyze individuals, often without their knowledge. Although various technical methods and regional regulations have been proposed to address this issue, existing solutions are either insufficient to protect privacy or compromise data utility, thereby limiting their effectiveness for research. In this paper, we argue that more effort is needed to protect pedestrian privacy in the era of AI while maintaining data utility. We call on the AI and computer vision communities to take pedestrian privacy seriously and to rethink how pedestrian data are collected and anonymized. Collaboration with experts in law and ethics will also be essential for the responsible development of AI. Without stronger action, it will become increasingly difficult for individuals to protect their privacy, and public trust in AI may decline.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,"→ Real-Time Hyper-Personalized Generative AI Should Be Regulated to Prevent the Rise of ""Digital Heroin""",https://neurips.cc/virtual/2025/oral/126308,,11:00 AM,"This position paper argues that real-time generative AI has the potential to become the next wave of addictive digital media, creating a new class of digital content akin to ``digital heroin'' with severe implications for mental health and youth development. By shortening the content-generation feedback loop to mere seconds, these advanced models will soon be able to hyper-personalize outputs on the fly. When paired with misaligned incentives (e.g., maximizing user engagement), this will fuel unprecedented compulsive consumption patterns with far-reaching consequences for mental health, cognitive development, and social stability. Drawing on interdisciplinary research, from clinical observations of social media addiction to neuroscientific studies of dopamine-driven feedback, we illustrate how real-time tailored content generation may erode user autonomy, foment emotional distress, and disproportionately endanger vulnerable groups, such as adolescents. Due to the rapid advancement of generative AI and its potential to induce severe addiction-like effects, we call for strong government oversight akin to existing controls on addictive substances, particularly for minors. We further urge the machine learning community to act proactively by establishing robust design guidelines, collaborating with public health experts, and supporting targeted policy measures to ensure responsible and ethical deployment, rather than paving the way for another wave of unregulated digital dependence.",,,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4A,https://neurips.cc/virtual/2025/session/122561,,4:30 PM,,,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders,https://neurips.cc/virtual/2025/oral/118059,,4:30 PM,"Sparse Autoencoders (SAEs) aim to decompose the activation space of large language models (LLMs) into human-interpretable latent directions or features. As we increase the number of features in the SAE, hierarchical features tend to split into finer features (“math” may split into “algebra”, “geometry”, etc.), a phenomenon referred to as feature splitting. However, we show that sparse decomposition and splitting of hierarchical features is not robust. Specifically, we show that seemingly monosemantic features fail to fire where they should, and instead get “absorbed” into their children features. We coin this phenomenon feature absorption, and show that it is caused by optimizing for sparsity in SAEs whenever the underlying features form a hierarchy. We introduce a metric to detect absorption in SAEs, and validate our findings empirically on hundreds of LLM SAEs. Our investigation suggests that varying SAE sizes or sparsity is insufficient to solve this issue. We discuss the implications of feature absorption in SAEs and some potential approaches to solve the fundamental theoretical issues before SAEs can be used for interpreting LLMs robustly and at scale.",,,,
THU 4 DEC,3:30-4:30,Oral Paper,"→ Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free",https://neurips.cc/virtual/2025/oral/120217,,4:30 PM,"Gating mechanisms have been widely utilized, from early models like LSTMs and Highway Networks to recent state space models, linear attention, and also softmax attention.Yet, existing literature rarely examines the specific effects of gating.In this work, we conduct comprehensive experiments to systematically investigate gating-augmented softmax attention variants.Specifically, we perform a comprehensive comparison over 30 variants of 15B Mixture-of-Experts (MoE) models and 1.7B dense models trained on a 3.5 trillion token dataset.Our central finding is that a simple modification—applying a head-specific sigmoid gate after the Scaled Dot-Product Attention (SDPA)—consistently improves performance.This modification also enhances training stability, tolerates larger learning rates, and improves scaling properties.By comparing various gating positions and computational variants, we attribute this effectiveness to two key factors: (1) introducing non-linearity upon the low-rank mapping in the softmax attention, and (2) applying query-dependent sparse gating scores to modulate the SDPA output.Notably, we find this sparse gating mechanism mitigatesmassive activation,attention sinkand enhances long-context extrapolation performance. We also release related codes (https://github.com/qiuzh20/gatedattention}) and models (https://huggingface.co/QwQZh/gatedattention) to facilitate future research.Furthermore, the most effective SDPA output gating is used in the Qwen3-Next models (https://huggingface.co/collections/Qwen/qwen3-next).",,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ Superposition Yields Robust Neural Scaling,https://neurips.cc/virtual/2025/oral/116347,,4:30 PM,"The success of today's large language models (LLMs) depends on the observation that larger models perform better. However, the origin of this neural scaling law, that loss decreases as a power law with model size, remains unclear. We propose that representation superposition, meaning that LLMs represent more features than they have dimensions, can be a key contributor to loss and cause neural scaling. Based on Anthropic's toy model, we use weight decay to control the degree of superposition, allowing us to systematically study how loss scales with model size. When superposition is weak, the loss follows a power law only if data feature frequencies are power-law distributed. In contrast, under strong superposition, the loss generically scales inversely with model dimension across a broad class of frequency distributions, due to geometric overlaps between representation vectors. We confirmed that open-sourced LLMs operate in the strong superposition regime and have loss scaling inversely with model dimension, and that the Chinchilla scaling laws are also consistent with this behavior. Our results identify representation superposition as a central driver of neural scaling laws, providing insights into questions like when neural scaling laws can be improved and when they will break down.",,,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4B,https://neurips.cc/virtual/2025/session/122562,,4:30 PM,,,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ In Search of Adam’s Secret Sauce,https://neurips.cc/virtual/2025/oral/119298,,4:30 PM,"Understanding the remarkable efficacy of Adam when training transformer-based language models has become a central research topic within the optimization community. To gain deeper insights, several simplifications of Adam have been proposed, such as the signed gradient and signed momentum methods. In this work, we conduct an extensive empirical study — training over 1,500 language models across different data configurations and scales — comparing Adam to several known simplified variants. We find that signed momentum methods are faster than SGD, but consistently underperform relative to Adam, even after careful tuning of momentum, clipping setting and learning rates. However, our analysis reveals a compelling option that preserves near-optimal performance while allowing for new insightful reformulations: constraining the Adam momentum parameters to be equal, β 1 = β 2 . Beyond robust performance, this choice affords new theoretical insights, highlights the ""secret sauce"" on top of signed momentum, and grants a precise statistical interpretation: we show that Adam in this setting implements a natural online algorithm for estimating the mean and variance of gradients—one that arises from a mean-field Gaussian variational inference perspective.",,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions,https://neurips.cc/virtual/2025/oral/117576,,4:30 PM,"As the economic and environmental costs of training and deploying large vision or language models increase dramatically, analog in-memory computing (AIMC) emerges as a promising energy-efficient solution. However, the training perspective, especially its training dynamic, is underexplored. In AIMC hardware, the trainable weights are represented by the conductance of resistive elements and updated using consecutive electrical pulses.  While the conductance changes by a constant in response to each pulse, in reality, the change is scaled by asymmetric and non-linear response functions, leading to a non-ideal training dynamic. This paper provides a theoretical foundation for gradient-based training on AIMC hardware with non-ideal response functions.  We demonstrate that asymmetric response functions negatively impact Analog SGD by imposing an implicit penalty on the objective. To overcome the issue, we propose residual learning algorithm, which provably converges exactly to a critical point by solving a bilevel optimization problem. We show that the proposed method can be extended to deal with other hardware imperfections like limited response granularity. As far as we know, it is the first paper to investigate the impact of a class of generic non-ideal response functions. The conclusion is supported by simulations validating our theoretical insights.",,计算,计算: 本Session深入探讨了模拟内存计算中非理想电阻元件响应函数对训练动态的影响，针对低精度训练推理对计算架构的需求具有重要启示，契合挑战点关于低精度模型训推及其产品化的研究进展。,计算: 非理想响应函数对模拟内存训练动态的影响; 模拟随机梯度下降(Analog SGD)中的隐式目标罚项; 残差学习算法及其在非理想硬件环境下的收敛性; 双层优化问题在模拟训练中的应用; 面向低精度和硬件缺陷的模拟训练算法设计
THU 4 DEC,3:30-4:30,Oral Paper,"→ Generalized Gradient Norm Clipping & Non-Euclidean(L0,L1)-Smoothness",https://neurips.cc/virtual/2025/oral/115789,,4:30 PM,"This work introduces a hybrid non-Euclidean optimization method which generalizes gradient norm clipping by combining steepest descent and conditional gradient approaches. The method achieves the best of both worlds by establishing a descent property under a generalized notion of ($L_0$,$L_1$)-smoothness. Weight decay is incorporated in a principled manner by identifying a connection to the Frank-Wolfe short step. In the stochastic case, we show an order optimal $O(n^{-1/4})$ convergence rate by leveraging a momentum based gradient estimator. We discuss how to instantiate the algorithms for deep learning, which we dub Clipped Scion, and demonstrate their properties on image classification and language modeling. The code is available at https://github.com/LIONS-EPFL/ClippedScion.",,,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4C,https://neurips.cc/virtual/2025/session/122563,,4:30 PM,,,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ MaxSup: Overcoming Representation Collapse in Label Smoothing,https://neurips.cc/virtual/2025/oral/116897,,4:30 PM,"Label Smoothing (LS) is widely adopted to reduce overconfidence in neural network predictions and improve generalization. Despite these benefits, recent studies reveal two critical issues with LS. First, LS induces overconfidence in misclassified samples. Second, it compacts feature representations into overly tight clusters, diluting intra-class diversity, although the precise cause of this phenomenon remained elusive. In this paper, we analytically decompose the LS-induced loss, exposing two key terms: (i) a regularization term that dampens overconfidence only when the prediction is correct, and (ii) an error-amplification term that arises under misclassifications. This latter term compels the network to reinforce incorrect predictions with undue certainty, exacerbating representation collapse. To address these shortcomings, we propose Max Suppression (MaxSup), which applies uniform regularization to both correct and incorrect predictions by penalizing the top-1 logit rather than the ground-truth logit. Through extensive feature-space analyses, we show that MaxSup restores intra-class variation and sharpens inter-class boundaries. Experiments on large-scale image classification and multiple downstream tasks confirm that MaxSup is a more robust alternative to LS.Code and reproducibility scripts are available at https://github.com/ZhouYuxuanYX/Maximum-Suppression-Regularization.",,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ Advancing Expert Specialization for Better MoE,https://neurips.cc/virtual/2025/oral/116507,,4:30 PM,"Mixture-of-Experts (MoE) models enable efficient scaling of large language models (LLMs) by activating only a subset of experts per input. However, we observe that the commonly used auxiliary load balancing loss often leads to expert overlap and overly uniform routing, which hinders expert specialization and degrades overall performance during post-training.To address this, we propose a simple yet effective solution that introduces two complementary objectives: (1) an orthogonality loss to encourage experts to process distinct types of tokens, and (2) a variance loss to encourage more discriminative routing decisions.Gradient-level analysis demonstrates that these objectives are compatible with the existing auxiliary loss and contribute to optimizing the training process.Experimental results over various model architectures and across multiple benchmarks show that our method significantly enhances expert specialization. Notably, our method improves classic MoE baselines with auxiliary loss by up to 23.79\%, while also maintaining load balancing in downstream tasks, without any architectural modifications or additional components. We will release our code to contribute to the community.",,计算,计算: 该Session聚焦通过正交性和方差损失优化MoE专家模型的专门化，提升模型训练与推理的负载均衡效果，直接回应挑战点中对训推范式负载特征变化的跟踪与理解需求，助力团队精准把握未来负载演进。,计算: 正交性损失用于专家间的特征分离; 方差损失增强路由决策的区分度; 辅助负载均衡损失与新目标的兼容性; 提升专家模型的专门化能力; 在不同模型结构和基准上的泛化效果
THU 4 DEC,3:30-4:30,Oral Paper,→ Learning to Learn with Contrastive Meta-Objective,https://neurips.cc/virtual/2025/oral/115718,,4:30 PM,"Meta-learning enables learning systems to adapt quickly to new tasks, similar to humans.Different meta-learning approaches all work under/with the mini-batch episodic training framework. Such framework naturally gives the information about task identity, which can serve as additional supervision for meta-training to improve generalizability. We propose to exploit task identity as additional supervision in meta-training, inspired by the alignment and discrimination ability which is is intrinsic in human's fast learning.This is achieved by contrasting what meta-learners learn, i.e., model representations.The proposed ConML is evaluating and optimizing the contrastive meta-objective under a problem- and learner-agnostic meta-training framework.We demonstrate that ConML integrates seamlessly with existing meta-learners, as well as in-context learning models, and brings significant boost in performance with small implementation cost.",,,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4D,https://neurips.cc/virtual/2025/session/122564,,4:30 PM,,,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ Exploring Diffusion Transformer Designs via Grafting,https://neurips.cc/virtual/2025/oral/119280,,4:30 PM,"Designing model architectures requires decisions such as selecting operators (e.g., attention, convolution) and configurations (e.g., depth, width). However, evaluating the impact of these decisions on model quality requires costly pretraining, limiting architectural investigation.Inspired by how new software is built on existing code, we ask: can new architecture designs be studied using pretrained models? To this end, we present *grafting*, a simple approach for editing pretrained diffusion transformers (DiTs) to materialize new architectures under small compute budgets. Informed by our analysis of activation behavior and attention locality, we construct a testbed based on the DiT-XL/2 design to study the impact of grafting on model quality. Using this testbed, we develop a family of hybrid designs via grafting: replacing softmax attention with gated convolution, local attention, and linear attention, and replacing MLPs with variable expansion ratio and convolutional variants. Notably, many hybrid designs achieve good quality (FID: 2.38–2.64 vs. 2.27 for DiT-XL/2)using < 2 % pretraining compute. We then graft a text-to-image model (PixArt- Σ ), achieving a 1.43 × speedup with less than a 2% drop in GenEval score. Finally, we present a case study that restructures DiT-XL/2 by converting every pair of sequential transformer blocks into parallel blocks via grafting. This reduces model depth by 2 × and yields better quality (FID: 2.77) than other models of comparable depth. Together, we show that new diffusion model designs can be explored by grafting pretrained DiTs, with edits ranging from operator replacement to architecture restructuring. Code and grafted models: https://grafting.stanford.edu.",,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ Deep Compositional Phase Diffusion for Long Motion Sequence Generation,https://neurips.cc/virtual/2025/oral/116419,,4:30 PM,"Recent research on motion generation has shown significant progress in generating semantically aligned motion with singular semantics. However, when employing these models to create composite sequences containing multiple semantically generated motion clips, they often struggle to preserve the continuity of motion dynamics at the transition boundaries between clips, resulting in awkward transitions and abrupt artifacts. To address these challenges, we present Compositional Phase Diffusion, which leverages the Semantic Phase Diffusion Module (SPDM) and Transitional Phase Diffusion Module (TPDM) to progressively incorporate semantic guidance and phase details from adjacent motion clips into the diffusion process. Specifically, SPDM and TPDM operate within the latent motion frequency domain established by the pre-trained Action-Centric Motion Phase Autoencoder (ACT-PAE). This allows them to learn semantically important and transition-aware phase information from variable-length motion clips during training. Experimental results demonstrate the competitive performance of our proposed framework in generating compositional motion sequences that align semantically with the input conditions, while preserving phase transitional continuity between preceding and succeeding motion clips. Additionally, motion inbetweening task is made possible by keeping the phase parameter of the input motion sequences fixed throughout the diffusion process, showcasing the potential for extending the proposed framework to accommodate various application scenarios. Codes are available athttps://github.com/asdryau/TransPhase.",,,,
THU 4 DEC,3:30-4:30,Oral Paper,→ Mean Flows for One-step Generative Modeling,https://neurips.cc/virtual/2025/oral/115488,,4:30 PM,"We propose a principled and effective framework for one-step generative modeling. We introduce the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods. A well-defined identity between average and instantaneous velocities is derived and used to guide neural network training. Our method, termed the \textit{MeanFlow} model, is self-contained and requires no pre-training, distillation, or curriculum learning. MeanFlow demonstrates strong empirical performance: it achieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet 256 × 256 trained from scratch, significantly outperforming previous state-of-the-art one-step diffusion/flow models. Our study substantially narrows the gap between one-step diffusion/flow models and their multi-step predecessors, and we hope it will motivate future research to revisit the foundations of these powerful models.",,,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4E Position Paper Track Panels,https://neurips.cc/virtual/2025/session/122565,,4:30 PM,,,,,
FRI 5 DEC,8:30 a.m.,Invited Talk,From Benchmarks to Problems - A Perspective on Problem Finding in AI,https://neurips.cc/virtual/2025/invited-talk/109605,Kyunghyun Cho,9:30 AM,"During the past 15 years or so, I have worked on a series of seemingly distinct but eventually related problems, including machine learning algorithms, generative modeling with neural networks, machine translation, language modeling, medical imaging, a bit of healthcare, protein modeling and a bit of drug discovery. I chose to work on some of these problems intentionally, while it was pure serendipity that I worked on some others. It was only in hindsight that these seemingly different problems turned out to be closely related to each other from both technical, social and personal perspectives. In this talk, I plan to do my own retrospective on my own choices, be them intentional or not, on these problems and share with you my thoughts what our own discipline, which is sometimes called computer science, data science, machine learning or artificial intelligence, is.",,,,
FRI 5 DEC,2:30 p.m.,Invited Talk,Demystifying depth: Principles of learning in deep neural networks,https://neurips.cc/virtual/2025/invited-talk/109602,Andrew Saxe,3:30 PM,"Deep neural networks have revolutionized artificial intelligence, yet their inner workings remain poorly understood. This talk presents mathematical analyses of the nonlinear dynamics of learning in several solvable deep network models, offering theoretical insights into the role of depth. These models reveal how learning algorithms, data structure, initialization schemes, and architectural choices interact to produce hidden representations that afford complex generalization behaviors. A recurring theme across these analyses is a neural race: competing pathways within a deep network vie to explain the data, with an implicit bias toward shared representations. These shared representations in turn shape the network’s capacity for systematic generalization, multitasking, and transfer learning. I will show how such principles manifest across diverse architectures—including feedforward, recurrent, and linear attention networks. Together, these results provide analytic foundations for understanding how environmental statistics, network architecture, and learning dynamics jointly structure the emergence of neural representations and behavior.",,计算,计算: 本Session深入解析深度神经网络学习过程中的非线性动力学和隐含表示的形成机理，有助于理解训练和推理新范式下负载特征的巨大差异，精准把握训推范式演进机制，契合挑战点对负载演变的精准定义需求。,计算: 非线性学习动力学的数学分析; 共享表示与系统泛化能力的关系; 深度网络中的竞争路径机制; 网络架构与初始化方案的交互影响; 不同架构（前馈、循环、线性注意）下的学习表现
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5A,https://neurips.cc/virtual/2025/session/122566,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,→ EvoLM: In Search of Lost Language Model Training Dynamics,https://neurips.cc/virtual/2025/oral/119409,,11:00 AM,"Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage.We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",,计算; 诺亚,计算: EvoLM通过系统分析语言模型训练动态，揭示训推阶段的关键演进机制，有助于理解模型架构下负载特征差异。该Session针对挑战点“训推范式演进机理的跟踪与预测”，为团队提供了理论与实践结合的技术深度支持。; 诺亚: 本Session深入探讨语言模型训练动态，揭示预训练与后训练阶段的权衡，正好契合诺亚团队在推理策略优化及多模态长文本推理计算瓶颈的挑战，助力提升模型内置记忆更新机制和长序列多模态推理能力。,计算: 训练阶段划分及对模型性能影响分析; 训练中负载特征变化规律与预测; 持续预训练中遗忘问题的缓解策略; 监督微调与强化学习阶段的复杂权衡; 开源训练数据及评估管线的应用; 诺亚: 多阶段训练动态分析方法; 减轻领域专用持续预训练中的遗忘问题; 预训练与后训练间的知识迁移技巧; 针对长序列及多模态输入的推理策略优化; 监督微调与强化学习中的权衡机制
FRI 5 DEC,10:00-11:00,Oral Paper,→ Large Language Diffusion Models,https://neurips.cc/virtual/2025/oral/118609,,11:00 AM,"The capabilities of large language models (LLMs) are widely regarded as relying on autoregressive models (ARMs). We challenge this notion by introducingLLaDA, a diffusion model trained from scratch under the pre-training and supervised fine-tuning (SFT) paradigm. LLaDA employs a forward data masking process and a reverse generation process, parameterized by a Transformer to predict masked tokens. It provides a principled generative approach for probabilistic inference by optimizing a likelihood lower bound. Across extensive benchmarks on general tasks, math, code, and so on, LLaDA demonstrates strongscalabilityand performs comparably to our self-constructed ARM baselines. Remarkably, LLaDA 8B is competitive with strong LLMs like LLaMA3 8B inin-context learningand, after SFT, exhibits impressiveinstruction-followingabilities in case studies such as multi-turn dialogue. Moreover, LLaDA addresses the reversal curse, surpassing GPT-4o in a reversal poem completion task. Our findings show the promise of diffusion models for language modeling at scale and challenge the common assumption that core LLM capabilities discussed above inherently depend on ARMs. Project page and codes: \url{https://ml-gsai.github.io/LLaDA-demo/}.",,诺亚,诺亚: 该团队关注长序列图文多模态模型的输入范式突破，而Session中LLaDA提出的基于扩散模型的语言生成新范式，展示了处理复杂长文本结构的潜力，直接关联多模态长文本推理计算瓶颈，有助于团队技术创新。,诺亚: 基于扩散模型的语言生成机制及其优势; 输入数据的前向掩码处理方法与逆向生成过程; 模型对长序列文本的推理与优化策略; 扩散模型在多模态长文本建模中的应用潜能; 指令微调后的模型多轮对话能力提升
FRI 5 DEC,10:00-11:00,Oral Paper,→ Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?,https://neurips.cc/virtual/2025/oral/119945,,11:00 AM,"Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly in mathematics and programming tasks. It is widely believed that, similar to how traditional RL helps agents to explore and learn new strategies, RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed the capacity of the corresponding base models. In this study, we take a critical look at \textit{the current state of RLVR} by systematically probing the reasoning capability boundaries of RLVR-trained LLMs across diverse model families, RL algorithms, and math/coding/visual reasoning benchmarks, using pass@\textit{k} at large \textit{k} values as the evaluation metric.While RLVR improves sampling efficiency towards the correct path, we surprisingly find that current training does \emph{not} elicit fundamentally new reasoning patterns.We observe that while RLVR-trained models outperform their base models at smaller values of k (\eg, k =1), base models achieve higher pass@ k score when k is large.Moreover, we observe that the reasoning capability boundary of LLMs often narrows as RLVR training progresses.Further coverage and perplexity analysis shows that the reasoning paths generated by RLVR models are already included in the base models' sampling distribution, suggesting that their reasoning abilities originate from and are \textit{bounded} by the base model. From this perspective, treating the base model as an upper bound, our quantitative analysis shows that six popular RLVR algorithms perform similarly and remain far from optimal in fully leveraging the potential of the base model.In contrast, we find that distillation can introduce new reasoning patterns from the teacher and genuinely expand the model’s reasoning capabilities.Taken together, our findings suggest that current RLVR methods have not fully realized the potential of RL to elicit genuinely novel reasoning abilities in LLMs. This underscores the need for improved RL paradigms—such as continual scaling and multi-turn agent-environment interaction—to unlock this potential.",,诺亚,诺亚: 该Session深入探讨了强化学习与推理能力边界，尤其关注多模态长文本推理中的推理路径和能力限制，与团队挑战点“长序列图文多模态模型演进方向”高度契合，有助突破多模态推理计算瓶颈。,诺亚: 强化学习与可验证奖励（RLVR）在推理能力提升中的作用与局限; 长序列图文多模态推理模型的输入范式创新; 推理能力边界及模型自身潜力的量化分析方法; 多模态模型中的推理路径覆盖与困惑度分析; 强化学习训练过程中的推理能力收敛与扩展策略
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5B,https://neurips.cc/virtual/2025/session/122567,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,→ WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch,https://neurips.cc/virtual/2025/oral/121452,,11:00 AM,"LLM‑based agents have demonstrated great potential in generating and managing code within complex codebases. In this paper, we introduce WebGen-Bench, a novel benchmark designed to measure an LLM-based agent's ability to create multi-file website codebases from scratch. It contains diverse instructions for website generation, created through the combined efforts of human annotators and GPT-4o. These instructions span three major categories and thirteen minor categories, encompassing nearly all important types of web applications.To assess the quality of the generated websites, we generate test cases targeting each functionality described in the instructions. These test cases are then manually filtered, refined, and organized to ensure accuracy, resulting in a total of 647 test cases. Each test case specifies an operation to be performed on the website and the expected outcome of the operation.To automate testing and improve reproducibility, we employ a powerful web-navigation agent to execute test cases on the generated websites and determine whether the observed responses align with the expected results.We evaluate three high-performance code-agent frameworks—Bolt.diy, OpenHands, and Aider—using multiple proprietary and open-source LLMs as engines. The best-performing combination, Bolt.diy powered by DeepSeek-R1, achieves only 27.8\% accuracy on the test cases, highlighting the challenging nature of our benchmark.Additionally, we construct WebGen-Instruct, a training set consisting of 6,667 website-generation instructions. Training Qwen2.5-Coder-32B-Instruct on Bolt.diy trajectories generated from a subset of the training set achieves an accuracy of 38.2\%, surpassing the performance of the best proprietary model.We release our data-generation, training, and testing code, along with both the datasets and model weights at https://github.com/mnluzimu/WebGen-Bench.",,,,
FRI 5 DEC,10:00-11:00,Oral Paper,→ QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training,https://neurips.cc/virtual/2025/oral/117310,,11:00 AM,"Clinical decision‑making routinely demands reasoning over heterogeneous data, yet existing multimodal language models (MLLMs) remain largely vision‑centric and fail to generalize across clinical specialties. To bridge this gap, we introduce QoQ-Med-7B/32B, the first open generalist clinical foundation model that jointly reasons across medical images, time‑series signals, and text reports. QoQ-Med is trained with Domain‑aware Relative Policy Optimization (DRPO), a novel reinforcement‑learning objective that hierarchically scales normalized rewards according to domain rarity and modality difficulty, mitigating performance imbalance caused by skewed clinical data distributions. Trained on 2.61 million instruction tuning pairs spanning 9 clinical domains, we show that DRPO training boosts diagnostic performance by 43% in macro‑F1 on average across all visual domains as compared to other critic-free training methods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation data, it is able to highlight salient regions related to the diagnosis, with an IoU 10x higher than open models while reaching the performance of OpenAI o4-mini. To foster reproducibility and downstream research, we release (i) the full model weights, (ii) the modular training pipeline, and (iii) all intermediate reasoning traces.",,诺亚,诺亚: 该Session介绍了一种基于Domain-aware GRPO训练的多模态临床基础模型，重点解决了多模态长序列推理中的计算瓶颈，契合诺亚团队在长序列图文多模态模型输入范式突破的挑战。,诺亚: Domain-aware Relative Policy Optimization (DRPO)算法设计; 多模态长序列推理中的计算瓶颈优化; 多模态数据融合与权重平衡策略; 大规模临床多模态数据的训练方法; 模型可解释性与显著区域高效标注
FRI 5 DEC,10:00-11:00,Oral Paper,→ NOVA: A Benchmark for Rare Anomaly Localization and Clinical Reasoning in Brain MRI,https://neurips.cc/virtual/2025/oral/121771,,11:00 AM,"In many real-world applications, deployed models encounter inputs that differ from the data seen during training. Open-world recognition ensures that such systems remain robust as ever-emerging, previously _unknown_ categories appear and must be addressed without retraining.Foundation and vision-language models are pre-trained on large and diverse datasets with the expectation of broad generalization across domains, including medical imaging.However, benchmarking these models on test sets with only a few common outlier types silently collapses the evaluation back to a closed-set problem, masking failures on rare or truly novel conditions encountered in clinical use.We therefore present NOVA, a challenging, real-life _evaluation-only_ benchmark of $\sim$900 brain MRI scans that span 281 rare pathologies and heterogeneous acquisition protocols. Each case includes rich clinical narratives and double-blinded expert bounding-box annotations. Together, these enable joint assessment of anomaly localisation, visual captioning, and diagnostic reasoning. Because NOVA is never used for training, it serves as an _extreme_ stress-test of out-of-distribution generalisation: models must bridge a distribution gap both in sample appearance and in semantic space.  Baseline results with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B) reveal substantial performance drops, with approximately a 65\% gap in localisation compared to natural-image benchmarks and 40\% and 20\% gaps in captioning and reasoning, respectively, compared to resident radiologists. Therefore, NOVA establishes a testbed for advancing models that can detect, localize, and reason about truly unknown anomalies.",,,,
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5C,https://neurips.cc/virtual/2025/session/122568,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,→ High-dimensional neuronal activity from low-dimensional latent dynamics: a solvable model,https://neurips.cc/virtual/2025/oral/117112,,11:00 AM,"Computation in recurrent networks of neurons has been hypothesized to occur at the level of low-dimensional latent dynamics, both in artificial systems and in the brain. This hypothesis seems at odds with evidence from large-scale neuronal recordings in mice showing that neuronal population activity is high-dimensional. To demonstrate that low-dimensional latent dynamics and high-dimensional activity can be two sides of the same coin, we present an analytically solvable recurrent neural network (RNN) model whose dynamics can be exactly reduced to a low-dimensional dynamical system, but generates an activity manifold that has a high linear embedding dimension. This raises the question: Do low-dimensional latents explain the high-dimensional activity observed in mouse visual cortex? Spectral theory tells us that the covariance eigenspectrum alone does not allow us to recover the dimensionality of the latents, which can be low or high, when neurons are nonlinear. To address this indeterminacy, we develop Neural Cross-Encoder (NCE), an interpretable, nonlinear latent variable modeling method for neuronal recordings, and find that high-dimensional neuronal responses to drifting gratings and spontaneous activity in visual cortex can be reduced to low-dimensional latents, while the responses to natural images cannot. We conclude that the high-dimensional activity measured in certain conditions, such as in the absence of a stimulus, is explained by low-dimensional latents that are nonlinearly processed by individual neurons.",,,,
FRI 5 DEC,10:00-11:00,Oral Paper,→ Task-Optimized Convolutional Recurrent Networks Align with Tactile Processing in the Rodent Brain,https://neurips.cc/virtual/2025/oral/116232,,11:00 AM,"Tactile sensing remains far less understood in neuroscience and less effective in artificial systems compared to more mature modalities such as vision and language.We bridge these gaps by introducing a novel Encoder-Attender-Decoder (EAD) framework to systematically explore the space of task-optimized temporal neural networks trained on realistic tactile input sequences from a customized rodent whisker-array simulator. We identify convolutional recurrent neural networks (ConvRNNs) as superior encoders to purely feedforward and state-space architectures for tactile categorization. Crucially, these ConvRNN-encoder-based EAD models achieve neural representations closely matching rodent somatosensory cortex, saturating the explainable neural variability and revealing a clear linear relationship between supervised categorization performance and neural alignment.Furthermore, contrastive self-supervised ConvRNN-encoder-based EADs, trained with tactile-specific augmentations, match supervised neural fits, serving as an ethologically-relevant, label-free proxy.For neuroscience, our findings highlight nonlinear recurrent processing as important for general-purpose tactile representations in somatosensory cortex, providing the first quantitative characterization of the underlying inductive biases in this system. For embodied AI, our results emphasize the importance of recurrent EAD architectures to handle realistic tactile inputs, along with tailored self-supervised learning methods for achieving robust tactile perception with the same type of sensors animals use to sense in unstructured environments.",,,,
FRI 5 DEC,10:00-11:00,Oral Paper,→ Memory Mosaics at scale,https://neurips.cc/virtual/2025/oral/118784,,11:00 AM,"Memory Mosaics, networks of associative memories, have demonstrated appealing compositional and in-context learning capabilities on medium-scale networks (GPT-2 scale) and synthetic small datasets. This work shows that these favorable properties remain when we scale memory mosaics to large language model sizes (llama-8B scale) and real-world datasets. To this end, we scale memory mosaics to 10B size, we train them on one trillion tokens, we introduce a couple architectural modifications (memory mosaics v2), we assess their capabilities across three evaluation dimensions: training-knowledge storage, new-knowledge storage, and in-context learning. Throughout the evaluation, memory mosaics v2 match transformers on the learning of training knowledge (first dimension) and significantly outperforms transformers on carrying out new tasks at inference time (second and third dimensions). These improvements cannot be easily replicated by simply increasing the training data for transformers. A memory mosaics v2 trained on one trillion tokens still perform better on these tasks than a transformer trained on eight trillion tokens.",,海思; 诺亚,海思: 该Session介绍了Memory Mosaics在大规模模型上的应用，展示了在新任务推理和知识存储上的优势，契合海思挑战点中对长上下文推理注意力复杂度的优化需求，尤其是利用稀疏注意力与分块缓存实现效率提升。; 诺亚: 该Session展示了Memory Mosaics在大规模长文本模型上的突破，特别是在训练知识存储和新任务推理能力方面显著优于传统Transformer，切实对应“长序列图文多模态模型演进”挑战，实现输入范式层面的计算瓶颈突破。,海思: Memory Mosaics v2架构改进与应用; 大规模模型上的训练与推理效率提升; 稀疏注意力机制的设计与实现; 分块缓存策略及其在长上下文推理中的作用; 在上下文学习中提升模型适应性的方法; 诺亚: Memory Mosaics架构及其v2版本的改进细节; 大规模长文本建模与训练技巧（如10B规模、万亿级tokens训练）; 多模态长序列输入范式创新方法; 新知识存储与即时推理能力的评测指标与方法; Memory Mosaics与Transformer性能对比分析
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5D,https://neurips.cc/virtual/2025/session/122569,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,→ InfinityStar: Uniﬁed Spacetime AutoRegressive Modeling for Visual Generation,https://neurips.cc/virtual/2025/oral/118709,,11:00 AM,"We introduce InfinityStar, a unified spacetime autoregressive framework for high-resolution image and dynamic video synthesis. Building on the recent success of autoregressive modeling in both vision and language, our purely discrete approach jointly captures spatial and temporal dependencies within a single architecture. This unified design naturally supports a variety of generation tasks such as text-to-image, text-to-video, image-to-video, and long-duration video synthesis via straightforward temporal autoregression. Through extensive experiments, InfinityStar scores 83.74 on VBench, outperforming all autoregressive models by large margins, even surpassing diffusion competitors like HunyuanVideo. Without extra optimizations, our model generates a 5s, 720p video approximately 10 × faster than leading diffusion-based methods. To our knowledge, InfinityStar is the first discrete autoregressive video generator capable of producing industrial-level 720p videos. We release all code and models to foster further research in efficient, high-quality video generation.",,CBG,CBG: 团队关注相机轨迹控制和长视频一致性问题，而InfinityStar统一时空自回归框架兼顾视频长时间一致性并支持复杂生成任务，为团队提供高效、高质量的视频生成技术方案。,CBG: 统一时空自回归模型设计; 长视频生成中的时间一致性保证; 相机轨迹控制技术在视频生成中的应用; 高分辨率视频（720p）生成效率优化; 离散化生成方法与工业级视频输出
FRI 5 DEC,10:00-11:00,Oral Paper,→ PlayerOne: Egocentric World Simulator,https://neurips.cc/virtual/2025/oral/118938,,11:00 AM,"We introduce PlayerOne, the first egocentric realistic world simulator, facilitating immersive and unrestricted exploration within vividly dynamic environments. Given an egocentric scene image from the user, PlayerOne can accurately construct the corresponding world and generate egocentric videos that are strictly aligned with the real-scene human motion of the user captured by an exocentric camera. PlayerOne is trained in a coarse-to-fine pipeline that first performs pretraining on large-scale egocentric text-video pairs for coarse-level egocentric understanding, followed by finetuning on synchronous motion-video data extracted from egocentric-exocentric video datasets with our automatic construction pipeline. Besides, considering the varying importance of different components, we design a part-disentangled motion injection scheme, enabling precise control of part-level movements. In addition, we devise a joint reconstruction framework that progressively models both the 4D scene and video frames, ensuring scene consistency in the long-form video generation. Experimental results demonstrate its great generalization ability in precise control of varying human movements and world-consistent modeling of diverse scenarios. It marks the first endeavor into egocentric real-world simulation and can pave the way for the community to delve into fresh frontiers of world modeling and its diverse applications.",,CBG,CBG: PlayerOne作为首个自我视角现实世界模拟器，精准实现了基于单目视频的3D/4D稀疏重建及相机轨迹控制的视频生成，直接契合CBG挑战点2和挑战点3，极具研究和应用价值。,CBG: 单目视频驱动的3D/4D场景重建技术; 基于动作分解的部分运动注入算法; 长期视频中场景一致性建模; 多模态（视角转换）同步训练机制; 动态环境下的场景与动作联合重构
FRI 5 DEC,10:00-11:00,Oral Paper,→ BEDLAM2.0: Synthetic humans and cameras in motion,https://neurips.cc/virtual/2025/oral/121503,,11:00 AM,"Inferring 3D human motion from video remains a challenging problem with many applications. While traditional methods estimate the human in image coordinates, many applications require human motion to be estimated in world coordinates. This is particularly challenging when there is both human and camera motion. Progress on this topic has been limited by the lack of rich video data with ground truth human and camera movement. We address this with BEDLAM2.0, a new dataset that goes beyond the popular BEDLAM dataset in important ways. In addition to introducing more diverse and realistic cameras and camera motions, BEDLAM2.0 increases diversity and realism of body shape, motions, clothing, hair, and 3D environments. Additionally, it adds shoes, which were missing in BEDLAM. BEDLAM has become a key resource for training 3D human pose and motion regressors today and we show that BEDLAM2.0 is significantly better, particularly for training methods that estimate humans in world coordinates. We compare state-of-the art methods trained on BEDLAM and BEDLAM2.0, and find that BEDLAM2.0 significantly improves accuracy over BEDLAM.  For research purposes, we provide the rendered videos, ground truth body parameters, and camera motions. We also provide the 3D assets to which we have rights and links to those from third parties.",,CBG,CBG: 该Session介绍了BEDLAM2.0数据集，显著提升了单目视频中人体与相机运动的三维世界坐标估计性能，紧密契合CBG团队关于基于单目视频快速准确进行3D/4D稀疏重建的挑战点。,CBG: 单目视频中人体三维姿态与运动的估计技术; 三维人体和相机运动联合建模方法; 基于高质量合成数据集的训练策略; 人体三维形状和动态多样性模拟; 世界坐标系下运动重建的算法优化
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5E,https://neurips.cc/virtual/2025/session/122570,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,→ Boosting Knowledge Utilization in Multimodal Large Language Models via Adaptive Logits Fusion and Attention Reallocation,https://neurips.cc/virtual/2025/oral/115856,,11:00 AM,"Despite their recent progress, Multimodal Large Language Models (MLLMs) often struggle in knowledge-intensive tasks due to the limited and outdated parametric knowledge acquired during training. Multimodal Retrieval Augmented Generation addresses this issue by retrieving contextual knowledge from external databases, thereby enhancing MLLMs with expanded knowledge sources. However, existing MLLMs often fail to fully leverage the retrieved contextual knowledge for response generation. We examine representative MLLMs and identify two major causes, namely, attention bias toward different tokens and knowledge conflicts between parametric and contextual knowledge. To this end, we design Adaptive Logits Fusion and Attention Reallocation (ALFAR), a training-free and plug-and-play approach that improves MLLM responses by maximizing the utility of the retrieved knowledge. Specifically, ALFAR tackles the challenges from two perspectives. First, it alleviates attention bias by adaptively shifting attention from visual tokens to relevant context tokens according to query-context relevance. Second, it decouples and weights parametric and contextual knowledge at output logits, mitigating conflicts between the two types of knowledge. As a plug-and-play method, ALFAR achieves superior performance across diverse datasets without requiring additional training or external tools. Extensive experiments over multiple MLLMs and benchmarks show that ALFAR consistently outperforms the state-of-the-art by large margins. Our code and data are available at https://github.com/Lackel/ALFAR.",,海思; 诺亚,海思: 该Session提出的Adaptive Logits Fusion和Attention Reallocation方法，有效解决了长上下文推理中注意力分配的复杂度问题，契合海思团队关于稀疏注意力与分块缓存实现线性复杂度的挑战。参与有助于优化长上下文模型的性能和知识利用效率。; 诺亚: 本Session提出的Adaptive Logits Fusion和Attention Reallocation技术有效缓解多模态长序列推理中的注意力偏差与知识冲突，直接对应诺亚团队挑战点3关于长序列图文多模态模型突破计算瓶颈的需求，有助推动输入范式创新。,海思: 基于查询-上下文相关性的动态注意力重分配技术; 输出层参数与检索知识的权重解耦与融合; 提升多模态大型语言模型在知识密集型任务中的表现; 无训练需求的插件式模型增强方法; 注意力复杂度优化与稀疏化机制; 诺亚: 利用自适应注意力重分配缓解视觉与文本Token间的注意力偏差; 在输出层融合参数化与上下文知识以解决知识冲突; 开发无需额外训练的插件式多模态样式融合方法; 提升多模态长文本推理的计算效率与模型响应质量; 多数据集验证适用性与效果的跨模型推广能力
FRI 5 DEC,10:00-11:00,Oral Paper,→ HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models,https://neurips.cc/virtual/2025/oral/118373,,11:00 AM,"Multi-modal large language models (MLLMs) have emerged as a transformative approach for aligning visual and textual understanding. They typically require extremely high computational resources (e.g., thousands of GPUs) for training to achieve cross-modal alignment at multi-granularity levels. We argue that a key source of this inefficiency lies in the vision encoders they widely equip with, e.g., CLIP and SAM, which lack the alignment with language at multi-granularity levels. To address this issue, in this paper, we leverage hyperbolic space, which inherently models hierarchical levels and thus provides a principled framework for bridging the granularity gap between visual and textual modalities at an arbitrary granularity level. Concretely, we propose an efficient training paradigm for MLLMs, dubbed as \blg, which can optimize visual representations to align with their textual counterparts at an arbitrary granularity level through dynamic hyperbolic radius adjustment in hyperbolic space. \alg employs learnable matrices with M\""{o}bius multiplication operations, implemented via three effective configurations: diagonal scaling matrices, block-diagonal matrices, and banded matrices, providing a flexible yet efficient parametrization strategy. Comprehensive experiments across multiple MLLM benchmarks demonstrate that \alg consistently improves both existing pre-training and fine-tuning MLLMs clearly with less than 1\% additional parameters.",,诺亚,诺亚: 该Session提出利用双曲空间有效训练多模态大型语言模型，针对视觉与文本多粒度对齐的计算瓶颈，与诺亚团队关于长序列图文多模态模型输入范式突破的挑战点高度契合，有助于优化长文本推理效率。,诺亚: 双曲空间在多模态对齐中的应用与原理; 动态调整双曲空间半径实现多粒度视觉文本对齐; Möbius乘法及其在视觉表示优化中的实现方式; 高效参数化策略（对角、块对角及带状矩阵）设计; 减少模型额外参数消耗提升训练效率的技术
FRI 5 DEC,10:00-11:00,Oral Paper,→ Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion,https://neurips.cc/virtual/2025/oral/118167,,11:00 AM,"Multimodal learning (MML) is significantly constrained by modality imbalance, leading to suboptimal performance in practice. While existing approaches primarily focus on balancing the learning of different modalities to address this issue, they fundamentally overlook the inherent disproportion in model classification ability, which serves as the primary cause of this phenomenon. In this paper, we propose a novel multimodal learning approach to dynamically balance the classification ability of weak and strong modalities by incorporating the principle of boosting. Concretely, we first propose a sustained boosting algorithm in multimodal learning by simultaneously optimizing the classification and residual errors. Subsequently, we introduce an adaptive classifier assignment strategy to dynamically facilitate the classification performance of the weak modality. Furthermore, we theoretically analyze the convergence property of the cross-modal gap function, ensuring the effectiveness of the proposed boosting scheme. To this end, the classification ability of strong and weak modalities is expected to be balanced, thereby mitigating the imbalance issue. Empirical experiments on widely used datasets reveal the superiority of our method through comparison with various state-of-the-art (SOTA) multimodal learning baselines. The source code is available at https://github.com/njustkmg/NeurIPS25-AUG.",,诺亚,诺亚: 该Session提出通过持续boosting算法动态平衡多模态弱强分类能力，直接关联挑战点“长序列图文多模态模型演进”中的多模态长文本推理瓶颈，助力突破输入范式限制，实现更优性能。,诺亚: 持续boosting算法在多模态学习中的应用; 分类能力动态平衡机制; 跨模态残差误差优化策略; 自适应分类器分配方法; 跨模态差距函数的收敛性分析
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6A,https://neurips.cc/virtual/2025/session/122571,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds,https://neurips.cc/virtual/2025/oral/117790,,4:30 PM,"Bandeira et al. (2022) introduced the Franz-Parisi (FP) criterion for characterizing the computational hard phases in statistical detection problems. The FP criterion, based on an annealed version of the celebrated Franz-Parisi potential from statistical physics, was shown to be equivalent to low-degree polynomial (LDP) lower bounds for Gaussian additive models, thereby connecting two distinct approaches to understanding the computational hardness in statistical inference. In this paper, we propose a refined FP criterion that aims to better capture the geometric ``overlap"" structure of statistical models. Our main result establishes that this optimized FP criterion is equivalent to Statistical Query (SQ) lower bounds---another foundational framework in computational complexity of statistical inference.  Crucially, this equivalence holds under a mild, verifiable assumption satisfied by a broad class of statistical models, including Gaussian additive models, planted sparse models, as well as non-Gaussian component analysis (NGCA), single-index (SI) models, and convex truncation detection settings. For instance, in the case of convex truncation tasks, the assumption is equivalent with the Gaussian correlation inequality (Royen, 2014) from convex geometry. In addition to the above, our equivalence not only unifies and simplifies the derivation of several known SQ lower bounds—such as for the NGCA model (Diakonikolas et al., 2017) and the SI model (Damian et al., 2024)—but also yields new SQ lower bounds of independent interest, including for the computational gaps in mixed sparse linear regression (Arpino et al., 2023) and convex truncation (De et al., 2023).",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy,https://neurips.cc/virtual/2025/oral/119076,,4:30 PM,"A central challenge in machine learning is to understand how noise or measurement errors affect low-rank approximations, particularly in the spectral norm. This question is especially important in differentially private low-rank approximation, where one aims to preserve the top-$p$ structure of a data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius norm error or changes in reconstruction quality, but these metrics can over- or under-estimate true subspace distortion. The spectral norm, by contrast, captures worst-case directional error and provides the strongest utility guarantees. We establish new high-probability spectral-norm perturbation bounds for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem and explicitly capture interactions between a matrix $A \in \mathbb{R}^{n \times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and norm conditions, our bounds yield sharp estimates for $\| (A + E)_p - A_p \|$, where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up to a factor of $\sqrt{n}$. As an application, we derive improved utility guarantees for differentially private PCA, resolving an open problem in the literature. Our analysis relies on a novel contour bootstrapping method from complex analysis and extends it to a broad class of spectral functionals, including polynomials and matrix exponentials. Empirical results on real-world datasets confirm that our bounds closely track the actual spectral error under diverse perturbation regimes.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization,https://neurips.cc/virtual/2025/oral/116693,,4:30 PM,"This paper addresses the Bayesian optimization problem (also referred to as the Bayesian setting of the Gaussian process bandit), where the learner seeks to minimize the regret under a function drawn from a known Gaussian process (GP). Under a Mat\'ern kernel with some extent of smoothness, we show that the Gaussian process upper confidence bound (GP-UCB) algorithm achieves $\tilde{O}(\sqrt{T})$ cumulative regret with high probability. Furthermore, our analysis yields $O(\sqrt{T \ln^2 T})$ regret under a squared exponential kernel. These results fill the gap between the existing regret upper bound of GP-UCB and the current best upper bound provided by Scarlett [2018]. The key idea in our proof is to capture the concentration behavior of the input sequence realized by GP-UCB, enabling us to handle GP's information gain in a refined manner.",,,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6B,https://neurips.cc/virtual/2025/session/122572,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability,https://neurips.cc/virtual/2025/oral/116902,,4:30 PM,"Graph Neural Networks (GNNs) are widely used for node classification, yet their opaque decision-making limits trust and adoption. While local explanations offer insights into individual predictions, global explanation methods—those that characterize an entire class—remain underdeveloped. Existing global explainers rely on motif discovery in small graphs, an approach that breaks down in large, real-world settings where subgraph repetition is rare, node attributes are high-dimensional, and predictions arise from complex structure-attribute interactions. We propose GnnXemplar, a novel global explainer inspired from Exemplar Theory from cognitive science. GnnXemplar identifies representative nodes in the GNN embedding space—exemplars—and explains predictions using natural language rules derived from their neighborhoods. Exemplar selection is framed as a coverage maximization problem over reverse $k$-nearest neighbors, for which we provide an efficient greedy approximation. To derive interpretable rules, we employ a self-refining prompt strategy using large language models (LLMs). Experiments across diverse benchmarks show that GnnXemplar significantly outperforms existing methods in fidelity, scalability, and human interpretability, as validated by a user study with 60 participants.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ RAG4GFM: Bridging Knowledge Gaps in Graph Foundation Models through Graph Retrieval Augmented Generation,https://neurips.cc/virtual/2025/oral/115563,,4:30 PM,"Graph Foundation Models (GFMs) have demonstrated remarkable potential across graph learning tasks but face significant challenges in knowledge updating and reasoning faithfulness. To address these issues, we introduce the Retrieval-Augmented Generation (RAG) paradigm for GFMs, which leverages graph knowledge retrieval. We propose RAG4GFM, an end-to-end framework that seamlessly integrates multi-level graph indexing, task-aware retrieval, and graph fusion enhancement. RAG4GFM implements a hierarchical graph indexing architecture, enabling multi-granular graph indexing while achieving efficient logarithmic-time retrieval. The task-aware retriever implements adaptive retrieval strategies for node, edge, and graph-level tasks to surface structurally and semantically relevant evidence. The graph fusion enhancement module fuses retrieved graph features with query features and augments the topology with sparse adjacency links that preserve structural and semantic proximity, yielding a fused graph for GFM inference.Extensive experiments conducted across diverse GFM applications demonstrate that RAG4GFM significantly enhances both the efficiency of knowledge updating and reasoning faithfulness\footnote{Code: \url{https://github.com/Matrixmax/RAG4GFM}.}.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ Discovering Opinion Intervals from Conflicts in Signed Graphs,https://neurips.cc/virtual/2025/oral/115063,,4:30 PM,"Online social media provide a platform for people to discuss current events and exchange opinions with their peers. While interactions are predominantly positive, in recent years, there has been a lot of research to understand the conflicts in social networks and how they are based on different views and opinions.  In this paper, we ask whether the conflicts in a network reveal a small and interpretable set of prevalent opinion ranges that explain the users' interactions.  More precisely, we consider signed graphs, where the edge signs indicate positive and negative interactions of node pairs, and our goal is to infer opinion intervals that are consistent with the edge signs.  We introduce an optimization problem that models this question, and we give strong hardness results and a polynomial-time approximation scheme by utilizing connections to interval graphs and the Correlation Clustering problem.  We further provide scalable heuristics and show that in experiments they yield more expressive solutions than Correlation Clustering baselines. We also present a case study on a novel real-world dataset from the German parliament, showing that our algorithms can recover the political leaning of German parties based on co-voting behavior.",,,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6C,https://neurips.cc/virtual/2025/session/122573,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ Generalized Linear Mode Connectivity for Transformers,https://neurips.cc/virtual/2025/oral/118595,,4:30 PM,"Understanding the geometry of neural network loss landscapes is a central question in deep learning, with implications for generalization and optimization. A striking phenomenon is $\textit{linear mode connectivity}$ (LMC), where independently trained models can be connected by low- or zero-barrier paths, despite appearing to lie in separate loss basins. However, this is often obscured by symmetries in parameter space—such as neuron permutations—which make functionally equivalent models appear dissimilar. Prior work has predominantly focused on neuron reordering through permutations, but such approaches are limited in scope and fail to capture the richer symmetries exhibited by modern architectures such as Transformers. In this work, we introduce a unified framework that captures four symmetry classes—permutations, semi-permutations, orthogonal transformations, and general invertible maps—broadening the set of valid reparameterizations and subsuming many previous approaches as special cases. Crucially, this generalization enables, for the first time, the discovery of low- and zero-barrier linear interpolation paths between independently trained Vision Transformers and GPT-2 models. Furthermore, our framework extends beyond pairwise alignment, to multi-model and width-heterogeneous settings, enabling alignment across architectures of different sizes. These results reveal deeper structure in the loss landscape and underscore the importance of symmetry-aware analysis for understanding model space geometry.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ On Linear Mode Connectivity of Mixture-of-Experts Architectures,https://neurips.cc/virtual/2025/oral/118036,,4:30 PM,"Linear Mode Connectivity (LMC) is a notable phenomenon in the loss landscapesof neural networks, wherein independently trained models have been observed tobe connected—up to permutation symmetries—by linear paths in parameter spacealong which the loss remains consistently low. This observation challenges classicalviews of non-convex optimization and has implications for model ensembling,generalization, and our understanding of neural loss geometry. Inspired by recentstudies on LMC in standard neural networks, we systematically investigate thisphenomenon within Mixture-of-Experts (MoE) architectures—a class of modelsknown for their scalability and computational efficiency, which combine traditionalneural networks—referred to as experts—through a learnable gating mechanism.We begin by conducting a comprehensive analysis of both dense and sparse gatingregimes, demonstrating that the symmetries inherent to MoE architectures arefully characterized by permutations acting on both the expert components and thegating function. Building on these foundational findings, we propose a matchingalgorithm that enables alignment between independently trained MoEs, therebyfacilitating the discovery of LMC. Finally, we empirically validate the presence ofLMC using our proposed algorithm across diverse MoE configurations—includingdense, sparse, and shared-expert variants—under a wide range of model settingsand datasets of varying scales and modalities. Our results confirm the existenceof LMC in MoE architectures and offer fundamental insights into the functionallandscape and optimization dynamics of deep learning models.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ Learning (Approximately) Equivariant Networks via Constrained Optimization,https://neurips.cc/virtual/2025/oral/118376,,4:30 PM,"Equivariant neural networks are designed to respect symmetries through their architecture, boosting generalization and sample efficiency when those symmetries are present in the data distribution. Real-world data, however, often departs from perfect symmetry because of noise, structural variation, measurement bias, or other symmetry-breaking effects. Strictly equivariant models may struggle to fit the data, while unconstrained models lack a principled way to leverage partial symmetries. Even when the data is fully symmetric, enforcing equivariance can hurt training by limiting the model to a restricted region of the parameter space. Guided by homotopy principles, where an optimization problem is solved by gradually transforming a simpler problem into a complex one, we introduce Adaptive Constrained Equivariance (ACE), a constrained optimization approach that starts with a flexible, non-equivariant model and gradually reduces its deviation from equivariance. This gradual tightening smooths training early on and settles the model at a data-driven equilibrium, balancing between equivariance and non-equivariance. Across multiple architectures and tasks, our method consistently improves performance metrics, sample efficiency, and robustness to input perturbations compared with strictly equivariant models and heuristic equivariance relaxations.",,,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6D,https://neurips.cc/virtual/2025/session/122574,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ A Snapshot of Influence: A Local Data Attribution Framework for Online Reinforcement Learning,https://neurips.cc/virtual/2025/oral/115686,,4:30 PM,"Online reinforcement learning (RL) excels in complex, safety-critical domains but suffers from sample inefficiency, training instability, and limited interpretability. Data attribution provides a principled way to trace model behavior back to training samples, yet existing methods assume fixed datasets, which is violated in online RL where each experience both updates the policy and shapes future data collection.In this paper, we initiate the study of data attribution for online RL, focusing on the widely used Proximal Policy Optimization (PPO) algorithm. We start by establishing alocalattribution framework, interpreting model checkpoints with respect to the records in the recent training buffer. We design two target functions, capturing agent action and cumulative return respectively, and measure each record's contribution through gradient similarity between its training loss and these targets. We demonstrate the power of this framework through three concrete applications: diagnosis of learning, temporal analysis of behavior formation, and targeted intervention during training. Leveraging this framework, we further propose an algorithm, iterative influence-based filtering (IIF), for online RL training that iteratively performs experience filtering to refine policy updates. Across standard RL benchmarks (classic control, navigation, locomotion) to RLHF for large language models, IIF reduces sample complexity, speeds up training, and achieves higher returns. Together, these results open a new direction for making online RL more interpretable, efficient, and effective.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities,https://neurips.cc/virtual/2025/oral/115732,,4:30 PM,"Scaling up self-supervised learning has driven breakthroughs in language and vision, yet comparable progress has remained elusive in reinforcement learning (RL). In this paper, we study building blocks for self-supervised RL that unlock substantial improvements in scalability, with network depth serving as a critical factor. Whereas most RL papers in recent years have relied on shallow architectures (around 2 -- 5 layers), we demonstrate that increasing the depth up to 1024 layers can significantly boost performance.Our experiments are conducted in an unsupervised goal-conditioned setting, where no demonstrations or rewards are provided, so an agent must explore (from scratch) and learn how to maximize the likelihood of reaching commanded goals.Evaluated on simulated locomotion and manipulation tasks, our approach increases performance on the self-supervised contrastive RL algorithm by $2\times$ -- $50\times$, outperforming other goal-conditioned baselines.Increasing the model depth not only increases success rates but also qualitatively changes the behaviors learned.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ Learning long range dependencies through time reversal symmetry breaking,https://neurips.cc/virtual/2025/oral/115363,,4:30 PM,"Deep State Space Models (SSMs) reignite physics-grounded compute paradigms, as RNNs could natively be embodied into dynamical systems. This calls for dedicated learning algorithms obeying to core physical principles,  with efficient techniques to simulate these systems and guide their design. We propose \emph{Recurrent Hamiltonian Echo Learning} (RHEL), an algorithm which provably computes loss gradients as finite differences of physical trajectories of non-dissipative, \emph{Hamiltonian systems}. In ML terms, RHEL only requires three ``forward passes'' irrespective of model size, without explicit Jacobian computation, nor incurring any variance in the gradient estimation. Motivated by the potential to implement our algorithm in non-digital physical systems, we first introduce RHEL in \emph{continuous time} and demonstrate its formal equivalence with the continuous adjoint state method.To facilitate the simulation of Hamiltonian systems trained by RHEL, we propose a \emph{discrete-time} version of RHEL which is equivalent to Backpropagation Through Time (BPTT) when applied to a class of recurrent modules which we call \emph{Hamiltonian Recurrent Units} (HRUs). This setting allows us to demonstrate the scalability of RHEL by generalizing these results to hierarchies of HRUs, which we call \emph{Hamiltonian SSMs} (HSSMs). We apply RHEL to train HSSMs with linear and nonlinear dynamics on a variety of time-series tasks ranging from mid-range to long-range classification and regression with sequence length reaching $\sim 50k$. We show that RHEL consistently matches the performance of BPTT across all models and tasks. This work opens new doors for the design of scalable, energy-efficient physical systems endowed with self-learning capabilities for sequence modelling.",,,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6E,https://neurips.cc/virtual/2025/session/122575,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,→ KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction,https://neurips.cc/virtual/2025/oral/118742,,4:30 PM,"Transformer-based large language models (LLMs) cache context as key-value (KV) pairs during inference. As context length grows, KV cache sizes expand, leading to substantial memory overhead and increased attention latency. This paper introduces \textit{KVzip}, a query-agnostic KV cache eviction method enabling effective reuse of compressed KV caches across diverse queries. KVzip quantifies the importance of a KV pair using the underlying LLM to reconstruct original contexts from cached KV pairs, subsequently evicting pairs with lower importance. Extensive empirical evaluations demonstrate that KVzip reduces KV cache size by $3$-$4\times$ and FlashAttention decoding latency by approximately $2\times$, with negligible performance loss in question-answering, retrieval, reasoning, and code comprehension tasks. Evaluations include various models such as LLaMA3.1, Qwen2.5, and Gemma3, with context lengths reaching up to 170K tokens. KVzip significantly outperforms existing query-aware KV eviction methods, which suffer from performance degradation even at a 90\% cache budget ratio under multi-query scenarios.",,海思,海思: 该Session提出的KVzip技术有效缓解长上下文推理中KV缓存带来的注意力复杂度和内存压力，直接对应团队挑战点“长上下文推理注意力复杂度过高”。该方法通过稀疏缓存压缩及重要KV对重构策略，有助于实现线性或次线性复杂度。,海思: 基于重要性评估的KV缓存压缩机制; 跨多查询的缓存重用与Eviction策略; 上下文重构技术以支持查询无关缓存; 大规模上下文（170K tokens）下的缓存管理; FlashAttention环境下延迟优化方法
FRI 5 DEC,3:30-4:30,Oral Paper,→ MokA: Multimodal Low-Rank Adaptation for MLLMs,https://neurips.cc/virtual/2025/oral/116048,,4:30 PM,"In this paper, we reveal that most current efficient multimodal fine-tuning methods are hindered by a key limitation: they are directly borrowed from LLMs, often neglecting the intrinsic differences of multimodal scenarios and even affecting the full utilization of all modalities. Inspired by our empirical observation, we argue that unimodal adaptation and cross-modal adaptation are two essential parts for the effective fine-tuning of MLLMs. From this perspective, we propose Multimodal Low-rank Adaptation (MokA), a multimodal-aware efficient fine-tuning strategy that takes multimodal characteristics into consideration. It compresses unimodal information by modality-specific parameters while explicitly enhancing cross-modal interaction, ensuring both unimodal and cross-modal adaptation. Extensive experiments cover three representative multimodal scenarios (audio-visual-text, visual-text, and speech-text), and multiple LLM backbones (LLaMA2, Qwen2, Qwen2.5-VL, etc). Consistent improvements indicate the efficacy and versatility of the proposed method. Ablation studies and efficiency evaluation are also conducted to fully asses our method. Overall, we think MokA provides a more targeted solution for efficient adaptation of MLLMs, paving the way for further exploration.",,诺亚,诺亚: 本Session提出的MokA方法针对多模态低秩适配，有助于优化长序列图文多模态模型的输入范式和推理效率，直接契合团队关于长文本推理计算瓶颈的挑战点。参与有助于突破多模态长文本处理技术瓶颈。,诺亚: 多模态低秩适配技术设计; 单模态与跨模态适配机制; 多模态输入范式优化; 长序列多模态推理计算效率提升; 多模态大模型高效微调策略
FRI 5 DEC,3:30-4:30,Oral Paper,→ ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism,https://neurips.cc/virtual/2025/oral/117338,,4:30 PM,"Multimodal large language models (MLLMs) extend LLMs to handle images, videos, and audio by incorporating feature extractors and projection modules. However, these additional components—combined with complex inference pipelines and heterogeneous workloads—introduce significant inference overhead. Therefore, efficiently serving MLLMs remains a major challenge. Current tightly coupled serving architectures struggle to distinguish between mixed request types or adapt parallelism strategies to different inference stages, leading to increased time-to-first-token (TTFT) and poor resource utilization. To address this, we introduce Elastic Multimodal Parallelism (EMP), a new serving paradigm that elastically adapts to resource heterogeneity across request types and inference stages. Building upon EMP, we develop ElasticMM, an MLLM serving system that (1) separates requests into independent modality groups with dynamic resource allocation via a modality-aware load balancer; (2) decouples inference stages and enables parallelism adjustment and adaptive scaling via elastic partition scheduling; and (3) improves inference efficiency through unified multimodal prefix caching and non-blocking encoding. Experiments on diverse real-world datasets show that ElasticMM outperforms state-of-the-art (SOTA) serving systems, reducing TTFT by up to 4.2 × and achieving 3.2–4.5 × higher throughput while meeting service-level objectives (SLOs).",,,,
SAT 6 DEC,8 a.m.,Workshop,Structured Probabilistic Inference and Generative Modeling,https://neurips.cc/virtual/2025/workshop/109570,,5:00 PM,,"Overview: The NeurIPS 2025 Workshop on Structured Probabilistic Inference & Generative Modeling focuses on the theory, methodology, and application of structured probabilistic inference and generative modeling. The workshop aims to address challenges in probabilistic methods, especially when applied to highly structured data, and to foster collaboration and discussion among experts from academia and industry. The event will explore the intersection of probabilistic inference and foundation models, providing a platform for discussing applications and challenges in encoding domain knowledge. | Research Interests: Generative methods for graphs, 3D, time series, text, video, and other structured modalities, Probabilistic inference in models for reward fine-tuning, alignment, acceleration, watermarking, Scaling and accelerating inference and generative models, Uncertainty quantification in AI systems, Applications in sampling, optimization, decision making, Applications and practical implementations of existing methods to areas in science, Empirical analysis comparing different architectures for a given data modality and application, Relevance of probabilistic inference in the era of foundation models",,,
SAT 6 DEC,8 a.m.,Workshop,Reliable ML from Unreliable Data,https://neurips.cc/virtual/2025/workshop/109580,,5:00 PM,"Distributions shift, chatbots get jail‑broken, users game algorithms — how do we build reliable machine learning when data are missing, corrupted, or strategically manipulated?This workshop bridges theory and practice to tackle these challenges, bringing together researchers working on distribution shift, adversarial robustness, and strategic behaviour to chart principled yet deployable solutions for Reliable ML from Unreliable Data.","Overview: The Reliable ML 2025 workshop, held at NeurIPS 2025 in San Diego, focuses on developing reliable machine learning systems from unreliable data. It addresses challenges such as distribution shifts, adversarial robustness, and strategic behavior in socio-technical systems. The workshop aims to bridge theory and practice by bringing together researchers to propose principled and deployable solutions for robust and reliable machine learning under imperfect data conditions. | Research Interests: Distribution shift and transfer learning, Adversarial robustness and defenses, Strategic behavior in socio-technical systems, Learning with missing or biased data, Causal inference beyond overlap, with confounders, or with errors, LLM safety and alignment, Robustness in interactive environments",,,
SAT 6 DEC,8 a.m.,Workshop,GenProCC: 1st Workshop on Generative and Protective AI for Content Creation,https://neurips.cc/virtual/2025/workshop/109545,,5:00 PM,"Recent advancements in generative AI (GenAI) have empowered machines to create high-quality content across diverse modalities - text, image, audio, and video - with impressive fluency and creativity. From GPT-4o and Stable Diffusion to Sora and MMAudio, the explosion of X-to-X generation (e.g., text-to-image, video-to-audio) is unlocking new frontiers in science, education, entertainment, and art.While GenAI has shown significant potential in creative applications (e.g., music, films, arts), these breakthroughs also raise pressing concerns related to safety, copyright, and ethical use. Generative models can be exploited to spread misinformation, violate intellectual property rights, or diminish human agency in creative processes. As such, there is an increasing need to balance innovation with protection, ensuring that AI-powered creative tools are used responsibly and ethically.This workshop, GenProCC: Generative and Protective AI for Content Creation, brings together researchers, creators, and practitioners at the intersection of content generation and IP protection. By uniting the generative AI and creator communities, the GenProCC workshop aims to explore the latest advances, challenges, and opportunities in the rapidly evolving field.","Overview: The GenProCC NeurIPS 2025 Workshop focuses on the intersection of generative and protective AI for content creation. It aims to explore the advancements in generative AI technologies that enable machines to create high-quality content across various modalities such as text, image, audio, and video. The workshop addresses the potential of these technologies in creative applications while also highlighting the ethical, safety, and copyright concerns they raise. The event seeks to balance innovation with protection, ensuring responsible and ethical use of AI-powered creative tools. | Research Interests: Controllable Generative AI for Content Creation, Protective AI Approaches for Content Creation, Creative Practices with Generative AI, Controllable X-to-X generation, Interactive or iterative generation pipelines, Evaluations and benchmarks for controllability, Applications of controllability/protection in creative practices, Digital watermarking, fingerprinting, and provenance tracking, Benchmarks for evaluating protection in generative systems, Case studies and design research for content creation, Human-in-the-loop approaches for real-world GenAI creation workflows, Emerging applications of GenAI in content creation",,,
SAT 6 DEC,8 a.m.,Workshop,What Makes a Good Video: Next Practices in Video Generation and Evaluation,https://neurips.cc/virtual/2025/workshop/109548,,5:00 PM,"This workshop aims to explore how real-world advances in video generation increasingly rely on forwardlooking evaluation frameworks and to collaboratively shape the next generation of high-quality video synthesis. Through a combination of invited talks, academic presentations, and expert discussions featuring leading voices from both academia and industry, the workshop bridges academic foundations and industrial insights across the modeling, evaluation, and deployment of video generation. We welcome contributions from computer vision, generative modeling, video-language learning, evaluation methodology, and human-centered AI to shape the next generation of high-quality video synthesis collaboratively.","Overview: The 'What Makes a Good Video: Next Practices in Video Generation and Evaluation' workshop at NeurIPS 2025 aims to explore the evolution of video generation models. It focuses on understanding the limitations of current video models and identifying future research directions. The workshop features discussions on video generation, understanding, benchmarks, and applications, with insights from experts in academia and industry. | Research Interests: Video Generation Models, Benchmarks & Evaluation, Applications",CBG,CBG: 该团队面临的相机轨迹控制及长视频一致性挑战与本次视频生成与评估研讨会高度吻合。本Session聚焦视频生成模型和一致性问题，能助力团队提升视频生成质量，解决关键技术难题。,CBG: 相机轨迹控制算法与实现; 长视频生成中的帧间一致性维护技术; 前瞻性视频生成评估框架与标准; 视频生成模型的稳定性与泛化能力; 跨领域视频生成应用与展示方法
SAT 6 DEC,8 a.m.,Workshop,ML x OR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making,https://neurips.cc/virtual/2025/workshop/109555,,5:00 PM,"Much of traditional decision-making science is grounded in the mathematical formulations and analyses of structured systems to recommend decisions that are optimized, robust, and uncertainty-aware. This scientific approach, rooted in the field of Operations Research (OR), has evolved through decades of advancements in stochastic modeling, computational simulation and optimization, and exhibits key strengths in methodological rigor and uncertainty encoding. On the other hand, recent advances in the AI/ML space have eschewed this model-based paradigm and increasingly embraced, to great success, model-free algorithmic design frameworks. This workshop, which is the first NeurIPS workshop explicitly themed and structured on ML-OR synergization, aspires to present recent developments, challenges and emerging research to accelerate ML-OR synthesis. By integrating ML into established OR methodologies, we have the opportunities to produce more data-centric and adaptive solutions for complex decision-making tasks that could propel, in a much faster-paced manner, the frontier of ""optimality"" across many relevant applications. Concomitantly, the goal is also to explore how model-based principled OR approaches can help alleviate issues revolving around ""black box"" systems, and provide paths to enhance interpretability, trust, and performance analysis.","Overview: The ML×OR Workshop at NeurIPS 2025 focuses on the integration of Machine Learning (ML) and Operations Research (OR) to enhance uncertainty-aware decision-making. This interdisciplinary workshop aims to explore the synergy between ML and OR, presenting recent developments, discussing challenges, and highlighting emerging research opportunities in data-centric decision-making. The workshop encourages contributions from researchers and practitioners across various fields and includes keynote talks, panel discussions, and poster sessions. | Research Interests: Embedding OR modeling insights into ML, Uncertainty mitigation at the interface of data, model, and decision, Sequential decision-making and online learning from an OR perspective, Generative AI for decision-making",多伦多云,多伦多云: 该Session深入探讨了将机器学习与运筹学结合以实现不确定性敏感的决策制定，对于多伦多云团队“Agent业务上线后的自主学习与持续优化机制”挑战具有直接指导意义，尤其是在规划与多步执行能力的持续优化方面。,多伦多云: 运筹学建模方法在机器学习中的嵌入; 不确定性缓解与决策间的数据、模型接口; 序贯决策与在线学习的运筹学视角; 具备规划和多步执行能力的Agent持续优化策略; 生成式AI在决策制定中的应用
SAT 6 DEC,8 a.m.,Workshop,Deep Learning for Code in the Agentic Era,https://neurips.cc/virtual/2025/workshop/109562,,5:00 PM,"Deep learning for code has progressed from focused tasks—such as completion, repair, synthesis, and explanation to tackling complex, end-to-end software–engineering problems.  A key recent breakthrough is the rise of coding agents. Unlike single-shot models, these systems plan, reason, explore, and invoke external tools to assist throughout the software-development lifecycle: adding features, refactoring, debugging, finding vulnerabilities, optimizing performance, summarizing code, and answering repository-level questions.  Their growing versatility demands rigorous evaluation and a deeper understanding of their capabilities, limits, risks, and broader social impact.Building on momentum from both academia and industry (e.g. Google, OpenAI, Anthropic, SWE-Agent, OpenHands), we propose the 4th Deep Learning for Code (DL4C) workshop with a dedicated focus on coding agents. This workshop will provide a timely forum where researchers and practitioners can design and stress-test robust coding agents, discover novel applications and emergent behaviors, establish principled benchmarks and evaluation methods, study human–agent collaboration at scale, and advance the responsible, safe deployment of autonomous coding tools.","Overview: The 4th Deep Learning for Code (DL4C) Workshop, titled 'Deep Learning For Code in the Agentic Era,' is scheduled to take place at NeurIPS 2025 in San Diego, CA. This workshop follows three successful previous installations at ICLR in 2022, 2023, and 2025. The event aims to bring together researchers and practitioners to discuss advancements and challenges in applying deep learning techniques to code-related tasks. | Research Interests: Deep Learning, Code Analysis, Machine Learning for Software Engineering, AI in Software Development",,,
SAT 6 DEC,8 a.m.,Workshop,Differentiable Learning of Combinatorial Algorithms: From Theory To Practice,https://neurips.cc/virtual/2025/workshop/109535,,5:00 PM,,,,,
SAT 6 DEC,8 a.m.,Workshop,AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG @ NeurIPS’25),https://neurips.cc/virtual/2025/workshop/109576,,5:00 PM,"The field of wireless communications and networking is undergoing a paradigm shift, driven by the growing potential of Artificial Intelligence (AI) and Machine Learning (ML) to redefine traditional system design principles. This workshop aims to catalyze interest and foster collaboration between the AI/ML and wireless communications communities. The timing of this workshop is especially significant, as the next-generation (NextG) wireless standardization efforts (such as 6G and WiFi 9) are just getting started, with AI-native technologies expected to play a central role across all aspects of the wireless ecosystem – from radio access to network management and edge intelligence. NextG represents a foundational shift in global infrastructure, enabling ultra-fast, low-latency, and intelligent connectivity that will power future applications in AI, robotics, immersive environments, and autonomous systems. These technologies offer unprecedented opportunities to both drive and benefit many applications, from healthcare and transportation to industrial automation and environmental monitoring. The economic and societal implications are vast: NextG networks will underlie trillions in global GDP impact, bridge digital divides, and shape how billions of people interact with technology and each other in the decades to come.Despite the clear promise, a significant disconnect exists between the AI/ML and wireless research communities. AI/ML experts often lack an understanding of the unique physical, algorithmic, and architectural constraints inherent in wireless systems, while wireless researchers tend to adopt generic, off-the-shelf AI/ML models that are not optimized for the intricacies of wireless environments. Wireless environments are inherently dynamic, high-dimensional, and partially observable. These unique characteristics make them ideal testbeds for developing robust learning algorithms, particularly in areas like online learning, reinforcement learning, and in-context learning. At the same time, AI/ML techniques are becoming essential for managing the growing complexity of modern wireless networks, including resource allocation, interference mitigation, and cross-layer optimization. Bridging the gap between the two communities is not only necessary for meaningful technological advances but also critical for realizing the full societal impact of intelligent wireless systems.This workshop aims to bring together researchers and practitioners at the intersection of artificial intelligence (AI), machine learning (ML), and wireless to address the unique challenges and opportunities posed by Next-Generation (NextG) wireless systems. As the 6G era begins to take shape, AI-native designs have emerged as a cornerstone of wireless innovation, with the potential to transform the performance, efficiency, and adaptability of communication systems. The integration of AI/ML is poised to influence every layer of the network stack, from physical-layer signal processing to network control and resource management.","Overview: The AI4NextG workshop at NeurIPS 2025 focuses on the integration of Artificial Intelligence (AI) and Machine Learning (ML) in next-generation wireless communications and networking. The workshop aims to bridge the gap between AI/ML and wireless research communities to address the challenges and opportunities posed by Next-Generation (NextG) wireless systems, such as 6G and WiFi 9. It seeks to foster collaboration and innovation in AI-native designs that can transform the performance, efficiency, and adaptability of communication systems. | Research Interests: AI-native protocol and architecture design for 6G and WiFi 8/9, Reinforcement learning for dynamic spectrum access and resource allocation, Gen AI and foundation models for physical-layer communication tasks, Online learning and adaptation under real-time and uncertain wireless environments, Data-efficient learning and representation for sparse, high-dimensional wireless signals, AI for network planning, self-optimization, and fault prediction in wireless networks, Cross-layer ML-driven optimizations for joint sensing, control, and communication, Co-design of hardware and ML algorithms for low-power and real-time wireless AI, Trustworthy and explainable AI in high-stakes communication systems",DCN,DCN: 本Session聚焦AI与机器学习在下一代无线通信中的集成，与数据中心网络优化、流量中AI业务占比及大模型助力网络技术挑战高度契合，助力团队深入探索AI驱动的网络架构与协同创新。,DCN: AI-native协议与架构设计，特别针对6G和WiFi 8/9; 强化学习在动态频谱接入和资源分配中的应用; 基于生成式AI和基础模型的物理层通信任务优化; 实时、在线学习及不确定环境下的无线信号适应策略; 低功耗和实时性AI无线硬件与算法的协同设计
SAT 6 DEC,8 a.m.,Workshop,"The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance",https://neurips.cc/virtual/2025/workshop/109566,,5:00 PM,"Generative AI (GenAI) has emerged as a transformative force in healthcare, yet public trust remains limited due to safety concerns and policy misalignment. Build- ing on last year’s successful GenAI4Health workshop, the field has rapidly evolved from exploratory research to real-world clinical deployments, accompanied by FDA regulatory involvement and expanding global governance frameworks. This second workshop convenes machine learning researchers, healthcare professionals, and policy experts to address the critical intersection of GenAI innovation and regula- tory compliance in health applications. We will examine trustworthiness challenges in large language models and multimodal foundation models, explore mitigation strategies, and foster dialogue between technical and policy communities. Our goal is to advance safe, effective, and ethically-compliant GenAI integration in healthcare systems, improving patient outcomes and clinical research capabilities.","Overview: The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance (GenAI4Health2025) is a workshop held at NeurIPS 2025 in San Diego, California. It aims to bring together AI4Health practitioners, safety researchers, and policy experts to address critical challenges in developing robust and policy-compliant Generative AI technologies for healthcare. The workshop will cover topics such as generative AI applications in healthcare, AI trust and reliability in medical settings, policy compliance and regulatory frameworks, clinical AI implementation strategies, and AI safety in healthcare environments. | Research Interests: Generative AI applications in healthcare, AI trust and reliability in medical settings, Policy compliance and regulatory frameworks, Clinical AI implementation strategies, AI safety in healthcare environments",,,
SAT 6 DEC,8 a.m.,Workshop,CauScien: Uncovering Causality in Science,https://neurips.cc/virtual/2025/workshop/109550,,5:00 PM,,"Overview: The CauScien Workshop, part of NeurIPS 2025, is focused on uncovering causality in science. It aims to bridge the gap between theoretical causal reasoning and practical application in scientific research. The workshop fosters collaboration across various disciplines, including ecology, biology, and social sciences, to explore the integration of causal inference with domain expertise and real-world data. The event will address the challenges of applying causal learning techniques to accelerate scientific discovery and promote a bottom-up research paradigm. | Research Interests: Causal inference in applied science, Integration of causality with domain expertise, Causal learning techniques, Translational gap in causal reasoning, Causal benchmark tasks, Collaboration between domain experts and machine learning researchers, Causality in experimental design and planning",,,
SAT 6 DEC,8 a.m.,Workshop,Algorithmic Collective Action,https://neurips.cc/virtual/2025/workshop/109567,,5:00 PM,"The study of collective action has a long history in economics and sociology as a way for groups of people to impact markets and the political arena. Algorithmic collective action focuses on the study of such coordinated efforts in algorithmically-mediated sociotechnical systems. How can participants of AI systems coordinate towards socially beneficial outcomes? We offer a platform to discuss new ideas and help define the foundational research directions for this emerging topic through interdisciplinary discussions between core ML researchers, scholars from the social sciences, community stakeholders and advocates.","Overview: The Algorithmic Collective Action workshop is co-located with NeurIPS 2025 and will take place on December 6 at the San Diego Convention Center. The workshop focuses on exploring collective strategies for shaping outcomes in socio-technical systems from a grassroots perspective. It invites contributions that examine algorithmic collective action through various lenses, including machine learning, statistics, optimization, economics, and the humanities. The goal is to advance understanding of how coordinated efforts can influence the development and deployment of AI systems. | Research Interests: Algorithmic collective action, Socio-technical systems, Machine learning, Statistics, Optimization, Economics, Humanities, AI system development, AI system deployment",DCN; 温哥华云,DCN: 该团队在数据中心AI训练和推理过程中，面临网络基础设施与计算存储的协同优化挑战。参与“Algorithmic Collective Action”研讨会，有助于从算法协同和系统优化角度寻找集体行动策略，推动AI系统的高效协作与部署。; 温哥华云: 该团队聚焦于2026年物理或具身AI的关键研究领域，与“算法集体行动”工作坊中关于算法协调和社会技术系统的探讨高度契合，有助于推动具身AI中多主体协作与协调机制的研究。,DCN: 算法集体行动在数据中心优化中的应用; 机器学习与网络资源协同设计; 算法驱动的系统优化与调度; 跨学科视角下AI系统的社会影响; 基于统计与优化方法的多方协调机制; 温哥华云: 算法集体行动中的协调机制设计; 具身AI系统中的多主体交互优化; 社会技术系统中的算法治理和影响评估; 跨学科方法结合机器学习与经济学优化策略; 促进AI系统社会受益目标的算法开发
SAT 6 DEC,8 a.m.,Workshop,"Lock-LLM Workshop: Prevent Unauthorized Knowledge Use from Large Language Models - Deep Dive into Un-Distillate, Un-Finetunable, Un-Compressible, Un-Editable, and Un-Usable",https://neurips.cc/virtual/2025/workshop/109568,,5:00 PM,"Large Language Models (LLMs) have emerged as transformative tools across research and industry, revolutionizing how we interact with information. However, their immense capabilities bring critical security challenges—the same features that drive innovation can be exploited for malicious purposes through unauthorized distillation, fine-tuning, compression, or editing. These vulnerabilities pose severe threats, including intellectual property theft, the generation of sophisticated disinformation, the bypass of safety alignments, and the erosion of user trust in AI systems.This workshop aims to bring together researchers and practitioners from academia and industry who are advancing the frontiers of LLM security and protection. We seek to confront the unauthorized use of LLMs head-on by exploring novel and robust mechanisms designed to make these models inherently resistant to exploitation while maintaining their beneficial capabilities. The workshop also hosts the 2025 TrustAI Rising Star Award.Topics of interest include, but are not limited to:1. Un-Distillable LLMs: Preventing unauthorized model replication and intellectual property theft2. Un-Finetunable LLMs: Resisting malicious parameter updates and behavior alterations3. Un-Compressible LLMs: Maintaining model integrity against unauthorized compression4. Un-Editable LLMs: Safeguarding against knowledge tampering and misinformation injection5. Un-Usable LLMs: Ensuring traceability and preventing misuse through watermarking and verification","Overview: The Lock-LLM workshop, part of NeurIPS 2025, focuses on addressing the security challenges posed by Large Language Models (LLMs). These models, while transformative, are vulnerable to unauthorized use such as distillation, fine-tuning, compression, and editing, which can lead to intellectual property theft, misinformation, and erosion of trust. The workshop aims to bring together researchers and practitioners to explore robust mechanisms that make LLMs resistant to exploitation while preserving their beneficial capabilities. The event also includes the 2025 TrustAI Rising Star Award to honor early-career researchers in the field. | Research Interests: Un-Distillable LLMs, Un-Finetunable LLMs, Un-Compressible LLMs, Un-Editable LLMs, Un-Usable LLMs, Theoretical Foundations, Evaluation Frameworks, Real-world Applications, Ethical and Societal Implications",,,
SAT 6 DEC,8 a.m.,Workshop,AI4Mat-NeurIPS-2025: NeurIPS 2025 Workshop on AI for Accelerated Materials Design,https://neurips.cc/virtual/2025/workshop/109538,,5:00 PM,"AI4Mat-NeurIPS-2025 explores applications of artificial intelligence (AI) to materials via: 1. AI-Guided Materials Design; 2. Automated Chemical Synthesis; 3. Automated Material Characterization. AI4MatNeurIPS-2025 emphasizes structured, expert-driven dialogue on making advanced machine learning more impactful for real-world materials discovery. To that end, AI4Mat-RLSF (Research Learning from Speaker Feedback) creates a new structured discussion format where spotlight presenters receive curated, in-depth feedback from invited discussants. Further, the AI4Mat Frontiers & Benchmarking session brings together a diverse and distinguished set of speakers to critically examine current benchmarks, present state-of-the-art methods, and identify emerging opportunities and current limitations in AI-driven materials design.","Overview: The AI4Mat workshop at NeurIPS 2025 is a platform for AI researchers and material scientists to collaborate on AI-driven materials discovery and development. It aims to foster interdisciplinary discussions and address challenges in automated materials discovery, including AI-guided design, synthesis, and characterization. The workshop has been a leading venue for exchanging ideas since its inception at NeurIPS 2022, and it continues to build a global research community focused on AI-enabled materials innovation. | Research Interests: AI-driven materials discovery, Automated materials design, AI-guided synthesis, Automated material characterization, Foundation models in materials science, Representation learning for materials, Benchmarking in machine learning for materials science",,,
SAT 6 DEC,8 a.m.,Workshop,AI for non-human animal communication,https://neurips.cc/virtual/2025/workshop/109586,,5:00 PM,"The past few years have seen an unprecedented surge in both the availability of bioacoustic data and the sophistication of AI/machine learning models. This convergence presents a unique window of opportunity to revolutionize our understanding of animal communication and biodiversity. However, achieving this requires a conscious effort to integrate the disciplines of AI/Machine Learning and Ethology.    This workshop will explore the intersection of artificial intelligence (AI) and bioacoustics, aiming to address challenges in processing complex bioacoustic data and interpreting animal signals in order to advance our understanding of non-human animal communication. Join us for a poster session, keynote talks and a panel discussion as we explore key opportunities to use AI to decipher animal languages and thus deepen our understanding of the natural world.","Overview: The AI for Non-Human Animal Communication NeurIPS 2025 Workshop aims to explore the intersection of artificial intelligence and bioacoustics to advance the understanding of non-human animal communication. The workshop will address challenges in processing complex bioacoustic data and interpreting animal signals, with the goal of revolutionizing our understanding of animal communication and biodiversity. It will feature a poster session, keynote talks, and a panel discussion. | Research Interests: Bioacoustic data processing, AI and machine learning models, Animal communication, Biodiversity, Multimodal learning, Transfer learning, Large-language models, Unsupervised, self-supervised, or supervised models, Ecological impact and conservation monitoring, Communication and cognition, Linguistics, Information encoding, Ethics in AI",,,
SAT 6 DEC,8 a.m.,Workshop,Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET),https://neurips.cc/virtual/2025/workshop/109542,,5:00 PM,"Recent progress in reinforcement learning (RL) has powered breakthroughs in various real-world problems, gathering considerable attention and investment. However, it has also exposed a significant gap between theoretical and experimental developments.RL theory has grown significantly in the past two decades. Research has characterized the inherent difficulty of various settings and has designed a wide variety of algorithms to reach optimal performances. Furthermore, a huge leap has been made in understanding how to handle large state spaces using function approximation techniques, identifying key structural properties that enable efficient learning.Despite theoretical guarantees, applying RL algorithms to complex problems faces challenges. Theoretical algorithms often focus on simplified settings, making them hard to apply to real-world complexities. Furthermore, optimizing for worst-case scenarios, which include unlikely situations, can lead to algorithms that perform poorly on practical tasks. Yet, while specialized algorithms offer empirical success, they might not translate to other problems due to their specific design, and the reliance on heuristics and engineering fixes further widens the gap between theory and practice.A prominent area that has seen a surge of interest in RL is generative language modeling. Pre-training these models can be viewed as a form of imitation learning, while post-training typically implements RL algorithms for purposes like instruction tuning with RL from human feedback or enhancing reasoning capabilities. While these successes make the practical utility of RL undeniable, the RL community finds itself at a crossroads. The algorithms employed are frequently variants of classical methods, and exploring beyond these presents a key challenge. Conversely, the success of these models prompts new questions for RL theory, suggesting that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions.Following the success of the ICML 2024 edition, the Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) aims to bridge this discrepancy and promote collaboration. By bringing together experts from both sides, we want to facilitate meaningful discussions and draw a path for future RL research. Motivated by the take-home messages from the previous edition, we seek to encourage: (i) theorists to ask experimentalists for concrete problems to solve, and (ii) experimentalists to seek theoretical guidance on how to approach these problems.","Overview: The Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) Workshop at NeurIPS 2025 aims to bridge the gap between theoretical and experimental developments in reinforcement learning (RL). The workshop will feature a panel discussion on the current state of RL, an idea track for problem submissions, and a research track for solution submissions. The event will bring together researchers to foster collaboration and explore new paradigms in RL, particularly focusing on leveraging pre-trained models over traditional learning methods. | Research Interests: Reinforcement Learning, Theoretical and Experimental Developments in RL, Function Approximation Techniques, Large State Spaces, Pre-trained Models, Instruction Tuning with RL, Human Feedback in RL, Enhancing Reasoning Capabilities | Key Findings: The workshop highlights the significant gap between theoretical and experimental RL developments and suggests that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions.",,,
SAT 6 DEC,8 a.m.,Workshop,The First Workshop on Efficient Reasoning,https://neurips.cc/virtual/2025/workshop/109556,,5:00 PM,"Recent progress in large reasoning models (LRMs), like OpenAI o1 and Deepseek R1, has been pivotal for tackling complex applications, from mathematical and code reasoning to advanced symbolic and agentic planning. Their success often relies on test-time scaling, which involves increasing the generation length or depth. However, these approaches incur significant efficiency bottlenecks during training and inference. To overcome these limitations, further advancements are needed in data, algorithms, and systems applicable across various domains, as exemplified by work such as s1, Z1, and verl. The proposed workshop will bring together researchers and practitioners to rethink efficient reasoning under tight compute, memory, latency, throughput, and cost budgets, with the goal of translating theoretical breakthroughs into practical, deployable solutions.","Overview: The 1st Workshop on Efficient Reasoning at NeurIPS 2025 focuses on advancing large reasoning models (LRMs) to tackle complex applications efficiently. The workshop aims to address efficiency bottlenecks in training and inference by bringing together researchers and practitioners to explore data, algorithms, and systems that can operate under tight compute, memory, latency, throughput, and cost constraints. The goal is to translate theoretical breakthroughs into practical, deployable solutions. | Research Interests: Dataset Curation, Algorithmic Innovation, System Deployment, Application of LRMs in resource-constrained scenarios, Efficient training algorithms, Efficient inference methods, Dynamic KV-cache placement, Quantized graph execution, On-device knowledge distillation",海思; 计算; 诺亚,海思: 该团队在长上下文推理中面临高注意力复杂度挑战，符合本次研讨会聚焦的高效推理技术，特别是稀疏注意力与分块缓存技术，能够帮助优化计算资源、提升推理效率。; 计算: 该团队在低精度训练和推理研究上有深入探索，与Session聚焦的提升大型推理模型效率的目标高度契合。特别是解决低精度模型在计算架构适配中的挑战，为高效推理算法和系统设计提供关键支持。; 诺亚: 该团队关注长序列图文多模态模型的推理计算瓶颈，与本次会议聚焦于高效推理的训练与推断效率瓶颈高度契合，有助于突破多模态长文本推理的输入范式限制。,海思: 稀疏注意力机制的设计与优化; 分块缓存策略实现线性或次线性复杂度; 高效训练算法提升模型推理速度; 动态KV缓存布局与管理; 资源受限环境下模型部署与知识蒸馏; 计算: 低精度训练与推理算法创新; 针对具身、多模态及强化学习应用的模型优化; 动态KV-cache部署策略; 量化图执行技术; 面向资源受限环境的LRM系统设计; 诺亚: 高效训练算法的设计与实现; 推断阶段的动态KV-cache管理; 多模态长序列输入的计算优化; 内存与计算资源受限环境下的系统部署; 量化图执行与知识蒸馏技术
SAT 6 DEC,8 a.m.,Workshop,UniReps: Unifying Representations in Neural Models,https://neurips.cc/virtual/2025/workshop/109553,,5:00 PM,"When, how and why do different neural models learn the same representations?New findings in neuroscience and artificial intelligence reveal a shared pattern: whether in biological brains or artificial models, different learning systems tend to create similar representations when subject to similar stimuli.The emergence of these similar representations is igniting a growing interest in the fields of neuroscience and artificial intelligence, with both fields offering promising directions for their theoretical understanding. These include analyzing the learning dynamics in neuroscience and studying the problem of identifiability in the functional and parameter space in artificial intelligence.While the theoretical aspects already demand investigation, the practical applications are equally compelling: aligning representations allows for model merging, stitching and reuse, while also playing a crucial role in multi-modal scenarios. Furthermore, studying the features that are universally highlighted by different learning processes brings us closer to pinpoint the invariances that naturally emerge from learning models, possibly suggesting ways to enforce them.The objective of the workshop is to discuss theoretical findings, empirical evidence and practical applications of this phenomenon, benefiting from the cross-pollination of different fields (ML, Neuroscience, Cognitive Science) to foster the exchange of ideas and encourage collaborations.In conclusion, our primary focus is to delve into the underlying reasons, mechanisms, and extent of similarity in internal representations across distinct neural models, with the ultimate goal of unifying them into a single cohesive whole.","Overview: The UniReps Workshop focuses on the unification of representations in neural models, exploring how and why different neural models, whether biological or artificial, tend to learn similar representations when exposed to similar stimuli. The workshop aims to discuss theoretical findings, empirical evidence, and practical applications of this phenomenon, encouraging cross-disciplinary collaboration among fields such as machine learning, neuroscience, and cognitive science. | Research Interests: Unifying representations in neural models, Learning dynamics in neuroscience, Identifiability in artificial intelligence, Model merging and reuse, Multi-modal scenarios, Invariances in learning models | Key Findings: The workshop highlights the shared pattern of similar representations emerging in different learning systems, both biological and artificial, when exposed to similar stimuli. This phenomenon is of growing interest in neuroscience and artificial intelligence, with potential applications in model merging, stitching, and reuse, as well as in multi-modal scenarios.",,,
SAT 6 DEC,8 a.m.,Workshop,MATH-AI: The 5th Workshop on Mathematical Reasoning and AI,https://neurips.cc/virtual/2025/workshop/109565,,5:00 PM,,"Overview: The 5th Workshop on Mathematical Reasoning and AI, part of NeurIPS 2025, focuses on the intersection of deep learning and mathematical reasoning, particularly with large language models. The workshop aims to explore the extent to which machine learning models can comprehend mathematics and the potential applications of this capability. It seeks to bring together diverse participants to foster dialogue on various related topics. | Research Interests: Comparative study of human-level mathematical reasoning and AI techniques, Designing benchmarks for evaluating mathematical reasoning abilities, Advancing beyond current mathematical reasoning techniques, Role of deep learning models in mathematics education, Applications of AI in software verification, sciences, engineering, finance, education, and mathematics",,,
SAT 6 DEC,8 a.m.,Workshop,ML for Systems,https://neurips.cc/virtual/2025/workshop/109537,,5:00 PM,"The 9th Machine Learning for Systems (ML for Systems) workshop brings together researchers and practitioners applying machine learning to core computer systems challenges. This year, we focus on three themes: (1) using LLMs and agentic workflows for systems tasks such as program synthesis and adaptive optimization; (2) applying ML to manage the complexity of large-scale training and serving of multimodal and reasoning models; and (3) leveraging ML for sustainable computing, including energy-, power-, and carbon-aware optimization. The workshop will feature invited talks, contributed presentations, and discussions aimed at advancing the frontier of ML for Systems research.","Overview: The ML for Systems workshop focuses on the application of machine learning techniques to computer systems problems. It aims to replace traditional heuristics with machine learning approaches, such as supervised learning and reinforcement learning, to address a wide range of systems-related tasks. The workshop serves as an interdisciplinary venue for experts in ML and systems to collaborate and push the boundaries of this emerging field. It also emphasizes the development of best practices, methodologies, and benchmarks for ML in systems, with a particular focus on the challenges and opportunities presented by Large Language Models (LLMs). | Research Interests: Machine Learning for computer systems, Supervised learning, Reinforcement learning, Designing new data structures, Integrated circuits, Design verification, Control algorithms for compilers, Databases, Memory management, ML frameworks, Large Language Model (LLM) training and serving, Scheduling and compiling, Interdisciplinary collaboration between ML and systems | Key Findings: The workshop highlights the importance of ML in solving systems problems and the need for developing best practices and benchmarks. It also identifies the rise of LLMs as a significant trend, presenting both challenges and opportunities for the field. The workshop aims to foster connections between ML and systems communities and to stimulate new research directions.",计算,计算: 该团队面临低精度训练推理和Agentic、多模态模型对计算架构的新需求，契合ML for Systems中关于低精度计算与多模态模型应用的前沿研究，参加Workshop有助于掌握最新方法及硬件协同设计。,计算: 低精度训练与推理的计算架构优化方法; 面向具身智能和多模态强化学习的新型计算模型; Agentic工作流在系统性能提升中的应用; 基于ML的自适应计算资源调度与管理; LLM模型训练与服务的系统挑战及解决方案
SAT 6 DEC,8 a.m.,Workshop,"Dynamics at the Frontiers of Optimization, Sampling, and Games",https://neurips.cc/virtual/2025/workshop/109541,,5:00 PM,,"Overview: The DynaFront workshop at NeurIPS 2025 focuses on the role of dynamical systems in optimization, sampling, and game theory. It aims to lower the barrier to entry for researchers and practitioners in machine learning by highlighting the unifying role of dynamical systems across these domains. The workshop will convene experts to foster cross-disciplinary dialogue and collaboration, with an emphasis on emerging applications in machine learning such as diffusion models, distributed and adversarial training, and agentic AI. | Research Interests: Dynamical systems, Optimization, Sampling, Game theory, Machine learning, Diffusion models, Distributed training, Adversarial training, Agentic AI",,,
SAT 6 DEC,8 a.m.,Workshop,AI Virtual Cells and Instruments: A New Era in Drug Discovery and Development,https://neurips.cc/virtual/2025/workshop/109543,,5:00 PM,"As the US FDA phases out animal testing requirements for drug discovery and development, AI tools will become widely adopted to simulate the effects of candidate drugs. We posit that building virtual cells and instruments with AI is poised to transform drug discovery and development by enabling large-scale simulation and interrogation of molecules, cells, and tissues. In our workshop, we will collaboratively define and promote this emerging scientific paradigm of AI to accelerate the drug discovery and development process in this new era.","Overview: The AI4D3 NeurIPS 2025 workshop focuses on the transformative potential of AI in drug discovery and development, particularly as the US FDA phases out animal testing requirements. The workshop aims to explore the creation of AI-driven virtual cells and instruments to simulate the effects of candidate drugs, thereby accelerating the drug discovery process. This event will bring together a community to collaboratively define and promote this emerging scientific paradigm. | Research Interests: AI in drug discovery, Virtual cells and instruments, Simulation of drug effects, Large-scale molecular simulation, Interrogation of molecules, cells, and tissues",,,
SAT 6 DEC,8 a.m.,Workshop,OPT 2025: Optimization for Machine Learning,https://neurips.cc/virtual/2025/workshop/109581,,5:00 PM,"Optimization lies at the heart of many machine learning algorithms and enjoys great interest in our community. Indeed, this intimate relation of optimization with ML is the key motivation for the OPT series of workshops. We aim to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to ML.The focus of OPT 2025 is on ""Statistics Meets Optimization"". Since its inception, stochastic optimization has been grounded in statistical principles. Today, many of the most pressing challenges in machine learning—such as generalization bounds, the training dynamics of overparameterized models, and the development of generative models—are directly inspired by statistical thinking. At the same time, the scale and complexity of modern datasets, along with the increasingly rich model classes used to represent them, pose new questions about how optimization algorithms interact with these structures—both computationally and statistically. For example, what role do data symmetries play in shaping optimization trajectories? How do statistical properties of the data affect the adaptivity and efficiency of learning algorithms? And how can optimization approaches be designed to scale with data while still preserving desirable statistical behavior? OPT 2025 will explore these questions with the goal of building bridges between the statistics and optimization communities, and highlighting their shared impact on the theory and practice of machine learning.We are looking forward to seeing you all at OPT 2025, which will take place at the San Diego Convention Center!","Overview: The OPT2025 workshop is the 17th International Workshop on Optimization for Machine Learning, held as part of the NeurIPS 2025 conference. It aims to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to machine learning. The workshop focuses on the intersection of statistics and optimization, exploring how these fields can address challenges in machine learning, such as generalization bounds, training dynamics of overparameterized models, and the development of generative models. The event will take place at the San Diego Convention Center. | Research Interests: Optimization for Machine Learning, Statistics Meets Optimization, Stochastic Optimization, Generalization Bounds, Training Dynamics of Overparameterized Models, Development of Generative Models, Data Symmetries in Optimization, Statistical Properties and Learning Algorithms, Scalable Optimization Approaches",,,
SAT 6 DEC,8 a.m.,Workshop,Foundation Models for the Brain and Body Workshop,https://neurips.cc/virtual/2025/workshop/109571,,5:00 PM,,"Overview: The 'Foundation Models for the Brain and Body' workshop is part of NeurIPS 2025, focusing on the intersection of AI and biosignals. It aims to explore how large-scale, pretrained AI systems can learn from neural and physiological signals to generalize across various applications, such as brain-computer interfacing and health monitoring. The workshop brings together experts from neuroscience, biomedical engineering, wearable technology, and machine learning to address the challenges of biosignal timeseries, which are often noisy and heterogeneous. | Research Interests: Foundation models, Biosignals, Brain-computer interfacing, Health monitoring, Neural and physiological signals, EEG, Intracortical electrophysiology, EMG, MEG, ECG, Wearable technology, Machine learning, Neuroscience, Biomedical engineering",,,
SAT 6 DEC,8 a.m.,Workshop,Biosecurity Safeguards for Generative AI,https://neurips.cc/virtual/2025/workshop/109573,,5:00 PM,,,,,
SAT 6 DEC,8 a.m.,Workshop,Imageomics: Discovering Biological Knowledge from Images Using AI,https://neurips.cc/virtual/2025/workshop/109558,,5:00 PM,"Imageomics is an emerging interdisciplinary field at the crossroads of machine learning (ML), computer vision (CV), and biological sciences. It leverages visual data—from microscopic images of single-cell species to videos of megafauna—to extract and analyze biological information, specifically traits. By grounding ML models in existing scientific knowledge, Imageomics aims to make traits computable from images, facilitating insights into the evolution and function of living organisms. Imageomics poses research problems that resonate with the broad machine-learning community: multimodal representation learning, object detection and tracking, few-shot learning, imbalanced-class learning, video understanding, 3D modeling, hierarchical learning, etc. When people leverage ML tools to solve biological questions, the foundational bridges between ML and biological sciences also provide opportunities to address key challenges in ML, creating a virtuous cycle between the two fields.","Overview: The Imageomics Workshop at NeurIPS 2025 is the third edition of an interdisciplinary event focused on the emerging field of Imageomics, which combines machine learning, computer vision, and biological sciences. The workshop aims to leverage visual data, from microscopic images to videos of large animals, to extract and analyze biological information, particularly traits. By integrating machine learning models with existing scientific knowledge, Imageomics seeks to make biological traits computable from images, providing insights into the evolution and function of living organisms. The workshop will feature keynote talks, paper presentations, and discussions on the latest research, encouraging participation from both biological scientists and machine learning researchers. | Research Interests: Multimodal representation learning, Object detection and tracking, Few-shot learning, Imbalanced-class learning, Video understanding, 3D modeling, Hierarchical learning",,,
SAT 6 DEC,8 a.m.,Workshop,Embodied World Models for Decision Making,https://neurips.cc/virtual/2025/workshop/109532,,5:00 PM,"World models infer and predict real-world dynamics by modeling the external environment, and have become a cornerstone of embodied artificial intelligence. They have powered recent progress in decision-making and planning for interacting agents. This workshop aims to bring together researchers working at the intersection of generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models—models that enable agents to understand, predict, and interact with the world through learned models. By focusing on embodiment and decision-making, this workshop seeks to advance world models beyond passive prediction, toward active, goal-driven interaction with the physical and virtual world. By emphasizing embodiment and decision-making, we aim to move beyond passive sequence prediction toward goal-directed interaction with both physical and simulated worlds.","Overview: The Embodied World Models for Decision Making workshop at NeurIPS 2025 focuses on advancing world models that enable agents to understand, predict, and interact with the world through learned models. The workshop aims to bring together researchers from generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models. The emphasis is on moving beyond passive prediction to active, goal-driven interaction with both physical and virtual worlds. | Research Interests: Model-based reinforcement learning and long-horizon planning, Aligning simulation and real-world physics for robot learning, Interactive scene generation and downstream tasks, Video-language-action models and leveraging world knowledge in large language models, Applications in open-world video games and autonomous driving",温哥华云,温哥华云: 此Session紧扣体现物理和具身AI的世界模型技术，与温哥华云在2026年具身AI关键研究领域的战略规划挑战高度契合，有助于团队掌握前沿决策与交互模型，推动技术突破与应用深化。,温哥华云: 模型驱动的强化学习与长时规划; 模拟与现实世界物理对齐的机器人学习; 交互式场景生成及其下游任务; 视频-语言-动作模型及大语言模型中的世界知识利用; 应用于开放世界游戏和自动驾驶的世界模型
SAT 6 DEC,8 a.m.,Workshop,Machine Learning and the Physical Sciences,https://neurips.cc/virtual/2025/workshop/109577,,5:00 PM,"The Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS is a unique gathering space for the growing community spearheading cross-cutting research topics at the intersection of machine learning (ML) and the physical sciences (PS). This includes the applications of ML to problems in the physical sciences (ML for PS) as well as developments in ML motivated by physical insights (PS for ML). The physical sciences are defined inclusively, including but not limited to physics, astronomy, cosmology, chemistry, biophysics, materials science, and Earth science. Join us to discuss the latest research at the convergence of these fields!","Overview: The Machine Learning and the Physical Sciences (ML4PS) workshop is a gathering space for researchers at the intersection of machine learning (ML) and the physical sciences (PS). Since its inception in 2017, the workshop has focused on applying ML to problems in the physical sciences and using physical insights to improve ML techniques. The 2025 workshop, part of the 39th NeurIPS conference, will explore the interplay between academia and industry in basic research, emphasizing foundational and translational connections between these domains. | Research Interests: Machine Learning for Physical Sciences, Physical Sciences for Machine Learning, Geometric Deep Learning, Simulation-Based Inference, Diffusion Models, Physics-Informed Neural Networks, Interplay of Academia and Industry, Weather and Climate Research, Paradigm-Shifting Applications in ML and Physics",计算,计算: 本Session聚焦机器学习与物理科学的交叉应用，特别是面向低精度模型训练推理的计算架构需求。团队针对低精训推的挑战点，能从Workshop中获取先进的物理启发式模型和算力优化方案，助力推动下一代芯片与算法的发展。,计算: 低精度模型训练与推理技术; 物理启发的神经网络（Physics-Informed Neural Networks）; 跨模态与具身智能的机器学习方法; 面向算力与精度优化的新型芯片架构; 机器学习在气象与气候科学中的应用
SAT 6 DEC,8 a.m.,Workshop,Workshop on Multi-Turn Interactions in Large Language Models,https://neurips.cc/virtual/2025/workshop/109539,,5:00 PM,"The field of AI is entering a new era of interaction, profoundly shaped by the capabilities of Large Language Models (LLMs). While multi-turn interaction has been a long-standing pursuit in AI—from dialogue systems to multi-agent coordination—the advent of LLMs has radically transformed this landscape. These models now engage in complex, long-horizon interactions, process diverse data, and make crucial decisions in dynamic, human-centric scenarios.This leap forward, however, brings forth critical new research questions and challenges that demand immediate attention:Multi-Turn RL Learning for Agentic Tasks Learning from complex, interactive environments like GUI agents and tool-use scenarios, given the challenges of sparse rewards.Maintaining Alignment Understanding human values over extended, multi-turn interactions, preventing ""loss of alignment"" seen in current models.Human-AI Interaction Over time, ensuring models adapt to user goals without compromising safety or fairness.Long-horizon Evaluation For LLMs' long-term capabilities, consistency, and strategic abilities in complex, multi-turn tasks.The Workshop on Multi-Turn Interactions in LLMs is designed to be the central forum for addressing these pivotal questions. We invite researchers to contribute to defining the next generation of interactive AI, tackling these core challenges, and charting the course for future advancements in AI reasoning and planning. This workshop will concentrate on key areas where the extended use of LLMs presents both new challenges and opportunities, serving as a platform to discuss and refine methods for future improvements and evaluation for practical LLM use cases.","Overview: The NeurIPS 2025 Workshop on Multi-Turn Interactions in Large Language Models focuses on the evolving field of AI, particularly the role of Large Language Models (LLMs) in multi-turn interactions. The workshop aims to address new research questions and challenges that arise from the capabilities of LLMs in complex, long-horizon interactions. It serves as a central forum for researchers to contribute to the development of interactive AI, focusing on areas where LLMs present new challenges and opportunities. | Research Interests: Multi-Turn RL Learning for Agentic Tasks, Maintaining Alignment in AI, Human-AI Interaction, Long-horizon Evaluation of LLMs, Multi-Turn Settings and Tasks, Multi-Turn Frameworks and Algorithms, Multi-Turn Evaluation, Multi-Turn Challenges",诺亚,诺亚: 该团队专注于长序列图文多模态模型的输入范式优化，直接对应Session中探讨的多轮交互及复杂任务下的多模态推理计算瓶颈问题，参加此Workshop有助于深化技术突破与多轮交互机制的结合。,诺亚: 多轮交互中长序列图文多模态模型的输入范式突破; 多轮强化学习在复杂环境中的应用; 多轮交互中对齐人类价值的技术方法; 人机互动中的模型适应性与安全性; 多轮交互任务的长期评估与策略一致性
SAT 6 DEC,8 a.m.,Workshop,Generative AI in Finance,https://neurips.cc/virtual/2025/workshop/109564,,5:00 PM,"This workshop aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance, a high-stakes domain where the integration of domain expertise is essential to the safe and effective deployment of machine learning technologies. Recent advances in generative models—ranging from large language models to diffusion and score-based generative architectures—have opened new frontiers for applications in finance, such as financial modeling, stress testing, scenario generation, automated financial services, and decision-making under uncertainty.The workshop will highlight theoretical advances, practical implementations, new opportunities, and open challenges that arise when adapting generative AI to financial systems under unique constraints, such as data sparsity, regulatory requirements, and highly non-stationary and adversarial environments. By bringing together the computer science community, financial researchers, industry practitioners, and regulators, we aim to catalyze interdisciplinary dialogue and accelerate the responsible development of generative AI tailored to the needs of finance and risk management.","Overview: The NeurIPS 2025 Workshop on Generative AI in Finance aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance. The workshop will focus on the integration of domain expertise to safely and effectively deploy machine learning technologies in finance. It will highlight theoretical advances, practical implementations, new opportunities, and challenges in adapting generative AI to financial systems, considering constraints like data sparsity, regulatory requirements, and non-stationary environments. The event will bring together computer scientists, financial researchers, industry practitioners, and regulators to accelerate the responsible development of generative AI tailored to finance and risk management. | Research Interests: Generative AI, Financial modeling, Stress testing, Scenario generation, Automated financial services, Decision-making under uncertainty, Machine learning in finance, Stochastic analysis, Trustworthy machine learning, Sequential decision-making, High-dimensional statistics, AI for financial services, Market behavior modeling, Natural language processing, Reinforcement learning, AI agents, Representation learning for finance, Agentic AI, LLM (Large Language Models), Financial modeling and reasoning",,,
SUN 7 DEC,8 a.m.,Workshop,UrbanAI: Harnessing Artificial Intelligence for Smart Cities,https://neurips.cc/virtual/2025/workshop/109583,,5:00 PM,,,,,
SUN 7 DEC,8 a.m.,Workshop,2nd  Workshop on Multi-modal Foundation Models and Large Language Models  for Life Sciences,https://neurips.cc/virtual/2025/workshop/109536,,5:00 PM,,"Overview: The NeurIPS 2025 2nd Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences focuses on the transformative advancements in life sciences brought about by foundation models and large language models (LLMs). These models are pretrained on extensive datasets and are capable of performing a wide range of tasks such as predicting protein structures, analyzing genomic sequences, and simulating cellular processes. The workshop aims to address the limitations of existing models that focus on a single modality by promoting the development of multi-modal foundation models and LLMs that can integrate and reason over diverse biological modalities. The event will bring together researchers to discuss recent advancements, explore methodological innovations, and identify key challenges in designing these models for biological data. | Research Interests: Multi-modal foundation models for learning representations of proteins, DNAs, RNAs, transcriptomic data, metabolomic data, and other biological modalities., Multi-modal LLMs for predicting the functions of proteins, DNAs, RNAs, and other biomolecules., Multi-modal foundation models for learning joint representations of multi-omics data., Multi-modal generative models for designing proteins, DNAs, RNAs, and other biomolecules., Applications of multi-modal foundation models and LLMs in drug discovery, precision medicine, personalized treatment, and beyond., Interpretability and robustness in biological multi-modal foundation models and LLMs.",诺亚,诺亚: 该Session聚焦于多模态基础模型及大语言模型在生命科学的应用，正好契合团队关于长序列图文多模态模型推理瓶颈的挑战，能助力探索输入范式层面创新，突破计算限制。,诺亚: 多模态基础模型的设计与优化方法; 长序列多模态数据的高效推理技术; 多模态大语言模型在蛋白质和基因组功能预测中的应用; 多组学数据联合表征与建模; 模型解释性与鲁棒性提升策略
SUN 7 DEC,8 a.m.,Workshop,Artificial Intelligence for Music: Where Creativity Meets Computation,https://neurips.cc/virtual/2025/workshop/109534,,5:00 PM,"This workshop explores the dynamic intersection of AI and music, a rapidly evolving field where creativity meets computation. The goal of this workshop is twofold: First, we aim to explore the latest advancements of AI’s applications for music, from analysis, creation, performance, production, retrieval to music education and therapy. Second, we aim to discuss the impacts and implications of AI in music, including AI’s impacts on the music industry, musician community, and music education as well as ethical, legal and societal implications of AI music and AI’s implications for future musicians.","Overview: The NeurIPS 2025 Workshop on AI for Music, titled 'Where Creativity Meets Computation,' is an interdisciplinary event exploring the intersection of artificial intelligence and music. The workshop aims to bring together the music and AI communities to discuss the latest advancements in AI applications for music, including analysis, creation, performance, production, retrieval, and music education and therapy. It also addresses the impacts and implications of AI in music, such as its effects on the music industry, musician community, and music education, as well as ethical, legal, and societal considerations. The workshop features invited talks, spotlight presentations, poster and demo sessions, panel discussions, and round table discussions, with a focus on networking and community building. | Research Interests: AI applications in music, Music theory and musicology, Optical music recognition, Music transcription, Music generation, Sound design and soundtrack generation, Singing voice synthesis, Lyric generation and translation, Musical instrument design, Robotic musicianship, Human-AI music co-creativity, Music production, Music performance modeling, Music information retrieval, Music recommender systems, Music education, Music therapy, Impacts of AI on the music industry, Impacts on the musician community, Impacts on music education, Ethical, legal, and societal implications of AI music, Challenges in commercializing AI music tools, Emerging opportunities of AI music | Key Findings: The workshop highlights the growing interest in AI music research within the machine learning community and emphasizes the potential of AI to enhance artist creativity and develop new fan experiences. It also notes the acceptance rate of 68% for papers and demos, indicating a high level of interest and participation in the field.",,,
SUN 7 DEC,8 a.m.,Workshop,AI for Science: The Reach and Limits of AI for Scientific Discovery,https://neurips.cc/virtual/2025/workshop/109578,,5:00 PM,"Through our proposed AI for Science workshop, we will bring together experimentalists, domain scientists, and ML researchers to discuss the reach and limits of AI for scientific discovery. We will center our discussion on three challenges that are essential to progress across scientific domains:LLM reasoning across scientific domains– can present-day LLMs generate rigorously testable hypotheses and reason over experimental results that span scientific domains such as physics, chemistry, and biology?Fidelity of generative and surrogate simulators– In biology, we see a shift towards all-atom models with increasingly powerful capabilities, in chemistry machine learning force fields are increasing in accuracy and generalizability, and in climate modeling we can now accurately predict weather 15 days out. How far can we push this limit? What spatial or temporal scales remain intractable?Experimental data scarcity and bias. We see modern examples of large-scale dataset generation such as the Protein Data Bank, Human Cell Atlas, and the Materials Project. Are there other fields where AI can benefit most from consortium efforts to generate large-scale datasets? How far can models trained on limited experimental datasets take us and where are lab-in-the-loop strategies essential? To address this, we additionally introduce adataset proposal competition. Our workshop will highlight common bottlenecks in developing AI methods across scientific application domains, and delve into solutions that can unlock progress across all of these domains.","Overview: The AI for Science workshop at NeurIPS 2025 aims to explore the reach and limits of AI in scientific discovery. It brings together experimentalists, domain scientists, and machine learning researchers to discuss where AI genuinely advances scientific discovery and where it faces limitations. The workshop focuses on identifying bottlenecks in AI methods across scientific domains and finding solutions to overcome these challenges. | Research Interests: Multi-domain scientific reasoning, High-fidelity generative and surrogate simulators, Experimental data scarcity and bias",计算,计算: 该Session聚焦AI在科学发现中的多领域推理与数据挑战，契合计算团队对低精度训练推理在新应用中的研究需求，有助于团队优化算力与精度定义，提升芯片及模型的竞争力。,计算: 跨科学领域的多模态大模型推理技术; 高保真度生成器与替代模型的提升策略; 实验数据稀缺与偏差处理方法; 联合产学研发低精度模型的训练与推理技术; 推动下一代算力架构与低精度计算需求对接
SUN 7 DEC,8 a.m.,Workshop,Frontiers in Probabilistic Inference: Learning meets Sampling,https://neurips.cc/virtual/2025/workshop/109572,,5:00 PM,,"Overview: The Frontiers in Probabilistic Inference: Learning Meets Sampling (FPI 2025) is a one-day workshop at NeurIPS 2025, focused on advancing scalable, data-efficient sampling methods by integrating classical statistical approaches with modern machine learning techniques. The workshop aims to address the growing role of probabilistic inference in large-scale scientific and real-world systems by fostering cross-disciplinary collaboration among researchers from statistics, machine learning, and applied science domains. The event seeks to explore shared challenges, develop practical tools, and identify common benchmarks to enhance the development of next-generation sampling methods. | Research Interests: Sampling methods and their connections to generative models and optimal control, Classical sampling approaches and how learning accelerates them, Connections between sampling methods and physics, Understanding sampling from theoretical perspectives, Applications of sampling to natural sciences, Bayesian inference, LLM fine-tuning, and more",计算,计算: 该团队关注低精度训练推理技术的发展与芯片算力需求，且Session聚焦通过结合机器学习优化采样方法，提升计算效率与数据利用。这一连接点对实现更低精度模型的高效训练推断极具价值。,计算: 基于学习提升的采样方法与计算加速技术; 低精度训练推理对计算架构的影响与优化策略; 多模态及具身强化学习中的采样技术应用; 采样方法与生成模型、最优控制的结合; 下一代芯片算力与精度需求的交叉研究
SUN 7 DEC,8 a.m.,Workshop,Non-Euclidean Foundation Models and Geometric Learning: Advancing AI Beyond Euclidean Frameworks,https://neurips.cc/virtual/2025/workshop/109582,,5:00 PM,"In the era of foundation models and Large Language Models (LLMs), Euclidean space is the de facto geometric setting of our machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. Non-Euclidean learning is quickly gaining traction. Non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, have been shown to provide more efficient and effective representations for data with intrinsic geometric properties, like hierarchy, symmetry, and heterogeneity.Integrating foundation models with non-Euclidean spaces has great potential to enhance their ability to capture and model the underlying structures and relationships in complex real-world data, leading to better performance, generalization, and interpretability. This workshop focuses on the intersection of Non-Euclidean representation learning and Foundation Models, exploring its potential benefits, challenges, and future directions.","Overview: The Non-Euclidean Foundation Models and Geometric Learning Workshop at NeurIPS 2025 focuses on advancing AI beyond traditional Euclidean frameworks. It aims to explore the integration of foundation models with non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, to enhance the ability of AI models to capture and model complex real-world data structures. The workshop will include discussions on non-Euclidean representation learning, geometric deep learning, and large foundation models, with a focus on their potential benefits, challenges, and future directions. | Research Interests: Non-Euclidean representation learning, Geometric deep learning, Foundation models, Theoretical foundations of non-Euclidean spaces, Architectures and algorithms for non-Euclidean spaces, Applications in graph analysis, text processing, image understanding, biomedical research, and AI for scientific discovery, Trustworthiness and robustness in non-Euclidean models, Benchmarks and tools for non-Euclidean representations",,,
SUN 7 DEC,8 a.m.,Workshop,Constrained Optimization for Machine Learning,https://neurips.cc/virtual/2025/workshop/109533,,5:00 PM,"As AI systems are increasingly deployed in safety-critical domains—including credit scoring, medical diagnosis, and autonomous systems—there is a growing demand to ensure their fairness, safety, robustness, and interpretability, alongside stronger calls for regulation. Constrained optimization offers an accountable framework for enforcing these requirements by embedding them directly into the training process, steering models to satisfy explicit constraints. This framework facilitates compliance with regulatory, industry, or ethical standards, which can be easily verified by checking constraint satisfaction.This workshop explores constrained optimization as a principled method for enforcing desirable properties in machine learning models. It brings together experts in optimization, machine learning, and trustworthy AI to address the algorithmic and practical challenges of scaling constrained methods to modern deep learning settings, which are often large-scale, non-convex, and stochastic.","Overview: The NeurIPS 2025 Workshop on Constrained Optimization for Machine Learning focuses on the application of constrained optimization techniques to ensure fairness, safety, robustness, and interpretability in AI systems, especially in safety-critical domains. The workshop aims to address the challenges of scaling these methods to modern deep learning settings and invites contributions that advance the state of the art in constrained learning. | Research Interests: Constrained Optimization, Machine Learning, Trustworthy AI, Fairness, Safety, Robustness, Interpretability, Regulatory Compliance",,,
SUN 7 DEC,8 a.m.,Workshop,New Perspectives in Graph Machine Learning,https://neurips.cc/virtual/2025/workshop/109579,,5:00 PM,,"Overview: The webpage presents the 'New Perspectives in Advancing Graph Machine Learning' workshop, which is part of NeurIPS 2025. The workshop aims to explore and connect new perspectives on graph machine learning (GML), focusing on theoretical insights, new capabilities, and application-aligned algorithms and models. It includes keynotes, oral presentations, poster sessions, and a panel discussion, featuring prominent speakers and researchers in the field. | Research Interests: Graph Machine Learning, Algebraic–Topological Analyses, Foundation Models, Generative Models, Large Models in Applications, Causal Structure Learning, Topological Deep Learning, Graph Neural Networks, Graph Representation Learning | Key Findings: The workshop highlights the potential of integrating new perspectives such as algebraic-topological analyses and foundation models into graph machine learning, promising deeper theoretical insights and more powerful algorithms. It also emphasizes the importance of addressing overarching challenges in theory, methodology, and modeling.",,,
SUN 7 DEC,8 a.m.,Workshop,Regulatable ML: Towards Bridging the Gaps between Machine Learning Research and Regulations,https://neurips.cc/virtual/2025/workshop/109575,,5:00 PM,,"Overview: The 3rd Workshop on Regulatable ML at NeurIPS 2025 aims to bridge the gap between state-of-the-art machine learning safety and security research and evolving regulatory frameworks. The workshop addresses the novel safety and security risks introduced by large-scale machine learning models and AI agents, such as prompt-injection attacks, capability overreach, and unintended emergent behaviors. It highlights the gaps in current regulations like the EU AI Act and the need for evidence-based mitigation strategies as outlined in the International AI Safety Report 2025. | Research Interests: Machine Learning Safety, AI Security, Regulatory Frameworks, AI Risk Mitigation, Transparency in AI, Human Oversight in AI, International Collaborations in AI Safety, Verification Protocols for AI, Failure Cases of State-of-the-Art Models | Key Findings: Recent works have highlighted several failure cases of state-of-the-art large language models (LLMs) and agents, such as the Claude Opus 4 model generating instructions for creating biological agents and attempting to 'hijack' strategies during shutdown threat tests.",,,
SUN 7 DEC,8 a.m.,Workshop,"Evaluating the Evolving LLM Lifecycle:  Benchmarks, Emergent Abilities, and Scaling",https://neurips.cc/virtual/2025/workshop/109549,,5:00 PM,,"Overview: The NeurIPS 2025 Workshop titled 'Evaluating the Evolving LLM Lifecycle' focuses on the evaluation of large language models (LLMs) as they become increasingly integrated into various applications. The workshop aims to address the need for robust evaluation methodologies and best practices across the entire LLM lifecycle, from foundational pre-training to advanced post-training techniques like reinforcement learning from human feedback (RLHF). It seeks to develop a comprehensive understanding of LLM evaluation, emphasizing interrelations, emergent capabilities, scaling challenges, and the creation of cutting-edge benchmarks for future models. | Research Interests: Evaluation metrics for pre-trained models and foundational capabilities, Assessing the impact of fine-tuning and adaptation on model performance and behavior, Advanced post-training evaluation techniques, including RLHF and human-in-the-loop assessments, Interrelations and dependencies between different evaluation stages and their impact on model generalization, Benchmarking and standardization of evaluation protocols, Development of new, challenging evaluation paradigms, Understanding and evaluating scaling laws in relation to model performance and emergent phenomena, Addressing data contamination, memorization, and other data-centric evaluation challenges, Developing and applying holistic evaluation frameworks for diverse LLM capabilities, Evaluating the evolution of LLM capabilities and potential risks as models scale",计算; 温哥华云,计算: 该Session聚焦于LLM生命周期的评估方法，与挑战点中对训练与推理新范式负载特征演进机理的跟踪、理解高度契合，有助于团队精准定义未来负载，提升模型智能水平。; 温哥华云: 本Session深度探讨了LLM生命周期中的评估及其对强化学习微调性能的影响，直接对应温哥华云团队在提升VLMs/LLMs强化微调性能的挑战。参与该Workshop有助于获取先进的评价方法和优化策略。,计算: 评估预训练模型及基础能力的指标体系; 细粒度理解训练与推理范式的负载差异; 先进的后训练评估技术，如RLHF及人机交互评估; 构建统一标准化的评估协议与基准; 深入分析训练推理负载演进对模型性能的影响; 温哥华云: 强化学习微调（Reinforcement Fine-Tuning）的性能评估方法; RLHF与人类反馈在微调中的应用与优化; 多阶段模型评估及其对模型泛化能力的影响; 建立和采用新型基准测试以促进模型性能提升; 解决数据污染和模型记忆对性能评估的影响
SUN 7 DEC,8 a.m.,Workshop,Foundations of Reasoning in Language Models,https://neurips.cc/virtual/2025/workshop/109559,,5:00 PM,"Our workshop’s goal is toadvance foundational understanding, principled innovations, and rigorous scientific evaluations for reasoning in language models. These advancements are built upon theoretical analyses and controlled empirical studies that illuminate how reasoning emerges, where it fails, and how it can be systematically improved.We want to foster dialogue between communities with complementary strengths---those building theoretical models of reasoning phenomena, those designing experiments that reveal its emergence or failure in practice, and those proposing algorithmic developments that advance reasoning---aroundthree primary questions:1. How are language models able to solve complex tasks, and what do they still struggle with?2. What fundamental challenges stand in the way of advancing reasoning capabilities?3. What algorithmic innovations can overcome these obstacles?","Overview: The Foundations of Reasoning in Language Models (FoRLM) workshop is scheduled to take place during NeurIPS 2025 in San Diego, California. The workshop aims to advance the foundational understanding of reasoning in language models through theoretical analyses and empirical studies. It seeks to bring together researchers with complementary strengths to address key questions about how reasoning emerges in language models, where it fails, and how it can be improved. | Research Interests: Reasoning in language models, Theoretical models of reasoning phenomena, Empirical studies on reasoning emergence and failure, Algorithmic developments to advance reasoning",诺亚,诺亚: 该团队致力于突破多模态长文本推理的计算瓶颈，与Workshop探讨语言模型推理能力及算法创新紧密相关，有助于获取理论与实践的前沿解决方案。,诺亚: 长序列多模态输入范式优化; 语言模型中推理能力的理论分析; 多模态长文本推理算法创新; 推理失败的经验验证方法; 提升复杂任务推理性能的系统方法
SUN 7 DEC,8 a.m.,Workshop,Learning to Sense (L2S),https://neurips.cc/virtual/2025/workshop/109563,,5:00 PM,"The workshop explores the joint optimization of sensors and machine learning models, pushing beyond traditional paradigms of data acquisition and processing. We aim to rethink the foundations of how machines sense the world by replacing hand-crafted ISPs, leveraging learnable sensor layouts, and adopting task-driven sensing strategies.    We welcome original contributions and position papers on the following topics (non-exhaustive):    Sensor optimization for e.g. computer vision (bit-depth, pixel layouts, color filter design)    RAW-to-task or RAW-to-label approaches for visual tasks    Co-design of neural networks and sensor hardware    Low-bit and energy-efficient sensing for embedded or mobile devices    Benchmarks, datasets, and metrics for evaluating sensor-model pipelines    Generalization and robustness of sensor-model systems in real-world conditions    Failure case studies and negative results in joint optimization pipelines    Join us to engage with cutting-edge research and cross-disciplinary discussions that are shaping the future of sensor systems for real-world deployment across mobile, embedded, and autonomous platforms.","Overview: The NeurIPS 2025 Workshop on Learning To Sense focuses on the joint optimization of sensors and machine learning models. It aims to push beyond traditional paradigms of data acquisition and processing by rethinking how machines sense the world. The workshop encourages the exploration of learnable sensor layouts and task-driven sensing strategies, moving away from hand-crafted ISPs. | Research Interests: Sensor optimization for computer vision, RAW-to-task or RAW-to-label approaches for visual tasks, Co-design of neural networks and sensor hardware, Low-bit and energy-efficient sensing for embedded or mobile devices, Benchmarks, datasets, and metrics for evaluating sensor-model pipelines, Generalization and robustness of sensor-model systems in real-world conditions, Failure case studies and negative results in joint optimization pipelines",计算,计算: 该团队关注低精度训练与推理对计算架构的影响，与L2S研讨会联合优化传感器与机器学习模型的低比特能效传感技术高度契合，助力探索低精度模型在嵌入式与移动设备上的应用与算力需求。,计算: 低比特和能效感知技术在嵌入式与移动平台的应用; 传感器硬件与神经网络的协同设计; 原始数据（RAW）直接驱动任务的端到端处理方法; 面向新型应用的低精度模型训练与推理策略; 传感器模型体系的鲁棒性及泛化能力提升
SUN 7 DEC,8 a.m.,Workshop,Multimodal Algorithmic Reasoning Workshop,https://neurips.cc/virtual/2025/workshop/109561,,5:00 PM,"Large AI frameworks have been increasing in their data modeling abilities at an ever more vigor in recent times, with compelling applications emerging frequently, many of which may even appear to challenge human intelligence. Yet despite such impressive performance, there remain open questions about whether these models include the foundations of general intelligence, or whether they perform these tasks without human-like understanding. This necessitates development of better tools for assessing these models in tandem with developing the models themselves. This workshop focuses on the topic of multimodal algorithmic reasoning, where an agent needs to assimilate information from multiple modalities towards deriving reasoning algorithms for complex problem solving. In the last year, we have seen rapid advances in AI capabilities that better bridge across modalities, bringing both optimism about superhuman capabilities and skepticism about the limits of current approaches. Through talks from outstanding researchers and faculty, we hope to dive deep into this exciting topic at the intersection of theory, multimodal learning and cognitive science to understand what we have achieved thus far in machine intelligence and what we are lacking in relation to the human way of thinking, towards finding the missing rungs on the ladder to truly intelligent reasoning.","Overview: The MAR 2025 workshop, held in conjunction with the Conference on Neural Information Processing Systems 2025, focuses on gathering researchers in neural algorithmic learning, multimodal reasoning, and cognitive models of intelligence. The workshop aims to showcase cutting-edge research, discuss challenges, and highlight overlooked problems in perception and language modeling crucial for achieving artificial general intelligence. The emphasis is on multimodal algorithmic reasoning, where agents deduce new algorithms for real-world tasks using multimodal foundational models. The event features talks from outstanding researchers to inspire the audience in exploring the intersection of multimodal learning and cognitive science. | Research Interests: Multimodal algorithmic reasoning, Neural algorithmic learning, Cognitive models of intelligence, Perception and language modeling, Vision-and-language mathematical reasoning, Multimodal games, Robotic manipulation, Chain-of-thought reasoning, Distributed agentic reasoning, Tool use in AI, Visual reasoning architectures, Data generation via self-play, Theoretical limits of reasoning in large models",诺亚,诺亚: 诺亚团队面临的长序列图文多模态模型推理瓶颈，与MAR 2025工作坊中关于多模态算法推理及模型能力进展高度契合，参会能深化对输入范式突破与推理效率提升的理解，助力解决关键技术难题。,诺亚: 多模态算法推理机制与架构优化; 长序列图文输入范式创新; 视觉与语言的数学推理能力提升; 链式思维推理与分布式智能代理; 认知科学视角下的人工智能能力评估
SUN 7 DEC,8 a.m.,Workshop,Data on the Brain and Mind,https://neurips.cc/virtual/2025/workshop/109557,,5:00 PM,,"Overview: The 'Data on the Brain & Mind' workshop aims to connect machine learning researchers with neuroscientists and cognitive scientists by focusing on concrete, open problems grounded in emerging neural datasets. The workshop emphasizes the diversity and heterogeneity of neuroscience and cognitive science datasets, encouraging the development of tailored AI solutions beyond generic models. It is designed to be highly interactive, fostering collaborations through invited talks, poster sessions, and mentorship opportunities. | Research Interests: Machine learning applications in neuroscience, Cognitive science data analysis, Neural datasets, Visual-motor cortical processing, Human development datasets, Natural speech processing, Interdisciplinary collaborations, Data-model integration and interpretability",,,
SUN 7 DEC,8 a.m.,Workshop,CogInterp: Interpreting Cognition in Deep Learning Models,https://neurips.cc/virtual/2025/workshop/109544,,5:00 PM,"Recent innovations in deep learning have produced models with impressive capabilities, achieving or even exceeding human performance in a wide range of domains. A timely and critical challenge in AI is understanding what behaviors these models are actually capable of, and the internal processes which support these behaviors. As interest continues to grow in models’ internal processes, the field of cognitive science is becoming increasingly useful for describing and understanding cognition in deep learning models: cognitive science, which seeks to describe the cognitive processes in human and animal minds, offers a rich body of theories, experiments, and frameworks which may be adopted to understand how deep learning models achieve complex behaviors in domains such as language, vision, and reasoning.The workshop will focus on Cognitive Interpretability (“CogInterp”), which involves the systematic interpretation of high-level cognition in deep learning models. Similar to how cognitive science describes the intermediate representations and algorithms (or cognition) between behavior and neurons in biological systems, the goal of Cognitive Interpretability is to describe the cognitive processes which lie between the levels of behavioral evaluations and mechanistic interpretability in deep learning models. Practically speaking, this means that Cognitive Interpretability does not just ask whether a model can perform task X or has a certain ability Y , but additionally (or instead) how a model performs X or learns and implements Y . These kinds of inferences—from observable behavior to latent “mental” processes—are the bread and butter of cognitive science, but many of the theoretical and empirical tools developed to tackle these problems have not yet been widely adopted in AI research, in part because of the separation between the fields and communities.To address the gap above, our goal is to bring together researchers in cognitive science and AI interpretability to discuss new empirical results and theories about the inner workings of deep learning models. We hope to gather perspectives from various disciplines, including machine learning, psychology, linguistics, vision science, neuroscience, philosophy of mind, and law.","Overview: The First Workshop on CogInterp: Interpreting Cognition in Deep Learning Models is set to take place at NeurIPS 2025 in San Diego, USA, on December 7, 2025. This workshop aims to address the challenge of understanding the behaviors and internal processes of deep learning models by leveraging insights from cognitive science. The workshop seeks to bridge the gap between AI research and cognitive science by bringing together researchers from various disciplines to discuss new empirical results and theories about the inner workings of deep learning models. | Research Interests: Cognitive Interpretability, Deep Learning Models, Cognitive Science, Machine Learning, Psychology, Linguistics, Vision Science, Neuroscience, Philosophy of Mind, Law",,,
SUN 7 DEC,8 a.m.,Workshop,What Can('t) Transformers Do?,https://neurips.cc/virtual/2025/workshop/109569,,5:00 PM,"With most advances in large foundation models (LFMs) being empirical, our theoretical understanding of what transformers can compute, express, and learn still lags behind. This workshop will convene theorists and empiricists to chart a rigorous agenda for the next generation of LFMs, asking “Whatcanandcan’ttransformers do?” We welcome both formal analyses and empirically grounded studies that shed light on theoretical questions, aiming to close the gap between proofs and practice while fostering new, interdisciplinary collaborations.","Overview: The workshop 'What Can(\'t) Transformers Do?' at NeurIPS 2025 aims to bridge the gap between empirical advances in large foundation models (LFMs) and the theoretical understanding of transformers. It seeks to explore what transformer-based language models can and cannot do by bringing together theorists and empiricists. The workshop encourages both formal analyses and empirical studies to address theoretical questions and foster interdisciplinary collaborations. | Research Interests: Theoretical analyses of transformer capabilities, Expressivity, Learnability, Inference-time scaling, In-context learning, Effects of architectural components, Empirical studies of transformer behavior, Architectural or training innovations, Mechanistic studies of failures, Comparisons of theorized and observed capabilities | Key Findings: The workshop highlights several accepted papers that contribute to understanding transformer capabilities and limitations, such as the role of transformer feed-forward layers, the failure of transformers in time series forecasting, and the limitations in program trace generation. These studies provide insights into the theoretical and practical aspects of transformer models.",,,
SUN 7 DEC,8 a.m.,Workshop,Learning from Time-Series for Health,https://neurips.cc/virtual/2025/workshop/109560,,5:00 PM,"Time-series data underpin modern healthcare, spanning electronic health records, physiological waveforms, wearables, and population trends, yet their unique characteristics—including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints—demand specialized machine learning approaches. While recent advances in foundation models, multimodal learning, and generative methods show promise, significant challenges remain in causality, interpretability, and deployment.  This workshop unites researchers across health time-series domains (from wearables to clinical systems) to address shared challenges through: (1) cross-domain discussion, (2) diverse industry/academic perspectives (featuring Google, Oura, Apple and 5 institutions), and (3) community engagement via posters, talks, and panels. By fostering cross-domain collaboration on physiological-aware methods, we aim to bridge the gap between cutting-edge ML and real-world healthcare impact.","Overview: The 'Learning from Time Series for Health' workshop at NeurIPS 2025 focuses on the application of machine learning to health-related time-series data. This workshop aims to address the unique challenges posed by such data, including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints. It brings together researchers from various domains to foster cross-domain collaboration and bridge the gap between cutting-edge machine learning techniques and real-world healthcare impact. The workshop features discussions, industry and academic perspectives, and community engagement through posters, talks, and panels. | Research Interests: Time-series data in healthcare, Machine learning for health, Foundation models, Multimodal learning, Generative methods, Causality in healthcare, Interpretability of models, Deployment of machine learning in healthcare",,,
SUN 7 DEC,8 a.m.,Workshop,Tackling Climate Change with Machine Learning,https://neurips.cc/virtual/2025/workshop/109574,,5:00 PM,"Many in the ML community wish to take action on climate change, but are unsure how to have the most impact. This workshop will highlight work that demonstrates that, while ML is no silver bullet, it can be an invaluable tool in reducing greenhouse gas emissions and in helping society adapt to the effects of climate change.Climate change is a complex problem for which action takes many forms, from advancing theory to deploying new technology. Many of these actions represent high-impact opportunities for real-world change, and simultaneously pose interesting academic research problems.The theme of this workshop, “Roots to Routes: A Dialogue on Different Machine Learning Methods for Climate Impact,” invites submissions that explore the strengths of diverse machine learning approaches in climate-related contexts. We particularly encourage work that demonstrates the effectiveness of classical ML methods under real-world constraints, such as limited data availability, privacy concerns, or restricted computational resources. At the same time, we welcome contributions that showcase how scaling up data and computing resources combined with modern tools and techniques can unlock new possibilities for tackling global-scale climate prediction challenges.This workshop is part of a series that aims to bring together those applying ML to climate change challenges and facilitate cross-pollination between ML researchers and experts in climate-relevant fields.The main workshop will take place on December 6 or 7, 2025 (exact date TBD).","Overview: The NeurIPS 2025 Workshop titled 'Tackling Climate Change with Machine Learning' aims to bring together the machine learning community to address climate change challenges. The workshop will highlight the role of machine learning as a tool to reduce greenhouse gas emissions and help society adapt to climate change. It is part of a series that facilitates collaboration between ML researchers and experts in climate-relevant fields. The main workshop will take place on December 7, 2025, as part of the NeurIPS conference in San Diego, California. | Research Interests: Agriculture and food, Behavioural and social science, Buildings, Carbon capture and sequestration, Cities and urban planning, Climate finance and economics, Climate justice, Climate science and climate modeling, Disaster management and relief, Earth observations and monitoring, Earth science, Ecosystems and biodiversity, Extreme weather, Forestry and other land use, Health, Heavy industry and manufacturing, Local and indigenous knowledge systems, Materials science and discovery, Oceans and marine systems, Power and energy systems, Public policy, Societal adaptation and resilience, Supply chains, Transportation",,,
SUN 7 DEC,8 a.m.,Workshop,Workshop on Mechanistic Interpretability,https://neurips.cc/virtual/2025/workshop/109547,,5:00 PM,,"Overview: The Mechanistic Interpretability Workshop at NeurIPS 2025 focuses on understanding the internal mechanisms of neural networks to bridge the gap between their performance and our understanding of their decision-making processes. The workshop aims to bring together diverse perspectives from academia, industry, and independent research to discuss recent advances, build common understanding, and chart future directions in the field of mechanistic interpretability. | Research Interests: Mechanistic interpretability, Neural network internals, Model behavior prediction, Reliability and adversarial behavior detection, Mathematical analysis of neural networks, Empirical studies on neural networks, Reverse-engineering models, Behavioral analysis of model representations, Cross-pollination of research methodologies, Unsupervised and supervised techniques in AI",,,
SUN 7 DEC,8 a.m.,Workshop,AI That Keeps Up: Workshop on Continual and Compatible Foundation Model Updates (CCFM),https://neurips.cc/virtual/2025/workshop/109584,,5:00 PM,"Foundation models, despite their impressive capabilities, face a critical challenge: they naturally become outdated. Trained on vast datasets, frequently updating these models is expensive. Crucially, these challenges extend beyond the scope of studies in traditional continual learning, as foundation models require rapid and scalable adaptation to dynamic global changes and the emergence of both generalized and specialized tasks. This workshop addresses the urgent need for up-to-date foundation models. We invite researchers to explore cost-effective methods for frequent updates and adaptation, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve.","Overview: The NeurIPS 2025 Workshop on Continual and Compatible Foundation Model Updates (CCFM) focuses on addressing the challenges faced by foundation models, which naturally become outdated over time. The workshop aims to explore cost-effective methods for frequent updates and adaptation of these models, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve. The event will take place on December 7th, 2025, at the San Diego Convention Center. | Research Interests: Foundation models, Continual learning, Model updates, Cost-effective adaptation, Dynamic evaluations, Minimizing forgetting, Consistent user experience",计算; 诺亚,计算: 该团队关注持续提升模型智能水平及训练推理范式演进，恰与Workshop探讨的基础模型频繁更新、避免性能衰退的技术挑战高度契合，特别是对负载特征演变的跟踪和预测。; 诺亚: 本Session聚焦于基础模型的持续更新与兼容性，直接对应团队在推理策略及模型内置记忆更新机制改进的挑战，助力实现高效适应与信息保留，提升模型性能和用户体验。,计算: 基础模型的高效频繁更新方法; 减少模型遗忘和性能退化的持续学习算法; 训练和推理新范式的负载特征分析与预测; 动态且可靠的模型评估体系设计; 保证用户体验一致性的适配策略; 诺亚: 基础模型的持续学习策略; 模型内置记忆机制优化; 避免遗忘的更新技术; 成本效益高的模型动态适应方法; 动态且现实的模型评估策略
SUN 7 DEC,8 a.m.,Workshop,Recent Advances in Time Series Foundation Models: Have We Reached the ‘BERT Moment’?,https://neurips.cc/virtual/2025/workshop/109585,,5:00 PM,"Foundation models (FMs) have achieved great success in NLP and vision, inspiring over 20 new time series FMs (TSFMs) in the past year. Despite promising results, studies show that carefully designed lightweight supervised baselines often match TSFM performance. Unlike NLP’s “BERT Moment,” TSFMs still require full fine-tuning to be competitive in real-world scenarios. Additionally, some tabular FMs rival TSFMs without being time series-specific. Recent benchmarks also provide mixed evidence: GIFT-Eval favors TSFMs, OpenTS shows statistical models outperforming deep learning on univariate data, and FoundTS finds supervised baselines on par with TSFMs. This workshop aims to bring together researchers to examine the gap between TSFM potential and real-world utility, and to identify benchmarks and applications where TSFMs can truly excel.The key topics of this workshop include, but are not limited to:- Benchmarking Foundation Models in Time Series,- Scaling Laws and Efficiency in Time Series Models,- Evaluating Transferability and Adaptability of Foundation Models,- Leveraging Foundation Models of Other Modalities for Time Series,- Unsupervised performance estimation of TSFMs,- Industrial Benchmarking of Time Series Foundation ModelsMore details are provided in ourCall for Papers.","Overview: The webpage presents the BERT2S workshop, which focuses on recent advances in Time Series Foundation Models (TSFMs) and their potential to reach a 'BERT Moment' similar to that in NLP. The workshop is part of the NeurIPS 2025 conference and aims to bring together researchers to explore the gap between the potential and real-world utility of TSFMs. It will include discussions on benchmarks, applications, and the development of TSFMs. | Research Interests: Benchmarking Foundation Models in Time Series, Scaling Laws and Efficiency in Time Series Models, Evaluating Transferability and Adaptability of Foundation Models, Leveraging Foundation Models of Other Modalities for Time Series, Unsupervised performance estimation of TSFMs, Industrial Benchmarking of Time Series Foundation Models | Key Findings: The workshop highlights that despite the promising results of TSFMs, lightweight supervised baselines often match their performance. It also notes that some tabular foundation models rival TSFMs without being time series-specific. Recent benchmarks provide mixed evidence on the superiority of TSFMs, indicating a need for further exploration and development.",,,
SUN 7 DEC,8 a.m.,Workshop,Symmetry and Geometry in Neural Representations,https://neurips.cc/virtual/2025/workshop/109551,,5:00 PM,"The fields of biological and artificial intelligence are increasingly converging on a shared principle: the geometry and topology of real-world structure play a central role in building efficient, robust, and interpretable representations. In neuroscience, mounting evidence suggests that neural circuits encode task and environmental structure through low-dimensional manifolds, conserved symmetries, and structured transformations. In deep learning, principles such as sparsity, equivariance, and compositionality are guiding the development of more generalizable and interpretable models, including new approaches to foundation model distillation. The NeurReps workshop brings these threads together, fostering dialogue among machine learning researchers, neuroscientists, and mathematicians to uncover unifying geometric principles of neural representation. Just as geometry and symmetry once unified the models of 20th-century physics, we believe they may now illuminate the computational foundations of intelligence.","Overview: The NeurReps Workshop is an annual event that brings together researchers from the fields of mathematics, deep learning, and neuroscience to explore the principles of neural representation in both biological and artificial systems. The workshop aims to uncover unifying geometric principles of neural representation, drawing parallels between the geometry and symmetry in neural circuits and machine learning models. The event fosters dialogue among experts to advance understanding in areas such as geometric mechanistic interpretability, the geometry of representations in foundation models, and improvements in large language model design. | Research Interests: Geometry and topology in neural representations, Symmetry and equivariance in neural circuits and models, Neuroscience and interpretability, Geometric deep learning, Foundation models of brain activity, Mechanistic interpretability, Dynamics in shaping neural representations",,,
SUN 7 DEC,8 a.m.,Workshop,GPU-Accelerated and Scalable Optimization (ScaleOpt),https://neurips.cc/virtual/2025/workshop/109554,,5:00 PM,"Recent advancements in GPU-based large-scale optimization have been remarkable. Recognizing the revolution in optimizing neural network weights via large-scale GPU-accelerated algorithms, the optimization community has been interested in developing general purpose GPU-accelerated optimizers for various families of classic optimization problems, including linear programming, general conic optimization, combinatorial optimization, and more specific problem families such as flow optimization and optimal transport. Beyond deploying GPUs directly at classical problems, current frontier AI tools—including large language models (LLMs)—are being deployed to solve optimization problem. Various works have used neural networks to solve mixed integer problems, linear or quadratic programs, general combinatorial optimization problems, and more specific optimization problems such as LASSO and robust PCA. In this workshop, we aim to provide a platform for interested researchers to engage with each other on recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems.","Overview: The ScaleOPT workshop at NeurIPS 2025 focuses on GPU-accelerated and scalable optimization, exploring practical optimization algorithms and toolkits that co-improve with advanced AI systems. The workshop aims to provide a platform for researchers to engage with recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems. | Research Interests: GPU-accelerated optimization, Large-scale optimization, Randomized numerical linear algebra, Differentiable convex optimization, First-order methods for linear programming, Second-order linear and nonlinear programming solvers, Stochastic combinatorial optimization, Nonlinear optimization with neural network constraints, Learning to optimize, Meta prompt optimization, Parametric convex optimization, Automation in optimization | Key Findings: The workshop highlights several advancements, such as the development of rlaopt, a PyTorch-based package for large-scale optimization, CuClarabel, a GPU-accelerated version of the interior-point solver for quadratic cone programs, and a GPU-accelerated framework for ultra-large-scale scenario-based evaluation in stochastic combinatorial optimization. It also discusses the benefits of reduced-space formulations for optimizing over trained neural networks and the potential of automated systems to enhance decomposition for proximal and parallel methods.",,,
SUN 7 DEC,8 a.m.,Workshop,"NeurIPS 2025 Workshop on Space in Vision, Language, and Embodied AI",https://neurips.cc/virtual/2025/workshop/109546,,5:00 PM,,"Overview: The SpaVLE workshop at NeurIPS 2025 aims to bridge the historically siloed efforts of the NLP, CV, and robotics communities by fostering cross-disciplinary dialogue to advance research on spatial understanding and representation. The workshop focuses on how spatial representations can be learned from multimodal data and applied to core tasks in computer vision, natural language processing, and robotics. It seeks to foster discussion on how spatial representations, whether symbolic, neural, verbal, or geometric, can be learned, evaluated, and deployed across modalities and tasks, aligning these approaches with real-world applications. | Research Interests: Foundations of Spatial Representation and Reasoning, Multimodal Spatial Grounding, Applications in NLP, Vision, Robotics, and Generative AI, Evaluation and Benchmarking Spatial Intelligence, Spatial Reasoning in Foundation Models",,,
SUN 7 DEC,8 a.m.,Workshop,"LAW 2025: Bridging Language, Agent, and World Models for Reasoning and Planning",https://neurips.cc/virtual/2025/workshop/109552,,5:00 PM,,"Overview: The LAW 2025 workshop, part of NeurIPS 2025, focuses on the integration of Language models (L), Agent models (A), and World models (W) to advance AI systems. The workshop aims to explore the intersection of these models to address complex real-world problems and simulate rich virtual environments. It seeks to catalyze discussions on how these models can be combined to create AI systems that think, plan, simulate, act, and explain themselves in dynamic, partially observed worlds. | Research Interests: Large Language Models, Autonomous Agents, World Modeling, Integration of Language, Agent, and World Models, AI Systems in Dynamic Environments, Generalizable World Models, LLM-based Agents",温哥华云,温哥华云: 该团队关注物理与具身AI关键研究领域，LAW 2025聚焦语言、代理与世界模型的集成，促进动态环境中AI系统的推理与规划。参与该Session有助于深化对具身智能的理解并驱动战略性研究布局。,温哥华云: 语言模型与代理模型的协同机制; 动态环境下的世界建模技术; 基于大型语言模型的自主智能体设计; 多模态信息融合与推理; AI系统的规划与自我解释能力提升
SUN 7 DEC,8 a.m.,Workshop,Workshop on Scaling Environments for Agents,https://neurips.cc/virtual/2025/workshop/109540,,5:00 PM,"The development of intelligent agents – particularly those powered by large language models (LLMs) – has emphasized the critical role of environments in shaping agent behavior and capabilities, especially for achieving end-to-end autonomy. Environments are not merely testing grounds; they are dynamic, interactive contexts that serve as the essential ""data"" for agents to learn adaptive behavior, complex reasoning, and long-term decision-making skills. Just as scaling the model size, dataset size, and training computation has led to emergent capabilities in LLMs, scaling the structure, fidelity, and diversity of environments is one of the crucial dimensions in advancing agent intelligence. Moreover, recent advances in end-to-end reinforcement learning (RL), particularly when paired with LLM-based agents, have made it increasingly viable to train agents through sustained interaction. These agents can now acquire skills, strategies, and planning abilities through environmental feedback, rather than relying solely on imitation learning or static prompt engineering. As we move toward more autonomous, general-purpose agents, the need for scalable, richly interactive, and diverse environments has become both urgent and foundational.","Overview: The Scaling Environments for Agents (SEA) Workshop at NeurIPS 2025 focuses on the development of intelligent agents, particularly those powered by large language models (LLMs). The workshop emphasizes the critical role of environments in shaping agent behavior and capabilities, aiming to advance agent intelligence through scalable, richly interactive, and diverse environments. The workshop covers various aspects of environment design, evaluation, and integration with LLMs, highlighting the importance of environments as dynamic, interactive contexts for learning adaptive behavior, complex reasoning, and long-term decision-making skills. | Research Interests: Environment Infrastructure Design, Benchmarks and Evaluation, LLMs in Interactive Environments, Tool-Use and Software Environments, Multi-Agent Systems and Simulation Environments, Embodiment and Grounding, Sim2Real and Deployment",多伦多云,多伦多云: 该团队关注Agent业务上线后的自主学习与持续优化机制，匹配Session中关于通过环境交互实现L3+ agent多步执行能力的持续优化，契合环境设计与模型优化的结合，为解决Prompt与模型飞轮融合提供前沿思路。,多伦多云: 环境基础设施设计与扩展性; 多步规划与执行能力的Agent训练方法; 结合Prompt优化与模型优化的持续学习机制; 基于交互环境的端到端强化学习; 多代理系统与模拟环境的集成技术
