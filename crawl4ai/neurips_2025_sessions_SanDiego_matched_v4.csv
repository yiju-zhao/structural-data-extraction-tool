date,time,type,title,url,speaker,end_time,abstract,overview,匹配团队,关注方向,推荐理由
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Telling Stories at Scale: Multimodal ML in the Global Media Landscape,https://neurips.cc/virtual/2025/128652,,9:30 AM,"Netflix has long been recognized as a pioneer in personalization, leveraging member preference data to recommend the most engaging shows, movies, and games. In recent years, we have expanded our use of machine learning and data-driven approaches to support a wide array of upstream creative and operational workflows. In this talk, we will discuss how modern AI methods – contrastive learning, transformers, cross-modal retrieval, graph neural networks, etc. – are transforming the curation, localization, promotion, and launch of stories on a global scale. A distinctive aspect of our work is the integration of highly creative assets—text, images, video, and speech—alongside traditional tabular datasets. We will highlight unique challenges that arise at the intersection of multimedia, personalization, and web-scale products, and share how advanced ML/AI techniques are addressing these challenges to connect great stories with our worldwide audience.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Data Scout: “From Prompt to Corpus: Accelerating Domain-Specific Data Collection with LLMGuided Discovery”,https://neurips.cc/virtual/2025/128656,,9:30 AM,"Training large language models for specialized disciplines such as advanced mathematics, molecular biology, or legal reasoning is limited by the scarcity of large, high quality, domain specific corpora. Most publicly available datasets are dominated by general purpose web text. When available, specialized data are fragmented across diverse sources such as preprints, conference papers, forums, lecture notes, and digitized books. No single source offers comprehensive real-world coverage across scientific domains. Consequently, scaling up authentic domain data remains a bottleneck: collecting a subset of relevant tokens often requires downloading and filtering hundreds of terabytes of raw web material, a process that is both time consuming and costly.x000Dx000DWe introduce Data Scout, a modular, LLM powered pipeline that turns a high-level user intent (e.g., “I need data for advanced mathematics”) into a vetted, list of seed URLs in minutes. The system first expands the original intent using an LLM that generates a hierarchical subgraph of related concepts; this taxonomy drives a diversified set of search queries that systematically cover the target domain while respecting known licensing signals. Candidate URLs are then filtered by the same LLM using chain of thought prompting based on topical relevance, licensing clarity, and crawlability. Our results show that that the list of selected candidate URLs when crawled can yield a high percentage of relevant pages (40%+) related to the user’s intended topic or query, compared to less than 1 percent in general web-scale corpora. Data Scout is available with both CLI and GUI front ends. By democratizing domain specific data acquisition, Data Scout enables researchers without dedicated crawling infrastructure to bootstrap large, high-fidelity corpora, accelerating the development of specialized LLMs across various niche domains fields.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Multimodal Data Foundation at Industry-Scale,https://neurips.cc/virtual/2025/128659,,9:30 AM,"Pre-training is fundamental to foundation models, enabling them to acquire broad knowledge that gives rise to emerging capabilities at later training stages, and scaling is the key for pre-training. In this talk, we present a recipe for building and curating pre-training, multimodal image-text paired data from scratch on a global scale, enabling mutual benefits between English and non-English data. We would like to share our key observations and insights with the community on: (1) why scaling matters, including the foundational role of data and key principles to hold for scaling; (2) how to design simple yet scalable data algorithms that enable industry-scale data collection and training without data filters, serving both research and production needs; (3) how the scaling improves Meta’s products at conventional and frontier machine learning areas. Submission is facilitated by Cogs & Marvel but is entirely organized, executed, and implemented by Meta.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Toward General Full Autonomy: Open Research Challenges in Scalable Self-Driving,https://neurips.cc/virtual/2025/128661,,9:30 AM,"Speaker: Ben Snyder, Director of AI Research for Autonomous Vehicles, General Motorsx000Dx000DGM’s driver-assistance systems now power millions of vehicles across North America, logging over half a billion hands-free miles with zero reported crashes—demonstrating the safety and scalability of autonomy at unprecedented consumer scale. Following GM’s acquisition of Cruise earlier this year, the combined teams now bring together a decade of experience to accelerate progress toward full, generalized autonomy. This talk will dive into the open research challenges ahead—from model architecture and the balance between imitation and reinforcement learning, to leveraging vision-language models for long-tail, common-sense reasoning, and advancing the training, deployment, and simulation infrastructure needed to scale truly generalized autonomy.",,温哥华云; 诺亚,温哥华云: Embodied AI; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session讨论自动驾驶具身智能架构、IL vs RL取舍、VLM长尾推理与仿真训练基础设施，可重点关注感知-决策-控制一体化与仿真驱动数据闭环。; 诺亚: Session讨论长尾场景下VLM常识推理与IL/RL融合策略及端到端架构，可重点关注自博弈、离线-在线混合训练与latent reasoning用于长尾决策。
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Beyond Benchmarks: Rethinking Reasoning in Language Models,https://neurips.cc/virtual/2025/128665,,9:30 AM,"Reasoning is often described as the next frontier for AI, but what does it really mean for a model to “reason”, and how should we measure it? Popular benchmarks like GSM8K suggest steady progress, yet controlled studies reveal that models can fail dramatically under small changes—such as swapping numbers or adding irrelevant details. Large Reasoning Models (LRMs), which generate explicit chains of thought, raise new optimism but also expose clear limits: they often underperform standard models on simple tasks, improve briefly at medium complexity, and then collapse on harder ones despite having unused compute. Crucially, reasoning is not the same as knowledge recall, tool use, or agent-like behavior. True reasoning involves solving novel problems, decomposing them into steps, generalizing to new contexts, recombining partial results, and finally generating novel hypotheses—capabilities current systems largely lack. Today’s evaluations, focused on final answers and contaminated benchmarks, risk giving a misleading sense of progress. This talk will provide a critical review of reasoning in language models, highlight why current evaluations can be deceptive, and emphasize that reasoning is not just about “what"" models answer, but “how"" they solve problems.",,诺亚,诺亚: 大模型后训练Reasoning，RL,诺亚: Session讨论LLM推理定义、评测偏差与LRM局限，可重点关注过程评估、分步监督与过程奖励在后训练Reasoning/RL中的落地
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Foundational Generative Recommendations for E-Commerce,https://neurips.cc/virtual/2025/128667,,9:30 AM,"Modern commerce platforms face the challenge of delivering personalized recommendations across billions of items to users with diverse intents, temporal dynamics, and cold-start scenarios. We present a generative foundation model for commerce built on Hierarchical Sequential Transduction Units (HSTU) that integrates Liquid Foundation Models (LFM) for rich textual product representations and custom CUDA kernels developed in collaboration with Nvidia for efficient training and online serving. Our approach demonstrates that generative methods unlock substantial gains through three key innovations: (1) large-scale contrastive learning with hard negative sampling; (2) temporal mechanisms that fuse multi-scale time signals (session, day, season) with commerce-specific features; and (3) optimized training and inference kernels. By treating LFM embeddings as auxiliary features rather than end-to-end fine-tuning, we maintain modularity while capturing semantic relationships. While results are promising, significant challenges remain in handling non-stationary preferences, multi-objective optimization, and ensuring fairness in generative retrieval—we discuss our roadmap toward truly foundational commerce models that generalize across domains and market conditions.",,,,
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,From Research to Markets: Applying Cutting-Edge Machine Learning in Quantitative Finance,https://neurips.cc/virtual/2025/128670,,9:30 AM,"In modern quantitative finance, the boundaries between academic machine learning research and real-world trading strategies are rapidly dissolving. In this talk, we will share how researchers at G-Research apply advances in deep learning, probabilistic modelling, reinforcement learning, and large-scale optimization to some of the most challenging problems in global financial markets. Our work transforms vast, noisy, and non-stationary data into predictive signals, demanding innovations that extend the state of the art in both theory and practice. This includes sequence modelling for high-frequency data, scalable Bayesian inference for uncertainty quantification, generative modelling for scenario analysis, and reinforcement learning for adaptive portfolio construction. Operating at the intersection of rigorous science and high-performance computing, we thrive in an environment where milliseconds matter and model generalization is paramount.x000Dx000DCome and see how cutting-edge machine learning meets the realities of global financial markets at G-Research.",,温哥华云,温哥华云: Reinforcement fine tuning (RFT),温哥华云: Session讨论量化中的强化学习、序列建模与可扩展贝叶斯UQ，可重点关注非平稳环境下RL样本效率与稳定性、离线-在线混合训练及生产化实践。
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection,https://neurips.cc/virtual/2025/128668,,9:30 AM,"The rapid integration of LLMs for synthetic data generation offers a powerful solution for data scarcity, a critical issue for training machine learning models. However, the resulting data quality is often questionable, requiring costly and time-consuming manual review. This oversight is especially challenging in the crucial domain of trustworthy and safe AI.x000Dx000DA significant need here is the automated identification of adversarial and harmful inputs, a process known as red-teaming, to improve guardrailing systems before deployment. Developing an effective, fully automated red-teaming approach capable of generating diverse, out-of-domain harmful content has been a long-standing challenge.x000Dx000DTo address data scarcity in harmful text detection & the challenge of automated red-teaming, we introduce GRAID (Geometric & Reflective AI-Driven Data Augmentation), a novel, versatile, & dynamic multi-agent framework.x000Dx000DGRAID operates in two stages:x000D1) Geometric Generation: A constrained, fine-tuned LLM generates geometrically controlled examples to diversify content within the original embedding space.x000D2) Reflective Augmentation: A multi-agentic reflective process promotes stylistic diversity & uncovers difficult edge cases.x000Dx000DThis combination ensures both reliable coverage of the input space & nuanced exploration of harmful content. We demonstrate that augmenting a harmful text classification dataset with GRAID significantly improves the performance of downstream real-world guardrail models. Furthermore, GRAID captures data variability in new geometric domains while preserving data relationships.x000Dx000DWhile initially focused on harmful text detection, GRAID’s modular design makes it an inherently domain-agnostic framework adaptable to various applications beyond classification. In this talk, we will detail how GRAID distinguishes itself from existing solutions, discuss its building blocks, & share insights on its easy adaptation for diverse synthetic data generation needs.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session讨论几何约束合成数据与多智能体反思式red-teaming，可重点关注其在安全RFT中的难例挖掘、评测覆盖与训练数据增广。; 诺亚: Session讨论几何约束生成与多智能体反思增广，可重点关注将其融入自博弈/learning from experience以构造对抗数据与基准。
TUE 2 DEC,9:30 a.m.,Tutorial,Planning in the Era of Language Models,https://neurips.cc/virtual/2025/109596,,12:00 PM,"For over six decades, the field of automated planning has been at the heart of AI, empowering intelligent systems to reason, act, and achieve goals in complex, dynamic environments. From robotics and logistics to space exploration, planning research has fueled autonomous decision-making in real-world applications.Today, as large language models redefine what’s possible in AI, the principles and methodologies of planning are more vital than ever. The planning community brings decades of experience in designing, benchmarking, and interpreting intelligent behavior; expertise that can accelerate the development of powerful, trustworthy, and general-purpose LLM-based agents.Participants will gain a clear understanding of what planning truly entails, what has been learned (and sometimes forgotten) in the shift toward LLM-based approaches, and how foundational insights from the planning community can inform the creation of stronger, more reliable, and more scalable LLM-powered planners.","Overview: The webpage presents a tutorial titled 'Planning in the Era of Language Models' scheduled for December 2nd, 2025, at NeurIPS in San Diego, CA. The tutorial focuses on the integration of automated planning with large language models (LLMs). It highlights the importance of planning in AI, especially as LLMs redefine AI capabilities. The tutorial aims to provide participants with insights into planning methodologies and how these can enhance the development of LLM-based agents. | Research Interests: Automated planning, Large language models, AI reasoning and decision-making, Planning formalisms and languages, Evaluation of planning tools, Human-aware AI systems",温哥华云; 计算,温哥华云: Embodied AI; 计算: 前沿应用负载,温哥华云: Session讨论LLM结合自动规划（PDDL/HTN、分层任务分解、基准评测），可重点关注具身场景的层级规划、长期目标分解与Plan-Act执行监控设计。; 计算: Session讨论LLM规划工作流与评测（任务分解、长程推理、回溯反思），可重点关注多步Plan-Act闭环对Agentic负载形态、算力峰谷与内存访问节律的影响。
TUE 2 DEC,9:30 a.m.,Tutorial,Foundations of Tensor/Low-Rank Computations for AI,https://neurips.cc/virtual/2025/109591,,12:00 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Human-AI Alignment: Foundations, Methods, Practice, and Challenges",https://neurips.cc/virtual/2025/109592,,12:00 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Model Merging: Theory, Practice and Applications",https://neurips.cc/virtual/2025/109593,,12:00 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,New Frontiers of Hyperparameter Optimization: Recent advances and open challenges in theory and practice,https://neurips.cc/virtual/2025/109594,,12:00 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Explain AI Models: Methods and Opportunities in Explainable AI, Data-Centric AI, and Mechanistic Interpretability",https://neurips.cc/virtual/2025/109599,,1:30 PM,,,,,
TUE 2 DEC,9:30 a.m.,Tutorial,Energy and Power as First-Class ML Design Metrics,https://neurips.cc/virtual/2025/109589,,12:00 PM,,"Overview: The tutorial titled 'Energy and Power as First-Class ML Design Metrics' at NeurIPS 2025 focuses on addressing energy as a critical bottleneck in machine learning. It provides practical measurements, a primer on power and energy as computing resources, and optimizations from kernels to clusters. The event is a collaboration between The ML.ENERGY Initiative at the University of Michigan and NVIDIA, featuring a series of sessions and an industry panel discussion. | Research Interests: Energy efficiency in machine learning, Power and energy as computing resources, Performance optimization under power constraints, Energy optimization with performance considerations, Industry applications of power and energy in ML",计算,计算: 高效模型架构,计算: Session讨论功耗-性能度量与功率约束优化，可重点关注低精度算子能耗剖析、能效Roofline与power capping，支撑精度规格与算力配置。
TUE 2 DEC,noon,Expo Demonstration,Multimodal AI Forensic Search for Video Surveillance,https://neurips.cc/virtual/2025/128632,,3:00 PM,"Video surveillance often requires searching for specific targets from long-duration videos using multiple cameras. Traditional tracking‑and‑detection pipelines demand heavy manual filtering, and even recent multimodal approaches such as using CLIP remain limited to shallow visual attributes (e.g., clothing color) and weak temporal reasoning. This makes forensic search labor‑intensive.x000Dx000DWe present ForeSea, a novel AI forensic search system that supports rich multimodal queries (text + image) and returns timestamped evidence of key events. ForeSea is organized as a multi‑stage pipeline that couples tracking and retrieval with time‑aware VideoLLM reasoning: (1) uses tracking model to filter out irrelevant segments (e.g., frames without people) and produces person‑centric clips; (2) retrieval constructs an index over tracked clips to form a searchable database; and (3) during inference, the multimodal query is embedded to retrieve the top N candidate clips, which are then fed into a time-aware VideoLMM that performs temporal grounding and generates precise answers from concise input. Through ForeSea's multi-stage pipeline, we can search for targets using both image and text queries (e.g., asking 'When does this person get involved in a fight?' with an image of the person). This approach eliminates the need for detailed textual descriptions and enables effective temporal understanding across long videos.x000Dx000DTo evaluate LMM based forensic search, we introduce AI Forensic‑QA, a benchmark for multimodal video question answering with temporal grounding. On this benchmark, ForeSea achieves an 8.6 % accuracy improvement and a 6.9 (IoU) gain over strong baselines. To the best of our knowledge, this is the first benchmark in this domain to support multimodal queries evaluation. Our live demo showcases multimodal search, timestamped evidence visualization, and side‑by‑side comparisons with SOTA models.",,诺亚; CBG,诺亚: 大模型长序列，多模态长序列; CBG: 3DAIGC,诺亚: Session讨论时间感知VideoLLM的长视频检索与时序定位，可重点关注检索-候选-Grounding测试时策略与模型内置记忆更新机制。; CBG: Session讨论跟踪+检索+时间感知VideoLLM的多阶段管线，可重点关注人物中心切片、跨镜时空关联与时序Grounding以提升分割与跟踪。
TUE 2 DEC,noon,Expo Demonstration,Efficient LiDAR Processing with AI Models Leveraging Heterogeneous Compute,https://neurips.cc/virtual/2025/128633,,3:00 PM,"This demo showcases heterogeneous compute execution of a LiDAR model running in real time on an edge device. The LiDAR processing, specifically 3D sparse convolution (spconv3d) network, runs on the Qualcomm Adreno GPU, while the Region Proposal Network (RPN) executes on the Qualcomm Hexagon NPU.  This division of labor across specialized processors reduces on-device inference latency and maximizes overall efficiency. Additionally, a lightweight, learnable voxel removal layer that hierarchically prunes redundant voxels further reduces inference time without compromising detection accuracy.x000Dx000D""This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.""x000Dx000DImplementation challenge that we tacklex000Dx000DLiDAR models often combine different types of operations: irregular, sparse computations (e.g., SpConv3D) and dense convolutional layers (e.g., CNNs). These operations have distinct hardware affinities—SpConv3D is better suited for SIMT-style GPUs, while CNNs benefit from SIMD-style NPUs. Efficient execution requires mapping each part of the model to the most appropriate compute unit.x000Dx000DAnother challenge is the variability in voxel density across LiDAR frames. Not all voxels contribute meaningfully to object detection, many represent ground planes or distant background and can be safely discarded. However, identifying and removing these in a lightweight, learnable way is non-trivial.",,温哥华云; CBG,温哥华云: Embodied AI; CBG: 3DAIGC,温哥华云: Session讨论边端LiDAR在GPU/NPU的异构映射、spconv3D/RPN分工与可学习体素裁剪，可重点关注具身系统实时感知的算子分配、异构调度与时延优化。; CBG: Session讨论spconv3D在GPU、RPN在NPU的分工及可学习体素裁剪，可重点关注3D/4D稀疏重建的稀疏卷积加速、体素裁剪与端侧实时部署。
TUE 2 DEC,noon,Expo Demonstration,Parallel generation with verification on device,https://neurips.cc/virtual/2025/128634,,3:00 PM,"In this work, we address the challenges of efficiently generating and verifying multiple responses from large language models (LLMs) directly on device. While sampling with non-zero temperature often yields improved responses compared to greedy approaches, selecting the best response requires generating several candidates and evaluating them without incurring significant latency or resource overhead. Cloud-based solutions often rely on separate verification models, which are impractical for on-device deployment due to resource constraints. Our proposed solution leverages multi-stream execution graphs and parallel LLM generation, enabling joint generation and verification within a unified framework. Combined with post-processing techniques such as majority voting, this approach minimizes latency and optimizes the selection of high-quality responses, paving the way for more effective on-device LLM inference.x000Dx000DSpecific challenge that we tackle (research/implementation-wise)x000Dx000DUsing non-zero temperature sampling with language models can result in higher-quality responses compared to greedy sampling, although this is not always assured. Achieving optimal output often requires generating multiple candidate responses and selecting the most suitable one for the user. This technique is widely adopted to enhance inference-time performance. When implemented on device, however, it presents two primary challenges: minimizing the latency associated with generating several responses and determining a resource-efficient method for selecting the best response from the generated set.",,海思; 计算; 诺亚,海思: 大语言模型和扩散模型的加速; 计算: 训推新范式; 诺亚: 大模型长序列，多模态长序列,海思: Session讨论端侧多流并行生成与联合验证，可重点关注NPU多流执行图调度、并行采样与多数投票的硬件落地与降延策略。; 计算: Session讨论端侧并行解码与联合验证的新范式，可重点关注流并行度、验证开销与带宽约束对架构定义与调度策略的影响。; 诺亚: Session讨论非零温度并行采样与端侧联合验证，可重点关注多数投票/一致性检查等测试时推理策略的精度-延迟权衡与算法优化。
TUE 2 DEC,noon,Expo Demonstration,Soft Prompts for On-Device Content Moderation,https://neurips.cc/virtual/2025/128635,,3:00 PM,"We demonstrate the first on-device integration of a safety-aligned large language model (LLM) using soft prompt distillation, powered by our proposed TV-DiSP framework. Our system showcases how a mobile device can run a quantized LLM equipped with learned soft prompts to moderate harmful or toxic content in real-time. The demo highlights the difference in LLM outputs with and without our soft prompts when subjected to adversarial or unsafe inputs, enabling efficient and safe deployment of LLMs on edge devices.x000Dx000DLLMs are known to produce unsafe or toxic outputs when prompted harmfully. Traditional safety mechanisms rely on dual-model architectures—pairing a base LLM with a separate guard model—which are memory and computationally expensive and unsuitable for deployment on resource-constrained devices like smartphones. The challenge is to achieve robust safety alignment without compromising latency, memory, or model utility in edge environments.",,多伦多云,多伦多云: AI Agent,多伦多云: Session讨论软提示蒸馏在端侧量化LLM的安全对齐与内容审核，可重点关注以TV-DiSP实现单模型护栏替代守卫模型、在Agent写操作前后的拦截与评测策略。
TUE 2 DEC,noon,Expo Demonstration,Generating group photos of multiple people from text and reference images,https://neurips.cc/virtual/2025/128636,,3:00 PM,"Reference-based multi-human image generation is emerging as a critical capability for personalization, synthetic data creation, and benchmarking generative models. Unlike single-subject generation, this task requires compositional reasoning to place multiple individuals—each with distinct identities—into a coherent scene guided by a text prompt. Existing models often fail to preserve identities or maintain spatial fidelity, which limits their applicability for real-world scenarios such as social content creation or training vision systems.x000Dx000DOur demo addresses these challenges by showcasing a state-of-the-art system for reference-based multi-human generation. The system takes reference images of multiple individuals and a text description of the desired scene, then produces a high-quality image featuring all participants in context. Built on the Flux-Kontext backbone and trained using synthetic data from DisCo (arXiv:2510.01399), our RL-based approach optimizes multiple rewards including Human Preference Score (HPS3) and Average ID Similarity. Evaluation on MultiHuman-Testbench (arXiv:2506.20879) confirms state-of-the-art performance.x000Dx000DThis demo showcases fast generation on a laptop powered by a Snapdragon processor, highlighting the efficiency and scalability of our solution.",,温哥华云; 海思; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session讨论基于RL的多目标图像生成优化（HPS3、ID相似度），可重点关注奖励设计与权重调度、离线RFT采样效率和可扩展训练。; 海思: Session讨论参考驱动的多人图像生成与文本/图像条件融合，可重点关注统一特征空间建模、身份嵌入缓存与轻量蒸馏以支撑低时延。; 诺亚: Session讨论多目标RL驱动的人偏好对齐与身份保持图像生成，可重点关注奖励组合/约束优化、偏好模型训练与策略稳定性。
TUE 2 DEC,noon,Expo Demonstration,Reasoning through Multimodal End-to-End Decision Transformer Networks and Vision Language Action (VLA) models,https://neurips.cc/virtual/2025/128637,,3:00 PM,"This demonstration showcases the live output and visualization capabilities of an edge-integrated VLA model for path planning in automated driving scenarios. By harnessing raw multimodal sensor inputs, including visual and voice data, the VLA model processes information in real time to generate safe, explainable, and repeatable driving trajectories. The system operates on a Snapdragon Ride Elite SoC platform and incorporates safety guardrails, enabling robust decision-making and transparent reasoning. Attendees will observe how end-to-end AI networks interpret complex environmental cues to deliver actionable driving paths, with a special focus on complex use cases involving vulnerable road users and other actors on the road. This demonstration highlights advances in multimodal reasoning and edge deployment for next-generation intelligent mobility solutions.",,温哥华云; 诺亚,温哥华云: Embodied AI; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session讨论端侧VLA与Decision Transformer在自动驾驶路径规划的实时推理与可解释性，可重点关注感知-行动对齐、离线RL序列建模与安全护栏工程化。; 诺亚: Session讨论Decision Transformer与VLA驱动的端到端决策推理，可重点关注离线RL/行为克隆、隐式规划、长尾场景安全约束下的推理校正策略。
TUE 2 DEC,noon,Expo Demonstration,Disaggregated LLM Serving on AI Accelerators,https://neurips.cc/virtual/2025/128638,,3:00 PM,"This demo showcases disaggregated serving on Qualcomm Cloud AI 100 Ultra Card, a power-efficient AI inference accelerator purpose-built for large language models (LLMs) serving. The accelerator has been deployed across multiple cloud service providers (CSPs) globally and is actively serving state-of-the-art LLMs and other generative AI workloads.x000Dx000DLLM inference typically involves two distinct stages: prefill and decode. The prefill stage is compute bound, while the decode stage is memory bound. Applying uniform parallelism strategies across both stages often results in suboptimal performance, particularly in key metrics such as Time to First Token (TTFT) and Requests Per Minute (RPM) at the cluster level.x000Dx000DThis demo highlights the performance benefits of disaggregated parallelism strategies tailored to the unique characteristics of each stage. By optimizing the execution of prefill and decode independently, we demonstrate significant improvements in TTFT and overall throughput.x000Dx000DKey benefits:x000Dx000DImproved TTFT: Faster initial response times for LLM queries.x000Dx000DHigher throughput: Increased number of requests served per minute at the cluster level.x000Dx000DOptimized resource utilization: Efficient mapping of compute and memory resources to match workload characteristics.x000Dx000DSLA-adherent performance: Maintains service quality and responsiveness within strict latency and throughput requirements.",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 训推新范式,海思: Session讨论LLM推理前填充/解码解耦与分离并行以优化首Token时延与吞吐，可重点关注阶段化算存映射、解码内存瓶颈加速与低时延调度。; 计算: Session讨论面向前填充/解码的分解化并行与TTFT/RPM权衡，可重点关注阶段化负载画像、并行策略对芯片与集群编排及SLA的影响。
TUE 2 DEC,noon,Expo Demonstration,SwiftEdit: Fast Text-guided Image Editing via One-step Diffusion on a Mobile Device,https://neurips.cc/virtual/2025/128639,,3:00 PM,"In this demo, we show an on-device inference of our one-step diffusion image editing model (SwiftEdit) [1] that performs interactive image editing based on the user’s source image and text prompt, running on an Android smartphone powered by Qualcomm Technologies’ latest Snapdragon Mobile Platform. On A100 GPUs, this technique can run in real-time with 0.23s per single edit operation. We expect SwiftEdit to perform each edit operation in seconds on the smartphone, demonstrating efficient and responsive on-device diffusion inference.x000Dx000DScientific Challenge that we tacklex000Dx000DExisting text-guided image editing methods fell short of the speed demands required for real-world and on-device applications due to the costly multi-step inversion and sampling process involved. In response to this, we developed SwiftEdit that performed image editing using just one-step inversion and one-step image reconstruction.x000Dx000DEfficiently running SwiftEdit requires concurrently on-boarding multiple deep models, including IP-Adapter (Vision Encoder and Image Projection), SwiftBrush (U-Net, VAE, Text Encoder), and SwiftBrush-based Inversion Network. This poses significant challenges for efficient execution and inter-module communication, while enabling an interactive image editing experience for the user — with all computation performed entirely on the edge device.",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构,海思: 该session展示在安卓手机端的一步扩散图像编辑（SwiftEdit），用一步反演+一步重建替代传统多步反演与采样，显著压缩推理路径，直接回应“在低延迟前提下实现实时推理”的难题；同时并行上板IP-Adapter（视觉编码与图像投影）、SwiftBrush（U-Net、VAE、文本编码器）与反演网络并优化模块间通信，提供了在文本+图像条件下减少条件融合与交互编辑延迟的具体工程做法。; 计算: SwiftEdit将多步扩散重构为一步反演+一步重建，并在边缘设备上协同IP-Adapter、U-net、VAE、文本编码器与反演网络，体现面向低时延/低功耗的生成模型架构演进与跨模块通信优化。该方法及其实测性能（A100单次编辑0.23s、手机侧秒级）可直接用于评估算力-带宽配比、算子融合与调度策略等系统需求，帮助把握高效生成模型架构的演进方向。
TUE 2 DEC,noon,Expo Demonstration,Mobile Video Diffusion Transformers,https://neurips.cc/virtual/2025/128640,,3:00 PM,"We demonstrate Neogradon, the first video diffusion transformer (DiT) designed to run on low-power NPUs in mobile devices, such as phones and laptops. Despite DiTs huge memory and computation cost due to the quadratic attention over thousands of video tokens, we show that mobile devices can run these models when being designed for efficiency. To achieve this level of efficiency:x000Dx000DWe replace the original large text encoder with a much smaller one with minimal quality loss through our novel distillation framework, which doesn’t require any image or video data.x000Dx000DWe propose an asymmetric decoder distillation approach, which allows us to replace the native codec-latent-VAE decoder with a more efficient one, without disturbing the generative latent-space of the video generation pipeline.x000Dx000DWith our block pruning strategy, we remove entire blocks from the MMDiT denoiser based on their relative importance and recover the original performance through a two-stage distillation process.x000Dx000DWe reduce the diffusion sampling cost using our novel extended version of DMD (distribution matching distillation) for the pyramidal flow-matching objective.x000Dx000DNeodragon generates 49 frames of 640x1024 resolution within 7.6 seconds on the Qualcomm Hexagon NPU with the VBench total score of 81.61, setting a new state of the art for mobile video generation.x000Dx000D""This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.""",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 训推新范式,海思: 该演示直面“移动端NPU上的Video DiT加速”，与贵组的扩散模型加速高度一致。具体对应难题：1) 通过块级剪枝+两阶段蒸馏、以及将DMD扩展到pyramidal flow-matching降低采样成本，在Qualcomm Hexagon NPU上实现7.6秒生成49帧且VBench=81.61，提供“低延迟且质量基本不降”的可复用路径；2) 用“无图像/视频数据”的文本编码器蒸馏将大文本编码器替换为小模型，直接降低多模态条件（文本→视频）编码时延；3) 正面应对“数千视频token导致的二次注意力”问题，以整块剪枝+蒸馏和采样蒸馏降低有效计算复杂度，并以非对称解码器蒸馏替换codec-latent-VAE以进一步缩短端到端延迟。; 计算: 该Session展示多项会改变训练/推理负载形态的新范式：无数据蒸馏构建小型文本编码器、非对称解码器蒸馏以在不破坏潜空间下替换为高效解码器、基于块重要性的整块剪枝并用两阶段蒸馏恢复精度、以及将DMD扩展到pyramidal flow-matching以削减扩散采样步数。这些方法在不改变任务目标的情况下显著改变推理路径（采样循环/模块深度/算子组合），为跟踪、理解并预测未来训推范式→负载特征的演进提供了具体技术样本。
TUE 2 DEC,noon,Expo Demonstration,Pushing the boundaries of chemical synthesis with RetroChimera,https://neurips.cc/virtual/2025/128641,,3:00 PM,"Retrosynthesis - the task of planning chemical reaction recipes to synthesize complex molecules - remains a bottleneck in the discovery of novel pharmaceuticals. We recently released RetroChimera - a model for predicting chemical reactions - which demonstrated robustness well outside of training distribution by transferring zero-shot to internal reaction data at a major pharmaceutical company. We also found that industrial organic chemists prefer predictions from RetroChimera over real patented reactions in terms of quality, revealing a high degree of alignment. In this demo, we will showcase the model, let attendees query it live, and show them how to interpret the results.",,,,
TUE 2 DEC,noon,Expo Demonstration,BeeAI,https://neurips.cc/virtual/2025/128642,,3:00 PM,"The BeeAI Framework is an open-source project for building reliable AI agents that combine autonomy with control. Current agent frameworks focus primarily on prompting and orchestration, leaving critical questions of predictability and safety unaddressed. BeeAI fills this gap with a lightweight framework that enables developers to build agents whose reasoning abilities are preserved while execution is constrained by declarative, rule-based requirements. At the core of the framework is the RequirementAgent, a novel agent design that enforces deterministic, controlled behaviors across heterogeneous language models. With RequirementAgent, developers can ensure consistent and reliable execution patterns regardless of differences in model reasoning, tool-calling abilities, or stochastic variation. This approach provides practitioners with a unified abstraction layer that simplifies the deployment of complex AI systems into production settings. As an incubating Linux Foundation AI project, BeeAI is gaining adoption in open source and enterprise contexts as organizations seek robust ways to operationalize AI agents at scale. At NeurIPS EXPO, we will showcase BeeAI’s architecture, real-world use cases, and lessons learned from applying declarative control to agent autonomy.",,多伦多云,多伦多云: AI Agent,多伦多云: BeeAI提出的RequirementAgent以声明式、规则驱动的方式约束代理执行，在异构大模型间强制确定性与可控行为，确保一致、可靠的执行与工具调用模式。这直接对应难题(2)“提升Agent行为的可靠性与进行管控与校验”：该框架提供可验证的约束机制与统一抽象层，支持对写操作等高风险动作的前置规则校验、执行审计与回放，提升生产环境中的可控性与安全性。Expo将展示的架构与实战经验，也为难题(3)中L3+多步规划执行Agent的管控策略与安全轨迹设计提供可落地的方法。
TUE 2 DEC,noon,Expo Demonstration,ContextForge,https://neurips.cc/virtual/2025/128643,,3:00 PM,"The rapid rise of autonomous AI agents across enterprises is creating a new class of security and governance challenges that are not adequately addressed with today’s technology. Context Forge MCP Gateway is an open-source, security-focused middleware that provides fine-grained control and extensibility for agent operations. With over 2.6k GitHub stars and a rapidly growing user community, Context Forge addresses emerging threat classes including prompt injection, data leakage, and misuse of sensitive resources. At its core, Context Forge introduces a plugin architecture modeled after Linux Security Modules, embedding reusable security hooks at critical points in agent execution (e.g., prompt handling, tool invocation, data transformation). This modular foundation enables organizations to enforce contextual policies at scale—ranging from PII redaction and provenance tagging to prompt injection detection and policy-based access control. With 39 plugins already available, Context Forge is establishing a standards-aligned ecosystem for securing agent workflows in real-world enterprise deployments. By blending research-driven design with open-source adoption it creates a practical path for organizations to advance agent trustworthiness, safety, and compliance.",,多伦多云,多伦多云: AI Agent,多伦多云: 该session展示的Context Forge MCP Gateway在prompt处理、工具调用、数据变换等关键环节提供可插拔的安全hook与策略（如policy-based access control、prompt injection检测、PII脱敏、provenance标记），可对写操作前置校验/后置审计、细粒度限制高风险工具权限并拦截注入与越权，直接对应“提升Agent写操作可靠性、对agent行为进行管控与校验”的难题，并可通过可追溯与策略执行框架建立上线后的持续管控机制。
TUE 2 DEC,noon,Expo Demonstration,LLM-Powered Intelligent Data Engineering: From Workflow Design to Ingestion andQuality Assurance,https://neurips.cc/virtual/2025/128644,,3:00 PM,"Modern enterprises depend on efficient data engineering pipelines to unlock value from diverse and large-scale datasets. Yet, current processes for workflow design, schema ingestion, and data quality validation remain complex, error-prone, and dependent on technical expertise. This creates barriers for non-expert users, slows down development, and introduces risks of data inconsistency.x000Dx000DWe present a suite of LLM-powered frameworks that reimagine enterprise data engineering across three critical dimensions: (i) From Natural Language to Executable ETL Flows, enabling intuitive pipeline creation with natural language specifications and automatic operator/property inference, (ii) All You Can Ingest, an end-to-end schema mapping and transformation framework that unifies semantic alignment, code synthesis, and robust validation, and (iii) Quality Assessment of Tabular Data, a scalable approach for auto-generating interpretable quality rules and executable validators tailored to specific datasets.x000Dx000DTogether, these innovations demonstrate how Large Language Models (LLMs), augmented with retrieval, code synthesis, reasoning, and guardrails, can transform the data engineering lifecycle into a more accessible, adaptive, and trustworthy process, reducing manual effort, accelerating time-to-value, and ensuring data fidelity at enterprise scale.",,,,
TUE 2 DEC,noon,Expo Demonstration,ALICE: Agentic Logic for Incident and Codebug Elimination,https://neurips.cc/virtual/2025/128646,,3:00 PM,"Modern incident root-cause analysis (RCA) is constrained by partial observability, symptom-centric signals, and the overwhelming noise present in logs, traces, and metrics. Diagnosing production failures often depends on instrumentation quality and human expertise, while latent software defects, configuration errors, and zero-day failure modes remain difficult to pinpoint. To address these challenges, we demonstrate a multi-agent system for incident diagnostics that augments observability data with application source code and static analysis signals.x000Dx000DOur system introduces two cooperating agents: the Code Context Agent (COCOA), which builds a knowledge graph of program dependencies, control/data flows, and caller–callee relationships; and the Incident Diagnostics Agent (IDA), which performs agentic reasoning over an entity topology graph enriched with observability streams. Together, these agents extend topology-aware planning (TAP) to simultaneously operate on program dependency graphs and infrastructure entity graphs, thereby linking runtime symptoms with underlying code-level causes.x000Dx000DThis demo showcases how multi-agent collaboration enables deeper, context-sensitive RCA. We walk through real-world inspired scenarios—including incidents where critical log lines are hidden in noisy observability streams or where latent defects emerge only after system updates—illustrating how the system surfaces root causes that would otherwise remain invisible. By bridging program analysis with runtime observability, our approach moves beyond symptom-driven diagnostics toward a more reliable, automated framework for incident management.",,DCN,DCN: Network4AI 与 AI4Network,DCN: Session讨论多智能体结合静态代码分析与可观测性实现拓扑感知RCA，可重点关注将TAP规划与知识图谱映射到网络拓扑/遥测，用于AI4Network的故障定位与变更前校验。
TUE 2 DEC,noon,Expo Demonstration,AI or Human,https://neurips.cc/virtual/2025/128647,,3:00 PM,"This demo from Sound Patrol will ask the audience to guess whether content is AI or Human, challenging the limits of human perception while showcasing an audio foundation model with multiple task heads, fine-tuned to classify and attribute the source of AI content",,,,
TUE 2 DEC,noon,Expo Demonstration,Who Needs Attention Anyway? Real-Time Control from Learned State Geometry,https://neurips.cc/virtual/2025/128648,,3:00 PM,"Large language models changed how we reason with data, not how we act under constraints. Their latency grows with context, adaptation depends on retraining, and safety is emergent rather than measurable. For robots, simulators, and industrial systems that must react now, this compute model is the wrong fit.CurvOS offers an alternative: a real-time operating layer where streaming state-space models (SSMs) meet geometry and reinforcement learning to deliver stable, on-device intelligence. At its core, CurvOS runs a fast streaming SSM coupled to a local Riemannian planner derived from decoder sensitivities. Each step predicts the next state, estimates local curvature (how small perturbations bend predicted dynamics), and moves a short distance along a geodesic within a trust radius.Compute per step stays fixed, so latency and adaptation remain bounded. Unlike streaming SSMs such as Mamba, CurvOS learns geometry online to steer predictions safely without retraining. The result is a compact, measurable control stack that reasons in real time, adapts continuously, and meets physical or chemical objectives under fixed budgets. CurvOS turns sequence models into predictable decision engines for systems where timing and safety matter most.",,温哥华云; 计算,温哥华云: Embodied AI; 计算: 训推新范式,温哥华云: 该Session提出的CurvOS以“流式SSM + 基于解码器敏感度的局部黎曼规划器”的实时控制栈，面向机器人/工业等具身系统，核心特性是固定步长计算、受信任半径内沿测地线安全前进、在线学习几何以避免重训练，并与RL结合实现可度量、安全的实时决策。这与具身AI在云端与边端需要的“低时延、稳定安全、可持续适配”的控制智能高度契合，可直接为物理AI服务与产品路线提供可落地的控制技术范式与评估指标。; 计算: CurvOS将序列模型从“注意力推理”转为“流式SSM+几何规划”的闭环实时决策范式：每步固定计算、无需重训练即可在线适配、安全通过局部几何（曲率、测地线、信任域）来引导预测与动作。这一范式改变了推理/训练的负载形态与资源调度假设（无KV缓存、状态量固定、持续在线更新），可直接用于洞察和定义未来训推负载特征与调度机制，是团队跟踪与预测新范式演进所需的具体技术样本。
TUE 2 DEC,noon,Expo Demonstration,"PRIME Guardrails in Action: A Live Demonstration of an Agentic, Multi-Layered Safety Framework for Generative AI",https://neurips.cc/virtual/2025/128650,,3:00 PM,"The rapid proliferation of large-scale Generative AI systems has created an urgent need for safety frameworks that are both robust and performant. Existing solutions often present a false dichotomy: simple, low-latency filters that are easily circumvented by adversarial inputs, or powerful, semantically-aware models that introduce prohibitive latency for real-time applications. This demonstration introduces a live, practical instantiation of the PRIME (Policy, Risk, Intervention, Monitoring, Evaluation) framework, a novel, modality-agnostic architecture designed to resolve this trade-off. We will showcase a production-grade, multi-layered “Defense in Depth” safety system that utilizes an agentic workflow to intelligently orchestrate heterogeneous guardrail models. The system combines the deep contextual reasoning of large proprietary models (e.g., Google’s Gemini) for nuanced threat assessment with the speed of specialized, open-source classifiers for rapid, early-exit filtering of common violations. Through a series of live, interactive examples, we will demonstrate the system's ability to detect and neutralize a range of adversarial inputs in real-time across both text and image modalities. Attendees will witness the framework successfully identifying and blocking prompt injection attacks, harmful content requests, and policy violations, thereby proving the efficacy of a hybrid, agentic approach to building safer, more trustworthy Generative AI experiences at scale.",,多伦多云,多伦多云: AI Agent,多伦多云: Session讨论PRIME多层守护轨与Agentic编排，可重点关注行为管控与评估的防御分层、早退过滤、跨模态注入检测及监测评估闭环。
TUE 2 DEC,noon,Expo Workshop,Creative and Protective AI for Music and Entertainment,https://neurips.cc/virtual/2025/128679,,1:30 PM,"Generative AI is reshaping how we create, experience, and safeguard music and entertainment. This workshop presents technologies that expand creative expression while honoring responsibility. On the creative side, we share collaborative artworks with leading sound artists, neural engines for sound design and performance, and automatic mixing that adapts to musical intent. We also present a large multimodal dataset for multishot speech video that supports research on coherent and controllable speech, together with specialized language models that orchestrate camera transitions, gestures, vocal cues, and sound effects. On the protective side, we advance AI methods for data attribution, traceability, and responsible model behavior that safeguard creative data and prevent unintended memorization, ensuring fairness, transparency, and respect for creators’ rights. Together, these threads outline an ecosystem in which AI amplifies artistic practice while preserving the integrity of human contribution.",,CBG,CBG: 3DAIGC,CBG: Session讨论多镜头语音视频数据集与镜头/手势/音效编排LM，可重点关注相机轨迹控制、长视频一致性建模与脚本驱动可控生成。
TUE 2 DEC,noon,Expo Workshop,Large-Scale Real-World Physical AI Systems,https://neurips.cc/virtual/2025/128672,,1:30 PM,"Motivation and Scopex000Dx000DPhysical AI systems comprise of four things: namely sensors like cameras and lidar, mechanical and electronic control unit, AI models to reason about the environment, and actuators to convert decisions to physical actions. It marries multiple domains like sensor design, perception, low-power real-time hardware design, and control loop action design. Autonomous driving is the most mature physical AI domain deployed for over 10 years, but it still has many open challenges. Humanoid robots are an emerging physical AI domain with potential for near term commercial deployment. One of the major challenges in physical AI is to scale to all real-world scenarios including corner cases in a safe manner. A scalable AI data flywheel is the most critical module to achieve this. Traditional physical AI models have a modular decomposition of perception and action tasks, but the community is increasingly moving towards a single end-to-end AI model.  Furthermore, recent advancements in LLMs and VLMs are leading to VLA (Vision-Language-Action) based end-to-end models. In the future, there will likely be a convergence of physical AI models across different domains like driving and robotics.  The proposed workshop covers the latest research and best practices in industrial research of physical AI by leaders in the domain. It also covers emerging technologies like VLA based foundation models, AI data flywheel, and cross-embodiment learning focused on Physical AI.",,温哥华云; 计算,温哥华云: Embodied AI; 计算: 训推新范式,温哥华云: Session讨论VLA端到端与跨具身学习、数据飞轮与真实场景覆盖，可重点关注跨域复用策略、数据闭环构建与角落案例采集管线。; 计算: Session讨论从模块化到VLA端到端的训推范式与飞轮闭环，可重点关注在线数据挖掘、闭环监督、跨具身权重共享与感知-控制联合训练。
TUE 2 DEC,noon,Expo Workshop,Checkmate: Fine-tune your own small language model for real-time chess reasoning and gameplay on AWS Trainium,https://neurips.cc/virtual/2025/128680,,1:30 PM,"In this hands-on workshop, participants will leverage AWS Trainium to fine-tune and deploy their own chess-playing language models. Building on recent research showing language models' effectiveness in reasoning, attendees will work with various chess datasets to create AI models that not only play chess but explain their strategic thinking through natural language. The 90-minute session will cover model fine-tuning techniques, optimization strategies specific to Trainium's architecture, and real-time deployment to a chess engine. The workshop culminates in a live tournament where participants' models compete against each other, providing immediate feedback on their implementations. Participants will leave with a working chess reasoning model, practical experience in fine-tuning language models on Trainium, and transferable skills for similar tasks. Python programming experience and familiarity with LLM concepts are required, in addition to a basic understanding of the rules of chess. Workshop materials and AWS credits will be provided.",,,,
TUE 2 DEC,noon,Expo Workshop,Workshop on multimodal Superintelligence,https://neurips.cc/virtual/2025/128681,,1:30 PM,"Multimodal machine learning is among the most promising directions of artificial intelligence. With remarkable progress in academia and industry on this topic, we are at the cusp of building next-generation multimodal models, i.e. multimodal superintelligence. These models can be defined as being able to observe, think, and act across several modalities. At this important junction, our workshop provides a forum for researchers to align and cross-polinate ideas. The Workshop on Multimodal Superintelligence will provide a venue where the community can gather to discuss the current state of multimodal machine learning science. Together, we will attempt to overcome the current barriers of modeling several modalities at once. We will also focus on topics such as cross-modal reasoning, alignment, fusion and co-learning.",,诺亚; 计算,诺亚: 大模型长序列，多模态长序列; 计算: 高效模型架构,诺亚: Session讨论跨模态推理、对齐与融合，可重点关注长序列跨模态对齐策略、层次化/稀疏融合与记忆更新机制，缓解长文本推理计算瓶颈。; 计算: Session讨论跨模态推理、对齐与融合，可重点关注统一语义空间、分层融合/路由化设计与长序列对齐策略，预判结构演进对计算架构影响。
TUE 2 DEC,noon,Expo Demonstration,Interpretable AI for Risk-Based Human Rights Assessment in Global Supply Chains,https://neurips.cc/virtual/2025/128649,,3:00 PM,"Amazon’s responsible sourcing efforts aim to protect people across its global supply chain. Yet detecting human rights risks such as forced labor or unsafe conditions across hundreds of thousands of suppliers is challenging. Auditing every site is costly and impractical, making a risk-based approach essential focusing resources where the likelihood and severity of issues are greatest. To address this, Amazon developed PRISM AI (Predictive Risk Intelligence for Supplier Management), an interpretable machine learning system that predicts and explains supplier-level risk across global supply chains. Trained on over 70,000 internal and third-party audit records, PRISM integrates signals from self-assessment questionnaires, grievance reports, adverse media, and geo-sector risk indices. These inputs help detect both documented and emerging risks in near real time. The model supports three supplier types: those with audit histories, limited data, or none. It adapts using transfer learning, rule-based heuristics, and domain-specific indicators. Each prediction includes transparent attribution, showing which factors such as safety violations or country-sector exposure, most influenced the score. Built with monotonic constraints, the system ensures logically consistent, explainable outputs for regulatory and operational use.x000DThis demo gives NeurIPS participants a hands-on view of how AI research can be operationalized for real-world impact. Already in production at Amazon, PRISM helps compliance teams prioritize audits, onboard suppliers, and escalate risks thereby reducing review time and improving oversight. For researchers, it highlights methods for building interpretable models under data imbalance and integrating structured and unstructured signals. For practitioners, PRISM shows how AI can scale responsible business practices and drive innovation across environmental and social sustainability domains.",,,,
TUE 2 DEC,noon,Expo Demonstration,Build verifiable apps using Generative AI and Automated Reasoning,https://neurips.cc/virtual/2025/128651,,3:00 PM,"Recent advancements in Generative AI have enabled customers to use LLMs to generate infrastructure code using AWS CLI commands. Because humans can make mistakes, when deployed such LLM-generated infrastructure code can have negative impacts, including on security.x000DMotivated by this challenge, this demonstration introduces participants to automated reasoning tooling that enhanced security in production for Amazon Q chat.x000DAWS Q Chat enables natural language interaction with AWS resources while employing automated reasoning to verify every generated API call against comprehensive semantic logic models. This prevents potentially harmful operations before execution and suggests corrections, creating a feedback loop that iterates until verifiably correct code is produced. Through this work, we demonstrate how organizations can leverage GenAI's efficiency while maintaining the rigorous verification standards required for production environments and participants will learn how to integrate these tools into their workflows to prevent security regressions and ensure reliable infrastructure management. This tutorial Scientists, Engineers, Security professionals and anyone interested in applying formal verification to their infrastructure.",,多伦多云,多伦多云: AI Agent,多伦多云: 团队难题#2强调“提升Agent行为的可靠性，尤其是写操作的可靠性，以及对Agent行为进行管控与校验”。该Session展示AWS Q Chat利用自动化推理与形式化语义逻辑模型，对LLM生成的每一次AWS API调用进行逐条验证，在执行前阻断潜在有害写操作并给出纠正建议，形成闭环直至可验证正确；还讲解如何将这一验证工具链集成到生产工作流防止安全回退。这与“写操作可靠性”“行为管控与校验”的技术点精确对应，可直接为上线Agent的写操作安全与可靠执行提供可落地方案。
TUE 2 DEC,noon,Expo Workshop,CausalFairness: An Open-Source Python Library for Causal Fairness Analysis,https://neurips.cc/virtual/2025/128677,,1:30 PM,"As machine learning (ML) systems are increasingly deployed in high-stakes domains, the need for robust methods to assess fairness has become more critical. While statistical fairness metrics are widely used due to their simplicity, they are limited in their ability to explain why disparities occur, as they rely on associative relationships in the data. In contrast, causal fairness metrics aim to uncover the underlying data-generating mechanisms that lead to observed disparities, enabling a deeper understanding of the influence of sensitive attributes and their proxies. Despite their promise, causal fairness metrics have seen limited adoption due to their technical and computational complexity. To address this gap, we present CausalFairness, the first open-source Python package designed to compute a diverse set of causal fairness metrics at both the group and individual levels. The metrics implemented are broadly applicable across classification and regression tasks (with easy extensions for intersectional analysis) and were selected for their significance in the fairness literature. We also demonstrate how standard statistical fairness metrics can be decomposed into their causal components, providing a complementary view of fairness grounded in causal reasoning. In this active learning talk participants will learn how to quantify bias using CausalFairness at the group (Counterfactual Equalized Odds , Counterfactual Effects) and individual (Counterfactual Fairness) levels by applying each method to three datasets - 1) the Adult Income dataset, 2) the COMPAS dataset, 3) Law School Admission Council (LSAC) Dataset. The session will elucidate on the intuition for computing and interpreting each metric, and conclude with a discussion of their limitations.",,,,
TUE 2 DEC,noon,Expo Demonstration,Learning to Steer LLMs with AI Steerability 360 and In-Context Explainability 360,https://neurips.cc/virtual/2025/128645,,3:00 PM,"Current algorithms for aligning LLM behavior are often implemented for narrow settings, making it difficult for researchers and developers to understand their effectiveness across model architectures, datasets, and tasks. To help provide a more informed and principled approach to steering model behavior, we present the AI Steerability 360 (AISteer360) and In-Context Explainability 360 (ICX360) toolkits. Participants will first be guided through a conceptual overview for how model behavior can be influenced across four model control surfaces: input (prompting), structural (weights/architecture), state (activations/attentions), and output (decoding). After the conceptual overview, we will guide attendees through how to apply some recently developed explainability tools (from ICX360) for understanding why models produce given, potentially undesirable, outputs and how this information is used to design targeted steering inventions (via AISteer360). Closing the loop, we will evaluate if the baseline behavior (of the original, unsteered model) was successfully mitigated by the selected steering inventions and investigate if steering introduced any unintended behavioral side-effects. All of the experiments throughout the demonstration will be facilitated solely by the tools in the two toolkits, illustrating their power to design end-to-end steering workflows. Attendees will come away with a practical understanding of how to apply these toolkits to their own alignment challenges.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session讨论四类控制面与ICX360/AISteer360的对齐闭环，可重点关注用解释信号构造RFT奖励、结合解码/激活干预，提升样本效率与离线稳健评测。; 诺亚: Session讨论AISteer360+ICX360用于不良行为诊断与定向干预，可重点关注RLHF/RLAIF与激活级、解码级控制结合，并基于可解释信号监测副作用。
TUE 2 DEC,noon,Expo Workshop,Introduction to Generative Computing,https://neurips.cc/virtual/2025/128678,,1:30 PM,"This hands-on workshop introduces a proposal that treats LLMs as computing elements governed by established software development principles—particularly task decomposition and modularization—at both the programming model (Mellea) and model level (LLM intrinsics).x000Dx000DLLM outputs are often unpredictable and incorrect. Agentic frameworks and prompt optimization libraries attempt to manage this by giving control to the LLM, but this leads to systems that are hard to debug, maintain, and scale. Mellea offers an alternative: a programming model that restores developer control through modular design, information hiding, and compositional contracts. This enables predictable fault models, better portability, and lower inference costs. Attendees will gain hands-on experience building applications using the Melleaic approach.x000Dx000DExtending these principles to the model level, the workshop introduces a modularization framework for LLMs using activated LoRAs. These produce components—LLM intrinsics—that match fine-tuned model accuracy for specific tasks but with significantly lower inference costs and latency, thanks to KV cache reuse. Participants will build applications using a pre-built library of RAG LLM intrinsics and learn how to train their own.x000Dx000DPresented by the creators of Mellea and the inventors of LLM intrinsics and aLoRA, this workshop equips attendees with foundational skills for scalable model/application co-design.",,多伦多云; 计算,多伦多云: AI Agent; 计算: 训推新范式,多伦多云: Session讨论Mellea模块化与组合契约提升Agent可控性与可靠性，可重点关注契约化规划-执行管控、RAG相关LLM内在函数封装及KV缓存复用。; 计算: Session讨论LLM内在函数与aLoRA协同及KV缓存复用，可重点关注推理负载画像、LoRA激活调度与KV复用对范式和算力需求的影响。
TUE 2 DEC,noon,Expo Workshop,Exploring Trust and Reliability in LLM Evaluation,https://neurips.cc/virtual/2025/128673,,1:30 PM,"The current paradigm of Large Language Model (LLM) evaluation faces a crisis of reliability. Traditional leaderboards—built on static benchmarks and surface-level metrics—have become increasingly distorted by benchmark contamination, prompt overfitting, and evaluation methodologies that fail to reflect model behavior in real-world use. As reasoning models emerge that generate detailed internal thought processes (e.g.,traces) before producing answers, existing evaluation practices—especially for multiple-choice and generation tasks—have become fundamentally inadequate.x000Dx000DThis lack of rigor not only undermines scientific progress and cross-model comparability, but also poses significant enterprise and societal risks, as evaluation results inform model selection, deployment safety, and governance in high-stakes environments.x000Dx000DThis workshop aims to reassert rigor in LLM evaluation by convening researchers and practitioners to address three intertwined challenges: (1) developing fair and consistent evaluation methods for reasoning and non-reasoning models, (2) confronting widespread contamination across public benchmarks and open-weight models, and (3) defining robust data curation and validation practices to prevent future contamination in both pretraining and post-training pipelines.x000Dx000DBy combining empirical findings, methodological advances, and practical case studies, this session—led by Capital One in collaboration with leading AI labs—seeks to chart a concrete path toward trustworthy, contamination-proof, and utility-aligned LLM evaluation frameworks.x000Dx000DThis 1.5-hour workshop will be structured around three highly focused, 25-minute talks, followed by a moderated discussion aimed at forging actionable paths forward for the community:x000Dx000DTalk 1: Robust Evaluation for Reasoning & Non-Reasoning Modelsx000Dx000DTalk 2: Benchmark Contamination — Detection, Measurement, & Findingsx000Dx000DTalk 3: Preventing Contamination — Building Clean & Reliable Data Pipelines",,诺亚; 温哥华云,诺亚: 大模型后训练Reasoning，RL; 温哥华云: Reinforcement fine tuning (RFT),诺亚: Session讨论推理模型评测可靠性与数据污染防控，可重点关注思维链与隐性推理的评测范式、污染检测与清洁数据管道。; 温哥华云: Session讨论推理与非推理模型的可靠评测与基准污染检测，可重点关注RFT后训练数据去污染流程、评测一致性指标与基准重建。
TUE 2 DEC,1:30 p.m.,Tutorial,Foundations of Imitation Learning: From Language Modeling to Continuous Control,https://neurips.cc/virtual/2025/109590,,4:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,Scale Test-Time Compute on Modern Hardware,https://neurips.cc/virtual/2025/109595,,3:00 PM,,,诺亚,诺亚: 大模型长序列，多模态长序列,诺亚: Session讨论测试时计算在现代硬件上的扩展，可重点关注测试时推理策略的计算预算与执行调度映射，用于长序列推理开销控制。
TUE 2 DEC,1:30 p.m.,Tutorial,Autoregressive Models Beyond Language,https://neurips.cc/virtual/2025/109587,,3:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,"Recent Developments in Geometric Machine Learning: Foundations, Models, and More",https://neurips.cc/virtual/2025/109600,,3:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,Theoretical Insights on Training Instability in Deep Learning,https://neurips.cc/virtual/2025/109597,,3:00 PM,,"Overview: The NeurIPS 2025 tutorial titled 'Theoretical Insights on Training Instability in Deep Learning' explores the oscillatory, spiky, and unstable nature of the optimization process in deep learning. This tutorial aims to provide theoretical insights into the benign nature of these training instabilities, offering perspectives from both optimization and statistical learning. The work challenges classical optimization theory by demonstrating that the best training configurations often operate in unstable regimes. | Research Interests: Gradient-based optimization, Training instability in deep learning, Large stepsizes in optimization, Statistical learning perspectives, Benign nature of instabilities, Optimization efficiency, Overfitting prevention, Implicit bias in optimization, Edge of stability in gradient descent | Key Findings: The tutorial highlights that large stepsizes can accelerate optimization and prevent overfitting, providing a new understanding of the implicit bias and stability in deep learning models. It also discusses the role of training at the edge of stability and how it can lead to efficient optimization and generalization.",计算,计算: 训推新范式,计算: Session讨论大步长与边缘稳定训练、隐式偏置与泛化机理，可重点关注学习率/批大小/优化器联动调度对负载画像与算力带宽取舍的影响。
TUE 2 DEC,1:30 p.m.,Tutorial,"The Science of Benchmarking: What’s Measured, What’s Missed, and What’s Next",https://neurips.cc/virtual/2025/109598,,3:00 PM,,,,,
TUE 2 DEC,1:30 p.m.,Tutorial,"Data Privacy, Memorization, & Legal Implications in  Generative AI: A Practical Guide",https://neurips.cc/virtual/2025/109588,,3:00 PM,,,nan,nan: ,nan: 
TUE 2 DEC,4 p.m.,Expo Talk Panel,Recent developments in embodied AI,https://neurips.cc/virtual/2025/128653,,5:00 PM,"Embodied AI is the study of systems that can perceive and interact with the physical world in real time. Real-world interactions pose unique challenges for AI systems since they naturally require a deep understanding of the physical world and/or its inhabitants. This understanding is often taken for granted in humans, where it is typically labelled as “intuitive physics” or “common sense”.x000Dx000DIt is widely agreed that solving this challenge would be as rewarding as it is hard, since it would be equivalent to creating truly capable “world models”, with countless applications in robotics, human-computer interaction, and even in advancing language modeling through concept grounding. Like other areas in AI, embodied AI has seen dramatic advances in recent years, fueled by the success of using pre-trained large language models as a central ingredient to allow for end-to-end training. While this development stands as one of many examples of the power of pre-trained language models, recently the converse has come true as well: embodied AI is increasingly being drawn on to understand real-world common sense and concept grounding in language models themselves, bringing back its early vision as a way to understand human-like cognition and world models.x000Dx000DThis talk will provide an in-depth discussion of embodied AI, with a focus on recent advances based on multi-modal large language models. It will discuss how end-to-end training has made it possible to instill key aspects of real-world common sense in a model and how this had enabled highly ambitious use-cases, such as generalist (“common sense”) robot control and real-world visual interaction (“chatbots that can see and hear you”). The talk will also discuss practical considerations, such as streaming inference at the edge, end-to-end training data generation and the role of reinforcement learning, as well as open challenges in state tracking and long-term memory.",,温哥华云; 计算; 诺亚,温哥华云: Embodied AI; 计算: 训推新范式; 诺亚: 大模型长序列，多模态长序列,温哥华云: Session讨论多模态LLM驱动的端到端具身训练与边缘流式推理，可重点关注数据生成闭环、RL在常识习得中的作用及通用机器人控制落地。; 计算: Session讨论端到端训练、RL与边缘流式推理的实践考量，可重点关注具身多模态负载的训练范式演进与推理管线特征建模。; 诺亚: Session讨论具身多模态的状态跟踪与长程记忆挑战，可重点关注记忆更新机制、流式交互中的上下文维护与跨模态对齐。
TUE 2 DEC,4 p.m.,Expo Talk Panel,Distributed Orthonormal Updates for Large-Scale Training,https://neurips.cc/virtual/2025/128655,,5:00 PM,"We propose a 50-minute technical talk on recent advances in orthonormal update methods for large-scale AI model training. This topic is rapidly gaining attention in the community, emerging as a strong successor to AdamW following the success of orthonormal optimizers in training production-scale models such as Kimi-K2 and GLM-4.5.x000DThe talk will center on the design and practice of orthonormal updates, focusing on optimizers such as Muon and Dion. While we will briefly discuss their theoretical foundations, the emphasis will be on practical usage: how to integrate these optimizers into modern training pipelines, interpret their algorithmic components, and leverage the implementation guidelines provided in our open-source codebase at github.com/microsoft/dion.x000DThe talk is designed to engage both researchers and practitioners in the NeurIPS community:x000DAcademic perspective: presents a new class of optimizers grounded in theory along with how they interact with distributed training.x000DIndustrial perspective: highlights how orthonormal updates are implemented in practice and what best practices are.x000DThis topic lies   at the intersection of optimization theory, scalable systems, and large-model training—an area of growing importance for both the research and applied machine learning communities.",,计算,计算: 训推新范式,计算: Session讨论正交归一更新优化器（Muon/Dion）与分布式训练实践，可重点关注其与FSDP/ZeRO、混合精度低精训的协同与收敛稳定性。
TUE 2 DEC,4 p.m.,Expo Talk Panel,Ling 2.0 and Ling-1T: Scaling Knowledge-Enhanced Large Language Models for Reasoning and Efficiency,https://neurips.cc/virtual/2025/128657,,5:00 PM,"The Ling 2.0 series represents a new generation of large language models designed around knowledge enhancement, reasoning efficiency, and scalable architecture innovation. Built upon trillion-scale sparse MoE foundations, Ling-1T achieves ~50B active parameters per token with FP8 mixed-precision pipelines and 1F1B interleaved scheduling, realizing over 40% training-throughput gains with negligible accuracy loss (<0.1%).x000DThis talk presents the technical journey behind Ling-mini, Ling-flash, and Ling-1T, focusing on (1) efficient large-scale training systems for trillion-parameter models; (2) the Ling Scaling Law and its implications for cross-domain reasoning; (3) hybrid attention and RL-based alignment strategies that enable both concise reasoning and long-context understanding; and (4) how these architectural and algorithmic advances empower industrial applications such as financial risk modeling and knowledge-grounded agents.x000DWe will conclude with open-sourced implementations (inclusionAI on Hugging Face and ModelScope) and future research directions toward trustworthy, efficient, and domain-enhanced LLMs.",,计算; 海思; 诺亚,计算: 高效模型架构; 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,计算: Session讨论FP8混合精度与1F1B在万亿MoE训练中的系统优化，可重点关注数值稳定性、流水并行与MoE调度对计算架构的约束。; 海思: Session讨论混合注意力与MoE效率优化，可重点关注长上下文稀疏注意力、分块KV缓存与FP8在降复杂度与低延迟推理中的应用。; 诺亚: Session讨论混合注意力支撑长上下文理解与Scaling Law，可重点关注长序列注意力剪枝、KV缓存预算与测试时推理解码策略优化。
TUE 2 DEC,4 p.m.,Expo Talk Panel,Agentic AI/RL,https://neurips.cc/virtual/2025/128662,,5:00 PM,"The transition from static language models to agentic AI systems driven by reinforcement learning (RL) places environments at the center of research and deployment. Environments provide the substrate where agents act, learn, and are evaluated—ranging from lightweight simulators and synthetic tasks to rich multi-agent ecosystems and real-world interfaces. Building and scaling these environments requires specialized tools and systems: standardized hubs for discovery and sharing, interfaces for reproducibility, and infrastructure that connects environments seamlessly to trainers, inference engines, and evaluation pipelines.x000Dx000DThis workshop will highlight the tools, environments, and system innovations enabling the next generation of agentic AI. Topics will include scalable RL environment frameworks, benchmarks for safety and robustness, high-performance simulators optimized for heterogeneous hardware, and environment–trainer integration at scale. We will also explore how environments interface with large-model post-training workflows, providing the data and feedback loops necessary for reward shaping, alignment, and deployment in production systems.x000Dx000DBy convening researchers, environment developers, and systems engineers, the workshop will create a venue to examine how environments, tools, and infrastructure together shape the future of agentic AI.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DPyTorch native RL and agentic development at scalex000DEnvironments for everyone - how open environments can democratize RL post training at scalex000DSafety in the new era of Agents",,温哥华云; 多伦多云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session明确覆盖“环境-训练器集成 at scale”“PyTorch 原生 RL 与 agentic 开发”“可复现实验接口与评估流水线”，以及“与大模型后训练工作流的接口（奖励塑形、对齐、部署）”。这些内容可直接支撑RFT从理论到生产的落地与规模化：环境-训练器无缝连接解决RFT在云上端到端工程化与可扩展性问题；标准化评测与安全/鲁棒性基准有助于构建RFT的可靠评估体系；后训练数据与反馈环路为提升样本效率与性能提供可操作的闭环。; 多伦多云: 团队难题聚焦“Agent评估准确性与覆盖”“写操作可靠性与行为管控/校验”“上线后的自主学习与持续优化”。Session提供“安全与鲁棒性基准”“Safety in the new era of Agents”“评估流水线与可复现实验接口”，可直接用于提升评估覆盖与安全性；“环境作为训练/评估基座”与“环境-训练器集成 at scale”可支持上线后的持续优化与管控闭环；“多智能体生态系统”与“后训练工作流（奖励塑形、对齐）”可用于具备planning与多步执行的L3+ agent的行为优化与可靠性校验（含写操作风险控制场景）。; 诺亚: 团队难题包含“自博弈与learning from experience训练框架”。Session重点的“可扩展RL环境框架”“多智能体生态系统”“高性能模拟器（异构硬件优化）”与“环境-训练器集成”正是自博弈/经验学习所需的基础设施；同时，“与后训练工作流对接的奖励塑形与对齐”直接支撑基于环境反馈的后训练推理能力提升与闭环迭代，实现自博弈、经验驱动训练的工程化落地与规模化运行。
TUE 2 DEC,4 p.m.,Expo Talk Panel,"Neural Arms Race: Authenticity, Infringement Analysis, and Attribution in the Age of AI Music",https://neurips.cc/virtual/2025/128669,,5:00 PM,"The same neural architectures powering music generation have become critical infrastructure for content moderation—creating a technological arms race where AI both threatens and protects creative rights. This talk presents Sound Patrol's production-scale response across three dimensions: (1) Authenticity Detection: Analyzing AI content in the wild begins with binary classification—was a given song created by AI or humans? Using MuQ and ResNet backbones with auxiliary task heads, we show how careful dataset construction and model ensembling enables attribution of when AI was used, where in a track (vocal vs instrumental), and which genAI platform generated it. (2) Infringement Analysis: Once identified as AI, content requires infringement screening. We combine singer deepfake detection via RawNet3, Burrows-Wheeler alignment-derived comparisons of MIDI transcripts, lyrics analysis via a combination of neural embeddings and LLMs, and neural fingerprinting achieving 88%+ accuracy under adversarial transforms. These analyses are orchestrated through dynamic expert routing, enabling sophisticated tagging and automated musicology reports. (3) Attribution Framework: We end with a pragmatic discussion of what it means for a piece of training data to influence a model output. We propose a set of principles guiding how fractional royalty models could be derived by examining prompts, training sets, and model outputs. Drawing from production deployments and industry evaluations, we offer the NeurIPS community technical blueprints for turning this arms race into equitable innovation—exploring how the same AI enabling infringement might ensure fair compensation to the artists whose work powers it all.",,,,
TUE 2 DEC,4 p.m.,Expo Talk Panel,Building an AI Ecosystem for Multiscale Biological Discovery,https://neurips.cc/virtual/2025/128658,,5:00 PM,"Understanding biological systems requires resolving their structure and organization across scales, from tissues to individual molecules. Advances in imaging and molecular profiling now generate vast multimodal datasets that capture biological architecture and dynamics with unprecedented fidelity. Unlocking insights from this data demands computational approaches capable of linking observations across spatial, temporal, and molecular dimensions.At the Chan Zuckerberg Imaging Institute (CZII), we are building the infrastructure, datasets, and community connections to enable this transformation. Our cryo-electron tomography (cryoET) processing pipeline supports high-throughput reconstruction and standardized metadata integration, forming the foundation for reproducible, machine-learning–ready datasets. The CryoET Data Portal (cryoetdataportal.czscience.com) provides open access to raw data, reconstructions, and curated annotations contributed by leading structural biology labs worldwide. Its programmatic API tools support segmentation, particle picking, and model benchmarking, creating a foundation for AI-driven structural discovery.To catalyze progress in automated molecular identification, the CZ Imaging Institute recently organized a Kaggle challenge inviting participants to develop models for detecting and labeling macromolecular complexes in real-world cryoET data. Building on this success, upcoming challenges organized by the CZI & CZ Biohub Network will extend this approach to datasets spanning different biological scales, from tissue architecture and cellular organization to subcellular and molecular structure.Together, these efforts form an open, interoperable ecosystem for machine learning in biological imaging. By combining standardized data infrastructure, scalable computation, and community-driven innovation, we aim to bridge the worlds of imaging and AI and accelerate the discovery of life’s organization across all scales.",,,,
TUE 2 DEC,4 p.m.,Expo Talk Panel,Building Foundational Models for Robotics at Tesla,https://neurips.cc/virtual/2025/128654,,5:00 PM,"Tesla's robots, both wheeled and legged, are developed with the goal of achieving general-purpose capability, analogous to the versatility observed in humans and animals. These systems rely primarily on scalable sensing modalities such as vision, audio etc, enabling robust performance within stringent power and cost constraints.x000Dx000DThis talk will describe the principles and methodology behind constructing foundation models for robotics at Tesla. We will discuss the architecture, data and training of large-scale multimodal models that control these robots in an end-to-end pixels-to-actuation fashion. We will also examine evaluation protocols, safety considerations, and strategies for reliable real-world deployment. Finally, we project the transformational benefits to society that widespread deployment of such advanced robotic systems can deliver.",,温哥华云; 计算,温哥华云: Embodied AI; 计算: 训推新范式,温哥华云: Session讨论端到端像素到执行的具身多模态基础模型，可重点关注数据闭环采集与训练、实机部署评测方法及安全约束策略; 计算: Session讨论像素到动作的端到端控制与大规模多模态训练，可重点关注闭环负载特征、在线推理路径与分布漂移下的稳健训练范式
WED 3 DEC,8:30 a.m.,Invited Talk,Rich Sutton_The Oak Architecture: A Vision of SuperIntelligence from Experience,https://neurips.cc/virtual/2025/invited-talk/109601,Rich Sutton,9:30 AM,"As AI has become a huge industry, to an extent it has lost its way. What is needed to get us back on track to true intelligence? We need agents that learn continually. We need world models and planning. We need knowledge that is high-level and learnable. We need to meta-learn how to generalize. The Oak architecture is one answer to all these needs. It is a model-based RL architecture with three special features: 1) all of its components learn continually, 2) each learned weight has a dedicated step-size parameter that is meta-learned using online cross-validation, and 3) abstractions in state and time are continually created in a five-step progression: Feature Construction, posing a SubTask based on the feature, learning an Option to solve the subtask, learning a Model of the option, and Planning using the option’s model (the FC-STOMP progression). The Oak architecture is rather meaty; in this talk we give an outline and point to the many works, prior and contemporaneous, that are contributing to its overall vision of how superintelligence can arise from an agent’s experience.",,诺亚; 温哥华云,诺亚: 大模型后训练Reasoning，RL; 温哥华云: Embodied AI,诺亚: Session讨论基于模型的持续RL与FC-STOMP选项规划，可重点关注learning-from-experience自博弈框架与在线交叉验证步长元学习，用于增强后训练推理与latent reasoning。; 温哥华云: Session讨论基于模型的持续RL与FC-STOMP抽象/规划，可重点关注具身任务的分层选项与世界模型构建，以及在线步长元学习以提升样本效率与在线适应。
WED 3 DEC,noon,Expo Workshop,"AI Assistants in the Wild: Agents, Adaptation, and Memory-Augmented Deployment",https://neurips.cc/virtual/2025/128671,,1:30 PM,"Motivation and Scopex000Dx000DGenerative AI is evolving from offline, single modality models into interactive agentic systems that perceive, decide, and act in the real world. This shift marks a transition from static generation to dynamic, context-aware interaction. As these systems move toward deployment on edge devices such as mobile phones, augmented reality glasses, and robots, they face constraints in compute, memory, and latency. Beyond efficiency and responsiveness, a new frontier is emerging: agents equipped with persistent memory that enables long-term adaptation and personalization.x000Dx000DThis workshop explores a timely and focused question. How do we build generative agents that are not only efficient and responsive but also able to accumulate, recall, and adapt based on personal memory over time? We aim to bring together perspectives from generative modeling, agentic learning, efficient model design, and memory systems to close the gap between lab scale prototypes and real-world deployment.x000Dx000DKey Themesx000DPersonal Memory Systems for AI Assistants: Architectures for persistent memory, retrieval-augmented generation, and long-term personalization.x000DReal-World Adaptation Few-shot generalization, continual learning, and task inference for evolving agent behavior.x000DGrounded and Trustworthy Generation: Techniques for hallucination mitigation, constraint-aware generation, and safety under uncertainty.x000DDeployment on Edge Platforms: Challenges and solutions for deploying generative agents on mobile, AR, and robotics platforms.x000Dx000DThis focused workshop aligns with emerging themes at NeurIPS including agentic learning, trustworthy AI, efficient multimodal generation, and embodied intelligence. It will spotlight the systems, algorithms, and design decisions needed to make generative AI truly adaptive and persistent, outside the data center and into the wild.",,存储; 多伦多云; 计算,存储: 单/多模型推理; 多伦多云: AI Agent; 计算: 前沿应用负载,存储: Session讨论Agent持久记忆与RAG端侧部署，可重点关注VectorDB/MemOS的I/O访问模式与KV缓存分层卸载、CXL内存协同。; 多伦多云: Session讨论真实环境Agent适配与记忆增强、可信生成，可重点关注评测基准设计、写操作可验证管控与持续优化飞轮在端侧的实现。; 计算: Session讨论端侧多模态Agent推理与持久记忆系统，可重点关注RAG/记忆引入的访存与带宽瓶颈、KV缓存与分层存储对负载特征的影响。
WED 3 DEC,noon,Expo Workshop,On Device/Edge AI,https://neurips.cc/virtual/2025/128674,,1:30 PM,"From smartphones and wearables to autonomous vehicles, robots, and AR/VR systems, the demand for models that are efficient, private, and adaptive in real-time has never been higher. Yet deploying state-of-the-art AI at the edge remains challenging: researchers and practitioners must navigate heterogeneous hardware, memory and power constraints, compression and distillation trade-offs, as well as privacy, safety, and reliability requirements.x000Dx000DThis workshop will bring together researchers, practitioners, and industry leaders to explore the frontiers of Edge AI. Topics will include lightweight model architectures, compiler/toolchain optimizations (e.g., quantization, pruning, sparsity), advances in frameworks such as ExecuTorch and TensorRT, distributed learning across devices, privacy-preserving training, and emerging applications where latency and trust are critical. Beyond technical advances, we will examine the broader implications for democratizing AI—enabling billions of devices to act as intelligent, personalized agents while reducing dependence on the cloud.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DOptimized AI on iOSx000DLeveraging ExecuTorch as a platform for mixed reality at scalex000DReal-time reasoning at the edgex000DMamba and SSM running at the edge",,海思; 计算; CBG,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构; CBG: 3DAIGC,海思: Session讨论端侧量化/剪枝、TensorRT/ExecuTorch与实时推理、SSM上端；可重点关注稀疏注意力与分块缓存、INT4/INT8部署和低延迟调度。; 计算: Session讨论轻量化与编译优化（量化/剪枝/稀疏）及SSM端侧实践；可重点关注低比特训推（NVFP4/MXFP6）、缓存/带宽对架构的约束。; CBG: Session讨论端侧轻量化与ExecuTorch在MR的规模化应用、iOS优化；可重点关注3D/视频模型INT8量化、稀疏化与端侧实时推理链路优化。
WED 3 DEC,noon,Expo Workshop,Multi-Agent Systems in Industry: From Research to Real-World Impact,https://neurips.cc/virtual/2025/128675,,1:30 PM,"This workshop will bridge the gap between the theoretical advancements in multi-agent systems and their practical applications in industry. The session will feature a series of poster presentations showcasing state-of-the-art, real-world multi-agent systems that are driving innovation across various sectors. We will delve into the challenges and opportunities of deploying these systems at scale, covering topics such as:x000DHuman-in-the-loop collaboration: Designing systems where AI agents and human experts work in synergy.x000DScalability and efficiency: Architecting multi-agent systems for large-scale industrial applications.x000DSafety and reliability: Ensuring the robustness and predictability of autonomous agents in critical systems.x000DDomain-specific applications: Highlighting successful implementations in areas such as software engineering, scientific research, and creative content generation.x000DThe goal of this workshop is to foster a discussion on the practical challenges and future directions of multi-agent systems, providing attendees with actionable insights and a deeper understanding of how these technologies are shaping the future of industry.",,计算; DCN,计算: 前沿应用负载; DCN: Network4AI 与 AI4Network,计算: Session讨论多智能体落地的扩展性与可靠性、人机协作与编排，可重点关注对并发通信、内存占用与尾延迟的影响，提炼Agentic负载的软硬协同要点。; DCN: Session讨论多智能体的可扩展性与可靠性及跨组件协同，可重点关注Agent间通信拓扑与流量模型、拥塞控制与服务编排实践，指导Network4AI演进。
WED 3 DEC,noon,Expo Workshop,Using the Virtual Cell Platform to Accelerate Machine Learning in Biology,https://neurips.cc/virtual/2025/128676,,1:30 PM,"Biology presents some of the most complex and high-impact challenges for machine learning, and single-cell transcriptomics is at the frontier of this work. In this workshop, we introduce the Virtual Cell Platform (VCP), a unified environment designed to accelerate model development and evaluation in biology. Using single-cell transcriptomics as a case study, we will demonstrate how the VCP enables researchers to train, benchmark, and interpret models in a reproducible and biologically meaningful way.

Participants will gain a primer on single-cell transcriptomics and learn how to evaluate models with cz-benchmarks, an open-source Python package providing standardized, community-driven tasks and metrics. Through the VCP CLI, attendees will pull datasets, run packaged models, and compare results programmatically. Hands-on exercises will guide participants through interactive visualizations, side-by-side model comparisons, and deep dives into model behavior using VCP’s no-code interface and BYOD (Bring Your Own Data) module.

By the end of the session, attendees will understand how to use the VCP to actively test and refine models during development, ensure biological relevance, and contribute models and benchmarks back to the community. This workshop highlights how the Virtual Cell Platform transforms ML infrastructure into a one-stop, researcher-friendly ecosystem, empowering the NeurIPS community to push the boundaries of AI in biology.",,,,
WED 3 DEC,2:30 p.m.,Invited Talk,Are We Having the Wrong Nightmares About AI?,https://neurips.cc/virtual/2025/invited-talk/109606,Zeynep Tufekci,3:30 PM,"Though seemingly opposite, doom and optimism regarding generative AI's spectacular rise both center on AGI or even superintelligence as a pivotal moment. But generative AI operates in a distinct manner from human intelligence, and it’s not a less intelligent human on a chip slowly getting smarter anymore than cars were mere horseless carriages. It must be understood on its own terms. And even if Terminator isn’t coming to kill us or superintelligence isn’t racing to save us, generative AI does bring profound challenges, well-beyond usual worries such as employment effects.  Technology facilitates progress by transforming the difficult into easy, the rare into ubiquitous, the scarce into abundant, the manual into automated, and the artisan into mass-produced. While potentially positive long-term, these inversions are extremely destabilizing during the transition, shattering the correlations and assumptions of our social order that relied on superseded difficulties as mechanisms of proof, filtering, sorting and signaling. For example, while few would dispute the value of the printing press or books, their introduction led to such destructive upheaval that the resulting religious wars caused proportionally more deaths than all other major wars and pandemics since combined. Historically, a new technology's revolutionary impact comes from making what's already possible and desired cheap, easy, fast, and large-scale, not from outdated or ill-fitting benchmarks that technologists tend to focus on. As such, Artificial Good-Enough Intelligence can unleash chaos and destruction long before, or if ever, AGI is reached. Existing AI is good enough to blur or pulverize our existing mechanisms of proof of accuracy, effort, veracity, authenticity, sincerity, and even humanity. The tumult from such a transition will require extensive technological, regulatory, and societal effort to counter. But the first step to getting started is having the right nightmares.",,,,
WED 3 DEC,4:30 p.m.,Expo Talk Panel,"Juries, Not Judges! Industry-Scale Evaluation of Trustworthy AI via Dynamic LLM Panels",https://neurips.cc/virtual/2025/128660,,5:30 PM,"As Large Language Models (LLMs) become central to high-stakes applications, the reliability of their evaluation systems is under intense scrutiny, especially in the financial industry. Traditional approaches - human annotation, single LLM judges, and static model juries - struggle to balance scalability, cost, and trustworthiness. We will discuss a promising framework: LLM Jury-on-Demand, a dynamic, learning-based framework that assembles an optimal panel of LLM evaluators for each task instance, leveraging predictive modeling to select and weight judges based on context-specific reliability. Our system adapts in real time, outperforming static ensembles and single judges in alignment with human expert judgment across summarization and retrieval-augmented generation benchmarks. This talk will showcase how adaptive LLM juries can transform evaluation of AI systems, offering robust, scalable, and context-aware solutions for industry and research. Attendees will gain practical insights into building trustworthy LLM evaluation pipelines, see live demos, and discuss future directions for reliable AI assessment in critical domains.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session讨论基于上下文可靠性预测的动态LLM评审团，可重点关注多评审器加权用于RFT奖励建模/校准与置信度感知采样，构建可扩展离线评测管线。; 诺亚: Session讨论动态LLM评审团与评审器加权选择，可重点关注在RLHF/后训练中替代或增强人评的自动奖励建模、评审偏差校准与实例级可靠性建模。
WED 3 DEC,4:30 p.m.,Expo Talk Panel,"Frontier Open-Weight Models: Building Transparent, Secure, and Sovereign AI",https://neurips.cc/virtual/2025/128664,,5:30 PM,"The next generation of AI will be defined not just by scale, but by openness. As the frontier in model capabilities accelerates, researchers and enterprises alike face a critical question: how do we advance state-of-the-art intelligence while preserving transparency, control, and security?x000Dx000DThis panel brings together leaders from open research, industry, and infrastructure to explore the emerging ecosystem of open-weight frontier models—systems that can be fully run, audited, and customized within private or sovereign environments. Discussion topics will include the research challenges behind training and aligning open models at scale, implications for reproducibility and safety, and how open access can enable new forms of collaboration between academia, government, and enterprise.x000Dx000DAttendees will gain insight into how the open frontier movement is reshaping AI research culture, infrastructure design, and deployment strategy worldwide.",,,,
WED 3 DEC,4:30 p.m.,Expo Talk Panel,The Co-X Framework: Versatile AI Agents for Automating and Augmenting Professional Workflows,https://neurips.cc/virtual/2025/128666,,5:30 PM,"Beyond monolithic models, the future of AI in industry lies in specialized agents that collaborate with human experts. This talk introduces the ""Co-X"" framework, a novel approach for creating a diverse ecosystem of collaborative agents tailored to specific professional domains. We will present four key agents built on this framework: the Co-AI Researcher, the Co-ML Engineer for automating software development cycles, the Co-Data Scientist for automating data analysis and insight generation, and the Co-Director for augmenting creative content generation. We will discuss the foundational technologies that enable this versatility—including long-term memory, tool use, and human-in-the-loop feedback—and demonstrate how the Co-X framework is poised to redefine productivity and innovation across industries.",,多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: Session讨论多Agent编排、长程记忆、工具调用与人类在环，可重点关注规划-执行闭环、HITL门控与记忆一致性策略，启发评估子项划分及写操作管控。; 诺亚: Session讨论协作式Agent、长期记忆与人类在环反馈，可重点关注HITL到自博弈的奖励成形、任务分解与规划器训练范式，支撑后训练推理。
WED 3 DEC,4:30 p.m.,Expo Talk Panel,Cosmos World Foundation Model Platform for Physical AI,https://neurips.cc/virtual/2025/128663,,5:30 PM,"Abstract: In this talk, I will introduce NVIDIA Cosmos, our World Foundation Model platform designed to advance Physical AI. Cosmos is built around three core pillars: Predict, Transfer, and Reason. I will provide updates on the latest releases—Predict 2.5 and Transfer 2.5—highlighting key improvements in generalization, efficiency, and scalability. In addition, I will share a preview of ongoing research directions that extend Cosmos toward richer world modeling and reasoning capabilities. Together, these developments aim to push the boundaries of how AI perceives, simulates, and interacts with complex real-world environments.",,温哥华云; 计算,温哥华云: Embodied AI; 计算: 训推新范式,温哥华云: Session讨论Cosmos物理AI世界模型与Predict/Transfer 2.5更新，可重点关注sim-to-real迁移、世界模型到策略学习链路及规模化训练实践。; 计算: Session讨论Cosmos三柱架构与2.5版效率可扩展性，可重点关注世界模型驱动的训推范式变化、仿真-推理-交互闭环的负载与调度。
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1A,https://neurips.cc/virtual/2025/session/122546,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference,https://neurips.cc/virtual/2025/oral/118170,,11:00 AM,"Large Language Models (LLMs) are now integral across various domains and have demonstrated impressive performance. Progress, however, rests on the premise that benchmark scores are both accurate and reproducible. We demonstrate that the reproducibility of LLM performance is fragile: changing system configuration, such as evaluation batch size, GPU count, and GPU version, can introduce significant differences in the generated responses. This issue is especially pronounced in reasoning models, where minor rounding differences in early tokens can cascade into divergent chains of thought, ultimately affecting accuracy. For instance, under bfloat16 precision with greedy decoding, a reasoning model like DeepSeek-R1-Distill-Qwen-7B can exhibit up to 9\% variation in accuracy and 9,000 tokens difference in response length due to differences in GPU count, type, and evaluation batch size.We trace the root cause of this variability to the non-associative nature of floating-point arithmetic under limited numerical precision. This work presents the first systematic investigation into how numerical precision affects reproducibility in LLM inference. Through carefully controlled experiments across various hardware, software, and precision settings, we quantify when and how model outputs diverge.Our analysis reveals that floating-point precision—while critical for reproducibility—is often neglected in evaluation practices.Inspired by this, we develop a lightweight inference pipeline, dubbed LayerCast, that stores weights in 16-bit precision but performs all computations in FP32, balancing memory efficiency with numerical stability. Code is available at https://github.com/nanomaoli/llm_reproducibility.",,计算,计算: 高效模型架构,计算: Session讨论低精度浮点非关联性致推理非确定性与LayerCast（16位存储+FP32计算），可重点关注bf16/MXFP6/NVFP4取舍、确定性评测与芯片算精度定义
WED 3 DEC,10:00-11:00,Oral Paper,  → Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond),https://neurips.cc/virtual/2025/oral/121422,,11:00 AM,"Large language models (LMs) often struggle to generate diverse, human-like creative content, raising concerns about the long-term homogenization of human thought through repeated exposure to similar outputs. Yet scalable methods for evaluating LM output diversity remain limited, especially beyond narrow tasks such as random number or name generation, or beyond repeated sampling from a single model. To address this gap, we introduce Infinity-Chat, a large-scale dataset of 26K diverse, real-world, open-ended user queries that admit a wide range of plausible answers with no single ground truth. We introduce the first comprehensive taxonomy for characterizing the full spectrum of open-ended prompts posed to LMs, comprising 6 top-level categories (e.g., creative content generation, brainstorm & ideation) that further breaks down to 17 subcategories. Using Infinity-Chat, we present a large-scale study of mode collapse in LMs, revealing a pronounced Artificial Hivemind effect in open-ended generation of LMs, characterized by (1) intra-model repetition, where a single model consistently generates similar responses, and more so (2) inter-model homogeneity, where different models produce strikingly similar outputs. Infinity-Chat also includes 31,250 human annotations, across absolute ratings and pairwise preferences, with 25 independent human annotations per example. This enables studying collective and individual-specific human preferences in response to open-ended queries. Our findings show that state-of-the-art LMs, reward models, and LM judges are less well calibrated to human ratings on model generations that elicit differing idiosyncratic annotator preferences, despite maintaining comparable overall quality. Overall, INFINITY-CHAT presents the first large-scale resource for systematically studying real-world open-ended queries to LMs, revealing critical insights to guide future research for mitigating long-term AI safety risks posed by the Artificial Hivemind.",,计算,计算: 训推新范式,计算: Session讨论开放式生成同质化评估、Infinity-Chat与多标注偏好/LM judge校准，可重点关注偏好建模与个性化对齐策略及评测基准设计。
WED 3 DEC,10:00-11:00,Oral Paper,  → SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing,https://neurips.cc/virtual/2025/oral/115002,,11:00 AM,"3D spatial reasoning in dynamic, audio-visual environments is a cornerstone of human cognition yet remains largely unexplored by existing Audio-Visual Large Language Models (AV-LLMs) and benchmarks, which predominantly focus on static or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D spatial reasoning in dynamic scenes with synchronized spatial audio. SAVVY-Bench is comprised of thousands of carefully curated question–answer pairs probing both directional and distance relationships involving static and moving objects, and requires fine-grained temporal grounding, consistent 3D localization, and multi-modal annotation. To tackle this challenge, we propose SAVVY, a novel training-free reasoning pipeline that consists of two stages: (i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as other audio-visual methods to track the trajectories of key objects related to the query using both visual and spatial audio cues, and (ii) Dynamic Global Map Construction, which aggregates multi-modal queried object trajectories and converts them into a unified global dynamic map. Using the constructed map, a final QA answer is obtained through a coordinate transformation that aligns the global map with the queried viewpoint. Empirical evaluation demonstrates that SAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a new standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.",,温哥华云; 诺亚; 计算,温哥华云: Embodied AI; 诺亚: 大模型长序列，多模态长序列; 计算: 前沿应用负载,温哥华云: Session讨论动态AV-LLM的3D空间推理与SAVVY-Bench，可重点关注时序轨迹估计与全局动态地图在具身导航与交互评测中的应用。; 诺亚: Session讨论动态场景的时序绑定与一致3D定位推理，可重点关注多模态长序列的时空对齐、轨迹级记忆更新与坐标变换式QA策略。; 计算: Session讨论AV-LLM动态3D空间推理的管线与基准，可重点关注多模态对齐、轨迹跟踪与地图构建对内存/带宽与时序算子负载的影响。
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1B,https://neurips.cc/virtual/2025/session/122547,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Optimal Mistake Bounds for Transductive Online Learning,https://neurips.cc/virtual/2025/oral/119099,,11:00 AM,"We resolve a 30-year-old open problem concerning the power of unlabeled data in online learning by tightly quantifying the gap between transductive and standard online learning. We prove that for every concept class $\mathcal{H}$ with Littlestone dimension $d$, the transductive mistake bound is at least $\Omega(\sqrt{d})$. This establishes an exponential improvement over previous lower bounds of $\Omega(\log \log d)$, $\Omega(\sqrt{\log d})$, and $\Omega(\log d)$, respectively due to Ben-David, Kushilevitz, and Mansour (1995, 1997) and Hanneke, Moran, and Shafer (2023). We also show that our bound is tight: for every $d$, there exists a class of Littlestone dimension $d$ with transductive mistake bound $O(\sqrt{d})$. Our upper bound also improves the previous best known upper bound of $(2/3) \cdot d$ from Ben-David et al. (1997). These results demonstrate a quadratic gap between transductive and standard online learning, thereby highlighting the benefit of advanced access to the unlabeled instance sequence. This stands in stark contrast to the PAC setting, where transductive and standard learning exhibit similar sample complexities.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → High-Dimensional Calibration from Swap Regret,https://neurips.cc/virtual/2025/oral/117761,,11:00 AM,"We study the online calibration of multi-dimensional forecasts over an arbitrary convex set $\mathcal{P} \subset \mathbb{R}^d$ relative to an arbitrary norm $\Vert\cdot\Vert$. We connect this with the problem of external regret minimization for online linear optimization, showing that if it is possible to guarantee $O(\sqrt{\rho T})$ worst-case regret after $T$ rounds when actions are drawn from $\mathcal{P}$ and losses are drawn from the dual $\Vert \cdot \Vert_*$ unit norm ball, then it is also possible to obtain $\epsilon$-calibrated forecasts after $T = \exp(O(\rho /\epsilon^2))$ rounds. When $\mathcal{P}$ is the $d$-dimensional simplex and $\Vert \cdot \Vert$ is the $\ell_1$-norm, the existence of $O(\sqrt{T\log d})$ algorithms for learning with experts implies that it is possible to obtain $\epsilon$-calibrated forecasts after $T = \exp(O(\log{d}/\epsilon^2)) = d^{O(1/\epsilon^2)}$ rounds, recovering a recent result of Peng 2025.Interestingly, our algorithm obtains this guarantee without requiring access to any online linear optimization subroutine or knowledge of the optimal rate $\rho$ -- in fact, our algorithm is identical for every setting of $\mathcal{P}$ and $\Vert \cdot \Vert$. Instead, we show that the optimal regularizer for the above OLO problem can be used to upper bound the above calibration error by a swap regret, which we then minimize by running the recent TreeSwap algorithm with Follow-The-Leader as a subroutine. The resulting algorithm is highly efficient and plays a distribution over simple averages of past observations in each round.Finally, we prove that any online calibration algorithm that guarantees $\epsilon T$ $\ell_1$-calibration error over the $d$-dimensional simplex requires $T \geq \exp(\mathrm{poly}(1/\epsilon))$ (assuming $d \geq \mathrm{poly}(1/\epsilon)$). This strengthens the corresponding $d^{\Omega(\log{1/\epsilon})}$ lower bound of Peng 2025, and shows that an exponential dependence on $1/\epsilon$ is necessary.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Does Stochastic Gradient really succeed for bandits?,https://neurips.cc/virtual/2025/oral/116754,,11:00 AM,"Recent works of Mei et al. (2023, 2024) have deepened the theoretical understanding of the *Stochastic Gradient Bandit* (SGB) policy, showing that using a constant learning rate guarantees asymptotic convergence to the optimal policy, and that sufficiently *small* learning rates can yield logarithmic regret. However, whether logarithmic regret holds beyond small learning rates remains unclear. In this work, we take a step towards characterizing the regret *regimes* of SGB as a function of its learning rate. For two--armed bandits, we identify a sharp threshold, scaling with the sub-optimality gap $\Delta$, below which SGB achieves *logarithmic* regret on all instances, and above which it can incur *polynomial* regret on some instances. This result highlights the necessity of knowing (or estimating) $\Delta$ to ensure logarithmic regret with a constant learning rate.For general $K$-armed bandits, we further show the learning rate must scale inversely with $K$ to avoid polynomial regret. We introduce novel techniques to derive regret upper bounds for SGB, laying the groundwork for future advances in the theory of gradient-based bandit algorithms.",,nan,nan: ,nan: 
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1C,https://neurips.cc/virtual/2025/session/122548,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Adjoint Schrödinger Bridge Sampler,https://neurips.cc/virtual/2025/oral/115787,,11:00 AM,"Computational methods for learning to sample from the Boltzmann distribution—where the target distribution is known only up to an unnormalized energy function—have advanced significantly recently. Due to the lack of explicit target samples, however, prior diffusion-based methods, known asdiffusion samplers, often require importance-weighted estimation or complicated learning processes. Both trade off scalability with extensive evaluations of the energy and model, thereby limiting their practical usage. In this work, we proposeAdjoint Schrödinger Bridge Sampler (ASBS), a new diffusion sampler that employs simple and scalable matching-based objectives yet without the need to estimate target samples during training. ASBS is grounded on a mathematical model—the Schrödinger Bridge—which enhances sampling efficiency via kinetic-optimal transportation. Through a new lens of stochastic optimal control theory, we demonstrate how SB-based diffusion samplers can be learned at scale via Adjoint Matching and prove convergence to the global solution. Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to arbitrary source distributions by relaxing the so-called memoryless condition that largely restricts the design space. Through extensive experiments, we demonstrate the effectiveness of ASBS on sampling from classical energy functions, amortized conformer generation, and molecular Boltzmann distributions. Codes are available at https://github.com/facebookresearch/adjoint_samplers",,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Rethinking Joint Maximum Mean Discrepancy for Visual Domain Adaptation,https://neurips.cc/virtual/2025/oral/117477,,11:00 AM,"In domain adaption (DA), joint maximum mean discrepancy (JMMD), as a famous distribution-distance metric, aims to measure joint probability distribution difference between the source domain and target domain, while it is still not fully explored and especially hard to be applied into a subspace-learning framework as its empirical estimation involves a tensor-product operator whose partial derivative is difficult to obtain. To solve this issue, we deduce a concise JMMD based on the Representer theorem that avoids the tensor-product operator and obtains two essential findings. First, we reveal the uniformity of JMMD by proving that previous marginal, class conditional, and weighted class conditional probability distribution distances are three special cases of JMMD with different label reproducing kernels. Second, inspired by graph embedding, we observe that the similarity weights, which strengthen the intra-class compactness in the graph of Hilbert Schmidt independence criterion (HSIC), take opposite signs in the graph of JMMD, revealing why JMMD degrades the feature discrimination. This motivates us to propose a novel loss JMMD-HSIC by jointly considering JMMD and HSIC to promote discrimination of JMMD. Extensive experiments on several cross-domain datasets could demonstrate the validity of our revealed theoretical results and the effectiveness of our proposed JMMD-HSIC.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Class-wise Balancing Data Replay for Federated Class-Incremental Learning,https://neurips.cc/virtual/2025/oral/117265,,11:00 AM,"Federated Class Incremental Learning (FCIL) aims to collaboratively process continuously increasing incoming tasks across multiple clients. Among various approaches, data replay has become a promising solution, which can alleviate forgetting by reintroducing representative samples from previous tasks. However, their performance is typically limited by class imbalance, both within the replay buffer due to limited global awareness and between replayed and newly arrived classes. To address this issue, we propose a class-wise balancing data replay method for FCIL (FedCBDR), which employs a global coordination mechanism for class-level memory construction and reweights the learning objective to alleviate the aforementioned imbalances. Specifically, FedCBDR has two key components: 1) the global-perspective data replay module reconstructs global representations of prior task knowledge in a privacy-preserving manner, which then guides a class-aware and importance-sensitive sampling strategy to achieve balanced replay; 2) Subsequently, to handle class imbalance across tasks, the task-aware temperature scaling module adaptively adjusts the temperature of logits at both class and instance levels based on task dynamics, which reduces the model’s overconfidence in majority classes while enhancing its sensitivity to minority classes. Experimental results verified that FedCBDR achieves balanced class-wise sampling under heterogeneous data distributions and improves generalization under task imbalance between earlier and recent tasks, yielding a 2%-15% Top-1 accuracy improvement over six state-of-the-art methods.",,,,
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1D,https://neurips.cc/virtual/2025/session/122549,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think,https://neurips.cc/virtual/2025/oral/116345,,11:00 AM,"REPA and its variants effectively mitigate training challenges in diffusion models by incorporating external visual representations from pretrained models, through alignment between the noisy hidden projections of denoising networks and foundational clean image representations. We argue that the external alignment, which is absent during the entire denoising inference process, falls short of fully harnessing the potential of discriminative representations. In this work, we propose a straightforward method called \textit{\textbf{R}epresentation \textbf{E}ntanglement for \textbf{G}eneration} (\textbf{REG}), which entangles low-level image latents with a single high-level class token from pretrained foundation models for denoising. REG acquires the capability to produce coherent image-class pairs directly from pure noise, substantially improving both generation quality and training efficiency.This is accomplished with negligible additional inference overhead, requiring only one single additional token for denoising (<0.5\% increase in FLOPs and latency).The inference process concurrently reconstructs both image latents and their corresponding global semantics, where the acquired semantic knowledge actively guides and enhances the image generation process.On ImageNet 256$\times$256, SiT-XL/2 + REG demonstrates remarkable convergence acceleration, achieving $\textbf{63}\times$ and $\textbf{23}\times$ faster training than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively, SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA trained for 4M iterations ($\textbf{10}\times$ longer). Code is available at: https://github.com/Martinser/REG.",,计算; 海思,计算: 高效模型架构; 海思: 大语言模型和扩散模型的加速,计算: Session讨论扩散Transformer的表征耦合与单token条件化提速，可重点关注其对模型架构演进预测与低精训推算子映射的启示。; 海思: Session讨论以单高层语义token与图像潜变量耦合的统一特征空间条件化，可重点关注其在多模态条件融合延迟与低开销推理中的应用。
WED 3 DEC,10:00-11:00,Oral Paper,  → On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity,https://neurips.cc/virtual/2025/oral/116379,,11:00 AM,"Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods, such as diffusion and flow matching techniques, generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the noisy nature of the loss as a key factor driving generalization in flow matching.First, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.",,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Why Diffusion Models Don’t Memorize:  The Role of Implicit Dynamical Regularization in Training,https://neurips.cc/virtual/2025/oral/119373,,11:00 AM,"Diffusion models have achieved remarkable success across a wide range of generative tasks. A key challenge is understanding the mechanisms that prevent their memorization of training data and allow generalization. In this work, we investigate the role of the training dynamics in the transition from generalization to memorization. Through extensive experiments and theoretical analysis, we identify two distinct timescales: an early time $\tau_\mathrm{gen}$ at which models begin to generate high-quality samples, and a later time $\tau_\mathrm{mem}$ beyond which memorization emerges. Crucially, we find that $\tau_\mathrm{mem}$ increases linearly with the training set size $n$, while $\tau_\mathrm{gen}$ remains constant. This creates a growing window of training times with $n$ where models generalize effectively, despite showing strong memorization if training continues beyond it. It is only when $n$ becomes larger than a model-dependent threshold that overfitting disappears at infinite training times.These findings reveal a form of implicit dynamical regularization in the training dynamics, which allow to avoid memorization even in highly overparameterized settings. Our results are supported by numerical experiments with standard U-Net architectures on realistic and synthetic  datasets, and by a theoretical analysis using a tractable random features model studied in the high-dimensional limit.",,计算,计算: 训推新范式,计算: Session讨论扩散模型训练动态的隐式正则与记忆化时序，可重点关注数据规模-训练步数配比、早停策略与训练窗口对负载特征建模。
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1E,https://neurips.cc/virtual/2025/session/122550,,11:00 AM,,,,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation,https://neurips.cc/virtual/2025/oral/115716,,11:00 AM,"Vision-and-Language Navigation (VLN) is a core task where embodied agents leverage their spatial mobility to navigate in 3D environments toward designated destinations based on natural language instructions. Recently, video-language large models (Video-VLMs) with strong generalization capabilities and rich commonsense knowledge have shown remarkable performance when applied to VLN tasks. However, these models still encounter the following challenges when applied to real-world 3D navigation: 1) Insufficient understanding of 3D geometry and spatial semantics; 2) Limited capacity for large-scale exploration and long-term environmental memory; 3) Poor adaptability to dynamic and changing environments.To address these limitations, we propose Dynam3D, a dynamic layered 3D representation model that leverages language-aligned, generalizable, and hierarchical 3D representations as visual input to train 3D-VLM in navigation action prediction. Given posed RGB-D images, our Dynam3D projects 2D CLIP features into 3D space and constructs multi-level 3D patch-instance-zone representations for 3D geometric and semantic understanding with a dynamic and layer-wise update strategy.  Our Dynam3D is capable of online encoding and localization of 3D instances, and dynamically updates them in changing environments to provide large-scale exploration and long-term memory capabilities for navigation. By leveraging large-scale 3D-language pretraining and task-specific adaptation, our Dynam3D sets new state-of-the-art performance on VLN benchmarks including R2R-CE, REVERIE-CE and NavRAG-CE under monocular settings. Furthermore, experiments for pre-exploration, lifelong memory, and real-world robot validate the effectiveness of practical deployment.",,温哥华云; 计算,温哥华云: Embodied AI; 计算: 前沿应用负载,温哥华云: Session讨论动态分层3D表示、实例在线定位与长期记忆在VLN中的应用，可重点关注3D-语言对齐预训练、层级token更新与动作预测链路的工程化落地; 计算: Session讨论动态3D token与长时环境记忆驱动的3D-VLM推理，可重点关注层级token增量更新对显存/带宽负载特征及在线编码的计算模式
WED 3 DEC,10:00-11:00,Oral Paper,  → Perception Encoder: The best visual embeddings are not at the output of the network,https://neurips.cc/virtual/2025/oral/118806,,11:00 AM,"We introduce Perception Encoder (PE), a family of state-of-the-art vision encoders for image and video understanding. Traditionally, vision encoders have relied on a variety of pretraining objectives, each excelling at different downstream tasks. Surprisingly, after scaling a carefully tuned image pretraining recipe and refining with a robust video data engine, we find that contrastive vision-language training alone can produce strong, general embeddings for all of these downstream tasks. There is only one caveat: these embeddings are hidden within the intermediate layers of the network. To draw them out, we introduce two alignment methods: language alignment for multimodal language modeling, and spatial alignment for dense prediction. Together, our PE family of models achieves state-of-the-art results on a wide variety of tasks, including zero-shot image and video classification and retrieval; document, image, and video Q&A; and spatial tasks such as detection, tracking, and depth estimation. We release our models, code, and novel dataset of synthetically and human-annotated videos: https://github.com/facebookresearch/perception_models",,计算; 诺亚,计算: 高效模型架构; 诺亚: 大模型长序列，多模态长序列,计算: Session讨论中间层视觉表征与语言/空间对齐训练，可重点关注多层特征抽取、对齐头架构及其对低精训推与算子布局的影响。; 诺亚: Session讨论中间层表征经语言对齐用于多模态建模，可重点关注跨层视觉特征注入LLM接口、视频QA长序列对齐与记忆更新策略。
WED 3 DEC,10:00-11:00,Oral Paper,  → Interactive Cross-modal Learning for Text-3D Scene Retrieval,https://neurips.cc/virtual/2025/oral/116803,,11:00 AM,"Text-3D Scene Retrieval (T3SR) aims to retrieve relevant scenes using linguistic queries. Although traditional T3SR methods have made significant progress in capturing fine-grained associations, they implicitly assume that query descriptions are information-complete. In practical deployments, however, limited by the capabilities of users and models, it is difficult or even impossible to directly obtain a perfect textual query suiting the entire scene and model, thereby leading to performance degradation. To address this issue, we propose a novel Interactive Text-3D Scene Retrieval Method (IDeal), which promotes the enhancement of the alignment between texts and 3D scenes through continuous interaction. To achieve this, we present an Interactive Retrieval Refinement framework (IRR), which employs a questioner to pose contextually relevant questions to an answerer in successive rounds that either promote detailed probing or encourage exploratory divergence within scenes. Upon the iterative responses received from the answerer, IRR adopts a retriever to perform both feature-level and semantic-level information fusion, facilitating scene-level interaction and understanding for more precise re-rankings. To bridge the domain gap between queries and interactive texts, we propose an Interaction Adaptation Tuning strategy (IAT). IAT mitigates the discriminability and diversity risks among augmented text features that approximate the interaction text domain, achieving contrastive domain adaptation for our retriever. Extensive experimental results on three datasets demonstrate the superiority of IDeal.",,nan,nan: ,nan: 
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2A,https://neurips.cc/virtual/2025/session/122551,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Agnostic Active Learning Is Always Better Than Passive Learning,https://neurips.cc/virtual/2025/oral/117512,,4:30 PM,"We sharply characterize the optimal first-order query complexity of agnostic active learning for all concept classes, and propose a new general active learning algorithm which achieves it. Remarkably, the optimal query complexity admits a leading term which is always strictly smaller than the sample complexity of passive supervised learning (by a factor proportional to the best-in-class error rate). This was not previously known to be possible in the agnostic setting. For comparison, in all previous general analyses, the leading term exhibits an additional factor, such as the disagreement coefficient or related complexity measure, and therefore only provides improvements over passive learning in restricted cases. The present work completely removes such factors from the leading term, implying that every concept class benefits from active learning in the non-realizable case. The results established in this work resolve an important long-standing open question central to the past two decades of research on the theory of agnostic active learning.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Tighter CMI-Based Generalization Bounds via Stochastic Projection and Quantization,https://neurips.cc/virtual/2025/oral/117680,,4:30 PM,"In this paper, we leverage stochastic projection and lossy compression to establish new conditional mutual information (CMI) bounds on the generalization error of statistical learning algorithms. It is shown that these bounds are generally tighter than the existing ones. In particular, we prove that for certain problem instances for which existing MI and CMI bounds were recently shown in Attias et al. [2024] and Livni [2023] to become vacuous or fail to describe the right generalization behavior, our bounds yield suitable generalization guarantees of the order of $\mathcal{O}(1/\sqrt{n})$, where $n$ is the size of the training dataset. Furthermore, we use our bounds to investigate the problem of data ""memorization"" raised in those works, and which asserts that there are learning problem instances for which any learning algorithm that has good prediction there exist distributions under which the algorithm must ""memorize'' a big fraction of the training dataset. We show that for every learning algorithm, there exists an auxiliary algorithm that does not memorize and which yields comparable generalization error for any data distribution. In part, this shows that memorization is not necessary for good generalization.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks,https://neurips.cc/virtual/2025/oral/118768,,4:30 PM,"Understanding the inductive bias and generalization properties of large overparametrized machine learning models requires to characterize the dynamics of the training algorithm.  We study the learning dynamics of large two-layer neural networks via dynamical mean field theory, a well established technique of non-equilibrium statistical physics. We show that, for large network width $m$,and large number of samples per input dimension $n/d$, the training dynamics exhibits a separation of timescales which implies:$(i)$ The emergence of a slow time scale associated with the growth in Gaussian/Rademacher complexity of the network;$(ii)$ Inductive bias towards small complexity if the initialization has small enough complexity;$(iii)$ A dynamical decoupling between feature learning and overfitting regimes; $(iv)$ A non-monotone behavior of the test error, associated  `feature unlearning' regime at large times.",,nan,nan: ,nan: 
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2B,https://neurips.cc/virtual/2025/session/122552,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → PhySense: Sensor Placement Optimization for Accurate Physics Sensing,https://neurips.cc/virtual/2025/oral/115066,,4:30 PM,"Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered. Code is available at this repository: https://github.com/thuml/PhySense.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session讨论稀疏观测重建与传感器布设联合优化（基于流的生成模型、跨注意力与PGD），可重点关注其在具身智能主动感知/传感位姿规划中的不确定性驱动布设策略。
WED 3 DEC,3:30-4:30,Oral Paper,  → TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability,https://neurips.cc/virtual/2025/oral/117509,,4:30 PM,"Vehicle GPS trajectories provide valuable movement information that supports various downstream tasks and applications. A desirable trajectory learning model should be able to transfer across regions and tasks without retraining, avoiding the need to maintain multiple specialized models and subpar performance with limited training data. However, each region has its unique spatial features and contexts, which are reflected in vehicle movement patterns and are difficult to generalize. Additionally, transferring across different tasks faces technical challenges due to the varying input-output structures required for each task. Existing efforts towards transferability primarily involve learning embedding vectors for trajectories, which perform poorly in region transfer and require retraining of prediction modules for task transfer.To address these challenges, we propose $\textit{TransferTraj}$, a vehicle GPS trajectory learning model that excels in both region and task transferability. For region transferability, we introduce RTTE as the main learnable module within TransferTraj. It integrates spatial, temporal, POI, and road network modalities of trajectories to effectively manage variations in spatial context distribution across regions. It also introduces a TRIE module for incorporating relative information of spatial features and a spatial context MoE module for handling movement patterns in diverse contexts. For task transferability, we propose a task-transferable input-output scheme that unifies the input-output structure of different tasks into the masking and recovery of modalities and trajectory points. This approach allows TransferTraj to be pre-trained once and transferred to different tasks without retraining. We conduct extensive experiments on three real-world vehicle trajectory datasets under various transfer settings, including task transfer, zero-shot region transfer, and few-shot region transfer. Experimental results demonstrate that TransferTraj significantly outperforms state-of-the-art baselines in different scenarios, validating its effectiveness in region and task transfer. Code is available at https://github.com/wtl52656/TransferTraj.",,nan,nan: ,nan: 
WED 3 DEC,3:30-4:30,Oral Paper,  → OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata,https://neurips.cc/virtual/2025/oral/121612,,4:30 PM,"Accurate visual localization from aerial views is a fundamental problem with applications in mapping, large-area inspection, and search-and-rescue operations. In many scenarios, these systems require high-precision localization while operating with limited resources (e.g., no internet connection or GNSS/GPS support), making large image databases or heavy 3D models impractical. Surprisingly, little attention has been given to leveraging orthographic geodata as an alternative paradigm, which is lightweight and increasingly available through free releases by governmental authorities (e.g., the European Union). To fill this gap, we propose OrthoLoC, the first large-scale dataset comprising 16,425 UAV images from Germany and the United States with multiple modalities. The dataset addresses domain shifts between UAV imagery and geospatial data. Its paired structure enables fair benchmarking of existing solutions by decoupling image retrieval from feature matching, allowing isolated evaluation of localization and calibration performance. Through comprehensive evaluation, we examine the impact of domain shifts, data resolutions, and covisibility on localization accuracy. Finally, we introduce a refinement technique called AdHoP, which can be integrated with any feature matcher, improving matching by up to 95% and reducing translation error by up to 63%. The dataset and code are available at: https://deepscenario.github.io/OrthoLoC .",,温哥华云,温哥华云: Embodied AI,温哥华云: Session讨论无GNSS下UAV基于正射地理数据的6-DoF定位标定与VPR增强，可重点关注OrthoLoC数据集与AdHoP在机器人定位鲁棒性上的应用。
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2C,https://neurips.cc/virtual/2025/session/122553,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → A multiscale analysis of mean-field transformers in the moderate interaction regime,https://neurips.cc/virtual/2025/oral/117616,,4:30 PM,"In this paper, we study the evolution of tokens through the depth of encoder-only transformer models at inference time by modeling them as a system of particles interacting in a mean-field way and studying the corresponding dynamics. More specifically, we consider this problem in the moderate interaction regime, where the number $N$ of tokens is large and the inverse temperature parameter $\beta$ of the model scales together with $N$. In this regime, the dynamics of the system displays a multiscale behavior: a fast phase, where the token empirical measure collapses on a low-dimensional space, an intermediate phase, where the measure further collapses into clusters, and a slow one, where such clusters sequentially merge into a single one. We provide a rigorous characterization of the limiting dynamics in each of these phases and prove convergence in the above mentioned limit, exemplifying our results with some simulations.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → The emergence of sparse attention: impact of data distribution and benefits of repetition,https://neurips.cc/virtual/2025/oral/116475,,4:30 PM,"Emergence is a fascinating property of large language models and neural networks more broadly: as models scale and train for longer, they sometimes develop new abilities in sudden ways. Despite initial studies, we still lack a comprehensive understanding of how and when these abilities emerge. To address this gap, we study the emergence over training of sparse attention, a critical and frequently observed attention pattern in Transformers. By combining theoretical analysis of a toy model with empirical observations on small Transformers trained on a linear regression variant, we uncover the mechanics driving sparse attention emergence and reveal that emergence timing follows power laws based on task structure, architecture, and optimizer choice. We additionally find that repetition can greatly speed up emergence. Finally, we confirm these results on a well-studied in-context associative recall task. Our findings provide a simple, theoretically grounded framework for understanding how data distributions and model design influence the learning dynamics behind one form of emergence.",,计算; 诺亚,计算: 高效模型架构; 诺亚: 大模型长序列，多模态长序列,计算: Session讨论稀疏注意力涌现机制与数据分布/重复影响，可重点关注幂律时机对架构演进和硬件映射的指引。; 诺亚: Session讨论稀疏注意力涌现与数据分布/重复关系，可重点关注利用重复加速长序列稀疏模式形成与测试时记忆策略。
WED 3 DEC,3:30-4:30,Oral Paper,  → From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer Training Dynamics,https://neurips.cc/virtual/2025/oral/116706,,4:30 PM,"Although transformer-based models have shown exceptional empirical performance, the fundamental principles governing their training dynamics are inadequately characterized beyond configuration-specific studies. Inspired by empirical evidence showing improved reasoning capabilities under small initialization scales in language models, we employ the gradient flow analytical framework established in \cite{zhou2022towards} to systematically investigate linearized Transformer training dynamics. Our theoretical analysis dissects the dynamics of attention modules into two distinct stages. In the first stage, asymmetric weight perturbations from random initialization sustain non-degenerate gradient dynamics in parameter matrices, facilitating systematic escape from small initialization regimes. Subsequently, these matrices undergo condensation, progressively aligning toward the target orientation. In the second stage, the previously static key-query matrices actively participate in training, driving the normalized matrices toward asymptotic rank collapse. This two-stage framework generalizes classical directional convergence results.",,,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2D,https://neurips.cc/virtual/2025/session/122554,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models,https://neurips.cc/virtual/2025/oral/119904,,4:30 PM,"Preference-based reinforcement learning (PbRL) has emerged as a promising paradigm for teaching robots complex behaviors without reward engineering. However, its effectiveness is often limited by two critical challenges: the reliance on extensive human input and the inherent difficulties in resolving query ambiguity and credit assignment during reward learning. In this paper, we introduce PRIMT, a PbRL framework designed to overcome these challenges by leveraging foundation models (FMs) for multimodal synthetic feedback and trajectory synthesis. Unlike prior approaches that rely on single-modality FM evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy, integrating the complementary strengths of vision-language models (VLMs) and large language models (LLMs) in evaluating robot behaviors for more reliable and comprehensive feedback. PRIMT also incorporates foresight trajectory generation to warm-start the trajectory buffer with bootstrapped samples, reducing early-stage query ambiguity, and hindsight trajectory augmentation for counterfactual reasoning with a causal auxiliary loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6 manipulation tasks on various benchmarks, demonstrating superior performance over FM-based and scripted baselines. Website at https://primt25.github.io/.",,温哥华云; 诺亚,温哥华云: Embodied AI; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session讨论多模态偏好RL与VLM/LLM融合评估，可重点关注FM合成反馈与前/后视轨迹增广提升具身策略样本效率与信用分配; 诺亚: Session讨论偏好RL与因果辅助损失、反事实轨迹增广，可重点关注将多模态FM合成反馈与信用分配机制迁移到大模型后训练与自博弈框架
WED 3 DEC,3:30-4:30,Oral Paper,  → Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks,https://neurips.cc/virtual/2025/oral/116055,,4:30 PM,"Neuromorphic computing systems are set to revolutionize energy-constrained robotics by achieving orders-of-magnitude efficiency gains, while enabling native temporal processing. Spiking Neural Networks (SNNs) represent a promising algorithmic approach for these systems, yet their application to complex control tasks faces two critical challenges: (1) the non-differentiable nature of spiking neurons necessitates surrogate gradients with unclear optimization properties, and (2) the stateful dynamics of SNNs require training on sequences, which in reinforcement learning (RL) is hindered by limited sequence lengths during early training, preventing the network from bridging its warm-up period.We address these challenges by systematically analyzing surrogate gradient slope settings, showing that shallower slopes increase gradient magnitude in deeper layers but reduce alignment with true gradients. In supervised learning, we find no clear preference for fixed or scheduled slopes. The effect is much more pronounced in RL settings, where shallower slopes or scheduled slopes lead to a $\times2.1$ improvement in both training and final deployed performance. Next, we propose a novel training approach that leverages a privileged guiding policy to bootstrap the learning process, while still exploiting online environment interactions with the spiking policy. Combining our method with an adaptive slope schedule for a real-world drone position control task, we achieve an average return of 400 points, substantially outperforming prior techniques, including Behavioral Cloning and TD3BC, which achieve at most –200 points under the same conditions. This work advances both the theoretical understanding of surrogate gradient learning in SNNs and practical training methodologies for neuromorphic controllers demonstrated in real-world robotic systems.",,计算; 温哥华云,计算: 训推新范式; 温哥华云: Embodied AI,计算: Session讨论SNN在RL中的自适应替代梯度与特权策略引导，可重点关注事件驱动负载形态、在线交互训练对算子/调度与内存访问建模的影响。; 温哥华云: Session讨论用于无人机控制的SNN替代梯度斜率调度与引导策略，可重点关注低功耗具身控制、warm-up跨越与在线学习在真实机器人系统中的落地路径。
WED 3 DEC,3:30-4:30,Oral Paper,  → SAGE: A Unified Framework for Generalizable Object State Recognition with State-Action Graph Embedding,https://neurips.cc/virtual/2025/oral/116465,,4:30 PM,"Recognizing the physical states of objects and their transformations within videos is crucial for structured video understanding and enabling robust real-world applications, such as robotic manipulation. However, pretrained vision-language models often struggle to capture these nuanced dynamics and their temporal context, and specialized object state recognition frameworks may not generalize to unseen actions or objects. We introduce SAGE (State-Action Graph Embeddings), a novel framework that offers a unified model of physical state transitions by decomposing states into fine-grained, language-described visual concepts that are sharable across different objects and actions. SAGE initially leverages Large Language Models to construct a State-Action Graph, which is then multimodally refined using Vision-Language Models. Extensive experiments show that our method significantly outperforms baselines, generalizes effectively to unseen objects and actions in open-world settings. SAGE improves the prior state-of-the-art by as much as 14.6% on novel state recognition with less than 5% of its inference time.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session讨论状态-动作图嵌入实现视频中物体物理状态识别与跨动作/对象泛化，可重点关注LLM构图+VLM精炼在机器人前置/后置状态建模与零样本操作迁移
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2E,https://neurips.cc/virtual/2025/session/122555,,4:30 PM,,,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing,https://neurips.cc/virtual/2025/oral/121634,,4:30 PM,"Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats. To study this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE). RISEBench focuses on four key reasoning categories: Temporal, Causal, Spatial, and Logical Reasoning. We curate high-quality test cases for each category and propose an robust evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and the LMM-as-a-judge approach. We conducted experiments evaluating nine prominent visual editing models, comprising both open-source and proprietary models. The evaluation results demonstrate that current models face significant challenges in reasoning-based editing tasks.  Even the most powerful model evaluated, GPT-image-1, achieves an accuracy of merely 28.8%. RISEBench effectively highlights the limitations of contemporary editing models, provides valuable insights,  and indicates potential future directions for the field of reasoning-aware visual editing. Our code and data have been released at https://github.com/PhoenixZ810/RISEBench.",,多伦多云,多伦多云: AI Agent,多伦多云: Session讨论RISEBench视觉编辑推理评测（时序/因果/空间/逻辑）与LMM-as-a-judge，可重点关注评测维度划分与裁判模型设计，迁移用于提升Agent评估覆盖度与可靠性。
WED 3 DEC,3:30-4:30,Oral Paper,  → CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding,https://neurips.cc/virtual/2025/oral/121509,,4:30 PM,"Coral reefs are vital yet vulnerable ecosystems that require continuous monitoring to support conservation. While coral reef images provide essential information in coral monitoring, interpreting such images remains challenging due to the need for domain expertise. Visual Question Answering (VQA), powered by Large Vision-Language Models (LVLMs), has great potential in user-friendly interaction with coral reef images. However, applying VQA to coral imagery demands a dedicated dataset that addresses two key challenges: domain-specific annotations and multidimensional questions. In this work, we introduce CoralVQA, the first large-scale VQA dataset for coral reef analysis. It contains 12,805 real-world coral images from 67 coral genera collected from 3 oceans, along with 277,653 question-answer pairs that comprehensively assess ecological and health-related conditions. To construct this dataset, we develop a semi-automatic data construction pipeline in collaboration with marine biologists to ensure both scalability and professional-grade data quality. CoralVQA presents novel challenges and provides a comprehensive benchmark for studying vision-language reasoning in the context of coral reef images. By evaluating several state-of-the-art LVLMs, we reveal key limitations and opportunities. These insights form a foundation for future LVLM development, with a particular emphasis on supporting coral conservation efforts.",,,,
WED 3 DEC,3:30-4:30,Oral Paper,  → OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model,https://neurips.cc/virtual/2025/oral/120304,,4:30 PM,"Understanding and synthesizing realistic 3D hand-object interactions (HOI) is critical for applications ranging from immersive AR/VR to dexterous robotics. Existing methods struggle with generalization, performing well on closed-set objects and predefined tasks but failing to handle unseen objects or open-vocabulary instructions. We introduce OpenHOI, the first framework for open-world HOI synthesis, capable of generating long-horizon manipulation sequences for novel objects guided by free-form language commands. Our approach integrates a 3D Multimodal Large Language Model (MLLM) fine-tuned for joint affordance grounding and semantic task decomposition, enabling precise localization of interaction regions (e.g., handles, buttons) and breakdown of complex instructions (e.g., “Find a water bottle and take a sip”) into executable sub-tasks. To synthesize physically plausible interactions, we propose an affordance-driven diffusion model paired with a training-free physics refinement stage that minimizes penetration and optimizes affordance alignment.Evaluations across diverse scenarios demonstrate OpenHOI’s superiority over state-of-the-art methods in generalizing to novel object categories, multi-stage tasks, and complex language instructions.",,温哥华云; CBG,温哥华云: Embodied AI; CBG: 3DAIGC,温哥华云: Session讨论3D-MLLM可供性定位与任务分解、扩散+物理约束生成，可重点关注开放词汇HOI在具身感知-规划-执行闭环的落地与评估。; CBG: Session讨论可供性驱动扩散与训练外物理优化生成长时手物体交互，可重点关注部件级语义与抓取点定位、交互一致性增强在视频-3D生成中的应用。
THU 4 DEC,8:30 a.m.,Invited Talk,The Art of (Artificial) Reasoning,https://neurips.cc/virtual/2025/invited-talk/109603,Yejin Choi,9:30 AM,"Scaling laws suggest that “more is more” — brute-force scaling of data and compute leads to stronger AI capabilities. However, despite rapid progress on benchmarks, state-of-the-art models still exhibit ""jagged intelligence,"" indicating that current scaling approaches may have limitations in terms of sustainability and robustness. Additionally, while the volume of papers on arXiv continues to grow rapidly, our scientific understanding of artificial intelligence hasn't kept pace with engineering advances, and the current literature presents seemingly contradictory findings that can be difficult to reconcile. In this talk, I will discuss key insights into the strengths and limitations of LLMs, examine when reinforcement learning succeeds or struggles in reasoning tasks, and explore methods for enhancing reasoning capabilities in smaller language models to help them close the gap against their larger counterparts in specific domains.",,诺亚; 温哥华云,诺亚: 大模型后训练Reasoning，RL; 温哥华云: Reinforcement fine tuning (RFT),诺亚: Session讨论强化学习在推理中的适用边界与小模型推理增强，可重点关注后训练Reasoning、自博弈与Latent Reasoning。; 温哥华云: Session讨论强化学习在推理任务成败条件与小模型推理增强，可重点关注RFT策略、样本效率与性能提升、可扩展性及从理论到生产落地。
THU 4 DEC,2:30 p.m.,Invited Talk,"On the Science of “Alien Intelligences”: Evaluating Cognitive Capabilities in Babies, Animals, and AI",https://neurips.cc/virtual/2025/invited-talk/109607,Melanie Mitchell,3:30 PM,"Today’s generative AI systems—termed by some researchers as “alien intelligences”—have exceeded human performance on many benchmarks meant to test humanlike cognitive capabilities.  However, these systems still struggle in unhumanlike ways on real-world tasks requiring these capabilities.  This disconnect may be due in part to neglect in the AI community of well-founded experimental protocols for evaluating cognition.  In this talk I will summarize several recommendations on experimental methods from developmental and comparative psychology—fields that study the “alien intelligences” of babies and non-human animals—and demonstrate the application of such methods in two case studies of cognitive abilities in LLMs: analogical reasoning and visual abstraction.",,诺亚; 温哥华云,诺亚: 大模型后训练Reasoning，RL; 温哥华云: Embodied AI,诺亚: Session讨论用发育/比较心理学评测LLM类比与视觉抽象，可重点关注将实验范式转化为推理基准、latent reasoning观测变量与奖励设计。; 温哥华云: Session讨论借鉴婴儿与动物实验评估AI认知能力，可重点关注迁移到具身场景，构建感知-推理-行动任务电池与通用能力量表。
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3A,https://neurips.cc/virtual/2025/session/122556,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Identifiability of Deep Polynomial Neural Networks,https://neurips.cc/virtual/2025/oral/118427,,11:00 AM,"Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability-a key property for ensuring interpretability-remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly compared to the activation degrees. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. We also settle an open conjecture on the dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach the expected dimension.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Depth-Bounds for Neural Networks via the Braid Arrangement,https://neurips.cc/virtual/2025/oral/117519,,11:00 AM,"We contribute towards resolving the open question of how many hidden layers are required in ReLU networks for exactly representing all continuous and piecewise linear functions on $\mathbb{R}^d$. While the question has been resolved in special cases, the best known lower bound in general is still 2. We focus on neural networks that are compatible with certain polyhedral complexes, more precisely with the braid fan.  For such neural networks, we prove a non-constant lower bound of $\Omega(\log\log d)$ hidden layers required to exactly represent the maximum of $d$ numbers. Additionally, we provide a combinatorial proof that neural networks satisfying this assumption require three hidden layers to compute the maximum of 5 numbers; this had only been verified with an excessive computation so far.Finally, we show that a natural generalization of the best known upper bound to maxout networks is not tight, by demonstrating that a rank-3 maxout layer followed by a rank-2 maxout layer is sufficient to represent the maximum of 7 numbers.",,nan,nan: ,nan: 
THU 4 DEC,10:00-11:00,Oral Paper,  → Learning Linear Attention in Polynomial Time,https://neurips.cc/virtual/2025/oral/118143,,11:00 AM,"Previous research has explored the expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the efficient learnability of Transformers from data has remained an open question.  Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention.  We show that learning the optimal multi head linear attention can be recast as finding the optimal kernel predictor in a suitably defined RKHS.  Moving to generalization, we construct an algorithm that, given a dataset, checks in polynomial time whether the set of best fit multi head linear attention networks on this data all perform an identical computation--a powerful notion for out of distribution generalization.  We empirically validate our theoretical findings on several canonical tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformer models.",,诺亚; 计算,诺亚: 大模型长序列，多模态长序列; 计算: 高效模型架构,诺亚: Session讨论线性注意力的PAC可学习性、RKHS核化与泛化一致性判定，可重点关注原生长序列架构选型及长序列下精度-计算权衡策略。; 计算: Session讨论多头线性注意力的可学习性与核化求解的理论保证，可重点关注其对高效模型架构走向、算力映射与算精定义的启示。
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3B,https://neurips.cc/virtual/2025/session/122557,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,  → ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts,https://neurips.cc/virtual/2025/oral/117276,,11:00 AM,"Current image fusion methods struggle with real-world composite degradations and lack the flexibility to accommodate user-specific needs. To address this, we propose ControlFusion, a controllable fusion network guided by language-vision prompts that adaptively mitigates composite degradations. On the one hand, we construct a degraded imaging model based on physical mechanisms, such as the Retinex theory and atmospheric scattering principle, to simulate composite degradations and provide a data foundation for addressing realistic degradations. On the other hand, we devise a prompt-modulated restoration and fusion network that dynamically enhances features according to degradation prompts, enabling adaptability to varying degradation levels. To support user-specific preferences in visual quality, a text encoder is incorporated to embed user-defined degradation types and levels as degradation prompts. Moreover, a spatial-frequency collaborative visual adapter is designed to autonomously perceive degradations from source images, thereby reducing complete reliance on user instructions. Extensive experiments demonstrate that ControlFusion outperforms SOTA fusion methods in fusion quality and degradation handling, particularly under real-world and compound degradations.",,CBG,CBG: 3DAIGC,CBG: Session讨论语言-视觉提示驱动的可控图像融合与复合退化恢复，可重点关注其在长视频生成一致性中的去雾/去噪增强、Retinex/散射物理建模与空频协同Adapter应用。
THU 4 DEC,10:00-11:00,Oral Paper,  → Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables,https://neurips.cc/virtual/2025/oral/118251,,11:00 AM,"Recently, deep learning-based pan-sharpening algorithms have achieved notable advancements over traditional methods. However, deep learning-based methods incur substantial computational overhead during inference, especially with large images. This excessive computational demand limits the applicability of these methods in real-world scenarios, particularly in the absence of dedicated computing devices such as GPUs and TPUs. To address these challenges, we propose Pan-LUT, a novel learnable look-up table (LUT) framework for pan-sharpening that strikes a balance between performance and computational efficiency for large remote sensing images. Our method makes it possible to process 15K$\times$15K remote sensing images on a 24GB GPU. To finely control the spectral transformation, we devise the PAN-guided look-up table (PGLUT) for channel-wise spectral mapping. To effectively capture fine-grained spatial details, we introduce the spatial details look-up table (SDLUT). Furthermore, to adaptively aggregate channel information for generating high-resolution multispectral images, we design an adaptive output look-up table (AOLUT). Our model contains fewer than 700K parameters and processes a 9K$\times$9K image in under 1 ms using one RTX 2080 Ti GPU, demonstrating significantly faster performance compared to other methods. Experiments reveal that Pan-LUT efficiently processes large remote sensing images in a lightweight manner, bridging the gap to real-world applications. Furthermore, our model surpasses SOTA methods in full-resolution scenes under real-world conditions, highlighting its effectiveness and efficiency.",,计算,计算: 训推新范式,计算: Session讨论可学习LUT推理范式（PGLUT/SDLUT/AOLUT）在超大图像上的高效实践，可重点关注表驱动推理的负载画像、存算权衡与缓存友好索引。
THU 4 DEC,10:00-11:00,Oral Paper,  → FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution,https://neurips.cc/virtual/2025/oral/117604,,11:00 AM,"Accurate, high-resolution ocean forecasting is crucial for maritime operations and environmental monitoring. While traditional numerical models are capable of producing sub-daily, eddy-resolving forecasts, they are computationally intensive and face challenges in maintaining accuracy at fine spatial and temporal scales. In contrast, recent data-driven approaches offer improved computational efficiency and emerging potential, yet typically operate at daily resolution and struggle with sub-daily predictions due to error accumulation over time.We introduce FuXi-Ocean, the first data-driven global ocean forecasting model achieving six-hourly predictions at eddy-resolving 1/12° spatial resolution, reaching depths of up to 1500 meters. The model architecture integrates a context-aware feature extraction module with a predictive network employing stacked attention blocks. The core innovation is the Mixture-of-Time (MoT) module, which adaptively integrates predictions from multiple temporal contexts by learning variable-specific reliability, mitigating cumulative errors in sequential forecasting. Through comprehensive experimental evaluation, FuXi-Ocean demonstrates superior skill in predicting key variables, including temperature, salinity, and currents, across multiple depths.",,计算,计算: 高效模型架构,计算: Session讨论MoT时序集成与堆叠注意力的高分辨率时空预测架构，可重点关注滚动推理下注意力/混合模块的算力与内存需求。
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3C,https://neurips.cc/virtual/2025/session/122558,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Auto-Compressing Networks,https://neurips.cc/virtual/2025/oral/116934,,11:00 AM,"Deep neural networks with short residual connections have demonstrated remarkable success across domains, but increasing depth often introduces computational redundancy without corresponding improvements in representation quality. We introduce Auto-Compressing Networks (ACNs), an architectural variant where additive long feedforward connections from each layer to the output replace traditional short residual connections. By analyzing the distinct dynamics induced by this modification, we reveal a unique property we coin asauto-compression—the ability of a network to organically compress information during training with gradient descent, through architectural design alone. Through auto-compression, information is dynamically ""pushed"" into early layers during training, enhancing their representational quality and revealing potential redundancy in deeper ones. We theoretically show that this property emerges from layer-wise training patterns found only in ACNs, where layers are dynamically utilized during training based on task requirements. We also find that ACNs exhibit enhanced noise robustness compared to residual networks, superior performance in low-data settings, improved transfer learning capabilities, and  mitigate catastrophic forgetting suggesting that they learn representations that generalize better despite using fewer parameters. Our results demonstrate up to 18\% reduction in catastrophic forgetting and 30-80\% architectural compression while maintaining accuracy across vision transformers, MLP-mixers, and BERT architectures. These findings establish ACNs as a practical approach to developing efficient neural architectures that automatically adapt their computational footprint to task complexity, while learning robust representations suitable for noisy real-world tasks and continual learning scenarios.",,计算,计算: 高效模型架构,计算: Session讨论ACN以长程加法连接替代短残差并引发自压缩训练动态，可重点关注其对算子图拓扑、层动态利用与弹性深度/早层重用的硬件映射与调度策略。
THU 4 DEC,10:00-11:00,Oral Paper,  → Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks,https://neurips.cc/virtual/2025/oral/119732,,11:00 AM,"Deployment of neural networks on resource-constrained devices demands models that are both compact and robust to adversarial inputs. However, compression and adversarial robustness often conflict. In this work, we introduce a dynamical low-rank training scheme enhanced with a novel spectral regularizer that controls the condition number of the low-rank core in each layer. This approach mitigates the sensitivity of compressed models to adversarial perturbations without sacrificing clean accuracy. The method is model- and data-agnostic, computationally efficient, and supports rank adaptivity to automatically compress the network at hand. Extensive experiments across standard architectures, datasets, and adversarial attacks show the regularized networks can achieve over 94 compression while recovering or improving adversarial accuracy relative to uncompressed baselines.",,计算,计算: 训推新范式,计算: Session讨论动态低秩训练与谱正则协同提升压缩模型鲁棒性与精度，可重点关注秩自适应带来的负载形态变化与正则开销对训推吞吐影响。
THU 4 DEC,10:00-11:00,Oral Paper,  → ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression,https://neurips.cc/virtual/2025/oral/116595,,11:00 AM,"The hypothesis that Convolutional Neural Networks (CNNs) are inherently texture-biased has shaped much of the discourse on feature use in deep learning. We revisit this hypothesis by examining limitations in the cue-conflict experiment by Geirhos et al. To address these limitations, we propose a domain-agnostic framework that quantifies feature reliance through systematic suppression of shape, texture, and color cues, avoiding the confounds of forced-choice conflicts. By evaluating humans and neural networks under controlled suppression conditions, we find that CNNs are not inherently texture-biased but predominantly rely on local shape features. Nonetheless, this reliance can be substantially mitigated through modern training strategies or architectures (ConvNeXt, ViTs). We further extend the analysis across computer vision, medical imaging, and remote sensing, revealing that reliance patterns differ systematically: computer vision models prioritize shape, medical imaging models emphasize color, and remote sensing models exhibit a stronger reliance on texture. Code is available at https://github.com/tomburgert/feature-reliance.",,,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3D,https://neurips.cc/virtual/2025/session/122559,,11:00 AM,,,,,
THU 4 DEC,10:00-11:00,Oral Paper,  → State Entropy Regularization for Robust Reinforcement Learning,https://neurips.cc/virtual/2025/oral/115740,,11:00 AM,"State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.",,诺亚; 温哥华云,诺亚: 大模型后训练Reasoning，RL; 温哥华云: Embodied AI,诺亚: Session讨论状态熵正则提升RL对结构化扰动的鲁棒性与理论保证，可重点关注融入自博弈/经验学习训练，优化迁移与有限rollout评估。; 温哥华云: Session讨论状态熵相较策略熵在转移鲁棒性上的优势与局限，可重点关注具身任务对空间相关扰动的适配与有限rollout评估策略。
THU 4 DEC,10:00-11:00,Oral Paper,  → A Clean Slate for Offline Reinforcement Learning,https://neurips.cc/virtual/2025/oral/119623,,11:00 AM,"Progress in offline reinforcement learning (RL) has been impeded by ambiguous problem definitions and entangled algorithmic designs, resulting in inconsistent implementations, insufficient ablations, and unfair evaluations. Although offline RL explicitly avoids environment interaction, prior methods frequently employ extensive, undocumented online evaluation for hyperparameter tuning, complicating method comparisons. Moreover, existing reference implementations differ significantly in boilerplate code, obscuring their core algorithmic contributions. We address these challenges by first introducing a rigorous taxonomy and a transparent evaluation protocol that explicitly quantifies online tuning budgets. To resolve opaque algorithmic design, we provide clean, minimalistic, single-file implementations of various model-free and model-based offline RL methods, significantly enhancing clarity and achieving substantial speed-ups. Leveraging these streamlined implementations, we propose Unifloral, a unified algorithm that encapsulates diverse prior approaches and enables development within a single, comprehensive hyperparameter space. Using Unifloral with our rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR (model-free) and MoBRAC (model-based) - which substantially outperform established baselines. Our implementation is publicly available at https://github.com/EmptyJackson/unifloral.",,,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies,https://neurips.cc/virtual/2025/oral/117976,,11:00 AM,"Reinforcement learning (RL) systems have countless applications, from energy-grid management to protein design. However, such real-world scenarios are often extremely difficult, combinatorial in nature, and require complex coordination between multiple agents. This level of complexity can cause even state-of-the-art RL systems, trained until convergence, to hit a performance ceiling which they are unable to break out of with zero-shot inference. Meanwhile, many digital or simulation-based applications allow for an inference phase that utilises a specific time and compute budget to explore multiple attempts before outputting a final solution. In this work, we show that such an inference phase employed at execution time, and the choice of a corresponding inference strategy, are key to breaking the performance ceiling observed in complex multi-agent RL problems. Our main result is striking: we can obtain up to a 126% and, on average, a 45% improvement over the previous state-of-the-art across 17 tasks, using only a couple seconds of extra wall-clock time during execution. We also demonstrate promising compute scaling properties, supported by over 60k experiments, making it the largest study on inference strategies for complex RL to date. We make all of our experimental data and code available.",,诺亚,诺亚: 大模型长序列，多模态长序列,诺亚: Session讨论多智能体RL的测试时推理/搜索策略。可重点关注best-of-N与MCTS在执行期计算预算调度及记忆更新机制中的结合。
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3E,https://neurips.cc/virtual/2025/session/122560,,11:00 AM,,,,,THU 4 DEC,10:00-11:00,Oral Paper,"  → Position: If Innovation in AI systematically Violates Fundamental Rights, Is It Innovation at All?",https://neurips.cc/virtual/2025/oral/126305,,11:00 AM,"Artificial intelligence (AI) now permeates critical infrastructures and decisionmaking systems where failures produce social, economic, and democratic harm. This position paper challenges the entrenched belief that regulation and innovation are opposites. As evidenced by analogies from aviation, pharmaceuticals, and welfare systems and recent cases of synthetic misinformation, bias and unaccountable decision-making, the absence of well-designed regulation has already created immeasurable damage. Regulation, when thoughtful and adaptive, is not a brake on innovation—it is its foundation. The present position paper examines the EU AI Act as a model of risk-based, responsibility-driven regulation that addresses the Collingridge Dilemma: acting early enough to prevent harm, yet flexibly enough to sustain innovation. Its adaptive mechanisms—regulatory sandboxes, small and medium enterprises (SMEs) support, real-world testing, fundamental rights impact assessment (FRIA)—demonstrate how regulation can accelerate responsibly, rather than delay, technological progress. The position paper summarises how governance tools transform perceived burdens into tangible advantages: legal certainty, consumer trust, and ethical competitiveness. Ultimately, the paper reframes progress: innovation and regulation advance together. By embedding transparency, impact assessments, accountability, and AI literacy into design and deployment, the EU framework defines what responsible innovation truly means—technological ambition disciplined by democratic values and fundamental rights.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session讨论EU AI Act风险分级、监管沙箱与FRIA等治理机制，可重点关注其在Embodied AI落地中的合规模型、真实场景测试流程与可解释与透明度设计。
THU 4 DEC,10:00-11:00,Oral Paper,  → More effort is needed to protect pedestrian privacy in the era of AI,https://neurips.cc/virtual/2025/oral/126301,,11:00 AM,"In the era of artificial intelligence (AI), pedestrian privacy is increasingly at risk. In research areas such as autonomous driving, computer vision, and surveillance, large datasets are often collected in public spaces, capturing pedestrians without consent or anonymization. These datasets are used to train systems that can identify, track, and analyze individuals, often without their knowledge. Although various technical methods and regional regulations have been proposed to address this issue, existing solutions are either insufficient to protect privacy or compromise data utility, thereby limiting their effectiveness for research. In this paper, we argue that more effort is needed to protect pedestrian privacy in the era of AI while maintaining data utility. We call on the AI and computer vision communities to take pedestrian privacy seriously and to rethink how pedestrian data are collected and anonymized. Collaboration with experts in law and ethics will also be essential for the responsible development of AI. Without stronger action, it will become increasingly difficult for individuals to protect their privacy, and public trust in AI may decline.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session讨论行人数据采集匿名化与隐私-效用权衡，可重点关注具身系统中的去识别化管线、合成数据替代与差分隐私策略。
THU 4 DEC,10:00-11:00,Oral Paper,"  → Real-Time Hyper-Personalized Generative AI Should Be Regulated to Prevent the Rise of ""Digital Heroin""",https://neurips.cc/virtual/2025/oral/126308,,11:00 AM,"This position paper argues that real-time generative AI has the potential to become the next wave of addictive digital media, creating a new class of digital content akin to ``digital heroin'' with severe implications for mental health and youth development. By shortening the content-generation feedback loop to mere seconds, these advanced models will soon be able to hyper-personalize outputs on the fly. When paired with misaligned incentives (e.g., maximizing user engagement), this will fuel unprecedented compulsive consumption patterns with far-reaching consequences for mental health, cognitive development, and social stability. Drawing on interdisciplinary research, from clinical observations of social media addiction to neuroscientific studies of dopamine-driven feedback, we illustrate how real-time tailored content generation may erode user autonomy, foment emotional distress, and disproportionately endanger vulnerable groups, such as adolescents. Due to the rapid advancement of generative AI and its potential to induce severe addiction-like effects, we call for strong government oversight akin to existing controls on addictive substances, particularly for minors. We further urge the machine learning community to act proactively by establishing robust design guidelines, collaborating with public health experts, and supporting targeted policy measures to ensure responsible and ethical deployment, rather than paving the way for another wave of unregulated digital dependence.",,计算,计算: 训推新范式,计算: Session讨论实时超个性化与秒级反馈闭环带来的成瘾风险，可重点关注在线RLHF与评估指标、节流与速率限制机制对训推范式及SLA的影响。
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4A,https://neurips.cc/virtual/2025/session/122561,,4:30 PM,,,,,
THU 4 DEC,3:30-4:30,Oral Paper,  → A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders,https://neurips.cc/virtual/2025/oral/118059,,4:30 PM,"Sparse Autoencoders (SAEs) aim to decompose the activation space of large language models (LLMs) into human-interpretable latent directions or features. As we increase the number of features in the SAE, hierarchical features tend to split into finer features (“math” may split into “algebra”, “geometry”, etc.), a phenomenon referred to as feature splitting. However, we show that sparse decomposition and splitting of hierarchical features is not robust. Specifically, we show that seemingly monosemantic features fail to fire where they should, and instead get “absorbed” into their children features. We coin this phenomenon feature absorption, and show that it is caused by optimizing for sparsity in SAEs whenever the underlying features form a hierarchy. We introduce a metric to detect absorption in SAEs, and validate our findings empirically on hundreds of LLM SAEs. Our investigation suggests that varying SAE sizes or sparsity is insufficient to solve this issue. We discuss the implications of feature absorption in SAEs and some potential approaches to solve the fundamental theoretical issues before SAEs can be used for interpreting LLMs robustly and at scale.",,,,
THU 4 DEC,3:30-4:30,Oral Paper,"  → Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free",https://neurips.cc/virtual/2025/oral/120217,,4:30 PM,"Gating mechanisms have been widely utilized, from early models like LSTMs and Highway Networks to recent state space models, linear attention, and also softmax attention.Yet, existing literature rarely examines the specific effects of gating.In this work, we conduct comprehensive experiments to systematically investigate gating-augmented softmax attention variants.Specifically, we perform a comprehensive comparison over 30 variants of 15B Mixture-of-Experts (MoE) models and 1.7B dense models trained on a 3.5 trillion token dataset.Our central finding is that a simple modification—applying a head-specific sigmoid gate after the Scaled Dot-Product Attention (SDPA)—consistently improves performance.This modification also enhances training stability, tolerates larger learning rates, and improves scaling properties.By comparing various gating positions and computational variants, we attribute this effectiveness to two key factors: (1) introducing non-linearity upon the low-rank mapping in the softmax attention, and (2) applying query-dependent sparse gating scores to modulate the SDPA output.Notably, we find this sparse gating mechanism mitigatesmassive activation,attention sinkand enhances long-context extrapolation performance. We also release related codes (https://github.com/qiuzh20/gatedattention}) and models (https://huggingface.co/QwQZh/gatedattention) to facilitate future research.Furthermore, the most effective SDPA output gating is used in the Qwen3-Next models (https://huggingface.co/collections/Qwen/qwen3-next).",,诺亚; 海思; 计算,诺亚: 大模型长序列，多模态长序列; 海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构,诺亚: Session讨论对SDPA输出施加按头sigmoid门控引入非线性与稀疏化，可重点关注长上下文外推、attention sink缓解与测试时记忆/缓存策略结合。; 海思: Session讨论SDPA输出的按头sigmoid稀疏门控并提升长上下文表现，可重点关注缓解attention sink、头/序列稀疏化与KV缓存裁剪以降延。; 计算: Session讨论SDPA后按头sigmoid门控带来非线性与稀疏化并稳训，可重点关注注意力架构演进、算子映射与低精度训推稳定性的影响。
THU 4 DEC,3:30-4:30,Oral Paper,  → Superposition Yields Robust Neural Scaling,https://neurips.cc/virtual/2025/oral/116347,,4:30 PM,"The success of today's large language models (LLMs) depends on the observation that larger models perform better. However, the origin of this neural scaling law, that loss decreases as a power law with model size, remains unclear. We propose that representation superposition, meaning that LLMs represent more features than they have dimensions, can be a key contributor to loss and cause neural scaling. Based on Anthropic's toy model, we use weight decay to control the degree of superposition, allowing us to systematically study how loss scales with model size. When superposition is weak, the loss follows a power law only if data feature frequencies are power-law distributed. In contrast, under strong superposition, the loss generically scales inversely with model dimension across a broad class of frequency distributions, due to geometric overlaps between representation vectors. We confirmed that open-sourced LLMs operate in the strong superposition regime and have loss scaling inversely with model dimension, and that the Chinchilla scaling laws are also consistent with this behavior. Our results identify representation superposition as a central driver of neural scaling laws, providing insights into questions like when neural scaling laws can be improved and when they will break down.",,计算,计算: 高效模型架构,计算: Session讨论[表示叠加驱动的神经缩放规律与权重衰减调控]，可重点关注[模型维度-损失逆比关系、Chinchilla法则修正与训练正则化策略]
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4B,https://neurips.cc/virtual/2025/session/122562,,4:30 PM,,,,,
THU 4 DEC,3:30-4:30,Oral Paper,  → In Search of Adam’s Secret Sauce,https://neurips.cc/virtual/2025/oral/119298,,4:30 PM,"Understanding the remarkable efficacy of Adam when training transformer-based language models has become a central research topic within the optimization community. To gain deeper insights, several simplifications of Adam have been proposed, such as the signed gradient and signed momentum methods. In this work, we conduct an extensive empirical study — training over 1,500 language models across different data configurations and scales — comparing Adam to several known simplified variants. We find that signed momentum methods are faster than SGD, but consistently underperform relative to Adam, even after careful tuning of momentum, clipping setting and learning rates. However, our analysis reveals a compelling option that preserves near-optimal performance while allowing for new insightful reformulations: constraining the Adam momentum parameters to be equal, β 1 = β 2 . Beyond robust performance, this choice affords new theoretical insights, highlights the ""secret sauce"" on top of signed momentum, and grants a precise statistical interpretation: we show that Adam in this setting implements a natural online algorithm for estimating the mean and variance of gradients—one that arises from a mean-field Gaussian variational inference perspective.",,计算; 温哥华云,计算: 训推新范式; 温哥华云: Reinforcement fine tuning (RFT),计算: Session讨论Adam在LLM训练中的机制、签名动量对比与β1=β2简化，可重点关注其对训练范式负载画像、默认超参稳健性与优化器演进趋势的影响。; 温哥华云: Session讨论Adam“均β”配置与在线均值方差估计在Transformer训练中的作用，可重点关注RFT中优化器选择、默认超参设定与收敛稳健性迁移实践，以提升样本效率。
THU 4 DEC,3:30-4:30,Oral Paper,  → Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions,https://neurips.cc/virtual/2025/oral/117576,,4:30 PM,"As the economic and environmental costs of training and deploying large vision or language models increase dramatically, analog in-memory computing (AIMC) emerges as a promising energy-efficient solution. However, the training perspective, especially its training dynamic, is underexplored. In AIMC hardware, the trainable weights are represented by the conductance of resistive elements and updated using consecutive electrical pulses.  While the conductance changes by a constant in response to each pulse, in reality, the change is scaled by asymmetric and non-linear response functions, leading to a non-ideal training dynamic. This paper provides a theoretical foundation for gradient-based training on AIMC hardware with non-ideal response functions.  We demonstrate that asymmetric response functions negatively impact Analog SGD by imposing an implicit penalty on the objective. To overcome the issue, we propose residual learning algorithm, which provably converges exactly to a critical point by solving a bilevel optimization problem. We show that the proposed method can be extended to deal with other hardware imperfections like limited response granularity. As far as we know, it is the first paper to investigate the impact of a class of generic non-ideal response functions. The conclusion is supported by simulations validating our theoretical insights.",,计算,计算: 高效模型架构,计算: Session讨论AIMC非理想响应对Analog SGD的影响与残差学习双层优化，可重点关注低精硬件训练收敛建模与精度规格定义。
THU 4 DEC,3:30-4:30,Oral Paper,"  → Generalized Gradient Norm Clipping & Non-Euclidean(L0,L1)-Smoothness",https://neurips.cc/virtual/2025/oral/115789,,4:30 PM,"This work introduces a hybrid non-Euclidean optimization method which generalizes gradient norm clipping by combining steepest descent and conditional gradient approaches. The method achieves the best of both worlds by establishing a descent property under a generalized notion of ($L_0$,$L_1$)-smoothness. Weight decay is incorporated in a principled manner by identifying a connection to the Frank-Wolfe short step. In the stochastic case, we show an order optimal $O(n^{-1/4})$ convergence rate by leveraging a momentum based gradient estimator. We discuss how to instantiate the algorithms for deep learning, which we dub Clipped Scion, and demonstrate their properties on image classification and language modeling. The code is available at https://github.com/LIONS-EPFL/ClippedScion.",,计算,计算: 训推新范式,计算: Session讨论广义梯度裁剪与L0/L1非欧平滑下的陡降-Frank-Wolfe混合优化，可重点关注其在优化器与权重衰减设计上提升训练稳定性的应用。
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4C,https://neurips.cc/virtual/2025/session/122563,,4:30 PM,,,,,
THU 4 DEC,3:30-4:30,Oral Paper,  → MaxSup: Overcoming Representation Collapse in Label Smoothing,https://neurips.cc/virtual/2025/oral/116897,,4:30 PM,"Label Smoothing (LS) is widely adopted to reduce overconfidence in neural network predictions and improve generalization. Despite these benefits, recent studies reveal two critical issues with LS. First, LS induces overconfidence in misclassified samples. Second, it compacts feature representations into overly tight clusters, diluting intra-class diversity, although the precise cause of this phenomenon remained elusive. In this paper, we analytically decompose the LS-induced loss, exposing two key terms: (i) a regularization term that dampens overconfidence only when the prediction is correct, and (ii) an error-amplification term that arises under misclassifications. This latter term compels the network to reinforce incorrect predictions with undue certainty, exacerbating representation collapse. To address these shortcomings, we propose Max Suppression (MaxSup), which applies uniform regularization to both correct and incorrect predictions by penalizing the top-1 logit rather than the ground-truth logit. Through extensive feature-space analyses, we show that MaxSup restores intra-class variation and sharpens inter-class boundaries. Experiments on large-scale image classification and multiple downstream tasks confirm that MaxSup is a more robust alternative to LS.Code and reproducibility scripts are available at https://github.com/ZhouYuxuanYX/Maximum-Suppression-Regularization.",,,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Advancing Expert Specialization for Better MoE,https://neurips.cc/virtual/2025/oral/116507,,4:30 PM,"Mixture-of-Experts (MoE) models enable efficient scaling of large language models (LLMs) by activating only a subset of experts per input. However, we observe that the commonly used auxiliary load balancing loss often leads to expert overlap and overly uniform routing, which hinders expert specialization and degrades overall performance during post-training.To address this, we propose a simple yet effective solution that introduces two complementary objectives: (1) an orthogonality loss to encourage experts to process distinct types of tokens, and (2) a variance loss to encourage more discriminative routing decisions.Gradient-level analysis demonstrates that these objectives are compatible with the existing auxiliary loss and contribute to optimizing the training process.Experimental results over various model architectures and across multiple benchmarks show that our method significantly enhances expert specialization. Notably, our method improves classic MoE baselines with auxiliary loss by up to 23.79\%, while also maintaining load balancing in downstream tasks, without any architectural modifications or additional components. We will release our code to contribute to the community.",,计算; DCN,计算: 高效模型架构; DCN: Network4AI 与 AI4Network,计算: Session讨论MoE专家专精的正交/方差损失与路由机制，可重点关注其对All-to-All通信、负载均衡与系统算子需求的影响。; DCN: Session讨论MoE路由方差与专家正交化以维持均衡，可重点关注对All-to-All流量倾斜、拥塞控制与拓扑映射的影响。
THU 4 DEC,3:30-4:30,Oral Paper,  → Learning to Learn with Contrastive Meta-Objective,https://neurips.cc/virtual/2025/oral/115718,,4:30 PM,"Meta-learning enables learning systems to adapt quickly to new tasks, similar to humans.Different meta-learning approaches all work under/with the mini-batch episodic training framework. Such framework naturally gives the information about task identity, which can serve as additional supervision for meta-training to improve generalizability. We propose to exploit task identity as additional supervision in meta-training, inspired by the alignment and discrimination ability which is is intrinsic in human's fast learning.This is achieved by contrasting what meta-learners learn, i.e., model representations.The proposed ConML is evaluating and optimizing the contrastive meta-objective under a problem- and learner-agnostic meta-training framework.We demonstrate that ConML integrates seamlessly with existing meta-learners, as well as in-context learning models, and brings significant boost in performance with small implementation cost.",,计算; 温哥华云; 诺亚,计算: 训推新范式; 温哥华云: Embodied AI; 诺亚: 大模型后训练Reasoning，RL,计算: Session讨论利用任务身份监督的对比式meta目标（ConML）与ICL整合，可重点关注其对训推范式演进、负载特征与算子需求的影响。; 温哥华云: Session讨论基于任务身份监督的对比式元目标与表示对齐，可重点关注其在具身任务快速适配、跨任务迁移与少样本策略学习中的应用。; 诺亚: Session讨论对比式元目标提升表示判别与ICL适配能力，可重点关注其与自博弈、经验学习结合的后训练流程，强化潜在推理泛化。
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4D,https://neurips.cc/virtual/2025/session/122564,,4:30 PM,,,,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Exploring Diffusion Transformer Designs via Grafting,https://neurips.cc/virtual/2025/oral/119280,,4:30 PM,"Designing model architectures requires decisions such as selecting operators (e.g., attention, convolution) and configurations (e.g., depth, width). However, evaluating the impact of these decisions on model quality requires costly pretraining, limiting architectural investigation.Inspired by how new software is built on existing code, we ask: can new architecture designs be studied using pretrained models? To this end, we present *grafting*, a simple approach for editing pretrained diffusion transformers (DiTs) to materialize new architectures under small compute budgets. Informed by our analysis of activation behavior and attention locality, we construct a testbed based on the DiT-XL/2 design to study the impact of grafting on model quality. Using this testbed, we develop a family of hybrid designs via grafting: replacing softmax attention with gated convolution, local attention, and linear attention, and replacing MLPs with variable expansion ratio and convolutional variants. Notably, many hybrid designs achieve good quality (FID: 2.38–2.64 vs. 2.27 for DiT-XL/2)using < 2 % pretraining compute. We then graft a text-to-image model (PixArt- Σ ), achieving a 1.43 × speedup with less than a 2% drop in GenEval score. Finally, we present a case study that restructures DiT-XL/2 by converting every pair of sequential transformer blocks into parallel blocks via grafting. This reduces model depth by 2 × and yields better quality (FID: 2.77) than other models of comparable depth. Together, we show that new diffusion model designs can be explored by grafting pretrained DiTs, with edits ranging from operator replacement to architecture restructuring. Code and grafted models: https://grafting.stanford.edu.",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构,海思: Session讨论[用grafting在预训练DiT上进行算子替换与并行重构提速]，可重点关注[线性/局部注意力与门控卷积对复杂度与延迟的影响]; 计算: Session讨论[基于grafting的DiT架构探索：算子替换与深度并行化]，可重点关注[软注意力向线性/局部注意力与卷积混合演进对算力/带宽的影响]
THU 4 DEC,3:30-4:30,Oral Paper,  → Deep Compositional Phase Diffusion for Long Motion Sequence Generation,https://neurips.cc/virtual/2025/oral/116419,,4:30 PM,"Recent research on motion generation has shown significant progress in generating semantically aligned motion with singular semantics. However, when employing these models to create composite sequences containing multiple semantically generated motion clips, they often struggle to preserve the continuity of motion dynamics at the transition boundaries between clips, resulting in awkward transitions and abrupt artifacts. To address these challenges, we present Compositional Phase Diffusion, which leverages the Semantic Phase Diffusion Module (SPDM) and Transitional Phase Diffusion Module (TPDM) to progressively incorporate semantic guidance and phase details from adjacent motion clips into the diffusion process. Specifically, SPDM and TPDM operate within the latent motion frequency domain established by the pre-trained Action-Centric Motion Phase Autoencoder (ACT-PAE). This allows them to learn semantically important and transition-aware phase information from variable-length motion clips during training. Experimental results demonstrate the competitive performance of our proposed framework in generating compositional motion sequences that align semantically with the input conditions, while preserving phase transitional continuity between preceding and succeeding motion clips. Additionally, motion inbetweening task is made possible by keeping the phase parameter of the input motion sequences fixed throughout the diffusion process, showcasing the potential for extending the proposed framework to accommodate various application scenarios. Codes are available athttps://github.com/asdryau/TransPhase.",,CBG; 温哥华云,CBG: 3DAIGC; 温哥华云: Embodied AI,CBG: Session讨论基于ACT-PAE频域的相位扩散（SPDM/TPDM）以保持跨片段连续性，可重点关注长视频一致性与动作补间的相位约束与过渡条件融合。; 温哥华云: Session讨论可组合相位扩散与频域表征提升长序列动作连贯性，可重点关注具身体态生成中的技能拼接、过渡规划与动作补间策略。
THU 4 DEC,3:30-4:30,Oral Paper,  → Mean Flows for One-step Generative Modeling,https://neurips.cc/virtual/2025/oral/115488,,4:30 PM,"We propose a principled and effective framework for one-step generative modeling. We introduce the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods. A well-defined identity between average and instantaneous velocities is derived and used to guide neural network training. Our method, termed the \textit{MeanFlow} model, is self-contained and requires no pre-training, distillation, or curriculum learning. MeanFlow demonstrates strong empirical performance: it achieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet 256 × 256 trained from scratch, significantly outperforming previous state-of-the-art one-step diffusion/flow models. Our study substantially narrows the gap between one-step diffusion/flow models and their multi-step predecessors, and we hope it will motivate future research to revisit the foundations of these powerful models.",,计算; 海思,计算: 高效模型架构; 海思: 大语言模型和扩散模型的加速,计算: Session讨论MeanFlow一步生成与平均速度恒等式，可重点关注其对算子形态、算存比与低精度训推映射（MXFP/NVFP）的适配。; 海思: Session讨论MeanFlow一步生成与平均-瞬时速度恒等式，可重点关注1-NFE延迟/功耗收益与算子特性，评估多模态条件接口适配。
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4E Position Paper Track Panels,https://neurips.cc/virtual/2025/session/122565,,4:30 PM,,,,,
FRI 5 DEC,8:30 a.m.,Invited Talk,From Benchmarks to Problems - A Perspective on Problem Finding in AI,https://neurips.cc/virtual/2025/invited-talk/109605,Kyunghyun Cho,9:30 AM,"During the past 15 years or so, I have worked on a series of seemingly distinct but eventually related problems, including machine learning algorithms, generative modeling with neural networks, machine translation, language modeling, medical imaging, a bit of healthcare, protein modeling and a bit of drug discovery. I chose to work on some of these problems intentionally, while it was pure serendipity that I worked on some others. It was only in hindsight that these seemingly different problems turned out to be closely related to each other from both technical, social and personal perspectives. In this talk, I plan to do my own retrospective on my own choices, be them intentional or not, on these problems and share with you my thoughts what our own discipline, which is sometimes called computer science, data science, machine learning or artificial intelligence, is.",,计算,计算: 高效模型架构,计算: Session讨论从基准到真实问题的发现方法与跨领域演进规律，可重点关注用于预判大模型架构演进、识别精度算力权衡的方法论。
FRI 5 DEC,2:30 p.m.,Invited Talk,Demystifying depth: Principles of learning in deep neural networks,https://neurips.cc/virtual/2025/invited-talk/109602,Andrew Saxe,3:30 PM,"Deep neural networks have revolutionized artificial intelligence, yet their inner workings remain poorly understood. This talk presents mathematical analyses of the nonlinear dynamics of learning in several solvable deep network models, offering theoretical insights into the role of depth. These models reveal how learning algorithms, data structure, initialization schemes, and architectural choices interact to produce hidden representations that afford complex generalization behaviors. A recurring theme across these analyses is a neural race: competing pathways within a deep network vie to explain the data, with an implicit bias toward shared representations. These shared representations in turn shape the network’s capacity for systematic generalization, multitasking, and transfer learning. I will show how such principles manifest across diverse architectures—including feedforward, recurrent, and linear attention networks. Together, these results provide analytic foundations for understanding how environmental statistics, network architecture, and learning dynamics jointly structure the emergence of neural representations and behavior.",,计算; 诺亚,计算: 高效模型架构; 诺亚: 大模型长序列，多模态长序列,计算: Session讨论深层网络学习动力学、隐式偏置、共享表示与线性注意力，可重点关注架构深度与初始化对泛化和算力需求的影响、线性注意力的演进趋势。; 诺亚: Session讨论线性注意力与循环网络中的学习动力学和共享表示，可重点关注长序列下线性注意力的表征形成机制及其对系统化泛化、迁移与多任务表现的影响。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5A,https://neurips.cc/virtual/2025/session/122566,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → EvoLM: In Search of Lost Language Model Training Dynamics,https://neurips.cc/virtual/2025/oral/119409,,11:00 AM,"Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage.We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",,温哥华云; 诺亚; 计算,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL; 计算: 训推新范式,温哥华云: Session讨论持续预训练与后训练衔接、SFT与RL权衡及遗忘缓解，可重点关注RFT超参与奖励设计、采样效率优化与可复现实验流水线落地。; 诺亚: Session讨论SFT与RL在推理能力上的权衡及持续预训练的桥接作用，可重点关注RLHF/RFT配置、遗忘抑制与跨域泛化评测，支撑自博弈与经验学习框架设计。; 计算: Session讨论预训练、持续预训练、SFT与RL的训练动态与收益边界，可重点关注阶段化负载特征、性价比拐点与管线配置准则，用于预测训推范式演进。
FRI 5 DEC,10:00-11:00,Oral Paper,  → Large Language Diffusion Models,https://neurips.cc/virtual/2025/oral/118609,,11:00 AM,"The capabilities of large language models (LLMs) are widely regarded as relying on autoregressive models (ARMs). We challenge this notion by introducingLLaDA, a diffusion model trained from scratch under the pre-training and supervised fine-tuning (SFT) paradigm. LLaDA employs a forward data masking process and a reverse generation process, parameterized by a Transformer to predict masked tokens. It provides a principled generative approach for probabilistic inference by optimizing a likelihood lower bound. Across extensive benchmarks on general tasks, math, code, and so on, LLaDA demonstrates strongscalabilityand performs comparably to our self-constructed ARM baselines. Remarkably, LLaDA 8B is competitive with strong LLMs like LLaMA3 8B inin-context learningand, after SFT, exhibits impressiveinstruction-followingabilities in case studies such as multi-turn dialogue. Moreover, LLaDA addresses the reversal curse, surpassing GPT-4o in a reversal poem completion task. Our findings show the promise of diffusion models for language modeling at scale and challenge the common assumption that core LLM capabilities discussed above inherently depend on ARMs. Project page and codes: \url{https://ml-gsai.github.io/LLaDA-demo/}.",,计算; 海思,计算: 训推新范式; 海思: 大语言模型和扩散模型的加速,计算: Session讨论基于扩散的语言生成（前向掩码/反向去噪、似然下界优化），可重点关注对训推负载特征、解码并行性与延迟权衡的影响。; 海思: Session讨论LLaDA等扩散式LLM的前向掩码与多步反向生成，可重点关注推理并行化、步数—质量折中与算子/缓存复用优化以实现低延迟加速。
FRI 5 DEC,10:00-11:00,Oral Paper,  → Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?,https://neurips.cc/virtual/2025/oral/119945,,11:00 AM,"Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly in mathematics and programming tasks. It is widely believed that, similar to how traditional RL helps agents to explore and learn new strategies, RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed the capacity of the corresponding base models. In this study, we take a critical look at \textit{the current state of RLVR} by systematically probing the reasoning capability boundaries of RLVR-trained LLMs across diverse model families, RL algorithms, and math/coding/visual reasoning benchmarks, using pass@\textit{k} at large \textit{k} values as the evaluation metric.While RLVR improves sampling efficiency towards the correct path, we surprisingly find that current training does \emph{not} elicit fundamentally new reasoning patterns.We observe that while RLVR-trained models outperform their base models at smaller values of k (\eg, k =1), base models achieve higher pass@ k score when k is large.Moreover, we observe that the reasoning capability boundary of LLMs often narrows as RLVR training progresses.Further coverage and perplexity analysis shows that the reasoning paths generated by RLVR models are already included in the base models' sampling distribution, suggesting that their reasoning abilities originate from and are \textit{bounded} by the base model. From this perspective, treating the base model as an upper bound, our quantitative analysis shows that six popular RLVR algorithms perform similarly and remain far from optimal in fully leveraging the potential of the base model.In contrast, we find that distillation can introduce new reasoning patterns from the teacher and genuinely expand the model’s reasoning capabilities.Taken together, our findings suggest that current RLVR methods have not fully realized the potential of RL to elicit genuinely novel reasoning abilities in LLMs. This underscores the need for improved RL paradigms—such as continual scaling and multi-turn agent-environment interaction—to unlock this potential.",,诺亚; 温哥华云; 计算,诺亚: 大模型后训练Reasoning，RL; 温哥华云: Reinforcement fine tuning (RFT); 计算: 训推新范式,诺亚: Session讨论RLVR对LLM推理边界与覆盖度的影响，可重点关注蒸馏引入新推理、自博弈与多轮交互以强化潜在推理。; 温哥华云: Session讨论RLVR在采样效率与推理能力上的真实收益，可重点关注大k下pass@k评测、覆盖度分析及蒸馏/混合RFT以提升落地与扩展性。; 计算: Session讨论RLVR与蒸馏对推理能力演进的边界，可重点关注持续扩展与多轮交互范式对训练负载与系统配置的影响。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5B,https://neurips.cc/virtual/2025/session/122567,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch,https://neurips.cc/virtual/2025/oral/121452,,11:00 AM,"LLM‑based agents have demonstrated great potential in generating and managing code within complex codebases. In this paper, we introduce WebGen-Bench, a novel benchmark designed to measure an LLM-based agent's ability to create multi-file website codebases from scratch. It contains diverse instructions for website generation, created through the combined efforts of human annotators and GPT-4o. These instructions span three major categories and thirteen minor categories, encompassing nearly all important types of web applications.To assess the quality of the generated websites, we generate test cases targeting each functionality described in the instructions. These test cases are then manually filtered, refined, and organized to ensure accuracy, resulting in a total of 647 test cases. Each test case specifies an operation to be performed on the website and the expected outcome of the operation.To automate testing and improve reproducibility, we employ a powerful web-navigation agent to execute test cases on the generated websites and determine whether the observed responses align with the expected results.We evaluate three high-performance code-agent frameworks—Bolt.diy, OpenHands, and Aider—using multiple proprietary and open-source LLMs as engines. The best-performing combination, Bolt.diy powered by DeepSeek-R1, achieves only 27.8\% accuracy on the test cases, highlighting the challenging nature of our benchmark.Additionally, we construct WebGen-Instruct, a training set consisting of 6,667 website-generation instructions. Training Qwen2.5-Coder-32B-Instruct on Bolt.diy trajectories generated from a subset of the training set achieves an accuracy of 38.2\%, surpassing the performance of the best proprietary model.We release our data-generation, training, and testing code, along with both the datasets and model weights at https://github.com/mnluzimu/WebGen-Bench.",,多伦多云,多伦多云: AI Agent,多伦多云: Session讨论网站生成代码Agent评测基准与导航执行自动校验，可重点关注写操作可靠性验证、评测子项划分与覆盖度提升。
FRI 5 DEC,10:00-11:00,Oral Paper,  → QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training,https://neurips.cc/virtual/2025/oral/117310,,11:00 AM,"Clinical decision‑making routinely demands reasoning over heterogeneous data, yet existing multimodal language models (MLLMs) remain largely vision‑centric and fail to generalize across clinical specialties. To bridge this gap, we introduce QoQ-Med-7B/32B, the first open generalist clinical foundation model that jointly reasons across medical images, time‑series signals, and text reports. QoQ-Med is trained with Domain‑aware Relative Policy Optimization (DRPO), a novel reinforcement‑learning objective that hierarchically scales normalized rewards according to domain rarity and modality difficulty, mitigating performance imbalance caused by skewed clinical data distributions. Trained on 2.61 million instruction tuning pairs spanning 9 clinical domains, we show that DRPO training boosts diagnostic performance by 43% in macro‑F1 on average across all visual domains as compared to other critic-free training methods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation data, it is able to highlight salient regions related to the diagnosis, with an IoU 10x higher than open models while reaching the performance of OpenAI o4-mini. To foster reproducibility and downstream research, we release (i) the full model weights, (ii) the modular training pipeline, and (iii) all intermediate reasoning traces.",,温哥华云; 诺亚; 计算,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL; 计算: 训推新范式,温哥华云: Session讨论DRPO与GRPO在多模态临床RFT中的对比，可重点关注领域稀缺加权与奖励归一化对稳定性和样本效率的作用。; 诺亚: Session讨论多模态临床模型的DRPO训练，可重点关注无critic相对策略优化在推理增强、奖励分层与跨模态对齐中的作用。; 计算: Session讨论面向多模态的域感知RFT范式DRPO及训练管线，可重点关注其对算力/带宽占比、训练负载形态与数据配比的影响。
FRI 5 DEC,10:00-11:00,Oral Paper,  → NOVA: A Benchmark for Rare Anomaly Localization and Clinical Reasoning in Brain MRI,https://neurips.cc/virtual/2025/oral/121771,,11:00 AM,"In many real-world applications, deployed models encounter inputs that differ from the data seen during training. Open-world recognition ensures that such systems remain robust as ever-emerging, previously _unknown_ categories appear and must be addressed without retraining.Foundation and vision-language models are pre-trained on large and diverse datasets with the expectation of broad generalization across domains, including medical imaging.However, benchmarking these models on test sets with only a few common outlier types silently collapses the evaluation back to a closed-set problem, masking failures on rare or truly novel conditions encountered in clinical use.We therefore present NOVA, a challenging, real-life _evaluation-only_ benchmark of $\sim$900 brain MRI scans that span 281 rare pathologies and heterogeneous acquisition protocols. Each case includes rich clinical narratives and double-blinded expert bounding-box annotations. Together, these enable joint assessment of anomaly localisation, visual captioning, and diagnostic reasoning. Because NOVA is never used for training, it serves as an _extreme_ stress-test of out-of-distribution generalisation: models must bridge a distribution gap both in sample appearance and in semantic space.  Baseline results with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B) reveal substantial performance drops, with approximately a 65\% gap in localisation compared to natural-image benchmarks and 40\% and 20\% gaps in captioning and reasoning, respectively, compared to resident radiologists. Therefore, NOVA establishes a testbed for advancing models that can detect, localize, and reason about truly unknown anomalies.",,多伦多云; 计算,多伦多云: AI Agent; 计算: 训推新范式,多伦多云: Session讨论开放世界识别与医学VLM在OOD下的定位/描述/诊断评测框架，可重点关注evaluation-only基准、稀有类别覆盖与多任务指标拆分。; 计算: Session讨论开放世界识别与零样本定位/诊断在极端OOD上的评测基准，可重点关注测试时适配(TTA)、开放集识别与无需重训练处理未知类的推理范式。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5C,https://neurips.cc/virtual/2025/session/122568,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → High-dimensional neuronal activity from low-dimensional latent dynamics: a solvable model,https://neurips.cc/virtual/2025/oral/117112,,11:00 AM,"Computation in recurrent networks of neurons has been hypothesized to occur at the level of low-dimensional latent dynamics, both in artificial systems and in the brain. This hypothesis seems at odds with evidence from large-scale neuronal recordings in mice showing that neuronal population activity is high-dimensional. To demonstrate that low-dimensional latent dynamics and high-dimensional activity can be two sides of the same coin, we present an analytically solvable recurrent neural network (RNN) model whose dynamics can be exactly reduced to a low-dimensional dynamical system, but generates an activity manifold that has a high linear embedding dimension. This raises the question: Do low-dimensional latents explain the high-dimensional activity observed in mouse visual cortex? Spectral theory tells us that the covariance eigenspectrum alone does not allow us to recover the dimensionality of the latents, which can be low or high, when neurons are nonlinear. To address this indeterminacy, we develop Neural Cross-Encoder (NCE), an interpretable, nonlinear latent variable modeling method for neuronal recordings, and find that high-dimensional neuronal responses to drifting gratings and spontaneous activity in visual cortex can be reduced to low-dimensional latents, while the responses to natural images cannot. We conclude that the high-dimensional activity measured in certain conditions, such as in the absence of a stimulus, is explained by low-dimensional latents that are nonlinearly processed by individual neurons.",,,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → Task-Optimized Convolutional Recurrent Networks Align with Tactile Processing in the Rodent Brain,https://neurips.cc/virtual/2025/oral/116232,,11:00 AM,"Tactile sensing remains far less understood in neuroscience and less effective in artificial systems compared to more mature modalities such as vision and language.We bridge these gaps by introducing a novel Encoder-Attender-Decoder (EAD) framework to systematically explore the space of task-optimized temporal neural networks trained on realistic tactile input sequences from a customized rodent whisker-array simulator. We identify convolutional recurrent neural networks (ConvRNNs) as superior encoders to purely feedforward and state-space architectures for tactile categorization. Crucially, these ConvRNN-encoder-based EAD models achieve neural representations closely matching rodent somatosensory cortex, saturating the explainable neural variability and revealing a clear linear relationship between supervised categorization performance and neural alignment.Furthermore, contrastive self-supervised ConvRNN-encoder-based EADs, trained with tactile-specific augmentations, match supervised neural fits, serving as an ethologically-relevant, label-free proxy.For neuroscience, our findings highlight nonlinear recurrent processing as important for general-purpose tactile representations in somatosensory cortex, providing the first quantitative characterization of the underlying inductive biases in this system. For embodied AI, our results emphasize the importance of recurrent EAD architectures to handle realistic tactile inputs, along with tailored self-supervised learning methods for achieving robust tactile perception with the same type of sensors animals use to sense in unstructured environments.",,温哥华云; 计算,温哥华云: Embodied AI; 计算: 训推新范式,温哥华云: Session讨论触觉ConvRNN编码与EAD框架及对比自监督，可重点关注其在具身AI战略布局中的触觉表征学习、无标注训练与任务管线设计。; 计算: Session讨论EAD下监督/对比自监督在触觉序列上的效果，可重点关注其在训推新范式中的时序数据增强、循环结构负载特征与无标注训练策略。
FRI 5 DEC,10:00-11:00,Oral Paper,  → Memory Mosaics at scale,https://neurips.cc/virtual/2025/oral/118784,,11:00 AM,"Memory Mosaics, networks of associative memories, have demonstrated appealing compositional and in-context learning capabilities on medium-scale networks (GPT-2 scale) and synthetic small datasets. This work shows that these favorable properties remain when we scale memory mosaics to large language model sizes (llama-8B scale) and real-world datasets. To this end, we scale memory mosaics to 10B size, we train them on one trillion tokens, we introduce a couple architectural modifications (memory mosaics v2), we assess their capabilities across three evaluation dimensions: training-knowledge storage, new-knowledge storage, and in-context learning. Throughout the evaluation, memory mosaics v2 match transformers on the learning of training knowledge (first dimension) and significantly outperforms transformers on carrying out new tasks at inference time (second and third dimensions). These improvements cannot be easily replicated by simply increasing the training data for transformers. A memory mosaics v2 trained on one trillion tokens still perform better on these tasks than a transformer trained on eight trillion tokens.",,计算; 诺亚,计算: 高效模型架构; 诺亚: 大模型长序列，多模态长序列,计算: Session讨论可扩展的关联记忆型LLM架构（Memory Mosaics v2），可重点关注其对算力/带宽、缓存组织与低精度算子设计的影响。; 诺亚: Session讨论可扩展的关联记忆网络在长上下文与推理期记忆写入上的机制，可重点关注内置记忆更新、检索-写入策略与ICL评测。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5D,https://neurips.cc/virtual/2025/session/122569,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → InfinityStar: Uniﬁed Spacetime AutoRegressive Modeling for Visual Generation,https://neurips.cc/virtual/2025/oral/118709,,11:00 AM,"We introduce InfinityStar, a unified spacetime autoregressive framework for high-resolution image and dynamic video synthesis. Building on the recent success of autoregressive modeling in both vision and language, our purely discrete approach jointly captures spatial and temporal dependencies within a single architecture. This unified design naturally supports a variety of generation tasks such as text-to-image, text-to-video, image-to-video, and long-duration video synthesis via straightforward temporal autoregression. Through extensive experiments, InfinityStar scores 83.74 on VBench, outperforming all autoregressive models by large margins, even surpassing diffusion competitors like HunyuanVideo. Without extra optimizations, our model generates a 5s, 720p video approximately 10 × faster than leading diffusion-based methods. To our knowledge, InfinityStar is the first discrete autoregressive video generator capable of producing industrial-level 720p videos. We release all code and models to foster further research in efficient, high-quality video generation.",,CBG; 计算,CBG: 3DAIGC; 计算: 训推新范式,CBG: Session讨论离散时空自回归视频生成，可重点关注长视频时序一致性、条件控制接口及相机轨迹可控性的实现与评测。; 计算: Session讨论统一离散时空自回归生成范式，可重点关注扩散到自回归的范式迁移、长时序解码负载特征与吞吐/时延权衡。
FRI 5 DEC,10:00-11:00,Oral Paper,  → PlayerOne: Egocentric World Simulator,https://neurips.cc/virtual/2025/oral/118938,,11:00 AM,"We introduce PlayerOne, the first egocentric realistic world simulator, facilitating immersive and unrestricted exploration within vividly dynamic environments. Given an egocentric scene image from the user, PlayerOne can accurately construct the corresponding world and generate egocentric videos that are strictly aligned with the real-scene human motion of the user captured by an exocentric camera. PlayerOne is trained in a coarse-to-fine pipeline that first performs pretraining on large-scale egocentric text-video pairs for coarse-level egocentric understanding, followed by finetuning on synchronous motion-video data extracted from egocentric-exocentric video datasets with our automatic construction pipeline. Besides, considering the varying importance of different components, we design a part-disentangled motion injection scheme, enabling precise control of part-level movements. In addition, we devise a joint reconstruction framework that progressively models both the 4D scene and video frames, ensuring scene consistency in the long-form video generation. Experimental results demonstrate its great generalization ability in precise control of varying human movements and world-consistent modeling of diverse scenarios. It marks the first endeavor into egocentric real-world simulation and can pave the way for the community to delve into fresh frontiers of world modeling and its diverse applications.",,CBG; 温哥华云; 计算,CBG: 3DAIGC; 温哥华云: Embodied AI; 计算: 前沿应用负载,CBG: Session讨论以身视角世界建模、4D场景与视频联合重建及部件解耦运动注入，可重点关注长视频一致性建模与单目位姿/相机轨迹控制相关算法。; 温哥华云: Session讨论以身视角世界模拟、外视动捕对齐与部件级运动控制，可重点关注具身智能中的世界建模趋势及数据同步构建管线与评测基准设计。; 计算: Session讨论以身视角视频生成与4D联合建模的预训-微调管线，可重点关注负载算力/带宽画像、数据吞吐与长序列生成的系统特性。
FRI 5 DEC,10:00-11:00,Oral Paper,  → BEDLAM2.0: Synthetic humans and cameras in motion,https://neurips.cc/virtual/2025/oral/121503,,11:00 AM,"Inferring 3D human motion from video remains a challenging problem with many applications. While traditional methods estimate the human in image coordinates, many applications require human motion to be estimated in world coordinates. This is particularly challenging when there is both human and camera motion. Progress on this topic has been limited by the lack of rich video data with ground truth human and camera movement. We address this with BEDLAM2.0, a new dataset that goes beyond the popular BEDLAM dataset in important ways. In addition to introducing more diverse and realistic cameras and camera motions, BEDLAM2.0 increases diversity and realism of body shape, motions, clothing, hair, and 3D environments. Additionally, it adds shoes, which were missing in BEDLAM. BEDLAM has become a key resource for training 3D human pose and motion regressors today and we show that BEDLAM2.0 is significantly better, particularly for training methods that estimate humans in world coordinates. We compare state-of-the art methods trained on BEDLAM and BEDLAM2.0, and find that BEDLAM2.0 significantly improves accuracy over BEDLAM.  For research purposes, we provide the rendered videos, ground truth body parameters, and camera motions. We also provide the 3D assets to which we have rights and links to those from third parties.",,CBG; 温哥华云,CBG: 3DAIGC; 温哥华云: Embodied AI,CBG: Session讨论世界坐标人体运动估计与相机自运动的合成数据BEDLAM2.0，可重点关注利用GT相机轨迹与人体参数提升单目3D/4D重建与相机轨迹控制。; 温哥华云: Session讨论世界坐标下人体与相机联合运动的合成视频与3D资产，可重点关注用于Embodied感知预训练、egomotion/人体先验建模及仿真到真实迁移评估。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5E,https://neurips.cc/virtual/2025/session/122570,,11:00 AM,,,,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → Boosting Knowledge Utilization in Multimodal Large Language Models via Adaptive Logits Fusion and Attention Reallocation,https://neurips.cc/virtual/2025/oral/115856,,11:00 AM,"Despite their recent progress, Multimodal Large Language Models (MLLMs) often struggle in knowledge-intensive tasks due to the limited and outdated parametric knowledge acquired during training. Multimodal Retrieval Augmented Generation addresses this issue by retrieving contextual knowledge from external databases, thereby enhancing MLLMs with expanded knowledge sources. However, existing MLLMs often fail to fully leverage the retrieved contextual knowledge for response generation. We examine representative MLLMs and identify two major causes, namely, attention bias toward different tokens and knowledge conflicts between parametric and contextual knowledge. To this end, we design Adaptive Logits Fusion and Attention Reallocation (ALFAR), a training-free and plug-and-play approach that improves MLLM responses by maximizing the utility of the retrieved knowledge. Specifically, ALFAR tackles the challenges from two perspectives. First, it alleviates attention bias by adaptively shifting attention from visual tokens to relevant context tokens according to query-context relevance. Second, it decouples and weights parametric and contextual knowledge at output logits, mitigating conflicts between the two types of knowledge. As a plug-and-play method, ALFAR achieves superior performance across diverse datasets without requiring additional training or external tools. Extensive experiments over multiple MLLMs and benchmarks show that ALFAR consistently outperforms the state-of-the-art by large margins. Our code and data are available at https://github.com/Lackel/ALFAR.",,诺亚; 计算,诺亚: 大模型长序列，多模态长序列; 计算: 训推新范式,诺亚: Session讨论Adaptive Logits Fusion与Attention Reallocation，可重点关注多模态RAG中参数/检索知识解耦与长上下文注意力分配。; 计算: Session讨论训练免改的RAG增强推理，可重点关注注意力重分配与Logits加权对推理负载形态与算力映射的影响。
FRI 5 DEC,10:00-11:00,Oral Paper,  → HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models,https://neurips.cc/virtual/2025/oral/118373,,11:00 AM,"Multi-modal large language models (MLLMs) have emerged as a transformative approach for aligning visual and textual understanding. They typically require extremely high computational resources (e.g., thousands of GPUs) for training to achieve cross-modal alignment at multi-granularity levels. We argue that a key source of this inefficiency lies in the vision encoders they widely equip with, e.g., CLIP and SAM, which lack the alignment with language at multi-granularity levels. To address this issue, in this paper, we leverage hyperbolic space, which inherently models hierarchical levels and thus provides a principled framework for bridging the granularity gap between visual and textual modalities at an arbitrary granularity level. Concretely, we propose an efficient training paradigm for MLLMs, dubbed as \blg, which can optimize visual representations to align with their textual counterparts at an arbitrary granularity level through dynamic hyperbolic radius adjustment in hyperbolic space. \alg employs learnable matrices with M\""{o}bius multiplication operations, implemented via three effective configurations: diagonal scaling matrices, block-diagonal matrices, and banded matrices, providing a flexible yet efficient parametrization strategy. Comprehensive experiments across multiple MLLM benchmarks demonstrate that \alg consistently improves both existing pre-training and fine-tuning MLLMs clearly with less than 1\% additional parameters.",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 训推新范式,海思: Session讨论超曲空间下多模态对齐与Möbius乘法的高效训练，可重点关注动态半径与带状/块对角参数化以统一特征空间、降低融合延迟。; 计算: Session讨论基于超曲空间与动态半径的MLLM高效训练范式，可重点关注半径调度、Möbius乘法与轻量参数化对预训/微调负载与吞吐的影响。
FRI 5 DEC,10:00-11:00,Oral Paper,  → Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion,https://neurips.cc/virtual/2025/oral/118167,,11:00 AM,"Multimodal learning (MML) is significantly constrained by modality imbalance, leading to suboptimal performance in practice. While existing approaches primarily focus on balancing the learning of different modalities to address this issue, they fundamentally overlook the inherent disproportion in model classification ability, which serves as the primary cause of this phenomenon. In this paper, we propose a novel multimodal learning approach to dynamically balance the classification ability of weak and strong modalities by incorporating the principle of boosting. Concretely, we first propose a sustained boosting algorithm in multimodal learning by simultaneously optimizing the classification and residual errors. Subsequently, we introduce an adaptive classifier assignment strategy to dynamically facilitate the classification performance of the weak modality. Furthermore, we theoretically analyze the convergence property of the cross-modal gap function, ensuring the effectiveness of the proposed boosting scheme. To this end, the classification ability of strong and weak modalities is expected to be balanced, thereby mitigating the imbalance issue. Empirical experiments on widely used datasets reveal the superiority of our method through comparison with various state-of-the-art (SOTA) multimodal learning baselines. The source code is available at https://github.com/njustkmg/NeurIPS25-AUG.",,计算; 诺亚,计算: 训推新范式; 诺亚: 大模型长序列，多模态长序列,计算: Session讨论boosting式多模态分类均衡与自适应分类器分配，可重点关注对训推负载形态、弱模态增强策略及优化流程落地的影响。; 诺亚: Session讨论跨模态差距收敛与自适应分类器分配的boosting训练，可重点关注弱模态增强对长序列多模态训练稳定性与输入范式设计的启示。
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6A,https://neurips.cc/virtual/2025/session/122571,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds,https://neurips.cc/virtual/2025/oral/117790,,4:30 PM,"Bandeira et al. (2022) introduced the Franz-Parisi (FP) criterion for characterizing the computational hard phases in statistical detection problems. The FP criterion, based on an annealed version of the celebrated Franz-Parisi potential from statistical physics, was shown to be equivalent to low-degree polynomial (LDP) lower bounds for Gaussian additive models, thereby connecting two distinct approaches to understanding the computational hardness in statistical inference. In this paper, we propose a refined FP criterion that aims to better capture the geometric ``overlap"" structure of statistical models. Our main result establishes that this optimized FP criterion is equivalent to Statistical Query (SQ) lower bounds---another foundational framework in computational complexity of statistical inference.  Crucially, this equivalence holds under a mild, verifiable assumption satisfied by a broad class of statistical models, including Gaussian additive models, planted sparse models, as well as non-Gaussian component analysis (NGCA), single-index (SI) models, and convex truncation detection settings. For instance, in the case of convex truncation tasks, the assumption is equivalent with the Gaussian correlation inequality (Royen, 2014) from convex geometry. In addition to the above, our equivalence not only unifies and simplifies the derivation of several known SQ lower bounds—such as for the NGCA model (Diakonikolas et al., 2017) and the SI model (Damian et al., 2024)—but also yields new SQ lower bounds of independent interest, including for the computational gaps in mixed sparse linear regression (Arpino et al., 2023) and convex truncation (De et al., 2023).",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy,https://neurips.cc/virtual/2025/oral/119076,,4:30 PM,"A central challenge in machine learning is to understand how noise or measurement errors affect low-rank approximations, particularly in the spectral norm. This question is especially important in differentially private low-rank approximation, where one aims to preserve the top-$p$ structure of a data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius norm error or changes in reconstruction quality, but these metrics can over- or under-estimate true subspace distortion. The spectral norm, by contrast, captures worst-case directional error and provides the strongest utility guarantees. We establish new high-probability spectral-norm perturbation bounds for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem and explicitly capture interactions between a matrix $A \in \mathbb{R}^{n \times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and norm conditions, our bounds yield sharp estimates for $\| (A + E)_p - A_p \|$, where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up to a factor of $\sqrt{n}$. As an application, we derive improved utility guarantees for differentially private PCA, resolving an open problem in the literature. Our analysis relies on a novel contour bootstrapping method from complex analysis and extends it to a broad class of spectral functionals, including polynomials and matrix exponentials. Empirical results on real-world datasets confirm that our bounds closely track the actual spectral error under diverse perturbation regimes.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization,https://neurips.cc/virtual/2025/oral/116693,,4:30 PM,"This paper addresses the Bayesian optimization problem (also referred to as the Bayesian setting of the Gaussian process bandit), where the learner seeks to minimize the regret under a function drawn from a known Gaussian process (GP). Under a Mat\'ern kernel with some extent of smoothness, we show that the Gaussian process upper confidence bound (GP-UCB) algorithm achieves $\tilde{O}(\sqrt{T})$ cumulative regret with high probability. Furthermore, our analysis yields $O(\sqrt{T \ln^2 T})$ regret under a squared exponential kernel. These results fill the gap between the existing regret upper bound of GP-UCB and the current best upper bound provided by Scarlett [2018]. The key idea in our proof is to capture the concentration behavior of the input sequence realized by GP-UCB, enabling us to handle GP's information gain in a refined manner.",,温哥华云,温哥华云: Reinforcement fine tuning (RFT),温哥华云: Session讨论在Matérn与SE核下GP-UCB遗憾界改进，可重点关注其对提高样本效率、指导RFT超参贝叶斯优化与探索-利用权衡的启示。
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6B,https://neurips.cc/virtual/2025/session/122572,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability,https://neurips.cc/virtual/2025/oral/116902,,4:30 PM,"Graph Neural Networks (GNNs) are widely used for node classification, yet their opaque decision-making limits trust and adoption. While local explanations offer insights into individual predictions, global explanation methods—those that characterize an entire class—remain underdeveloped. Existing global explainers rely on motif discovery in small graphs, an approach that breaks down in large, real-world settings where subgraph repetition is rare, node attributes are high-dimensional, and predictions arise from complex structure-attribute interactions. We propose GnnXemplar, a novel global explainer inspired from Exemplar Theory from cognitive science. GnnXemplar identifies representative nodes in the GNN embedding space—exemplars—and explains predictions using natural language rules derived from their neighborhoods. Exemplar selection is framed as a coverage maximization problem over reverse $k$-nearest neighbors, for which we provide an efficient greedy approximation. To derive interpretable rules, we employ a self-refining prompt strategy using large language models (LLMs). Experiments across diverse benchmarks show that GnnXemplar significantly outperforms existing methods in fidelity, scalability, and human interpretability, as validated by a user study with 60 participants.",,,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → RAG4GFM: Bridging Knowledge Gaps in Graph Foundation Models through Graph Retrieval Augmented Generation,https://neurips.cc/virtual/2025/oral/115563,,4:30 PM,"Graph Foundation Models (GFMs) have demonstrated remarkable potential across graph learning tasks but face significant challenges in knowledge updating and reasoning faithfulness. To address these issues, we introduce the Retrieval-Augmented Generation (RAG) paradigm for GFMs, which leverages graph knowledge retrieval. We propose RAG4GFM, an end-to-end framework that seamlessly integrates multi-level graph indexing, task-aware retrieval, and graph fusion enhancement. RAG4GFM implements a hierarchical graph indexing architecture, enabling multi-granular graph indexing while achieving efficient logarithmic-time retrieval. The task-aware retriever implements adaptive retrieval strategies for node, edge, and graph-level tasks to surface structurally and semantically relevant evidence. The graph fusion enhancement module fuses retrieved graph features with query features and augments the topology with sparse adjacency links that preserve structural and semantic proximity, yielding a fused graph for GFM inference.Extensive experiments conducted across diverse GFM applications demonstrate that RAG4GFM significantly enhances both the efficiency of knowledge updating and reasoning faithfulness\footnote{Code: \url{https://github.com/Matrixmax/RAG4GFM}.}.",,存储; 计算,存储: 单/多模型推理; 计算: 训推新范式,存储: Session讨论分层图索引与任务自适应检索，可重点关注检索IO模式、向量-图混合索引的数据布局及对KV/存储调度的影响。; 计算: Session讨论RAG4GFM范式：层级索引+图融合推理，可重点关注对训推负载的变化，含稀疏算子/内存亲和诉求及索引构建与在线更新成本。
FRI 5 DEC,3:30-4:30,Oral Paper,  → Discovering Opinion Intervals from Conflicts in Signed Graphs,https://neurips.cc/virtual/2025/oral/115063,,4:30 PM,"Online social media provide a platform for people to discuss current events and exchange opinions with their peers. While interactions are predominantly positive, in recent years, there has been a lot of research to understand the conflicts in social networks and how they are based on different views and opinions.  In this paper, we ask whether the conflicts in a network reveal a small and interpretable set of prevalent opinion ranges that explain the users' interactions.  More precisely, we consider signed graphs, where the edge signs indicate positive and negative interactions of node pairs, and our goal is to infer opinion intervals that are consistent with the edge signs.  We introduce an optimization problem that models this question, and we give strong hardness results and a polynomial-time approximation scheme by utilizing connections to interval graphs and the Correlation Clustering problem.  We further provide scalable heuristics and show that in experiments they yield more expressive solutions than Correlation Clustering baselines. We also present a case study on a novel real-world dataset from the German parliament, showing that our algorithms can recover the political leaning of German parties based on co-voting behavior.",,,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6C,https://neurips.cc/virtual/2025/session/122573,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Generalized Linear Mode Connectivity for Transformers,https://neurips.cc/virtual/2025/oral/118595,,4:30 PM,"Understanding the geometry of neural network loss landscapes is a central question in deep learning, with implications for generalization and optimization. A striking phenomenon is $\textit{linear mode connectivity}$ (LMC), where independently trained models can be connected by low- or zero-barrier paths, despite appearing to lie in separate loss basins. However, this is often obscured by symmetries in parameter space—such as neuron permutations—which make functionally equivalent models appear dissimilar. Prior work has predominantly focused on neuron reordering through permutations, but such approaches are limited in scope and fail to capture the richer symmetries exhibited by modern architectures such as Transformers. In this work, we introduce a unified framework that captures four symmetry classes—permutations, semi-permutations, orthogonal transformations, and general invertible maps—broadening the set of valid reparameterizations and subsuming many previous approaches as special cases. Crucially, this generalization enables, for the first time, the discovery of low- and zero-barrier linear interpolation paths between independently trained Vision Transformers and GPT-2 models. Furthermore, our framework extends beyond pairwise alignment, to multi-model and width-heterogeneous settings, enabling alignment across architectures of different sizes. These results reveal deeper structure in the loss landscape and underscore the importance of symmetry-aware analysis for understanding model space geometry.",,计算,计算: 训推新范式,计算: Session讨论对称性驱动的广义LMC与Transformer权重对齐，可重点关注宽度异构对齐与线性插值/模型合并对训推范式和负载特征的影响。
FRI 5 DEC,3:30-4:30,Oral Paper,  → On Linear Mode Connectivity of Mixture-of-Experts Architectures,https://neurips.cc/virtual/2025/oral/118036,,4:30 PM,"Linear Mode Connectivity (LMC) is a notable phenomenon in the loss landscapesof neural networks, wherein independently trained models have been observed tobe connected—up to permutation symmetries—by linear paths in parameter spacealong which the loss remains consistently low. This observation challenges classicalviews of non-convex optimization and has implications for model ensembling,generalization, and our understanding of neural loss geometry. Inspired by recentstudies on LMC in standard neural networks, we systematically investigate thisphenomenon within Mixture-of-Experts (MoE) architectures—a class of modelsknown for their scalability and computational efficiency, which combine traditionalneural networks—referred to as experts—through a learnable gating mechanism.We begin by conducting a comprehensive analysis of both dense and sparse gatingregimes, demonstrating that the symmetries inherent to MoE architectures arefully characterized by permutations acting on both the expert components and thegating function. Building on these foundational findings, we propose a matchingalgorithm that enables alignment between independently trained MoEs, therebyfacilitating the discovery of LMC. Finally, we empirically validate the presence ofLMC using our proposed algorithm across diverse MoE configurations—includingdense, sparse, and shared-expert variants—under a wide range of model settingsand datasets of varying scales and modalities. Our results confirm the existenceof LMC in MoE architectures and offer fundamental insights into the functionallandscape and optimization dynamics of deep learning models.",,计算,计算: 高效模型架构,计算: Session讨论MoE架构的LMC及专家/门控置换对齐算法，可重点关注稀疏/稠密门控对训练稳定性与模型融合的影响，研判架构演进对算子与内存需求。
FRI 5 DEC,3:30-4:30,Oral Paper,  → Learning (Approximately) Equivariant Networks via Constrained Optimization,https://neurips.cc/virtual/2025/oral/118376,,4:30 PM,"Equivariant neural networks are designed to respect symmetries through their architecture, boosting generalization and sample efficiency when those symmetries are present in the data distribution. Real-world data, however, often departs from perfect symmetry because of noise, structural variation, measurement bias, or other symmetry-breaking effects. Strictly equivariant models may struggle to fit the data, while unconstrained models lack a principled way to leverage partial symmetries. Even when the data is fully symmetric, enforcing equivariance can hurt training by limiting the model to a restricted region of the parameter space. Guided by homotopy principles, where an optimization problem is solved by gradually transforming a simpler problem into a complex one, we introduce Adaptive Constrained Equivariance (ACE), a constrained optimization approach that starts with a flexible, non-equivariant model and gradually reduces its deviation from equivariance. This gradual tightening smooths training early on and settles the model at a data-driven equilibrium, balancing between equivariance and non-equivariance. Across multiple architectures and tasks, our method consistently improves performance metrics, sample efficiency, and robustness to input perturbations compared with strictly equivariant models and heuristic equivariance relaxations.",,CBG; 温哥华云; 计算,CBG: 3DAIGC; 温哥华云: Embodied AI; 计算: 训推新范式,CBG: Session讨论[近似等变网络与同伦式约束训练]，可重点关注[SE(3)等变在点云/位姿重建、运动分割与长视频一致性中的模型改造]; 温哥华云: Session讨论[近似等变网络与自适应约束优化ACE]，可重点关注[SE(3)场景下感知与控制模型的等变性建模、鲁棒性与样本效率提升]; 计算: Session讨论[自适应约束等变ACE与同伦式训练]，可重点关注[约束强度调度对训练算子、负载峰值与收敛效率的影响]
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6D,https://neurips.cc/virtual/2025/session/122574,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → A Snapshot of Influence: A Local Data Attribution Framework for Online Reinforcement Learning,https://neurips.cc/virtual/2025/oral/115686,,4:30 PM,"Online reinforcement learning (RL) excels in complex, safety-critical domains but suffers from sample inefficiency, training instability, and limited interpretability. Data attribution provides a principled way to trace model behavior back to training samples, yet existing methods assume fixed datasets, which is violated in online RL where each experience both updates the policy and shapes future data collection.In this paper, we initiate the study of data attribution for online RL, focusing on the widely used Proximal Policy Optimization (PPO) algorithm. We start by establishing alocalattribution framework, interpreting model checkpoints with respect to the records in the recent training buffer. We design two target functions, capturing agent action and cumulative return respectively, and measure each record's contribution through gradient similarity between its training loss and these targets. We demonstrate the power of this framework through three concrete applications: diagnosis of learning, temporal analysis of behavior formation, and targeted intervention during training. Leveraging this framework, we further propose an algorithm, iterative influence-based filtering (IIF), for online RL training that iteratively performs experience filtering to refine policy updates. Across standard RL benchmarks (classic control, navigation, locomotion) to RLHF for large language models, IIF reduces sample complexity, speeds up training, and achieves higher returns. Together, these results open a new direction for making online RL more interpretable, efficient, and effective.",,温哥华云; 诺亚; 多伦多云,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL; 多伦多云: AI Agent,温哥华云: Session讨论在线RL本地数据归因与IIF经验筛选，助力RLHF提效稳训，可重点关注梯度相似度贡献评估、训练缓冲区局部归因与PPO在线干预。; 诺亚: Session讨论在线RL本地归因与IIF经验过滤，支撑经验驱动学习与训练诊断，可重点关注梯度相似度归因、按贡献经验干预及其在PPO中的验证。; 多伦多云: Session讨论行为形成的本地归因与目标化训练干预，有助提升Agent可靠性与持续优化，可重点关注训练缓冲区局部归因、经验筛选与在线干预机制。
FRI 5 DEC,3:30-4:30,Oral Paper,  → 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities,https://neurips.cc/virtual/2025/oral/115732,,4:30 PM,"Scaling up self-supervised learning has driven breakthroughs in language and vision, yet comparable progress has remained elusive in reinforcement learning (RL). In this paper, we study building blocks for self-supervised RL that unlock substantial improvements in scalability, with network depth serving as a critical factor. Whereas most RL papers in recent years have relied on shallow architectures (around 2 -- 5 layers), we demonstrate that increasing the depth up to 1024 layers can significantly boost performance.Our experiments are conducted in an unsupervised goal-conditioned setting, where no demonstrations or rewards are provided, so an agent must explore (from scratch) and learn how to maximize the likelihood of reaching commanded goals.Evaluated on simulated locomotion and manipulation tasks, our approach increases performance on the self-supervised contrastive RL algorithm by $2\times$ -- $50\times$, outperforming other goal-conditioned baselines.Increasing the model depth not only increases success rates but also qualitatively changes the behaviors learned.",,计算; 温哥华云,计算: 高效模型架构; 温哥华云: Embodied AI,计算: Session讨论自监督RL中的千层深度网络与目标条件对比学习，可重点关注深度扩展对算力/显存、并行稳定性及低精度训推适配。; 温哥华云: Session讨论具身任务中千层深度自监督RL以提升目标达成，可重点关注无示例目标条件训练在运动/操控上的策略表示、探索与样本效率。
FRI 5 DEC,3:30-4:30,Oral Paper,  → Learning long range dependencies through time reversal symmetry breaking,https://neurips.cc/virtual/2025/oral/115363,,4:30 PM,"Deep State Space Models (SSMs) reignite physics-grounded compute paradigms, as RNNs could natively be embodied into dynamical systems. This calls for dedicated learning algorithms obeying to core physical principles,  with efficient techniques to simulate these systems and guide their design. We propose \emph{Recurrent Hamiltonian Echo Learning} (RHEL), an algorithm which provably computes loss gradients as finite differences of physical trajectories of non-dissipative, \emph{Hamiltonian systems}. In ML terms, RHEL only requires three ``forward passes'' irrespective of model size, without explicit Jacobian computation, nor incurring any variance in the gradient estimation. Motivated by the potential to implement our algorithm in non-digital physical systems, we first introduce RHEL in \emph{continuous time} and demonstrate its formal equivalence with the continuous adjoint state method.To facilitate the simulation of Hamiltonian systems trained by RHEL, we propose a \emph{discrete-time} version of RHEL which is equivalent to Backpropagation Through Time (BPTT) when applied to a class of recurrent modules which we call \emph{Hamiltonian Recurrent Units} (HRUs). This setting allows us to demonstrate the scalability of RHEL by generalizing these results to hierarchies of HRUs, which we call \emph{Hamiltonian SSMs} (HSSMs). We apply RHEL to train HSSMs with linear and nonlinear dynamics on a variety of time-series tasks ranging from mid-range to long-range classification and regression with sequence length reaching $\sim 50k$. We show that RHEL consistently matches the performance of BPTT across all models and tasks. This work opens new doors for the design of scalable, energy-efficient physical systems endowed with self-learning capabilities for sequence modelling.",,诺亚; 海思; 计算,诺亚: 大模型长序列，多模态长序列; 海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构,诺亚: Session讨论RHEL与哈密顿SSM/HRU的长序列建模与训练，可重点关注50k序列下的线性扩展、与Transformer对比及内置记忆更新策略。; 海思: Session讨论无需注意力的哈密顿SSM/HRU及RHEL训练，可重点关注以线性复杂度替代长上下文注意力的芯片加速与低延迟推理。; 计算: Session讨论基于哈密顿动力学的RHEL与HSSM训练范式，可重点关注三次前向与无雅可比回传对算力、带宽与存储映射的影响。
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6E,https://neurips.cc/virtual/2025/session/122575,,4:30 PM,,,,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction,https://neurips.cc/virtual/2025/oral/118742,,4:30 PM,"Transformer-based large language models (LLMs) cache context as key-value (KV) pairs during inference. As context length grows, KV cache sizes expand, leading to substantial memory overhead and increased attention latency. This paper introduces \textit{KVzip}, a query-agnostic KV cache eviction method enabling effective reuse of compressed KV caches across diverse queries. KVzip quantifies the importance of a KV pair using the underlying LLM to reconstruct original contexts from cached KV pairs, subsequently evicting pairs with lower importance. Extensive empirical evaluations demonstrate that KVzip reduces KV cache size by $3$-$4\times$ and FlashAttention decoding latency by approximately $2\times$, with negligible performance loss in question-answering, retrieval, reasoning, and code comprehension tasks. Evaluations include various models such as LLaMA3.1, Qwen2.5, and Gemma3, with context lengths reaching up to 170K tokens. KVzip significantly outperforms existing query-aware KV eviction methods, which suffer from performance degradation even at a 90\% cache budget ratio under multi-query scenarios.",,存储; 海思; 诺亚,存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,存储: Session讨论查询无关KV缓存压缩与上下文重构，可重点关注多模型多查询下KV加载卸载与调度、分层内存协同及RAG缓存复用。; 海思: Session讨论查询无关KV压缩以降内存与解码时延，可重点关注硬件友好KV重要性评估、FlashAttention优化与带宽容量权衡。; 诺亚: Session讨论长上下文KV缓存压缩与跨查询复用，可重点关注缓存重要性评估、上下文重构算法与测试时记忆更新结合。
FRI 5 DEC,3:30-4:30,Oral Paper,  → MokA: Multimodal Low-Rank Adaptation for MLLMs,https://neurips.cc/virtual/2025/oral/116048,,4:30 PM,"In this paper, we reveal that most current efficient multimodal fine-tuning methods are hindered by a key limitation: they are directly borrowed from LLMs, often neglecting the intrinsic differences of multimodal scenarios and even affecting the full utilization of all modalities. Inspired by our empirical observation, we argue that unimodal adaptation and cross-modal adaptation are two essential parts for the effective fine-tuning of MLLMs. From this perspective, we propose Multimodal Low-rank Adaptation (MokA), a multimodal-aware efficient fine-tuning strategy that takes multimodal characteristics into consideration. It compresses unimodal information by modality-specific parameters while explicitly enhancing cross-modal interaction, ensuring both unimodal and cross-modal adaptation. Extensive experiments cover three representative multimodal scenarios (audio-visual-text, visual-text, and speech-text), and multiple LLM backbones (LLaMA2, Qwen2, Qwen2.5-VL, etc). Consistent improvements indicate the efficacy and versatility of the proposed method. Ablation studies and efficiency evaluation are also conducted to fully asses our method. Overall, we think MokA provides a more targeted solution for efficient adaptation of MLLMs, paving the way for further exploration.",,计算,计算: 高效模型架构,计算: Session讨论多模态感知LoRA（单模态/跨模态双路径），可重点关注适配位置与秩对算子形态、显存/带宽及算力映射的影响。
FRI 5 DEC,3:30-4:30,Oral Paper,  → ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism,https://neurips.cc/virtual/2025/oral/117338,,4:30 PM,"Multimodal large language models (MLLMs) extend LLMs to handle images, videos, and audio by incorporating feature extractors and projection modules. However, these additional components—combined with complex inference pipelines and heterogeneous workloads—introduce significant inference overhead. Therefore, efficiently serving MLLMs remains a major challenge. Current tightly coupled serving architectures struggle to distinguish between mixed request types or adapt parallelism strategies to different inference stages, leading to increased time-to-first-token (TTFT) and poor resource utilization. To address this, we introduce Elastic Multimodal Parallelism (EMP), a new serving paradigm that elastically adapts to resource heterogeneity across request types and inference stages. Building upon EMP, we develop ElasticMM, an MLLM serving system that (1) separates requests into independent modality groups with dynamic resource allocation via a modality-aware load balancer; (2) decouples inference stages and enables parallelism adjustment and adaptive scaling via elastic partition scheduling; and (3) improves inference efficiency through unified multimodal prefix caching and non-blocking encoding. Experiments on diverse real-world datasets show that ElasticMM outperforms state-of-the-art (SOTA) serving systems, reducing TTFT by up to 4.2 × and achieving 3.2–4.5 × higher throughput while meeting service-level objectives (SLOs).",,存储; 计算,存储: 单/多模型推理; 计算: 训推新范式,存储: Session讨论EMP的模态感知负载均衡、阶段解耦与统一前缀缓存，可重点关注KV Cache加载/卸载调度、CXL内存-存储协同及多模型混部。; 计算: Session讨论弹性多模态并行与阶段解耦、自适应伸缩，可重点关注并行粒度与调度对负载画像及芯片算力/带宽需求的影响建模。
