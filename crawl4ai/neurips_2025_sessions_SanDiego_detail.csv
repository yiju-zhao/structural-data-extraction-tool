date,time,type,title,url,speaker,end_time,abstract,overview
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Telling Stories at Scale: Multimodal ML in the Global Media Landscape,https://neurips.cc/virtual/2025/128652,,9:30 AM,"Netflix has long been recognized as a pioneer in personalization, leveraging member preference data to recommend the most engaging shows, movies, and games. In recent years, we have expanded our use of machine learning and data-driven approaches to support a wide array of upstream creative and operational workflows. In this talk, we will discuss how modern AI methods – contrastive learning, transformers, cross-modal retrieval, graph neural networks, etc. – are transforming the curation, localization, promotion, and launch of stories on a global scale. A distinctive aspect of our work is the integration of highly creative assets—text, images, video, and speech—alongside traditional tabular datasets. We will highlight unique challenges that arise at the intersection of multimedia, personalization, and web-scale products, and share how advanced ML/AI techniques are addressing these challenges to connect great stories with our worldwide audience.",
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Data Scout: “From Prompt to Corpus: Accelerating Domain-Specific Data Collection with LLMGuided Discovery”,https://neurips.cc/virtual/2025/128656,,9:30 AM,"Training large language models for specialized disciplines such as advanced mathematics, molecular biology, or legal reasoning is limited by the scarcity of large, high quality, domain specific corpora. Most publicly available datasets are dominated by general purpose web text. When available, specialized data are fragmented across diverse sources such as preprints, conference papers, forums, lecture notes, and digitized books. No single source offers comprehensive real-world coverage across scientific domains. Consequently, scaling up authentic domain data remains a bottleneck: collecting a subset of relevant tokens often requires downloading and filtering hundreds of terabytes of raw web material, a process that is both time consuming and costly.x000Dx000DWe introduce Data Scout, a modular, LLM powered pipeline that turns a high-level user intent (e.g., “I need data for advanced mathematics”) into a vetted, list of seed URLs in minutes. The system first expands the original intent using an LLM that generates a hierarchical subgraph of related concepts; this taxonomy drives a diversified set of search queries that systematically cover the target domain while respecting known licensing signals. Candidate URLs are then filtered by the same LLM using chain of thought prompting based on topical relevance, licensing clarity, and crawlability. Our results show that that the list of selected candidate URLs when crawled can yield a high percentage of relevant pages (40%+) related to the user’s intended topic or query, compared to less than 1 percent in general web-scale corpora. Data Scout is available with both CLI and GUI front ends. By democratizing domain specific data acquisition, Data Scout enables researchers without dedicated crawling infrastructure to bootstrap large, high-fidelity corpora, accelerating the development of specialized LLMs across various niche domains fields.",
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Multimodal Data Foundation at Industry-Scale,https://neurips.cc/virtual/2025/128659,,9:30 AM,"Pre-training is fundamental to foundation models, enabling them to acquire broad knowledge that gives rise to emerging capabilities at later training stages, and scaling is the key for pre-training. In this talk, we present a recipe for building and curating pre-training, multimodal image-text paired data from scratch on a global scale, enabling mutual benefits between English and non-English data. We would like to share our key observations and insights with the community on: (1) why scaling matters, including the foundational role of data and key principles to hold for scaling; (2) how to design simple yet scalable data algorithms that enable industry-scale data collection and training without data filters, serving both research and production needs; (3) how the scaling improves Meta’s products at conventional and frontier machine learning areas. Submission is facilitated by Cogs & Marvel but is entirely organized, executed, and implemented by Meta.",
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Toward General Full Autonomy: Open Research Challenges in Scalable Self-Driving,https://neurips.cc/virtual/2025/128661,,9:30 AM,"Speaker: Ben Snyder, Director of AI Research for Autonomous Vehicles, General Motorsx000Dx000DGM’s driver-assistance systems now power millions of vehicles across North America, logging over half a billion hands-free miles with zero reported crashes—demonstrating the safety and scalability of autonomy at unprecedented consumer scale. Following GM’s acquisition of Cruise earlier this year, the combined teams now bring together a decade of experience to accelerate progress toward full, generalized autonomy. This talk will dive into the open research challenges ahead—from model architecture and the balance between imitation and reinforcement learning, to leveraging vision-language models for long-tail, common-sense reasoning, and advancing the training, deployment, and simulation infrastructure needed to scale truly generalized autonomy.",
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Beyond Benchmarks: Rethinking Reasoning in Language Models,https://neurips.cc/virtual/2025/128665,,9:30 AM,"Reasoning is often described as the next frontier for AI, but what does it really mean for a model to “reason”, and how should we measure it? Popular benchmarks like GSM8K suggest steady progress, yet controlled studies reveal that models can fail dramatically under small changes—such as swapping numbers or adding irrelevant details. Large Reasoning Models (LRMs), which generate explicit chains of thought, raise new optimism but also expose clear limits: they often underperform standard models on simple tasks, improve briefly at medium complexity, and then collapse on harder ones despite having unused compute. Crucially, reasoning is not the same as knowledge recall, tool use, or agent-like behavior. True reasoning involves solving novel problems, decomposing them into steps, generalizing to new contexts, recombining partial results, and finally generating novel hypotheses—capabilities current systems largely lack. Today’s evaluations, focused on final answers and contaminated benchmarks, risk giving a misleading sense of progress. This talk will provide a critical review of reasoning in language models, highlight why current evaluations can be deceptive, and emphasize that reasoning is not just about “what"" models answer, but “how"" they solve problems.",
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Foundational Generative Recommendations for E-Commerce,https://neurips.cc/virtual/2025/128667,,9:30 AM,"Modern commerce platforms face the challenge of delivering personalized recommendations across billions of items to users with diverse intents, temporal dynamics, and cold-start scenarios. We present a generative foundation model for commerce built on Hierarchical Sequential Transduction Units (HSTU) that integrates Liquid Foundation Models (LFM) for rich textual product representations and custom CUDA kernels developed in collaboration with Nvidia for efficient training and online serving. Our approach demonstrates that generative methods unlock substantial gains through three key innovations: (1) large-scale contrastive learning with hard negative sampling; (2) temporal mechanisms that fuse multi-scale time signals (session, day, season) with commerce-specific features; and (3) optimized training and inference kernels. By treating LFM embeddings as auxiliary features rather than end-to-end fine-tuning, we maintain modularity while capturing semantic relationships. While results are promising, significant challenges remain in handling non-stationary preferences, multi-objective optimization, and ensuring fairness in generative retrieval—we discuss our roadmap toward truly foundational commerce models that generalize across domains and market conditions.",
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,From Research to Markets: Applying Cutting-Edge Machine Learning in Quantitative Finance,https://neurips.cc/virtual/2025/128670,,9:30 AM,"In modern quantitative finance, the boundaries between academic machine learning research and real-world trading strategies are rapidly dissolving. In this talk, we will share how researchers at G-Research apply advances in deep learning, probabilistic modelling, reinforcement learning, and large-scale optimization to some of the most challenging problems in global financial markets. Our work transforms vast, noisy, and non-stationary data into predictive signals, demanding innovations that extend the state of the art in both theory and practice. This includes sequence modelling for high-frequency data, scalable Bayesian inference for uncertainty quantification, generative modelling for scenario analysis, and reinforcement learning for adaptive portfolio construction. Operating at the intersection of rigorous science and high-performance computing, we thrive in an environment where milliseconds matter and model generalization is paramount.x000Dx000DCome and see how cutting-edge machine learning meets the realities of global financial markets at G-Research.",
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection,https://neurips.cc/virtual/2025/128668,,9:30 AM,"The rapid integration of LLMs for synthetic data generation offers a powerful solution for data scarcity, a critical issue for training machine learning models. However, the resulting data quality is often questionable, requiring costly and time-consuming manual review. This oversight is especially challenging in the crucial domain of trustworthy and safe AI.x000Dx000DA significant need here is the automated identification of adversarial and harmful inputs, a process known as red-teaming, to improve guardrailing systems before deployment. Developing an effective, fully automated red-teaming approach capable of generating diverse, out-of-domain harmful content has been a long-standing challenge.x000Dx000DTo address data scarcity in harmful text detection & the challenge of automated red-teaming, we introduce GRAID (Geometric & Reflective AI-Driven Data Augmentation), a novel, versatile, & dynamic multi-agent framework.x000Dx000DGRAID operates in two stages:x000D1) Geometric Generation: A constrained, fine-tuned LLM generates geometrically controlled examples to diversify content within the original embedding space.x000D2) Reflective Augmentation: A multi-agentic reflective process promotes stylistic diversity & uncovers difficult edge cases.x000Dx000DThis combination ensures both reliable coverage of the input space & nuanced exploration of harmful content. We demonstrate that augmenting a harmful text classification dataset with GRAID significantly improves the performance of downstream real-world guardrail models. Furthermore, GRAID captures data variability in new geometric domains while preserving data relationships.x000Dx000DWhile initially focused on harmful text detection, GRAID’s modular design makes it an inherently domain-agnostic framework adaptable to various applications beyond classification. In this talk, we will detail how GRAID distinguishes itself from existing solutions, discuss its building blocks, & share insights on its easy adaptation for diverse synthetic data generation needs.",
TUE 2 DEC,9:30 a.m.,Tutorial,Planning in the Era of Language Models,https://neurips.cc/virtual/2025/109596,,12:00 PM,"For over six decades, the field of automated planning has been at the heart of AI, empowering intelligent systems to reason, act, and achieve goals in complex, dynamic environments. From robotics and logistics to space exploration, planning research has fueled autonomous decision-making in real-world applications.Today, as large language models redefine what’s possible in AI, the principles and methodologies of planning are more vital than ever. The planning community brings decades of experience in designing, benchmarking, and interpreting intelligent behavior; expertise that can accelerate the development of powerful, trustworthy, and general-purpose LLM-based agents.Participants will gain a clear understanding of what planning truly entails, what has been learned (and sometimes forgotten) in the shift toward LLM-based approaches, and how foundational insights from the planning community can inform the creation of stronger, more reliable, and more scalable LLM-powered planners.","Overview: The webpage presents a tutorial titled 'Planning in the Era of Language Models' scheduled for December 2nd, 2025, at NeurIPS in San Diego, CA. The tutorial focuses on the integration of automated planning with large language models (LLMs). It highlights the importance of planning in AI, especially as LLMs redefine AI capabilities. The tutorial aims to provide participants with insights into planning methodologies and how these can enhance the development of LLM-based agents. | Research Interests: Automated planning, Large language models, AI reasoning and decision-making, Planning formalisms and languages, Evaluation of planning tools, Human-aware AI systems"
TUE 2 DEC,9:30 a.m.,Tutorial,Foundations of Tensor/Low-Rank Computations for AI,https://neurips.cc/virtual/2025/109591,,12:00 PM,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Human-AI Alignment: Foundations, Methods, Practice, and Challenges",https://neurips.cc/virtual/2025/109592,,12:00 PM,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Model Merging: Theory, Practice and Applications",https://neurips.cc/virtual/2025/109593,,12:00 PM,,
TUE 2 DEC,9:30 a.m.,Tutorial,New Frontiers of Hyperparameter Optimization: Recent advances and open challenges in theory and practice,https://neurips.cc/virtual/2025/109594,,12:00 PM,,
TUE 2 DEC,9:30 a.m.,Tutorial,"Explain AI Models: Methods and Opportunities in Explainable AI, Data-Centric AI, and Mechanistic Interpretability",https://neurips.cc/virtual/2025/109599,,1:30 PM,,
TUE 2 DEC,9:30 a.m.,Tutorial,Energy and Power as First-Class ML Design Metrics,https://neurips.cc/virtual/2025/109589,,12:00 PM,,"Overview: The tutorial titled 'Energy and Power as First-Class ML Design Metrics' at NeurIPS 2025 focuses on addressing energy as a critical bottleneck in machine learning. It provides practical measurements, a primer on power and energy as computing resources, and optimizations from kernels to clusters. The event is a collaboration between The ML.ENERGY Initiative at the University of Michigan and NVIDIA, featuring a series of sessions and an industry panel discussion. | Research Interests: Energy efficiency in machine learning, Power and energy as computing resources, Performance optimization under power constraints, Energy optimization with performance considerations, Industry applications of power and energy in ML"
TUE 2 DEC,noon,Expo Demonstration,Multimodal AI Forensic Search for Video Surveillance,https://neurips.cc/virtual/2025/128632,,3:00 PM,"Video surveillance often requires searching for specific targets from long-duration videos using multiple cameras. Traditional tracking‑and‑detection pipelines demand heavy manual filtering, and even recent multimodal approaches such as using CLIP remain limited to shallow visual attributes (e.g., clothing color) and weak temporal reasoning. This makes forensic search labor‑intensive.x000Dx000DWe present ForeSea, a novel AI forensic search system that supports rich multimodal queries (text + image) and returns timestamped evidence of key events. ForeSea is organized as a multi‑stage pipeline that couples tracking and retrieval with time‑aware VideoLLM reasoning: (1) uses tracking model to filter out irrelevant segments (e.g., frames without people) and produces person‑centric clips; (2) retrieval constructs an index over tracked clips to form a searchable database; and (3) during inference, the multimodal query is embedded to retrieve the top N candidate clips, which are then fed into a time-aware VideoLMM that performs temporal grounding and generates precise answers from concise input. Through ForeSea's multi-stage pipeline, we can search for targets using both image and text queries (e.g., asking 'When does this person get involved in a fight?' with an image of the person). This approach eliminates the need for detailed textual descriptions and enables effective temporal understanding across long videos.x000Dx000DTo evaluate LMM based forensic search, we introduce AI Forensic‑QA, a benchmark for multimodal video question answering with temporal grounding. On this benchmark, ForeSea achieves an 8.6 % accuracy improvement and a 6.9 (IoU) gain over strong baselines. To the best of our knowledge, this is the first benchmark in this domain to support multimodal queries evaluation. Our live demo showcases multimodal search, timestamped evidence visualization, and side‑by‑side comparisons with SOTA models.",
TUE 2 DEC,noon,Expo Demonstration,Efficient LiDAR Processing with AI Models Leveraging Heterogeneous Compute,https://neurips.cc/virtual/2025/128633,,3:00 PM,"This demo showcases heterogeneous compute execution of a LiDAR model running in real time on an edge device. The LiDAR processing, specifically 3D sparse convolution (spconv3d) network, runs on the Qualcomm Adreno GPU, while the Region Proposal Network (RPN) executes on the Qualcomm Hexagon NPU.  This division of labor across specialized processors reduces on-device inference latency and maximizes overall efficiency. Additionally, a lightweight, learnable voxel removal layer that hierarchically prunes redundant voxels further reduces inference time without compromising detection accuracy.x000Dx000D""This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.""x000Dx000DImplementation challenge that we tacklex000Dx000DLiDAR models often combine different types of operations: irregular, sparse computations (e.g., SpConv3D) and dense convolutional layers (e.g., CNNs). These operations have distinct hardware affinities—SpConv3D is better suited for SIMT-style GPUs, while CNNs benefit from SIMD-style NPUs. Efficient execution requires mapping each part of the model to the most appropriate compute unit.x000Dx000DAnother challenge is the variability in voxel density across LiDAR frames. Not all voxels contribute meaningfully to object detection, many represent ground planes or distant background and can be safely discarded. However, identifying and removing these in a lightweight, learnable way is non-trivial.",
TUE 2 DEC,noon,Expo Demonstration,Parallel generation with verification on device,https://neurips.cc/virtual/2025/128634,,3:00 PM,"In this work, we address the challenges of efficiently generating and verifying multiple responses from large language models (LLMs) directly on device. While sampling with non-zero temperature often yields improved responses compared to greedy approaches, selecting the best response requires generating several candidates and evaluating them without incurring significant latency or resource overhead. Cloud-based solutions often rely on separate verification models, which are impractical for on-device deployment due to resource constraints. Our proposed solution leverages multi-stream execution graphs and parallel LLM generation, enabling joint generation and verification within a unified framework. Combined with post-processing techniques such as majority voting, this approach minimizes latency and optimizes the selection of high-quality responses, paving the way for more effective on-device LLM inference.x000Dx000DSpecific challenge that we tackle (research/implementation-wise)x000Dx000DUsing non-zero temperature sampling with language models can result in higher-quality responses compared to greedy sampling, although this is not always assured. Achieving optimal output often requires generating multiple candidate responses and selecting the most suitable one for the user. This technique is widely adopted to enhance inference-time performance. When implemented on device, however, it presents two primary challenges: minimizing the latency associated with generating several responses and determining a resource-efficient method for selecting the best response from the generated set.",
TUE 2 DEC,noon,Expo Demonstration,Soft Prompts for On-Device Content Moderation,https://neurips.cc/virtual/2025/128635,,3:00 PM,"We demonstrate the first on-device integration of a safety-aligned large language model (LLM) using soft prompt distillation, powered by our proposed TV-DiSP framework. Our system showcases how a mobile device can run a quantized LLM equipped with learned soft prompts to moderate harmful or toxic content in real-time. The demo highlights the difference in LLM outputs with and without our soft prompts when subjected to adversarial or unsafe inputs, enabling efficient and safe deployment of LLMs on edge devices.x000Dx000DLLMs are known to produce unsafe or toxic outputs when prompted harmfully. Traditional safety mechanisms rely on dual-model architectures—pairing a base LLM with a separate guard model—which are memory and computationally expensive and unsuitable for deployment on resource-constrained devices like smartphones. The challenge is to achieve robust safety alignment without compromising latency, memory, or model utility in edge environments.",
TUE 2 DEC,noon,Expo Demonstration,Generating group photos of multiple people from text and reference images,https://neurips.cc/virtual/2025/128636,,3:00 PM,"Reference-based multi-human image generation is emerging as a critical capability for personalization, synthetic data creation, and benchmarking generative models. Unlike single-subject generation, this task requires compositional reasoning to place multiple individuals—each with distinct identities—into a coherent scene guided by a text prompt. Existing models often fail to preserve identities or maintain spatial fidelity, which limits their applicability for real-world scenarios such as social content creation or training vision systems.x000Dx000DOur demo addresses these challenges by showcasing a state-of-the-art system for reference-based multi-human generation. The system takes reference images of multiple individuals and a text description of the desired scene, then produces a high-quality image featuring all participants in context. Built on the Flux-Kontext backbone and trained using synthetic data from DisCo (arXiv:2510.01399), our RL-based approach optimizes multiple rewards including Human Preference Score (HPS3) and Average ID Similarity. Evaluation on MultiHuman-Testbench (arXiv:2506.20879) confirms state-of-the-art performance.x000Dx000DThis demo showcases fast generation on a laptop powered by a Snapdragon processor, highlighting the efficiency and scalability of our solution.",
TUE 2 DEC,noon,Expo Demonstration,Reasoning through Multimodal End-to-End Decision Transformer Networks and Vision Language Action (VLA) models,https://neurips.cc/virtual/2025/128637,,3:00 PM,"This demonstration showcases the live output and visualization capabilities of an edge-integrated VLA model for path planning in automated driving scenarios. By harnessing raw multimodal sensor inputs, including visual and voice data, the VLA model processes information in real time to generate safe, explainable, and repeatable driving trajectories. The system operates on a Snapdragon Ride Elite SoC platform and incorporates safety guardrails, enabling robust decision-making and transparent reasoning. Attendees will observe how end-to-end AI networks interpret complex environmental cues to deliver actionable driving paths, with a special focus on complex use cases involving vulnerable road users and other actors on the road. This demonstration highlights advances in multimodal reasoning and edge deployment for next-generation intelligent mobility solutions.",
TUE 2 DEC,noon,Expo Demonstration,Disaggregated LLM Serving on AI Accelerators,https://neurips.cc/virtual/2025/128638,,3:00 PM,"This demo showcases disaggregated serving on Qualcomm Cloud AI 100 Ultra Card, a power-efficient AI inference accelerator purpose-built for large language models (LLMs) serving. The accelerator has been deployed across multiple cloud service providers (CSPs) globally and is actively serving state-of-the-art LLMs and other generative AI workloads.x000Dx000DLLM inference typically involves two distinct stages: prefill and decode. The prefill stage is compute bound, while the decode stage is memory bound. Applying uniform parallelism strategies across both stages often results in suboptimal performance, particularly in key metrics such as Time to First Token (TTFT) and Requests Per Minute (RPM) at the cluster level.x000Dx000DThis demo highlights the performance benefits of disaggregated parallelism strategies tailored to the unique characteristics of each stage. By optimizing the execution of prefill and decode independently, we demonstrate significant improvements in TTFT and overall throughput.x000Dx000DKey benefits:x000Dx000DImproved TTFT: Faster initial response times for LLM queries.x000Dx000DHigher throughput: Increased number of requests served per minute at the cluster level.x000Dx000DOptimized resource utilization: Efficient mapping of compute and memory resources to match workload characteristics.x000Dx000DSLA-adherent performance: Maintains service quality and responsiveness within strict latency and throughput requirements.",
TUE 2 DEC,noon,Expo Demonstration,SwiftEdit: Fast Text-guided Image Editing via One-step Diffusion on a Mobile Device,https://neurips.cc/virtual/2025/128639,,3:00 PM,"In this demo, we show an on-device inference of our one-step diffusion image editing model (SwiftEdit) [1] that performs interactive image editing based on the user’s source image and text prompt, running on an Android smartphone powered by Qualcomm Technologies’ latest Snapdragon Mobile Platform. On A100 GPUs, this technique can run in real-time with 0.23s per single edit operation. We expect SwiftEdit to perform each edit operation in seconds on the smartphone, demonstrating efficient and responsive on-device diffusion inference.x000Dx000DScientific Challenge that we tacklex000Dx000DExisting text-guided image editing methods fell short of the speed demands required for real-world and on-device applications due to the costly multi-step inversion and sampling process involved. In response to this, we developed SwiftEdit that performed image editing using just one-step inversion and one-step image reconstruction.x000Dx000DEfficiently running SwiftEdit requires concurrently on-boarding multiple deep models, including IP-Adapter (Vision Encoder and Image Projection), SwiftBrush (U-Net, VAE, Text Encoder), and SwiftBrush-based Inversion Network. This poses significant challenges for efficient execution and inter-module communication, while enabling an interactive image editing experience for the user — with all computation performed entirely on the edge device.",
TUE 2 DEC,noon,Expo Demonstration,Mobile Video Diffusion Transformers,https://neurips.cc/virtual/2025/128640,,3:00 PM,"We demonstrate Neogradon, the first video diffusion transformer (DiT) designed to run on low-power NPUs in mobile devices, such as phones and laptops. Despite DiTs huge memory and computation cost due to the quadratic attention over thousands of video tokens, we show that mobile devices can run these models when being designed for efficiency. To achieve this level of efficiency:x000Dx000DWe replace the original large text encoder with a much smaller one with minimal quality loss through our novel distillation framework, which doesn’t require any image or video data.x000Dx000DWe propose an asymmetric decoder distillation approach, which allows us to replace the native codec-latent-VAE decoder with a more efficient one, without disturbing the generative latent-space of the video generation pipeline.x000Dx000DWith our block pruning strategy, we remove entire blocks from the MMDiT denoiser based on their relative importance and recover the original performance through a two-stage distillation process.x000Dx000DWe reduce the diffusion sampling cost using our novel extended version of DMD (distribution matching distillation) for the pyramidal flow-matching objective.x000Dx000DNeodragon generates 49 frames of 640x1024 resolution within 7.6 seconds on the Qualcomm Hexagon NPU with the VBench total score of 81.61, setting a new state of the art for mobile video generation.x000Dx000D""This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.""",
TUE 2 DEC,noon,Expo Demonstration,Pushing the boundaries of chemical synthesis with RetroChimera,https://neurips.cc/virtual/2025/128641,,3:00 PM,"Retrosynthesis - the task of planning chemical reaction recipes to synthesize complex molecules - remains a bottleneck in the discovery of novel pharmaceuticals. We recently released RetroChimera - a model for predicting chemical reactions - which demonstrated robustness well outside of training distribution by transferring zero-shot to internal reaction data at a major pharmaceutical company. We also found that industrial organic chemists prefer predictions from RetroChimera over real patented reactions in terms of quality, revealing a high degree of alignment. In this demo, we will showcase the model, let attendees query it live, and show them how to interpret the results.",
TUE 2 DEC,noon,Expo Demonstration,BeeAI,https://neurips.cc/virtual/2025/128642,,3:00 PM,"The BeeAI Framework is an open-source project for building reliable AI agents that combine autonomy with control. Current agent frameworks focus primarily on prompting and orchestration, leaving critical questions of predictability and safety unaddressed. BeeAI fills this gap with a lightweight framework that enables developers to build agents whose reasoning abilities are preserved while execution is constrained by declarative, rule-based requirements. At the core of the framework is the RequirementAgent, a novel agent design that enforces deterministic, controlled behaviors across heterogeneous language models. With RequirementAgent, developers can ensure consistent and reliable execution patterns regardless of differences in model reasoning, tool-calling abilities, or stochastic variation. This approach provides practitioners with a unified abstraction layer that simplifies the deployment of complex AI systems into production settings. As an incubating Linux Foundation AI project, BeeAI is gaining adoption in open source and enterprise contexts as organizations seek robust ways to operationalize AI agents at scale. At NeurIPS EXPO, we will showcase BeeAI’s architecture, real-world use cases, and lessons learned from applying declarative control to agent autonomy.",
TUE 2 DEC,noon,Expo Demonstration,ContextForge,https://neurips.cc/virtual/2025/128643,,3:00 PM,"The rapid rise of autonomous AI agents across enterprises is creating a new class of security and governance challenges that are not adequately addressed with today’s technology. Context Forge MCP Gateway is an open-source, security-focused middleware that provides fine-grained control and extensibility for agent operations. With over 2.6k GitHub stars and a rapidly growing user community, Context Forge addresses emerging threat classes including prompt injection, data leakage, and misuse of sensitive resources. At its core, Context Forge introduces a plugin architecture modeled after Linux Security Modules, embedding reusable security hooks at critical points in agent execution (e.g., prompt handling, tool invocation, data transformation). This modular foundation enables organizations to enforce contextual policies at scale—ranging from PII redaction and provenance tagging to prompt injection detection and policy-based access control. With 39 plugins already available, Context Forge is establishing a standards-aligned ecosystem for securing agent workflows in real-world enterprise deployments. By blending research-driven design with open-source adoption it creates a practical path for organizations to advance agent trustworthiness, safety, and compliance.",
TUE 2 DEC,noon,Expo Demonstration,LLM-Powered Intelligent Data Engineering: From Workflow Design to Ingestion andQuality Assurance,https://neurips.cc/virtual/2025/128644,,3:00 PM,"Modern enterprises depend on efficient data engineering pipelines to unlock value from diverse and large-scale datasets. Yet, current processes for workflow design, schema ingestion, and data quality validation remain complex, error-prone, and dependent on technical expertise. This creates barriers for non-expert users, slows down development, and introduces risks of data inconsistency.x000Dx000DWe present a suite of LLM-powered frameworks that reimagine enterprise data engineering across three critical dimensions: (i) From Natural Language to Executable ETL Flows, enabling intuitive pipeline creation with natural language specifications and automatic operator/property inference, (ii) All You Can Ingest, an end-to-end schema mapping and transformation framework that unifies semantic alignment, code synthesis, and robust validation, and (iii) Quality Assessment of Tabular Data, a scalable approach for auto-generating interpretable quality rules and executable validators tailored to specific datasets.x000Dx000DTogether, these innovations demonstrate how Large Language Models (LLMs), augmented with retrieval, code synthesis, reasoning, and guardrails, can transform the data engineering lifecycle into a more accessible, adaptive, and trustworthy process, reducing manual effort, accelerating time-to-value, and ensuring data fidelity at enterprise scale.",
TUE 2 DEC,noon,Expo Demonstration,ALICE: Agentic Logic for Incident and Codebug Elimination,https://neurips.cc/virtual/2025/128646,,3:00 PM,"Modern incident root-cause analysis (RCA) is constrained by partial observability, symptom-centric signals, and the overwhelming noise present in logs, traces, and metrics. Diagnosing production failures often depends on instrumentation quality and human expertise, while latent software defects, configuration errors, and zero-day failure modes remain difficult to pinpoint. To address these challenges, we demonstrate a multi-agent system for incident diagnostics that augments observability data with application source code and static analysis signals.x000Dx000DOur system introduces two cooperating agents: the Code Context Agent (COCOA), which builds a knowledge graph of program dependencies, control/data flows, and caller–callee relationships; and the Incident Diagnostics Agent (IDA), which performs agentic reasoning over an entity topology graph enriched with observability streams. Together, these agents extend topology-aware planning (TAP) to simultaneously operate on program dependency graphs and infrastructure entity graphs, thereby linking runtime symptoms with underlying code-level causes.x000Dx000DThis demo showcases how multi-agent collaboration enables deeper, context-sensitive RCA. We walk through real-world inspired scenarios—including incidents where critical log lines are hidden in noisy observability streams or where latent defects emerge only after system updates—illustrating how the system surfaces root causes that would otherwise remain invisible. By bridging program analysis with runtime observability, our approach moves beyond symptom-driven diagnostics toward a more reliable, automated framework for incident management.",
TUE 2 DEC,noon,Expo Demonstration,AI or Human,https://neurips.cc/virtual/2025/128647,,3:00 PM,"This demo from Sound Patrol will ask the audience to guess whether content is AI or Human, challenging the limits of human perception while showcasing an audio foundation model with multiple task heads, fine-tuned to classify and attribute the source of AI content",
TUE 2 DEC,noon,Expo Demonstration,Who Needs Attention Anyway? Real-Time Control from Learned State Geometry,https://neurips.cc/virtual/2025/128648,,3:00 PM,"Large language models changed how we reason with data, not how we act under constraints. Their latency grows with context, adaptation depends on retraining, and safety is emergent rather than measurable. For robots, simulators, and industrial systems that must react now, this compute model is the wrong fit.CurvOS offers an alternative: a real-time operating layer where streaming state-space models (SSMs) meet geometry and reinforcement learning to deliver stable, on-device intelligence. At its core, CurvOS runs a fast streaming SSM coupled to a local Riemannian planner derived from decoder sensitivities. Each step predicts the next state, estimates local curvature (how small perturbations bend predicted dynamics), and moves a short distance along a geodesic within a trust radius.Compute per step stays fixed, so latency and adaptation remain bounded. Unlike streaming SSMs such as Mamba, CurvOS learns geometry online to steer predictions safely without retraining. The result is a compact, measurable control stack that reasons in real time, adapts continuously, and meets physical or chemical objectives under fixed budgets. CurvOS turns sequence models into predictable decision engines for systems where timing and safety matter most.",
TUE 2 DEC,noon,Expo Demonstration,"PRIME Guardrails in Action: A Live Demonstration of an Agentic, Multi-Layered Safety Framework for Generative AI",https://neurips.cc/virtual/2025/128650,,3:00 PM,"The rapid proliferation of large-scale Generative AI systems has created an urgent need for safety frameworks that are both robust and performant. Existing solutions often present a false dichotomy: simple, low-latency filters that are easily circumvented by adversarial inputs, or powerful, semantically-aware models that introduce prohibitive latency for real-time applications. This demonstration introduces a live, practical instantiation of the PRIME (Policy, Risk, Intervention, Monitoring, Evaluation) framework, a novel, modality-agnostic architecture designed to resolve this trade-off. We will showcase a production-grade, multi-layered “Defense in Depth” safety system that utilizes an agentic workflow to intelligently orchestrate heterogeneous guardrail models. The system combines the deep contextual reasoning of large proprietary models (e.g., Google’s Gemini) for nuanced threat assessment with the speed of specialized, open-source classifiers for rapid, early-exit filtering of common violations. Through a series of live, interactive examples, we will demonstrate the system's ability to detect and neutralize a range of adversarial inputs in real-time across both text and image modalities. Attendees will witness the framework successfully identifying and blocking prompt injection attacks, harmful content requests, and policy violations, thereby proving the efficacy of a hybrid, agentic approach to building safer, more trustworthy Generative AI experiences at scale.",
TUE 2 DEC,noon,Expo Workshop,Creative and Protective AI for Music and Entertainment,https://neurips.cc/virtual/2025/128679,,1:30 PM,"Generative AI is reshaping how we create, experience, and safeguard music and entertainment. This workshop presents technologies that expand creative expression while honoring responsibility. On the creative side, we share collaborative artworks with leading sound artists, neural engines for sound design and performance, and automatic mixing that adapts to musical intent. We also present a large multimodal dataset for multishot speech video that supports research on coherent and controllable speech, together with specialized language models that orchestrate camera transitions, gestures, vocal cues, and sound effects. On the protective side, we advance AI methods for data attribution, traceability, and responsible model behavior that safeguard creative data and prevent unintended memorization, ensuring fairness, transparency, and respect for creators’ rights. Together, these threads outline an ecosystem in which AI amplifies artistic practice while preserving the integrity of human contribution.",
TUE 2 DEC,noon,Expo Workshop,Large-Scale Real-World Physical AI Systems,https://neurips.cc/virtual/2025/128672,,1:30 PM,"Motivation and Scopex000Dx000DPhysical AI systems comprise of four things: namely sensors like cameras and lidar, mechanical and electronic control unit, AI models to reason about the environment, and actuators to convert decisions to physical actions. It marries multiple domains like sensor design, perception, low-power real-time hardware design, and control loop action design. Autonomous driving is the most mature physical AI domain deployed for over 10 years, but it still has many open challenges. Humanoid robots are an emerging physical AI domain with potential for near term commercial deployment. One of the major challenges in physical AI is to scale to all real-world scenarios including corner cases in a safe manner. A scalable AI data flywheel is the most critical module to achieve this. Traditional physical AI models have a modular decomposition of perception and action tasks, but the community is increasingly moving towards a single end-to-end AI model.  Furthermore, recent advancements in LLMs and VLMs are leading to VLA (Vision-Language-Action) based end-to-end models. In the future, there will likely be a convergence of physical AI models across different domains like driving and robotics.  The proposed workshop covers the latest research and best practices in industrial research of physical AI by leaders in the domain. It also covers emerging technologies like VLA based foundation models, AI data flywheel, and cross-embodiment learning focused on Physical AI.",
TUE 2 DEC,noon,Expo Workshop,Checkmate: Fine-tune your own small language model for real-time chess reasoning and gameplay on AWS Trainium,https://neurips.cc/virtual/2025/128680,,1:30 PM,"In this hands-on workshop, participants will leverage AWS Trainium to fine-tune and deploy their own chess-playing language models. Building on recent research showing language models' effectiveness in reasoning, attendees will work with various chess datasets to create AI models that not only play chess but explain their strategic thinking through natural language. The 90-minute session will cover model fine-tuning techniques, optimization strategies specific to Trainium's architecture, and real-time deployment to a chess engine. The workshop culminates in a live tournament where participants' models compete against each other, providing immediate feedback on their implementations. Participants will leave with a working chess reasoning model, practical experience in fine-tuning language models on Trainium, and transferable skills for similar tasks. Python programming experience and familiarity with LLM concepts are required, in addition to a basic understanding of the rules of chess. Workshop materials and AWS credits will be provided.",
TUE 2 DEC,noon,Expo Workshop,Workshop on multimodal Superintelligence,https://neurips.cc/virtual/2025/128681,,1:30 PM,"Multimodal machine learning is among the most promising directions of artificial intelligence. With remarkable progress in academia and industry on this topic, we are at the cusp of building next-generation multimodal models, i.e. multimodal superintelligence. These models can be defined as being able to observe, think, and act across several modalities. At this important junction, our workshop provides a forum for researchers to align and cross-polinate ideas. The Workshop on Multimodal Superintelligence will provide a venue where the community can gather to discuss the current state of multimodal machine learning science. Together, we will attempt to overcome the current barriers of modeling several modalities at once. We will also focus on topics such as cross-modal reasoning, alignment, fusion and co-learning.",
TUE 2 DEC,noon,Expo Demonstration,Interpretable AI for Risk-Based Human Rights Assessment in Global Supply Chains,https://neurips.cc/virtual/2025/128649,,3:00 PM,"Amazon’s responsible sourcing efforts aim to protect people across its global supply chain. Yet detecting human rights risks such as forced labor or unsafe conditions across hundreds of thousands of suppliers is challenging. Auditing every site is costly and impractical, making a risk-based approach essential focusing resources where the likelihood and severity of issues are greatest. To address this, Amazon developed PRISM AI (Predictive Risk Intelligence for Supplier Management), an interpretable machine learning system that predicts and explains supplier-level risk across global supply chains. Trained on over 70,000 internal and third-party audit records, PRISM integrates signals from self-assessment questionnaires, grievance reports, adverse media, and geo-sector risk indices. These inputs help detect both documented and emerging risks in near real time. The model supports three supplier types: those with audit histories, limited data, or none. It adapts using transfer learning, rule-based heuristics, and domain-specific indicators. Each prediction includes transparent attribution, showing which factors such as safety violations or country-sector exposure, most influenced the score. Built with monotonic constraints, the system ensures logically consistent, explainable outputs for regulatory and operational use.x000DThis demo gives NeurIPS participants a hands-on view of how AI research can be operationalized for real-world impact. Already in production at Amazon, PRISM helps compliance teams prioritize audits, onboard suppliers, and escalate risks thereby reducing review time and improving oversight. For researchers, it highlights methods for building interpretable models under data imbalance and integrating structured and unstructured signals. For practitioners, PRISM shows how AI can scale responsible business practices and drive innovation across environmental and social sustainability domains.",
TUE 2 DEC,noon,Expo Demonstration,Build verifiable apps using Generative AI and Automated Reasoning,https://neurips.cc/virtual/2025/128651,,3:00 PM,"Recent advancements in Generative AI have enabled customers to use LLMs to generate infrastructure code using AWS CLI commands. Because humans can make mistakes, when deployed such LLM-generated infrastructure code can have negative impacts, including on security.x000DMotivated by this challenge, this demonstration introduces participants to automated reasoning tooling that enhanced security in production for Amazon Q chat.x000DAWS Q Chat enables natural language interaction with AWS resources while employing automated reasoning to verify every generated API call against comprehensive semantic logic models. This prevents potentially harmful operations before execution and suggests corrections, creating a feedback loop that iterates until verifiably correct code is produced. Through this work, we demonstrate how organizations can leverage GenAI's efficiency while maintaining the rigorous verification standards required for production environments and participants will learn how to integrate these tools into their workflows to prevent security regressions and ensure reliable infrastructure management. This tutorial Scientists, Engineers, Security professionals and anyone interested in applying formal verification to their infrastructure.",
TUE 2 DEC,noon,Expo Workshop,CausalFairness: An Open-Source Python Library for Causal Fairness Analysis,https://neurips.cc/virtual/2025/128677,,1:30 PM,"As machine learning (ML) systems are increasingly deployed in high-stakes domains, the need for robust methods to assess fairness has become more critical. While statistical fairness metrics are widely used due to their simplicity, they are limited in their ability to explain why disparities occur, as they rely on associative relationships in the data. In contrast, causal fairness metrics aim to uncover the underlying data-generating mechanisms that lead to observed disparities, enabling a deeper understanding of the influence of sensitive attributes and their proxies. Despite their promise, causal fairness metrics have seen limited adoption due to their technical and computational complexity. To address this gap, we present CausalFairness, the first open-source Python package designed to compute a diverse set of causal fairness metrics at both the group and individual levels. The metrics implemented are broadly applicable across classification and regression tasks (with easy extensions for intersectional analysis) and were selected for their significance in the fairness literature. We also demonstrate how standard statistical fairness metrics can be decomposed into their causal components, providing a complementary view of fairness grounded in causal reasoning. In this active learning talk participants will learn how to quantify bias using CausalFairness at the group (Counterfactual Equalized Odds , Counterfactual Effects) and individual (Counterfactual Fairness) levels by applying each method to three datasets - 1) the Adult Income dataset, 2) the COMPAS dataset, 3) Law School Admission Council (LSAC) Dataset. The session will elucidate on the intuition for computing and interpreting each metric, and conclude with a discussion of their limitations.",
TUE 2 DEC,noon,Expo Demonstration,Learning to Steer LLMs with AI Steerability 360 and In-Context Explainability 360,https://neurips.cc/virtual/2025/128645,,3:00 PM,"Current algorithms for aligning LLM behavior are often implemented for narrow settings, making it difficult for researchers and developers to understand their effectiveness across model architectures, datasets, and tasks. To help provide a more informed and principled approach to steering model behavior, we present the AI Steerability 360 (AISteer360) and In-Context Explainability 360 (ICX360) toolkits. Participants will first be guided through a conceptual overview for how model behavior can be influenced across four model control surfaces: input (prompting), structural (weights/architecture), state (activations/attentions), and output (decoding). After the conceptual overview, we will guide attendees through how to apply some recently developed explainability tools (from ICX360) for understanding why models produce given, potentially undesirable, outputs and how this information is used to design targeted steering inventions (via AISteer360). Closing the loop, we will evaluate if the baseline behavior (of the original, unsteered model) was successfully mitigated by the selected steering inventions and investigate if steering introduced any unintended behavioral side-effects. All of the experiments throughout the demonstration will be facilitated solely by the tools in the two toolkits, illustrating their power to design end-to-end steering workflows. Attendees will come away with a practical understanding of how to apply these toolkits to their own alignment challenges.",
TUE 2 DEC,noon,Expo Workshop,Introduction to Generative Computing,https://neurips.cc/virtual/2025/128678,,1:30 PM,"This hands-on workshop introduces a proposal that treats LLMs as computing elements governed by established software development principles—particularly task decomposition and modularization—at both the programming model (Mellea) and model level (LLM intrinsics).x000Dx000DLLM outputs are often unpredictable and incorrect. Agentic frameworks and prompt optimization libraries attempt to manage this by giving control to the LLM, but this leads to systems that are hard to debug, maintain, and scale. Mellea offers an alternative: a programming model that restores developer control through modular design, information hiding, and compositional contracts. This enables predictable fault models, better portability, and lower inference costs. Attendees will gain hands-on experience building applications using the Melleaic approach.x000Dx000DExtending these principles to the model level, the workshop introduces a modularization framework for LLMs using activated LoRAs. These produce components—LLM intrinsics—that match fine-tuned model accuracy for specific tasks but with significantly lower inference costs and latency, thanks to KV cache reuse. Participants will build applications using a pre-built library of RAG LLM intrinsics and learn how to train their own.x000Dx000DPresented by the creators of Mellea and the inventors of LLM intrinsics and aLoRA, this workshop equips attendees with foundational skills for scalable model/application co-design.",
TUE 2 DEC,noon,Expo Workshop,Exploring Trust and Reliability in LLM Evaluation,https://neurips.cc/virtual/2025/128673,,1:30 PM,"The current paradigm of Large Language Model (LLM) evaluation faces a crisis of reliability. Traditional leaderboards—built on static benchmarks and surface-level metrics—have become increasingly distorted by benchmark contamination, prompt overfitting, and evaluation methodologies that fail to reflect model behavior in real-world use. As reasoning models emerge that generate detailed internal thought processes (e.g.,traces) before producing answers, existing evaluation practices—especially for multiple-choice and generation tasks—have become fundamentally inadequate.x000Dx000DThis lack of rigor not only undermines scientific progress and cross-model comparability, but also poses significant enterprise and societal risks, as evaluation results inform model selection, deployment safety, and governance in high-stakes environments.x000Dx000DThis workshop aims to reassert rigor in LLM evaluation by convening researchers and practitioners to address three intertwined challenges: (1) developing fair and consistent evaluation methods for reasoning and non-reasoning models, (2) confronting widespread contamination across public benchmarks and open-weight models, and (3) defining robust data curation and validation practices to prevent future contamination in both pretraining and post-training pipelines.x000Dx000DBy combining empirical findings, methodological advances, and practical case studies, this session—led by Capital One in collaboration with leading AI labs—seeks to chart a concrete path toward trustworthy, contamination-proof, and utility-aligned LLM evaluation frameworks.x000Dx000DThis 1.5-hour workshop will be structured around three highly focused, 25-minute talks, followed by a moderated discussion aimed at forging actionable paths forward for the community:x000Dx000DTalk 1: Robust Evaluation for Reasoning & Non-Reasoning Modelsx000Dx000DTalk 2: Benchmark Contamination — Detection, Measurement, & Findingsx000Dx000DTalk 3: Preventing Contamination — Building Clean & Reliable Data Pipelines",
TUE 2 DEC,1:30 p.m.,Tutorial,Foundations of Imitation Learning: From Language Modeling to Continuous Control,https://neurips.cc/virtual/2025/109590,,4:00 PM,,
TUE 2 DEC,1:30 p.m.,Tutorial,Scale Test-Time Compute on Modern Hardware,https://neurips.cc/virtual/2025/109595,,3:00 PM,,
TUE 2 DEC,1:30 p.m.,Tutorial,Autoregressive Models Beyond Language,https://neurips.cc/virtual/2025/109587,,3:00 PM,,
TUE 2 DEC,1:30 p.m.,Tutorial,"Recent Developments in Geometric Machine Learning: Foundations, Models, and More",https://neurips.cc/virtual/2025/109600,,3:00 PM,,
TUE 2 DEC,1:30 p.m.,Tutorial,Theoretical Insights on Training Instability in Deep Learning,https://neurips.cc/virtual/2025/109597,,3:00 PM,,"Overview: The NeurIPS 2025 tutorial titled 'Theoretical Insights on Training Instability in Deep Learning' explores the oscillatory, spiky, and unstable nature of the optimization process in deep learning. This tutorial aims to provide theoretical insights into the benign nature of these training instabilities, offering perspectives from both optimization and statistical learning. The work challenges classical optimization theory by demonstrating that the best training configurations often operate in unstable regimes. | Research Interests: Gradient-based optimization, Training instability in deep learning, Large stepsizes in optimization, Statistical learning perspectives, Benign nature of instabilities, Optimization efficiency, Overfitting prevention, Implicit bias in optimization, Edge of stability in gradient descent | Key Findings: The tutorial highlights that large stepsizes can accelerate optimization and prevent overfitting, providing a new understanding of the implicit bias and stability in deep learning models. It also discusses the role of training at the edge of stability and how it can lead to efficient optimization and generalization."
TUE 2 DEC,1:30 p.m.,Tutorial,"The Science of Benchmarking: What’s Measured, What’s Missed, and What’s Next",https://neurips.cc/virtual/2025/109598,,3:00 PM,,
TUE 2 DEC,1:30 p.m.,Tutorial,"Data Privacy, Memorization, & Legal Implications in  Generative AI: A Practical Guide",https://neurips.cc/virtual/2025/109588,,3:00 PM,,
TUE 2 DEC,4 p.m.,Expo Talk Panel,Recent developments in embodied AI,https://neurips.cc/virtual/2025/128653,,5:00 PM,"Embodied AI is the study of systems that can perceive and interact with the physical world in real time. Real-world interactions pose unique challenges for AI systems since they naturally require a deep understanding of the physical world and/or its inhabitants. This understanding is often taken for granted in humans, where it is typically labelled as “intuitive physics” or “common sense”.x000Dx000DIt is widely agreed that solving this challenge would be as rewarding as it is hard, since it would be equivalent to creating truly capable “world models”, with countless applications in robotics, human-computer interaction, and even in advancing language modeling through concept grounding. Like other areas in AI, embodied AI has seen dramatic advances in recent years, fueled by the success of using pre-trained large language models as a central ingredient to allow for end-to-end training. While this development stands as one of many examples of the power of pre-trained language models, recently the converse has come true as well: embodied AI is increasingly being drawn on to understand real-world common sense and concept grounding in language models themselves, bringing back its early vision as a way to understand human-like cognition and world models.x000Dx000DThis talk will provide an in-depth discussion of embodied AI, with a focus on recent advances based on multi-modal large language models. It will discuss how end-to-end training has made it possible to instill key aspects of real-world common sense in a model and how this had enabled highly ambitious use-cases, such as generalist (“common sense”) robot control and real-world visual interaction (“chatbots that can see and hear you”). The talk will also discuss practical considerations, such as streaming inference at the edge, end-to-end training data generation and the role of reinforcement learning, as well as open challenges in state tracking and long-term memory.",
TUE 2 DEC,4 p.m.,Expo Talk Panel,Distributed Orthonormal Updates for Large-Scale Training,https://neurips.cc/virtual/2025/128655,,5:00 PM,"We propose a 50-minute technical talk on recent advances in orthonormal update methods for large-scale AI model training. This topic is rapidly gaining attention in the community, emerging as a strong successor to AdamW following the success of orthonormal optimizers in training production-scale models such as Kimi-K2 and GLM-4.5.x000DThe talk will center on the design and practice of orthonormal updates, focusing on optimizers such as Muon and Dion. While we will briefly discuss their theoretical foundations, the emphasis will be on practical usage: how to integrate these optimizers into modern training pipelines, interpret their algorithmic components, and leverage the implementation guidelines provided in our open-source codebase at github.com/microsoft/dion.x000DThe talk is designed to engage both researchers and practitioners in the NeurIPS community:x000DAcademic perspective: presents a new class of optimizers grounded in theory along with how they interact with distributed training.x000DIndustrial perspective: highlights how orthonormal updates are implemented in practice and what best practices are.x000DThis topic lies   at the intersection of optimization theory, scalable systems, and large-model training—an area of growing importance for both the research and applied machine learning communities.",
TUE 2 DEC,4 p.m.,Expo Talk Panel,Ling 2.0 and Ling-1T: Scaling Knowledge-Enhanced Large Language Models for Reasoning and Efficiency,https://neurips.cc/virtual/2025/128657,,5:00 PM,"The Ling 2.0 series represents a new generation of large language models designed around knowledge enhancement, reasoning efficiency, and scalable architecture innovation. Built upon trillion-scale sparse MoE foundations, Ling-1T achieves ~50B active parameters per token with FP8 mixed-precision pipelines and 1F1B interleaved scheduling, realizing over 40% training-throughput gains with negligible accuracy loss (<0.1%).x000DThis talk presents the technical journey behind Ling-mini, Ling-flash, and Ling-1T, focusing on (1) efficient large-scale training systems for trillion-parameter models; (2) the Ling Scaling Law and its implications for cross-domain reasoning; (3) hybrid attention and RL-based alignment strategies that enable both concise reasoning and long-context understanding; and (4) how these architectural and algorithmic advances empower industrial applications such as financial risk modeling and knowledge-grounded agents.x000DWe will conclude with open-sourced implementations (inclusionAI on Hugging Face and ModelScope) and future research directions toward trustworthy, efficient, and domain-enhanced LLMs.",
TUE 2 DEC,4 p.m.,Expo Talk Panel,Agentic AI/RL,https://neurips.cc/virtual/2025/128662,,5:00 PM,"The transition from static language models to agentic AI systems driven by reinforcement learning (RL) places environments at the center of research and deployment. Environments provide the substrate where agents act, learn, and are evaluated—ranging from lightweight simulators and synthetic tasks to rich multi-agent ecosystems and real-world interfaces. Building and scaling these environments requires specialized tools and systems: standardized hubs for discovery and sharing, interfaces for reproducibility, and infrastructure that connects environments seamlessly to trainers, inference engines, and evaluation pipelines.x000Dx000DThis workshop will highlight the tools, environments, and system innovations enabling the next generation of agentic AI. Topics will include scalable RL environment frameworks, benchmarks for safety and robustness, high-performance simulators optimized for heterogeneous hardware, and environment–trainer integration at scale. We will also explore how environments interface with large-model post-training workflows, providing the data and feedback loops necessary for reward shaping, alignment, and deployment in production systems.x000Dx000DBy convening researchers, environment developers, and systems engineers, the workshop will create a venue to examine how environments, tools, and infrastructure together shape the future of agentic AI.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DPyTorch native RL and agentic development at scalex000DEnvironments for everyone - how open environments can democratize RL post training at scalex000DSafety in the new era of Agents",
TUE 2 DEC,4 p.m.,Expo Talk Panel,"Neural Arms Race: Authenticity, Infringement Analysis, and Attribution in the Age of AI Music",https://neurips.cc/virtual/2025/128669,,5:00 PM,"The same neural architectures powering music generation have become critical infrastructure for content moderation—creating a technological arms race where AI both threatens and protects creative rights. This talk presents Sound Patrol's production-scale response across three dimensions: (1) Authenticity Detection: Analyzing AI content in the wild begins with binary classification—was a given song created by AI or humans? Using MuQ and ResNet backbones with auxiliary task heads, we show how careful dataset construction and model ensembling enables attribution of when AI was used, where in a track (vocal vs instrumental), and which genAI platform generated it. (2) Infringement Analysis: Once identified as AI, content requires infringement screening. We combine singer deepfake detection via RawNet3, Burrows-Wheeler alignment-derived comparisons of MIDI transcripts, lyrics analysis via a combination of neural embeddings and LLMs, and neural fingerprinting achieving 88%+ accuracy under adversarial transforms. These analyses are orchestrated through dynamic expert routing, enabling sophisticated tagging and automated musicology reports. (3) Attribution Framework: We end with a pragmatic discussion of what it means for a piece of training data to influence a model output. We propose a set of principles guiding how fractional royalty models could be derived by examining prompts, training sets, and model outputs. Drawing from production deployments and industry evaluations, we offer the NeurIPS community technical blueprints for turning this arms race into equitable innovation—exploring how the same AI enabling infringement might ensure fair compensation to the artists whose work powers it all.",
TUE 2 DEC,4 p.m.,Expo Talk Panel,Building an AI Ecosystem for Multiscale Biological Discovery,https://neurips.cc/virtual/2025/128658,,5:00 PM,"Understanding biological systems requires resolving their structure and organization across scales, from tissues to individual molecules. Advances in imaging and molecular profiling now generate vast multimodal datasets that capture biological architecture and dynamics with unprecedented fidelity. Unlocking insights from this data demands computational approaches capable of linking observations across spatial, temporal, and molecular dimensions.At the Chan Zuckerberg Imaging Institute (CZII), we are building the infrastructure, datasets, and community connections to enable this transformation. Our cryo-electron tomography (cryoET) processing pipeline supports high-throughput reconstruction and standardized metadata integration, forming the foundation for reproducible, machine-learning–ready datasets. The CryoET Data Portal (cryoetdataportal.czscience.com) provides open access to raw data, reconstructions, and curated annotations contributed by leading structural biology labs worldwide. Its programmatic API tools support segmentation, particle picking, and model benchmarking, creating a foundation for AI-driven structural discovery.To catalyze progress in automated molecular identification, the CZ Imaging Institute recently organized a Kaggle challenge inviting participants to develop models for detecting and labeling macromolecular complexes in real-world cryoET data. Building on this success, upcoming challenges organized by the CZI & CZ Biohub Network will extend this approach to datasets spanning different biological scales, from tissue architecture and cellular organization to subcellular and molecular structure.Together, these efforts form an open, interoperable ecosystem for machine learning in biological imaging. By combining standardized data infrastructure, scalable computation, and community-driven innovation, we aim to bridge the worlds of imaging and AI and accelerate the discovery of life’s organization across all scales.",
TUE 2 DEC,4 p.m.,Expo Talk Panel,Building Foundational Models for Robotics at Tesla,https://neurips.cc/virtual/2025/128654,,5:00 PM,"Tesla's robots, both wheeled and legged, are developed with the goal of achieving general-purpose capability, analogous to the versatility observed in humans and animals. These systems rely primarily on scalable sensing modalities such as vision, audio etc, enabling robust performance within stringent power and cost constraints.x000Dx000DThis talk will describe the principles and methodology behind constructing foundation models for robotics at Tesla. We will discuss the architecture, data and training of large-scale multimodal models that control these robots in an end-to-end pixels-to-actuation fashion. We will also examine evaluation protocols, safety considerations, and strategies for reliable real-world deployment. Finally, we project the transformational benefits to society that widespread deployment of such advanced robotic systems can deliver.",
WED 3 DEC,8:30 a.m.,Invited Talk,Rich Sutton_The Oak Architecture: A Vision of SuperIntelligence from Experience,https://neurips.cc/virtual/2025/invited-talk/109601,Rich Sutton,9:30 AM,"As AI has become a huge industry, to an extent it has lost its way. What is needed to get us back on track to true intelligence? We need agents that learn continually. We need world models and planning. We need knowledge that is high-level and learnable. We need to meta-learn how to generalize. The Oak architecture is one answer to all these needs. It is a model-based RL architecture with three special features: 1) all of its components learn continually, 2) each learned weight has a dedicated step-size parameter that is meta-learned using online cross-validation, and 3) abstractions in state and time are continually created in a five-step progression: Feature Construction, posing a SubTask based on the feature, learning an Option to solve the subtask, learning a Model of the option, and Planning using the option’s model (the FC-STOMP progression). The Oak architecture is rather meaty; in this talk we give an outline and point to the many works, prior and contemporaneous, that are contributing to its overall vision of how superintelligence can arise from an agent’s experience.",
WED 3 DEC,noon,Expo Workshop,"AI Assistants in the Wild: Agents, Adaptation, and Memory-Augmented Deployment",https://neurips.cc/virtual/2025/128671,,1:30 PM,"Motivation and Scopex000Dx000DGenerative AI is evolving from offline, single modality models into interactive agentic systems that perceive, decide, and act in the real world. This shift marks a transition from static generation to dynamic, context-aware interaction. As these systems move toward deployment on edge devices such as mobile phones, augmented reality glasses, and robots, they face constraints in compute, memory, and latency. Beyond efficiency and responsiveness, a new frontier is emerging: agents equipped with persistent memory that enables long-term adaptation and personalization.x000Dx000DThis workshop explores a timely and focused question. How do we build generative agents that are not only efficient and responsive but also able to accumulate, recall, and adapt based on personal memory over time? We aim to bring together perspectives from generative modeling, agentic learning, efficient model design, and memory systems to close the gap between lab scale prototypes and real-world deployment.x000Dx000DKey Themesx000DPersonal Memory Systems for AI Assistants: Architectures for persistent memory, retrieval-augmented generation, and long-term personalization.x000DReal-World Adaptation Few-shot generalization, continual learning, and task inference for evolving agent behavior.x000DGrounded and Trustworthy Generation: Techniques for hallucination mitigation, constraint-aware generation, and safety under uncertainty.x000DDeployment on Edge Platforms: Challenges and solutions for deploying generative agents on mobile, AR, and robotics platforms.x000Dx000DThis focused workshop aligns with emerging themes at NeurIPS including agentic learning, trustworthy AI, efficient multimodal generation, and embodied intelligence. It will spotlight the systems, algorithms, and design decisions needed to make generative AI truly adaptive and persistent, outside the data center and into the wild.",
WED 3 DEC,noon,Expo Workshop,On Device/Edge AI,https://neurips.cc/virtual/2025/128674,,1:30 PM,"From smartphones and wearables to autonomous vehicles, robots, and AR/VR systems, the demand for models that are efficient, private, and adaptive in real-time has never been higher. Yet deploying state-of-the-art AI at the edge remains challenging: researchers and practitioners must navigate heterogeneous hardware, memory and power constraints, compression and distillation trade-offs, as well as privacy, safety, and reliability requirements.x000Dx000DThis workshop will bring together researchers, practitioners, and industry leaders to explore the frontiers of Edge AI. Topics will include lightweight model architectures, compiler/toolchain optimizations (e.g., quantization, pruning, sparsity), advances in frameworks such as ExecuTorch and TensorRT, distributed learning across devices, privacy-preserving training, and emerging applications where latency and trust are critical. Beyond technical advances, we will examine the broader implications for democratizing AI—enabling billions of devices to act as intelligent, personalized agents while reducing dependence on the cloud.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DOptimized AI on iOSx000DLeveraging ExecuTorch as a platform for mixed reality at scalex000DReal-time reasoning at the edgex000DMamba and SSM running at the edge",
WED 3 DEC,noon,Expo Workshop,Multi-Agent Systems in Industry: From Research to Real-World Impact,https://neurips.cc/virtual/2025/128675,,1:30 PM,"This workshop will bridge the gap between the theoretical advancements in multi-agent systems and their practical applications in industry. The session will feature a series of poster presentations showcasing state-of-the-art, real-world multi-agent systems that are driving innovation across various sectors. We will delve into the challenges and opportunities of deploying these systems at scale, covering topics such as:x000DHuman-in-the-loop collaboration: Designing systems where AI agents and human experts work in synergy.x000DScalability and efficiency: Architecting multi-agent systems for large-scale industrial applications.x000DSafety and reliability: Ensuring the robustness and predictability of autonomous agents in critical systems.x000DDomain-specific applications: Highlighting successful implementations in areas such as software engineering, scientific research, and creative content generation.x000DThe goal of this workshop is to foster a discussion on the practical challenges and future directions of multi-agent systems, providing attendees with actionable insights and a deeper understanding of how these technologies are shaping the future of industry.",
WED 3 DEC,noon,Expo Workshop,Using the Virtual Cell Platform to Accelerate Machine Learning in Biology,https://neurips.cc/virtual/2025/128676,,1:30 PM,"Biology presents some of the most complex and high-impact challenges for machine learning, and single-cell transcriptomics is at the frontier of this work. In this workshop, we introduce the Virtual Cell Platform (VCP), a unified environment designed to accelerate model development and evaluation in biology. Using single-cell transcriptomics as a case study, we will demonstrate how the VCP enables researchers to train, benchmark, and interpret models in a reproducible and biologically meaningful way.

Participants will gain a primer on single-cell transcriptomics and learn how to evaluate models with cz-benchmarks, an open-source Python package providing standardized, community-driven tasks and metrics. Through the VCP CLI, attendees will pull datasets, run packaged models, and compare results programmatically. Hands-on exercises will guide participants through interactive visualizations, side-by-side model comparisons, and deep dives into model behavior using VCP’s no-code interface and BYOD (Bring Your Own Data) module.

By the end of the session, attendees will understand how to use the VCP to actively test and refine models during development, ensure biological relevance, and contribute models and benchmarks back to the community. This workshop highlights how the Virtual Cell Platform transforms ML infrastructure into a one-stop, researcher-friendly ecosystem, empowering the NeurIPS community to push the boundaries of AI in biology.",
WED 3 DEC,2:30 p.m.,Invited Talk,Are We Having the Wrong Nightmares About AI?,https://neurips.cc/virtual/2025/invited-talk/109606,Zeynep Tufekci,3:30 PM,"Though seemingly opposite, doom and optimism regarding generative AI's spectacular rise both center on AGI or even superintelligence as a pivotal moment. But generative AI operates in a distinct manner from human intelligence, and it’s not a less intelligent human on a chip slowly getting smarter anymore than cars were mere horseless carriages. It must be understood on its own terms. And even if Terminator isn’t coming to kill us or superintelligence isn’t racing to save us, generative AI does bring profound challenges, well-beyond usual worries such as employment effects.  Technology facilitates progress by transforming the difficult into easy, the rare into ubiquitous, the scarce into abundant, the manual into automated, and the artisan into mass-produced. While potentially positive long-term, these inversions are extremely destabilizing during the transition, shattering the correlations and assumptions of our social order that relied on superseded difficulties as mechanisms of proof, filtering, sorting and signaling. For example, while few would dispute the value of the printing press or books, their introduction led to such destructive upheaval that the resulting religious wars caused proportionally more deaths than all other major wars and pandemics since combined. Historically, a new technology's revolutionary impact comes from making what's already possible and desired cheap, easy, fast, and large-scale, not from outdated or ill-fitting benchmarks that technologists tend to focus on. As such, Artificial Good-Enough Intelligence can unleash chaos and destruction long before, or if ever, AGI is reached. Existing AI is good enough to blur or pulverize our existing mechanisms of proof of accuracy, effort, veracity, authenticity, sincerity, and even humanity. The tumult from such a transition will require extensive technological, regulatory, and societal effort to counter. But the first step to getting started is having the right nightmares.",
WED 3 DEC,4:30 p.m.,Expo Talk Panel,"Juries, Not Judges! Industry-Scale Evaluation of Trustworthy AI via Dynamic LLM Panels",https://neurips.cc/virtual/2025/128660,,5:30 PM,"As Large Language Models (LLMs) become central to high-stakes applications, the reliability of their evaluation systems is under intense scrutiny, especially in the financial industry. Traditional approaches - human annotation, single LLM judges, and static model juries - struggle to balance scalability, cost, and trustworthiness. We will discuss a promising framework: LLM Jury-on-Demand, a dynamic, learning-based framework that assembles an optimal panel of LLM evaluators for each task instance, leveraging predictive modeling to select and weight judges based on context-specific reliability. Our system adapts in real time, outperforming static ensembles and single judges in alignment with human expert judgment across summarization and retrieval-augmented generation benchmarks. This talk will showcase how adaptive LLM juries can transform evaluation of AI systems, offering robust, scalable, and context-aware solutions for industry and research. Attendees will gain practical insights into building trustworthy LLM evaluation pipelines, see live demos, and discuss future directions for reliable AI assessment in critical domains.",
WED 3 DEC,4:30 p.m.,Expo Talk Panel,"Frontier Open-Weight Models: Building Transparent, Secure, and Sovereign AI",https://neurips.cc/virtual/2025/128664,,5:30 PM,"The next generation of AI will be defined not just by scale, but by openness. As the frontier in model capabilities accelerates, researchers and enterprises alike face a critical question: how do we advance state-of-the-art intelligence while preserving transparency, control, and security?x000Dx000DThis panel brings together leaders from open research, industry, and infrastructure to explore the emerging ecosystem of open-weight frontier models—systems that can be fully run, audited, and customized within private or sovereign environments. Discussion topics will include the research challenges behind training and aligning open models at scale, implications for reproducibility and safety, and how open access can enable new forms of collaboration between academia, government, and enterprise.x000Dx000DAttendees will gain insight into how the open frontier movement is reshaping AI research culture, infrastructure design, and deployment strategy worldwide.",
WED 3 DEC,4:30 p.m.,Expo Talk Panel,The Co-X Framework: Versatile AI Agents for Automating and Augmenting Professional Workflows,https://neurips.cc/virtual/2025/128666,,5:30 PM,"Beyond monolithic models, the future of AI in industry lies in specialized agents that collaborate with human experts. This talk introduces the ""Co-X"" framework, a novel approach for creating a diverse ecosystem of collaborative agents tailored to specific professional domains. We will present four key agents built on this framework: the Co-AI Researcher, the Co-ML Engineer for automating software development cycles, the Co-Data Scientist for automating data analysis and insight generation, and the Co-Director for augmenting creative content generation. We will discuss the foundational technologies that enable this versatility—including long-term memory, tool use, and human-in-the-loop feedback—and demonstrate how the Co-X framework is poised to redefine productivity and innovation across industries.",
WED 3 DEC,4:30 p.m.,Expo Talk Panel,Cosmos World Foundation Model Platform for Physical AI,https://neurips.cc/virtual/2025/128663,,5:30 PM,"Abstract: In this talk, I will introduce NVIDIA Cosmos, our World Foundation Model platform designed to advance Physical AI. Cosmos is built around three core pillars: Predict, Transfer, and Reason. I will provide updates on the latest releases—Predict 2.5 and Transfer 2.5—highlighting key improvements in generalization, efficiency, and scalability. In addition, I will share a preview of ongoing research directions that extend Cosmos toward richer world modeling and reasoning capabilities. Together, these developments aim to push the boundaries of how AI perceives, simulates, and interacts with complex real-world environments.",
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1A,https://neurips.cc/virtual/2025/session/122546,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference,https://neurips.cc/virtual/2025/oral/118170,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond),https://neurips.cc/virtual/2025/oral/121422,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing,https://neurips.cc/virtual/2025/oral/115002,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1B,https://neurips.cc/virtual/2025/session/122547,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Optimal Mistake Bounds for Transductive Online Learning,https://neurips.cc/virtual/2025/oral/119099,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → High-Dimensional Calibration from Swap Regret,https://neurips.cc/virtual/2025/oral/117761,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Does Stochastic Gradient really succeed for bandits?,https://neurips.cc/virtual/2025/oral/116754,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1C,https://neurips.cc/virtual/2025/session/122548,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Adjoint Schrödinger Bridge Sampler,https://neurips.cc/virtual/2025/oral/115787,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Rethinking Joint Maximum Mean Discrepancy for Visual Domain Adaptation,https://neurips.cc/virtual/2025/oral/117477,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Class-wise Balancing Data Replay for Federated Class-Incremental Learning,https://neurips.cc/virtual/2025/oral/117265,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1D,https://neurips.cc/virtual/2025/session/122549,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think,https://neurips.cc/virtual/2025/oral/116345,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity,https://neurips.cc/virtual/2025/oral/116379,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Why Diffusion Models Don’t Memorize:  The Role of Implicit Dynamical Regularization in Training,https://neurips.cc/virtual/2025/oral/119373,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1E,https://neurips.cc/virtual/2025/session/122550,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation,https://neurips.cc/virtual/2025/oral/115716,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Perception Encoder: The best visual embeddings are not at the output of the network,https://neurips.cc/virtual/2025/oral/118806,,11:00 AM,,
WED 3 DEC,10:00-11:00,Oral Paper,  → Interactive Cross-modal Learning for Text-3D Scene Retrieval,https://neurips.cc/virtual/2025/oral/116803,,11:00 AM,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2A,https://neurips.cc/virtual/2025/session/122551,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Agnostic Active Learning Is Always Better Than Passive Learning,https://neurips.cc/virtual/2025/oral/117512,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Tighter CMI-Based Generalization Bounds via Stochastic Projection and Quantization,https://neurips.cc/virtual/2025/oral/117680,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks,https://neurips.cc/virtual/2025/oral/118768,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2B,https://neurips.cc/virtual/2025/session/122552,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → PhySense: Sensor Placement Optimization for Accurate Physics Sensing,https://neurips.cc/virtual/2025/oral/115066,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability,https://neurips.cc/virtual/2025/oral/117509,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata,https://neurips.cc/virtual/2025/oral/121612,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2C,https://neurips.cc/virtual/2025/session/122553,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → A multiscale analysis of mean-field transformers in the moderate interaction regime,https://neurips.cc/virtual/2025/oral/117616,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → The emergence of sparse attention: impact of data distribution and benefits of repetition,https://neurips.cc/virtual/2025/oral/116475,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer Training Dynamics,https://neurips.cc/virtual/2025/oral/116706,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2D,https://neurips.cc/virtual/2025/session/122554,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models,https://neurips.cc/virtual/2025/oral/119904,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks,https://neurips.cc/virtual/2025/oral/116055,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → SAGE: A Unified Framework for Generalizable Object State Recognition with State-Action Graph Embedding,https://neurips.cc/virtual/2025/oral/116465,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2E,https://neurips.cc/virtual/2025/session/122555,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing,https://neurips.cc/virtual/2025/oral/121634,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding,https://neurips.cc/virtual/2025/oral/121509,,4:30 PM,,
WED 3 DEC,3:30-4:30,Oral Paper,  → OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model,https://neurips.cc/virtual/2025/oral/120304,,4:30 PM,,
THU 4 DEC,8:30 a.m.,Invited Talk,The Art of (Artificial) Reasoning,https://neurips.cc/virtual/2025/invited-talk/109603,Yejin Choi,9:30 AM,"Scaling laws suggest that “more is more” — brute-force scaling of data and compute leads to stronger AI capabilities. However, despite rapid progress on benchmarks, state-of-the-art models still exhibit ""jagged intelligence,"" indicating that current scaling approaches may have limitations in terms of sustainability and robustness. Additionally, while the volume of papers on arXiv continues to grow rapidly, our scientific understanding of artificial intelligence hasn't kept pace with engineering advances, and the current literature presents seemingly contradictory findings that can be difficult to reconcile. In this talk, I will discuss key insights into the strengths and limitations of LLMs, examine when reinforcement learning succeeds or struggles in reasoning tasks, and explore methods for enhancing reasoning capabilities in smaller language models to help them close the gap against their larger counterparts in specific domains.",
THU 4 DEC,2:30 p.m.,Invited Talk,"On the Science of “Alien Intelligences”: Evaluating Cognitive Capabilities in Babies, Animals, and AI",https://neurips.cc/virtual/2025/invited-talk/109607,Melanie Mitchell,3:30 PM,"Today’s generative AI systems—termed by some researchers as “alien intelligences”—have exceeded human performance on many benchmarks meant to test humanlike cognitive capabilities.  However, these systems still struggle in unhumanlike ways on real-world tasks requiring these capabilities.  This disconnect may be due in part to neglect in the AI community of well-founded experimental protocols for evaluating cognition.  In this talk I will summarize several recommendations on experimental methods from developmental and comparative psychology—fields that study the “alien intelligences” of babies and non-human animals—and demonstrate the application of such methods in two case studies of cognitive abilities in LLMs: analogical reasoning and visual abstraction.",
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3A,https://neurips.cc/virtual/2025/session/122556,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Identifiability of Deep Polynomial Neural Networks,https://neurips.cc/virtual/2025/oral/118427,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Depth-Bounds for Neural Networks via the Braid Arrangement,https://neurips.cc/virtual/2025/oral/117519,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Learning Linear Attention in Polynomial Time,https://neurips.cc/virtual/2025/oral/118143,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3B,https://neurips.cc/virtual/2025/session/122557,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts,https://neurips.cc/virtual/2025/oral/117276,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables,https://neurips.cc/virtual/2025/oral/118251,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution,https://neurips.cc/virtual/2025/oral/117604,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3C,https://neurips.cc/virtual/2025/session/122558,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Auto-Compressing Networks,https://neurips.cc/virtual/2025/oral/116934,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks,https://neurips.cc/virtual/2025/oral/119732,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression,https://neurips.cc/virtual/2025/oral/116595,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3D,https://neurips.cc/virtual/2025/session/122559,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → State Entropy Regularization for Robust Reinforcement Learning,https://neurips.cc/virtual/2025/oral/115740,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → A Clean Slate for Offline Reinforcement Learning,https://neurips.cc/virtual/2025/oral/119623,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies,https://neurips.cc/virtual/2025/oral/117976,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3E,https://neurips.cc/virtual/2025/session/122560,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,"  → Position: If Innovation in AI systematically Violates Fundamental Rights, Is It Innovation at All?",https://neurips.cc/virtual/2025/oral/126305,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,  → More effort is needed to protect pedestrian privacy in the era of AI,https://neurips.cc/virtual/2025/oral/126301,,11:00 AM,,
THU 4 DEC,10:00-11:00,Oral Paper,"  → Real-Time Hyper-Personalized Generative AI Should Be Regulated to Prevent the Rise of ""Digital Heroin""",https://neurips.cc/virtual/2025/oral/126308,,11:00 AM,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4A,https://neurips.cc/virtual/2025/session/122561,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders,https://neurips.cc/virtual/2025/oral/118059,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,"  → Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free",https://neurips.cc/virtual/2025/oral/120217,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Superposition Yields Robust Neural Scaling,https://neurips.cc/virtual/2025/oral/116347,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4B,https://neurips.cc/virtual/2025/session/122562,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → In Search of Adam’s Secret Sauce,https://neurips.cc/virtual/2025/oral/119298,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions,https://neurips.cc/virtual/2025/oral/117576,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,"  → Generalized Gradient Norm Clipping & Non-Euclidean(L0,L1)-Smoothness",https://neurips.cc/virtual/2025/oral/115789,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4C,https://neurips.cc/virtual/2025/session/122563,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → MaxSup: Overcoming Representation Collapse in Label Smoothing,https://neurips.cc/virtual/2025/oral/116897,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Advancing Expert Specialization for Better MoE,https://neurips.cc/virtual/2025/oral/116507,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Learning to Learn with Contrastive Meta-Objective,https://neurips.cc/virtual/2025/oral/115718,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4D,https://neurips.cc/virtual/2025/session/122564,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Exploring Diffusion Transformer Designs via Grafting,https://neurips.cc/virtual/2025/oral/119280,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Deep Compositional Phase Diffusion for Long Motion Sequence Generation,https://neurips.cc/virtual/2025/oral/116419,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Mean Flows for One-step Generative Modeling,https://neurips.cc/virtual/2025/oral/115488,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4E Position Paper Track Panels,https://neurips.cc/virtual/2025/session/122565,,4:30 PM,,
THU 4 DEC,3:30-4:30,Oral Paper,  → Position Paper Panel: Machine Unlearning and Privacy,https://neurips.cc/virtual/2025/panel/128225,,4:30 PM,This panel consists of authors from the following papers:,
THU 4 DEC,3:30-4:30,Oral Paper,  → Position Paper Panel: Conference Critique,https://neurips.cc/virtual/2025/panel/128226,,4:30 PM,This panel consists of authors from the following papers:,
FRI 5 DEC,8:30 a.m.,Invited Talk,From Benchmarks to Problems - A Perspective on Problem Finding in AI,https://neurips.cc/virtual/2025/invited-talk/109605,Kyunghyun Cho,9:30 AM,"During the past 15 years or so, I have worked on a series of seemingly distinct but eventually related problems, including machine learning algorithms, generative modeling with neural networks, machine translation, language modeling, medical imaging, a bit of healthcare, protein modeling and a bit of drug discovery. I chose to work on some of these problems intentionally, while it was pure serendipity that I worked on some others. It was only in hindsight that these seemingly different problems turned out to be closely related to each other from both technical, social and personal perspectives. In this talk, I plan to do my own retrospective on my own choices, be them intentional or not, on these problems and share with you my thoughts what our own discipline, which is sometimes called computer science, data science, machine learning or artificial intelligence, is.",
FRI 5 DEC,2:30 p.m.,Invited Talk,Demystifying depth: Principles of learning in deep neural networks,https://neurips.cc/virtual/2025/invited-talk/109602,Andrew Saxe,3:30 PM,"Deep neural networks have revolutionized artificial intelligence, yet their inner workings remain poorly understood. This talk presents mathematical analyses of the nonlinear dynamics of learning in several solvable deep network models, offering theoretical insights into the role of depth. These models reveal how learning algorithms, data structure, initialization schemes, and architectural choices interact to produce hidden representations that afford complex generalization behaviors. A recurring theme across these analyses is a neural race: competing pathways within a deep network vie to explain the data, with an implicit bias toward shared representations. These shared representations in turn shape the network’s capacity for systematic generalization, multitasking, and transfer learning. I will show how such principles manifest across diverse architectures—including feedforward, recurrent, and linear attention networks. Together, these results provide analytic foundations for understanding how environmental statistics, network architecture, and learning dynamics jointly structure the emergence of neural representations and behavior.",
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5A,https://neurips.cc/virtual/2025/session/122566,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → EvoLM: In Search of Lost Language Model Training Dynamics,https://neurips.cc/virtual/2025/oral/119409,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → Large Language Diffusion Models,https://neurips.cc/virtual/2025/oral/118609,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?,https://neurips.cc/virtual/2025/oral/119945,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5B,https://neurips.cc/virtual/2025/session/122567,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch,https://neurips.cc/virtual/2025/oral/121452,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training,https://neurips.cc/virtual/2025/oral/117310,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → NOVA: A Benchmark for Rare Anomaly Localization and Clinical Reasoning in Brain MRI,https://neurips.cc/virtual/2025/oral/121771,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5C,https://neurips.cc/virtual/2025/session/122568,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → High-dimensional neuronal activity from low-dimensional latent dynamics: a solvable model,https://neurips.cc/virtual/2025/oral/117112,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → Task-Optimized Convolutional Recurrent Networks Align with Tactile Processing in the Rodent Brain,https://neurips.cc/virtual/2025/oral/116232,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → Memory Mosaics at scale,https://neurips.cc/virtual/2025/oral/118784,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5D,https://neurips.cc/virtual/2025/session/122569,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → InfinityStar: Uniﬁed Spacetime AutoRegressive Modeling for Visual Generation,https://neurips.cc/virtual/2025/oral/118709,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → PlayerOne: Egocentric World Simulator,https://neurips.cc/virtual/2025/oral/118938,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → BEDLAM2.0: Synthetic humans and cameras in motion,https://neurips.cc/virtual/2025/oral/121503,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5E,https://neurips.cc/virtual/2025/session/122570,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → Boosting Knowledge Utilization in Multimodal Large Language Models via Adaptive Logits Fusion and Attention Reallocation,https://neurips.cc/virtual/2025/oral/115856,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models,https://neurips.cc/virtual/2025/oral/118373,,11:00 AM,,
FRI 5 DEC,10:00-11:00,Oral Paper,  → Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion,https://neurips.cc/virtual/2025/oral/118167,,11:00 AM,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6A,https://neurips.cc/virtual/2025/session/122571,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds,https://neurips.cc/virtual/2025/oral/117790,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy,https://neurips.cc/virtual/2025/oral/119076,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization,https://neurips.cc/virtual/2025/oral/116693,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6B,https://neurips.cc/virtual/2025/session/122572,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability,https://neurips.cc/virtual/2025/oral/116902,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → RAG4GFM: Bridging Knowledge Gaps in Graph Foundation Models through Graph Retrieval Augmented Generation,https://neurips.cc/virtual/2025/oral/115563,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Discovering Opinion Intervals from Conflicts in Signed Graphs,https://neurips.cc/virtual/2025/oral/115063,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6C,https://neurips.cc/virtual/2025/session/122573,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Generalized Linear Mode Connectivity for Transformers,https://neurips.cc/virtual/2025/oral/118595,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → On Linear Mode Connectivity of Mixture-of-Experts Architectures,https://neurips.cc/virtual/2025/oral/118036,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Learning (Approximately) Equivariant Networks via Constrained Optimization,https://neurips.cc/virtual/2025/oral/118376,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6D,https://neurips.cc/virtual/2025/session/122574,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → A Snapshot of Influence: A Local Data Attribution Framework for Online Reinforcement Learning,https://neurips.cc/virtual/2025/oral/115686,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities,https://neurips.cc/virtual/2025/oral/115732,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → Learning long range dependencies through time reversal symmetry breaking,https://neurips.cc/virtual/2025/oral/115363,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6E,https://neurips.cc/virtual/2025/session/122575,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction,https://neurips.cc/virtual/2025/oral/118742,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → MokA: Multimodal Low-Rank Adaptation for MLLMs,https://neurips.cc/virtual/2025/oral/116048,,4:30 PM,,
FRI 5 DEC,3:30-4:30,Oral Paper,  → ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism,https://neurips.cc/virtual/2025/oral/117338,,4:30 PM,,
SAT 6 DEC,8 a.m.,Workshop,Structured Probabilistic Inference and Generative Modeling,https://neurips.cc/virtual/2025/workshop/109570,,5:00 PM,,"Overview: The NeurIPS 2025 Workshop on Structured Probabilistic Inference & Generative Modeling focuses on the theory, methodology, and application of structured probabilistic inference and generative modeling. The workshop aims to address challenges in probabilistic methods, especially when applied to highly structured data, and to foster collaboration and discussion among experts from academia and industry. The event will explore the intersection of probabilistic inference and foundation models, providing a platform for discussing applications and challenges in encoding domain knowledge. | Research Interests: Generative methods for graphs, 3D, time series, text, video, and other structured modalities, Probabilistic inference in models for reward fine-tuning, alignment, acceleration, watermarking, Scaling and accelerating inference and generative models, Uncertainty quantification in AI systems, Applications in sampling, optimization, decision making, Applications and practical implementations of existing methods to areas in science, Empirical analysis comparing different architectures for a given data modality and application, Relevance of probabilistic inference in the era of foundation models"
SAT 6 DEC,8 a.m.,Workshop,Reliable ML from Unreliable Data,https://neurips.cc/virtual/2025/workshop/109580,,5:00 PM,"Distributions shift, chatbots get jail‑broken, users game algorithms — how do we build reliable machine learning when data are missing, corrupted, or strategically manipulated?This workshop bridges theory and practice to tackle these challenges, bringing together researchers working on distribution shift, adversarial robustness, and strategic behaviour to chart principled yet deployable solutions for Reliable ML from Unreliable Data.","Overview: The Reliable ML 2025 workshop, held at NeurIPS 2025 in San Diego, focuses on developing reliable machine learning systems from unreliable data. It addresses challenges such as distribution shifts, adversarial robustness, and strategic behavior in socio-technical systems. The workshop aims to bridge theory and practice by bringing together researchers to propose principled and deployable solutions for robust and reliable machine learning under imperfect data conditions. | Research Interests: Distribution shift and transfer learning, Adversarial robustness and defenses, Strategic behavior in socio-technical systems, Learning with missing or biased data, Causal inference beyond overlap, with confounders, or with errors, LLM safety and alignment, Robustness in interactive environments"
SAT 6 DEC,8 a.m.,Workshop,GenProCC: 1st Workshop on Generative and Protective AI for Content Creation,https://neurips.cc/virtual/2025/workshop/109545,,5:00 PM,"Recent advancements in generative AI (GenAI) have empowered machines to create high-quality content across diverse modalities - text, image, audio, and video - with impressive fluency and creativity. From GPT-4o and Stable Diffusion to Sora and MMAudio, the explosion of X-to-X generation (e.g., text-to-image, video-to-audio) is unlocking new frontiers in science, education, entertainment, and art.While GenAI has shown significant potential in creative applications (e.g., music, films, arts), these breakthroughs also raise pressing concerns related to safety, copyright, and ethical use. Generative models can be exploited to spread misinformation, violate intellectual property rights, or diminish human agency in creative processes. As such, there is an increasing need to balance innovation with protection, ensuring that AI-powered creative tools are used responsibly and ethically.This workshop, GenProCC: Generative and Protective AI for Content Creation, brings together researchers, creators, and practitioners at the intersection of content generation and IP protection. By uniting the generative AI and creator communities, the GenProCC workshop aims to explore the latest advances, challenges, and opportunities in the rapidly evolving field.","Overview: The GenProCC NeurIPS 2025 Workshop focuses on the intersection of generative and protective AI for content creation. It aims to explore the advancements in generative AI technologies that enable machines to create high-quality content across various modalities such as text, image, audio, and video. The workshop addresses the potential of these technologies in creative applications while also highlighting the ethical, safety, and copyright concerns they raise. The event seeks to balance innovation with protection, ensuring responsible and ethical use of AI-powered creative tools. | Research Interests: Controllable Generative AI for Content Creation, Protective AI Approaches for Content Creation, Creative Practices with Generative AI, Controllable X-to-X generation, Interactive or iterative generation pipelines, Evaluations and benchmarks for controllability, Applications of controllability/protection in creative practices, Digital watermarking, fingerprinting, and provenance tracking, Benchmarks for evaluating protection in generative systems, Case studies and design research for content creation, Human-in-the-loop approaches for real-world GenAI creation workflows, Emerging applications of GenAI in content creation"
SAT 6 DEC,8 a.m.,Workshop,What Makes a Good Video: Next Practices in Video Generation and Evaluation,https://neurips.cc/virtual/2025/workshop/109548,,5:00 PM,"This workshop aims to explore how real-world advances in video generation increasingly rely on forwardlooking evaluation frameworks and to collaboratively shape the next generation of high-quality video synthesis. Through a combination of invited talks, academic presentations, and expert discussions featuring leading voices from both academia and industry, the workshop bridges academic foundations and industrial insights across the modeling, evaluation, and deployment of video generation. We welcome contributions from computer vision, generative modeling, video-language learning, evaluation methodology, and human-centered AI to shape the next generation of high-quality video synthesis collaboratively.","Overview: The 'What Makes a Good Video: Next Practices in Video Generation and Evaluation' workshop at NeurIPS 2025 aims to explore the evolution of video generation models. It focuses on understanding the limitations of current video models and identifying future research directions. The workshop features discussions on video generation, understanding, benchmarks, and applications, with insights from experts in academia and industry. | Research Interests: Video Generation Models, Benchmarks & Evaluation, Applications"
SAT 6 DEC,8 a.m.,Workshop,ML x OR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making,https://neurips.cc/virtual/2025/workshop/109555,,5:00 PM,"Much of traditional decision-making science is grounded in the mathematical formulations and analyses of structured systems to recommend decisions that are optimized, robust, and uncertainty-aware. This scientific approach, rooted in the field of Operations Research (OR), has evolved through decades of advancements in stochastic modeling, computational simulation and optimization, and exhibits key strengths in methodological rigor and uncertainty encoding. On the other hand, recent advances in the AI/ML space have eschewed this model-based paradigm and increasingly embraced, to great success, model-free algorithmic design frameworks. This workshop, which is the first NeurIPS workshop explicitly themed and structured on ML-OR synergization, aspires to present recent developments, challenges and emerging research to accelerate ML-OR synthesis. By integrating ML into established OR methodologies, we have the opportunities to produce more data-centric and adaptive solutions for complex decision-making tasks that could propel, in a much faster-paced manner, the frontier of ""optimality"" across many relevant applications. Concomitantly, the goal is also to explore how model-based principled OR approaches can help alleviate issues revolving around ""black box"" systems, and provide paths to enhance interpretability, trust, and performance analysis.","Overview: The ML×OR Workshop at NeurIPS 2025 focuses on the integration of Machine Learning (ML) and Operations Research (OR) to enhance uncertainty-aware decision-making. This interdisciplinary workshop aims to explore the synergy between ML and OR, presenting recent developments, discussing challenges, and highlighting emerging research opportunities in data-centric decision-making. The workshop encourages contributions from researchers and practitioners across various fields and includes keynote talks, panel discussions, and poster sessions. | Research Interests: Embedding OR modeling insights into ML, Uncertainty mitigation at the interface of data, model, and decision, Sequential decision-making and online learning from an OR perspective, Generative AI for decision-making"
SAT 6 DEC,8 a.m.,Workshop,Deep Learning for Code in the Agentic Era,https://neurips.cc/virtual/2025/workshop/109562,,5:00 PM,"Deep learning for code has progressed from focused tasks—such as completion, repair, synthesis, and explanation to tackling complex, end-to-end software–engineering problems.  A key recent breakthrough is the rise of coding agents. Unlike single-shot models, these systems plan, reason, explore, and invoke external tools to assist throughout the software-development lifecycle: adding features, refactoring, debugging, finding vulnerabilities, optimizing performance, summarizing code, and answering repository-level questions.  Their growing versatility demands rigorous evaluation and a deeper understanding of their capabilities, limits, risks, and broader social impact.Building on momentum from both academia and industry (e.g. Google, OpenAI, Anthropic, SWE-Agent, OpenHands), we propose the 4th Deep Learning for Code (DL4C) workshop with a dedicated focus on coding agents. This workshop will provide a timely forum where researchers and practitioners can design and stress-test robust coding agents, discover novel applications and emergent behaviors, establish principled benchmarks and evaluation methods, study human–agent collaboration at scale, and advance the responsible, safe deployment of autonomous coding tools.","Overview: The 4th Deep Learning for Code (DL4C) Workshop, titled 'Deep Learning For Code in the Agentic Era,' is scheduled to take place at NeurIPS 2025 in San Diego, CA. This workshop follows three successful previous installations at ICLR in 2022, 2023, and 2025. The event aims to bring together researchers and practitioners to discuss advancements and challenges in applying deep learning techniques to code-related tasks. | Research Interests: Deep Learning, Code Analysis, Machine Learning for Software Engineering, AI in Software Development"
SAT 6 DEC,8 a.m.,Workshop,Differentiable Learning of Combinatorial Algorithms: From Theory To Practice,https://neurips.cc/virtual/2025/workshop/109535,,5:00 PM,,
SAT 6 DEC,8 a.m.,Workshop,AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG @ NeurIPS’25),https://neurips.cc/virtual/2025/workshop/109576,,5:00 PM,"The field of wireless communications and networking is undergoing a paradigm shift, driven by the growing potential of Artificial Intelligence (AI) and Machine Learning (ML) to redefine traditional system design principles. This workshop aims to catalyze interest and foster collaboration between the AI/ML and wireless communications communities. The timing of this workshop is especially significant, as the next-generation (NextG) wireless standardization efforts (such as 6G and WiFi 9) are just getting started, with AI-native technologies expected to play a central role across all aspects of the wireless ecosystem – from radio access to network management and edge intelligence. NextG represents a foundational shift in global infrastructure, enabling ultra-fast, low-latency, and intelligent connectivity that will power future applications in AI, robotics, immersive environments, and autonomous systems. These technologies offer unprecedented opportunities to both drive and benefit many applications, from healthcare and transportation to industrial automation and environmental monitoring. The economic and societal implications are vast: NextG networks will underlie trillions in global GDP impact, bridge digital divides, and shape how billions of people interact with technology and each other in the decades to come.Despite the clear promise, a significant disconnect exists between the AI/ML and wireless research communities. AI/ML experts often lack an understanding of the unique physical, algorithmic, and architectural constraints inherent in wireless systems, while wireless researchers tend to adopt generic, off-the-shelf AI/ML models that are not optimized for the intricacies of wireless environments. Wireless environments are inherently dynamic, high-dimensional, and partially observable. These unique characteristics make them ideal testbeds for developing robust learning algorithms, particularly in areas like online learning, reinforcement learning, and in-context learning. At the same time, AI/ML techniques are becoming essential for managing the growing complexity of modern wireless networks, including resource allocation, interference mitigation, and cross-layer optimization. Bridging the gap between the two communities is not only necessary for meaningful technological advances but also critical for realizing the full societal impact of intelligent wireless systems.This workshop aims to bring together researchers and practitioners at the intersection of artificial intelligence (AI), machine learning (ML), and wireless to address the unique challenges and opportunities posed by Next-Generation (NextG) wireless systems. As the 6G era begins to take shape, AI-native designs have emerged as a cornerstone of wireless innovation, with the potential to transform the performance, efficiency, and adaptability of communication systems. The integration of AI/ML is poised to influence every layer of the network stack, from physical-layer signal processing to network control and resource management.","Overview: The AI4NextG workshop at NeurIPS 2025 focuses on the integration of Artificial Intelligence (AI) and Machine Learning (ML) in next-generation wireless communications and networking. The workshop aims to bridge the gap between AI/ML and wireless research communities to address the challenges and opportunities posed by Next-Generation (NextG) wireless systems, such as 6G and WiFi 9. It seeks to foster collaboration and innovation in AI-native designs that can transform the performance, efficiency, and adaptability of communication systems. | Research Interests: AI-native protocol and architecture design for 6G and WiFi 8/9, Reinforcement learning for dynamic spectrum access and resource allocation, Gen AI and foundation models for physical-layer communication tasks, Online learning and adaptation under real-time and uncertain wireless environments, Data-efficient learning and representation for sparse, high-dimensional wireless signals, AI for network planning, self-optimization, and fault prediction in wireless networks, Cross-layer ML-driven optimizations for joint sensing, control, and communication, Co-design of hardware and ML algorithms for low-power and real-time wireless AI, Trustworthy and explainable AI in high-stakes communication systems"
SAT 6 DEC,8 a.m.,Workshop,"The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance",https://neurips.cc/virtual/2025/workshop/109566,,5:00 PM,"Generative AI (GenAI) has emerged as a transformative force in healthcare, yet public trust remains limited due to safety concerns and policy misalignment. Build- ing on last year’s successful GenAI4Health workshop, the field has rapidly evolved from exploratory research to real-world clinical deployments, accompanied by FDA regulatory involvement and expanding global governance frameworks. This second workshop convenes machine learning researchers, healthcare professionals, and policy experts to address the critical intersection of GenAI innovation and regula- tory compliance in health applications. We will examine trustworthiness challenges in large language models and multimodal foundation models, explore mitigation strategies, and foster dialogue between technical and policy communities. Our goal is to advance safe, effective, and ethically-compliant GenAI integration in healthcare systems, improving patient outcomes and clinical research capabilities.","Overview: The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance (GenAI4Health2025) is a workshop held at NeurIPS 2025 in San Diego, California. It aims to bring together AI4Health practitioners, safety researchers, and policy experts to address critical challenges in developing robust and policy-compliant Generative AI technologies for healthcare. The workshop will cover topics such as generative AI applications in healthcare, AI trust and reliability in medical settings, policy compliance and regulatory frameworks, clinical AI implementation strategies, and AI safety in healthcare environments. | Research Interests: Generative AI applications in healthcare, AI trust and reliability in medical settings, Policy compliance and regulatory frameworks, Clinical AI implementation strategies, AI safety in healthcare environments"
SAT 6 DEC,8 a.m.,Workshop,CauScien: Uncovering Causality in Science,https://neurips.cc/virtual/2025/workshop/109550,,5:00 PM,,"Overview: The CauScien Workshop, part of NeurIPS 2025, is focused on uncovering causality in science. It aims to bridge the gap between theoretical causal reasoning and practical application in scientific research. The workshop fosters collaboration across various disciplines, including ecology, biology, and social sciences, to explore the integration of causal inference with domain expertise and real-world data. The event will address the challenges of applying causal learning techniques to accelerate scientific discovery and promote a bottom-up research paradigm. | Research Interests: Causal inference in applied science, Integration of causality with domain expertise, Causal learning techniques, Translational gap in causal reasoning, Causal benchmark tasks, Collaboration between domain experts and machine learning researchers, Causality in experimental design and planning"
SAT 6 DEC,8 a.m.,Workshop,Algorithmic Collective Action,https://neurips.cc/virtual/2025/workshop/109567,,5:00 PM,"The study of collective action has a long history in economics and sociology as a way for groups of people to impact markets and the political arena. Algorithmic collective action focuses on the study of such coordinated efforts in algorithmically-mediated sociotechnical systems. How can participants of AI systems coordinate towards socially beneficial outcomes? We offer a platform to discuss new ideas and help define the foundational research directions for this emerging topic through interdisciplinary discussions between core ML researchers, scholars from the social sciences, community stakeholders and advocates.","Overview: The Algorithmic Collective Action workshop is co-located with NeurIPS 2025 and will take place on December 6 at the San Diego Convention Center. The workshop focuses on exploring collective strategies for shaping outcomes in socio-technical systems from a grassroots perspective. It invites contributions that examine algorithmic collective action through various lenses, including machine learning, statistics, optimization, economics, and the humanities. The goal is to advance understanding of how coordinated efforts can influence the development and deployment of AI systems. | Research Interests: Algorithmic collective action, Socio-technical systems, Machine learning, Statistics, Optimization, Economics, Humanities, AI system development, AI system deployment"
SAT 6 DEC,8 a.m.,Workshop,"Lock-LLM Workshop: Prevent Unauthorized Knowledge Use from Large Language Models - Deep Dive into Un-Distillate, Un-Finetunable, Un-Compressible, Un-Editable, and Un-Usable",https://neurips.cc/virtual/2025/workshop/109568,,5:00 PM,"Large Language Models (LLMs) have emerged as transformative tools across research and industry, revolutionizing how we interact with information. However, their immense capabilities bring critical security challenges—the same features that drive innovation can be exploited for malicious purposes through unauthorized distillation, fine-tuning, compression, or editing. These vulnerabilities pose severe threats, including intellectual property theft, the generation of sophisticated disinformation, the bypass of safety alignments, and the erosion of user trust in AI systems.This workshop aims to bring together researchers and practitioners from academia and industry who are advancing the frontiers of LLM security and protection. We seek to confront the unauthorized use of LLMs head-on by exploring novel and robust mechanisms designed to make these models inherently resistant to exploitation while maintaining their beneficial capabilities. The workshop also hosts the 2025 TrustAI Rising Star Award.Topics of interest include, but are not limited to:1. Un-Distillable LLMs: Preventing unauthorized model replication and intellectual property theft2. Un-Finetunable LLMs: Resisting malicious parameter updates and behavior alterations3. Un-Compressible LLMs: Maintaining model integrity against unauthorized compression4. Un-Editable LLMs: Safeguarding against knowledge tampering and misinformation injection5. Un-Usable LLMs: Ensuring traceability and preventing misuse through watermarking and verification","Overview: The Lock-LLM workshop, part of NeurIPS 2025, focuses on addressing the security challenges posed by Large Language Models (LLMs). These models, while transformative, are vulnerable to unauthorized use such as distillation, fine-tuning, compression, and editing, which can lead to intellectual property theft, misinformation, and erosion of trust. The workshop aims to bring together researchers and practitioners to explore robust mechanisms that make LLMs resistant to exploitation while preserving their beneficial capabilities. The event also includes the 2025 TrustAI Rising Star Award to honor early-career researchers in the field. | Research Interests: Un-Distillable LLMs, Un-Finetunable LLMs, Un-Compressible LLMs, Un-Editable LLMs, Un-Usable LLMs, Theoretical Foundations, Evaluation Frameworks, Real-world Applications, Ethical and Societal Implications"
SAT 6 DEC,8 a.m.,Workshop,AI4Mat-NeurIPS-2025: NeurIPS 2025 Workshop on AI for Accelerated Materials Design,https://neurips.cc/virtual/2025/workshop/109538,,5:00 PM,"AI4Mat-NeurIPS-2025 explores applications of artificial intelligence (AI) to materials via: 1. AI-Guided Materials Design; 2. Automated Chemical Synthesis; 3. Automated Material Characterization. AI4MatNeurIPS-2025 emphasizes structured, expert-driven dialogue on making advanced machine learning more impactful for real-world materials discovery. To that end, AI4Mat-RLSF (Research Learning from Speaker Feedback) creates a new structured discussion format where spotlight presenters receive curated, in-depth feedback from invited discussants. Further, the AI4Mat Frontiers & Benchmarking session brings together a diverse and distinguished set of speakers to critically examine current benchmarks, present state-of-the-art methods, and identify emerging opportunities and current limitations in AI-driven materials design.","Overview: The AI4Mat workshop at NeurIPS 2025 is a platform for AI researchers and material scientists to collaborate on AI-driven materials discovery and development. It aims to foster interdisciplinary discussions and address challenges in automated materials discovery, including AI-guided design, synthesis, and characterization. The workshop has been a leading venue for exchanging ideas since its inception at NeurIPS 2022, and it continues to build a global research community focused on AI-enabled materials innovation. | Research Interests: AI-driven materials discovery, Automated materials design, AI-guided synthesis, Automated material characterization, Foundation models in materials science, Representation learning for materials, Benchmarking in machine learning for materials science"
SAT 6 DEC,8 a.m.,Workshop,AI for non-human animal communication,https://neurips.cc/virtual/2025/workshop/109586,,5:00 PM,"The past few years have seen an unprecedented surge in both the availability of bioacoustic data and the sophistication of AI/machine learning models. This convergence presents a unique window of opportunity to revolutionize our understanding of animal communication and biodiversity. However, achieving this requires a conscious effort to integrate the disciplines of AI/Machine Learning and Ethology.

This workshop will explore the intersection of artificial intelligence (AI) and bioacoustics, aiming to address challenges in processing complex bioacoustic data and interpreting animal signals in order to advance our understanding of non-human animal communication. Join us for a poster session, keynote talks and a panel discussion as we explore key opportunities to use AI to decipher animal languages and thus deepen our understanding of the natural world.","Overview: The AI for Non-Human Animal Communication NeurIPS 2025 Workshop aims to explore the intersection of artificial intelligence and bioacoustics to advance the understanding of non-human animal communication. The workshop will address challenges in processing complex bioacoustic data and interpreting animal signals, with the goal of revolutionizing our understanding of animal communication and biodiversity. It will feature a poster session, keynote talks, and a panel discussion. | Research Interests: Bioacoustic data processing, AI and machine learning models, Animal communication, Biodiversity, Multimodal learning, Transfer learning, Large-language models, Unsupervised, self-supervised, or supervised models, Ecological impact and conservation monitoring, Communication and cognition, Linguistics, Information encoding, Ethics in AI"
SAT 6 DEC,8 a.m.,Workshop,Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET),https://neurips.cc/virtual/2025/workshop/109542,,5:00 PM,"Recent progress in reinforcement learning (RL) has powered breakthroughs in various real-world problems, gathering considerable attention and investment. However, it has also exposed a significant gap between theoretical and experimental developments.RL theory has grown significantly in the past two decades. Research has characterized the inherent difficulty of various settings and has designed a wide variety of algorithms to reach optimal performances. Furthermore, a huge leap has been made in understanding how to handle large state spaces using function approximation techniques, identifying key structural properties that enable efficient learning.Despite theoretical guarantees, applying RL algorithms to complex problems faces challenges. Theoretical algorithms often focus on simplified settings, making them hard to apply to real-world complexities. Furthermore, optimizing for worst-case scenarios, which include unlikely situations, can lead to algorithms that perform poorly on practical tasks. Yet, while specialized algorithms offer empirical success, they might not translate to other problems due to their specific design, and the reliance on heuristics and engineering fixes further widens the gap between theory and practice.A prominent area that has seen a surge of interest in RL is generative language modeling. Pre-training these models can be viewed as a form of imitation learning, while post-training typically implements RL algorithms for purposes like instruction tuning with RL from human feedback or enhancing reasoning capabilities. While these successes make the practical utility of RL undeniable, the RL community finds itself at a crossroads. The algorithms employed are frequently variants of classical methods, and exploring beyond these presents a key challenge. Conversely, the success of these models prompts new questions for RL theory, suggesting that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions.Following the success of the ICML 2024 edition, the Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) aims to bridge this discrepancy and promote collaboration. By bringing together experts from both sides, we want to facilitate meaningful discussions and draw a path for future RL research. Motivated by the take-home messages from the previous edition, we seek to encourage: (i) theorists to ask experimentalists for concrete problems to solve, and (ii) experimentalists to seek theoretical guidance on how to approach these problems.","Overview: The Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) Workshop at NeurIPS 2025 aims to bridge the gap between theoretical and experimental developments in reinforcement learning (RL). The workshop will feature a panel discussion on the current state of RL, an idea track for problem submissions, and a research track for solution submissions. The event will bring together researchers to foster collaboration and explore new paradigms in RL, particularly focusing on leveraging pre-trained models over traditional learning methods. | Research Interests: Reinforcement Learning, Theoretical and Experimental Developments in RL, Function Approximation Techniques, Large State Spaces, Pre-trained Models, Instruction Tuning with RL, Human Feedback in RL, Enhancing Reasoning Capabilities | Key Findings: The workshop highlights the significant gap between theoretical and experimental RL developments and suggests that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions."
SAT 6 DEC,8 a.m.,Workshop,The First Workshop on Efficient Reasoning,https://neurips.cc/virtual/2025/workshop/109556,,5:00 PM,"Recent progress in large reasoning models (LRMs), like OpenAI o1 and Deepseek R1, has been pivotal for tackling complex applications, from mathematical and code reasoning to advanced symbolic and agentic planning. Their success often relies on test-time scaling, which involves increasing the generation length or depth. However, these approaches incur significant efficiency bottlenecks during training and inference. To overcome these limitations, further advancements are needed in data, algorithms, and systems applicable across various domains, as exemplified by work such as s1, Z1, and verl. The proposed workshop will bring together researchers and practitioners to rethink efficient reasoning under tight compute, memory, latency, throughput, and cost budgets, with the goal of translating theoretical breakthroughs into practical, deployable solutions.","Overview: The 1st Workshop on Efficient Reasoning at NeurIPS 2025 focuses on advancing large reasoning models (LRMs) to tackle complex applications efficiently. The workshop aims to address efficiency bottlenecks in training and inference by bringing together researchers and practitioners to explore data, algorithms, and systems that can operate under tight compute, memory, latency, throughput, and cost constraints. The goal is to translate theoretical breakthroughs into practical, deployable solutions. | Research Interests: Dataset Curation, Algorithmic Innovation, System Deployment, Application of LRMs in resource-constrained scenarios, Efficient training algorithms, Efficient inference methods, Dynamic KV-cache placement, Quantized graph execution, On-device knowledge distillation"
SAT 6 DEC,8 a.m.,Workshop,UniReps: Unifying Representations in Neural Models,https://neurips.cc/virtual/2025/workshop/109553,,5:00 PM,"When, how and why do different neural models learn the same representations?New findings in neuroscience and artificial intelligence reveal a shared pattern: whether in biological brains or artificial models, different learning systems tend to create similar representations when subject to similar stimuli.The emergence of these similar representations is igniting a growing interest in the fields of neuroscience and artificial intelligence, with both fields offering promising directions for their theoretical understanding. These include analyzing the learning dynamics in neuroscience and studying the problem of identifiability in the functional and parameter space in artificial intelligence.While the theoretical aspects already demand investigation, the practical applications are equally compelling: aligning representations allows for model merging, stitching and reuse, while also playing a crucial role in multi-modal scenarios. Furthermore, studying the features that are universally highlighted by different learning processes brings us closer to pinpoint the invariances that naturally emerge from learning models, possibly suggesting ways to enforce them.The objective of the workshop is to discuss theoretical findings, empirical evidence and practical applications of this phenomenon, benefiting from the cross-pollination of different fields (ML, Neuroscience, Cognitive Science) to foster the exchange of ideas and encourage collaborations.In conclusion, our primary focus is to delve into the underlying reasons, mechanisms, and extent of similarity in internal representations across distinct neural models, with the ultimate goal of unifying them into a single cohesive whole.","Overview: The UniReps Workshop focuses on the unification of representations in neural models, exploring how and why different neural models, whether biological or artificial, tend to learn similar representations when exposed to similar stimuli. The workshop aims to discuss theoretical findings, empirical evidence, and practical applications of this phenomenon, encouraging cross-disciplinary collaboration among fields such as machine learning, neuroscience, and cognitive science. | Research Interests: Unifying representations in neural models, Learning dynamics in neuroscience, Identifiability in artificial intelligence, Model merging and reuse, Multi-modal scenarios, Invariances in learning models | Key Findings: The workshop highlights the shared pattern of similar representations emerging in different learning systems, both biological and artificial, when exposed to similar stimuli. This phenomenon is of growing interest in neuroscience and artificial intelligence, with potential applications in model merging, stitching, and reuse, as well as in multi-modal scenarios."
SAT 6 DEC,8 a.m.,Workshop,MATH-AI: The 5th Workshop on Mathematical Reasoning and AI,https://neurips.cc/virtual/2025/workshop/109565,,5:00 PM,,"Overview: The 5th Workshop on Mathematical Reasoning and AI, part of NeurIPS 2025, focuses on the intersection of deep learning and mathematical reasoning, particularly with large language models. The workshop aims to explore the extent to which machine learning models can comprehend mathematics and the potential applications of this capability. It seeks to bring together diverse participants to foster dialogue on various related topics. | Research Interests: Comparative study of human-level mathematical reasoning and AI techniques, Designing benchmarks for evaluating mathematical reasoning abilities, Advancing beyond current mathematical reasoning techniques, Role of deep learning models in mathematics education, Applications of AI in software verification, sciences, engineering, finance, education, and mathematics"
SAT 6 DEC,8 a.m.,Workshop,ML for Systems,https://neurips.cc/virtual/2025/workshop/109537,,5:00 PM,"The 9th Machine Learning for Systems (ML for Systems) workshop brings together researchers and practitioners applying machine learning to core computer systems challenges. This year, we focus on three themes: (1) using LLMs and agentic workflows for systems tasks such as program synthesis and adaptive optimization; (2) applying ML to manage the complexity of large-scale training and serving of multimodal and reasoning models; and (3) leveraging ML for sustainable computing, including energy-, power-, and carbon-aware optimization. The workshop will feature invited talks, contributed presentations, and discussions aimed at advancing the frontier of ML for Systems research.","Overview: The ML for Systems workshop focuses on the application of machine learning techniques to computer systems problems. It aims to replace traditional heuristics with machine learning approaches, such as supervised learning and reinforcement learning, to address a wide range of systems-related tasks. The workshop serves as an interdisciplinary venue for experts in ML and systems to collaborate and push the boundaries of this emerging field. It also emphasizes the development of best practices, methodologies, and benchmarks for ML in systems, with a particular focus on the challenges and opportunities presented by Large Language Models (LLMs). | Research Interests: Machine Learning for computer systems, Supervised learning, Reinforcement learning, Designing new data structures, Integrated circuits, Design verification, Control algorithms for compilers, Databases, Memory management, ML frameworks, Large Language Model (LLM) training and serving, Scheduling and compiling, Interdisciplinary collaboration between ML and systems | Key Findings: The workshop highlights the importance of ML in solving systems problems and the need for developing best practices and benchmarks. It also identifies the rise of LLMs as a significant trend, presenting both challenges and opportunities for the field. The workshop aims to foster connections between ML and systems communities and to stimulate new research directions."
SAT 6 DEC,8 a.m.,Workshop,"Dynamics at the Frontiers of Optimization, Sampling, and Games",https://neurips.cc/virtual/2025/workshop/109541,,5:00 PM,,"Overview: The DynaFront workshop at NeurIPS 2025 focuses on the role of dynamical systems in optimization, sampling, and game theory. It aims to lower the barrier to entry for researchers and practitioners in machine learning by highlighting the unifying role of dynamical systems across these domains. The workshop will convene experts to foster cross-disciplinary dialogue and collaboration, with an emphasis on emerging applications in machine learning such as diffusion models, distributed and adversarial training, and agentic AI. | Research Interests: Dynamical systems, Optimization, Sampling, Game theory, Machine learning, Diffusion models, Distributed training, Adversarial training, Agentic AI"
SAT 6 DEC,8 a.m.,Workshop,AI Virtual Cells and Instruments: A New Era in Drug Discovery and Development,https://neurips.cc/virtual/2025/workshop/109543,,5:00 PM,"As the US FDA phases out animal testing requirements for drug discovery and development, AI tools will become widely adopted to simulate the effects of candidate drugs. We posit that building virtual cells and instruments with AI is poised to transform drug discovery and development by enabling large-scale simulation and interrogation of molecules, cells, and tissues. In our workshop, we will collaboratively define and promote this emerging scientific paradigm of AI to accelerate the drug discovery and development process in this new era.","Overview: The AI4D3 NeurIPS 2025 workshop focuses on the transformative potential of AI in drug discovery and development, particularly as the US FDA phases out animal testing requirements. The workshop aims to explore the creation of AI-driven virtual cells and instruments to simulate the effects of candidate drugs, thereby accelerating the drug discovery process. This event will bring together a community to collaboratively define and promote this emerging scientific paradigm. | Research Interests: AI in drug discovery, Virtual cells and instruments, Simulation of drug effects, Large-scale molecular simulation, Interrogation of molecules, cells, and tissues"
SAT 6 DEC,8 a.m.,Workshop,OPT 2025: Optimization for Machine Learning,https://neurips.cc/virtual/2025/workshop/109581,,5:00 PM,"Optimization lies at the heart of many machine learning algorithms and enjoys great interest in our community. Indeed, this intimate relation of optimization with ML is the key motivation for the OPT series of workshops. We aim to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to ML.The focus of OPT 2025 is on ""Statistics Meets Optimization"". Since its inception, stochastic optimization has been grounded in statistical principles. Today, many of the most pressing challenges in machine learning—such as generalization bounds, the training dynamics of overparameterized models, and the development of generative models—are directly inspired by statistical thinking. At the same time, the scale and complexity of modern datasets, along with the increasingly rich model classes used to represent them, pose new questions about how optimization algorithms interact with these structures—both computationally and statistically. For example, what role do data symmetries play in shaping optimization trajectories? How do statistical properties of the data affect the adaptivity and efficiency of learning algorithms? And how can optimization approaches be designed to scale with data while still preserving desirable statistical behavior? OPT 2025 will explore these questions with the goal of building bridges between the statistics and optimization communities, and highlighting their shared impact on the theory and practice of machine learning.We are looking forward to seeing you all at OPT 2025, which will take place at the San Diego Convention Center!","Overview: The OPT2025 workshop is the 17th International Workshop on Optimization for Machine Learning, held as part of the NeurIPS 2025 conference. It aims to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to machine learning. The workshop focuses on the intersection of statistics and optimization, exploring how these fields can address challenges in machine learning, such as generalization bounds, training dynamics of overparameterized models, and the development of generative models. The event will take place at the San Diego Convention Center. | Research Interests: Optimization for Machine Learning, Statistics Meets Optimization, Stochastic Optimization, Generalization Bounds, Training Dynamics of Overparameterized Models, Development of Generative Models, Data Symmetries in Optimization, Statistical Properties and Learning Algorithms, Scalable Optimization Approaches"
SAT 6 DEC,8 a.m.,Workshop,Foundation Models for the Brain and Body Workshop,https://neurips.cc/virtual/2025/workshop/109571,,5:00 PM,,"Overview: The 'Foundation Models for the Brain and Body' workshop is part of NeurIPS 2025, focusing on the intersection of AI and biosignals. It aims to explore how large-scale, pretrained AI systems can learn from neural and physiological signals to generalize across various applications, such as brain-computer interfacing and health monitoring. The workshop brings together experts from neuroscience, biomedical engineering, wearable technology, and machine learning to address the challenges of biosignal timeseries, which are often noisy and heterogeneous. | Research Interests: Foundation models, Biosignals, Brain-computer interfacing, Health monitoring, Neural and physiological signals, EEG, Intracortical electrophysiology, EMG, MEG, ECG, Wearable technology, Machine learning, Neuroscience, Biomedical engineering"
SAT 6 DEC,8 a.m.,Workshop,Biosecurity Safeguards for Generative AI,https://neurips.cc/virtual/2025/workshop/109573,,5:00 PM,,
SAT 6 DEC,8 a.m.,Workshop,Imageomics: Discovering Biological Knowledge from Images Using AI,https://neurips.cc/virtual/2025/workshop/109558,,5:00 PM,"Imageomics is an emerging interdisciplinary field at the crossroads of machine learning (ML), computer vision (CV), and biological sciences. It leverages visual data—from microscopic images of single-cell species to videos of megafauna—to extract and analyze biological information, specifically traits. By grounding ML models in existing scientific knowledge, Imageomics aims to make traits computable from images, facilitating insights into the evolution and function of living organisms. Imageomics poses research problems that resonate with the broad machine-learning community: multimodal representation learning, object detection and tracking, few-shot learning, imbalanced-class learning, video understanding, 3D modeling, hierarchical learning, etc. When people leverage ML tools to solve biological questions, the foundational bridges between ML and biological sciences also provide opportunities to address key challenges in ML, creating a virtuous cycle between the two fields.","Overview: The Imageomics Workshop at NeurIPS 2025 is the third edition of an interdisciplinary event focused on the emerging field of Imageomics, which combines machine learning, computer vision, and biological sciences. The workshop aims to leverage visual data, from microscopic images to videos of large animals, to extract and analyze biological information, particularly traits. By integrating machine learning models with existing scientific knowledge, Imageomics seeks to make biological traits computable from images, providing insights into the evolution and function of living organisms. The workshop will feature keynote talks, paper presentations, and discussions on the latest research, encouraging participation from both biological scientists and machine learning researchers. | Research Interests: Multimodal representation learning, Object detection and tracking, Few-shot learning, Imbalanced-class learning, Video understanding, 3D modeling, Hierarchical learning"
SAT 6 DEC,8 a.m.,Workshop,Embodied World Models for Decision Making,https://neurips.cc/virtual/2025/workshop/109532,,5:00 PM,"World models infer and predict real-world dynamics by modeling the external environment, and have become a cornerstone of embodied artificial intelligence. They have powered recent progress in decision-making and planning for interacting agents. This workshop aims to bring together researchers working at the intersection of generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models—models that enable agents to understand, predict, and interact with the world through learned models. By focusing on embodiment and decision-making, this workshop seeks to advance world models beyond passive prediction, toward active, goal-driven interaction with the physical and virtual world. By emphasizing embodiment and decision-making, we aim to move beyond passive sequence prediction toward goal-directed interaction with both physical and simulated worlds.","Overview: The Embodied World Models for Decision Making workshop at NeurIPS 2025 focuses on advancing world models that enable agents to understand, predict, and interact with the world through learned models. The workshop aims to bring together researchers from generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models. The emphasis is on moving beyond passive prediction to active, goal-driven interaction with both physical and virtual worlds. | Research Interests: Model-based reinforcement learning and long-horizon planning, Aligning simulation and real-world physics for robot learning, Interactive scene generation and downstream tasks, Video-language-action models and leveraging world knowledge in large language models, Applications in open-world video games and autonomous driving"
SAT 6 DEC,8 a.m.,Workshop,Machine Learning and the Physical Sciences,https://neurips.cc/virtual/2025/workshop/109577,,5:00 PM,"The Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS is a unique gathering space for the growing community spearheading cross-cutting research topics at the intersection of machine learning (ML) and the physical sciences (PS). This includes the applications of ML to problems in the physical sciences (ML for PS) as well as developments in ML motivated by physical insights (PS for ML). The physical sciences are defined inclusively, including but not limited to physics, astronomy, cosmology, chemistry, biophysics, materials science, and Earth science. Join us to discuss the latest research at the convergence of these fields!","Overview: The Machine Learning and the Physical Sciences (ML4PS) workshop is a gathering space for researchers at the intersection of machine learning (ML) and the physical sciences (PS). Since its inception in 2017, the workshop has focused on applying ML to problems in the physical sciences and using physical insights to improve ML techniques. The 2025 workshop, part of the 39th NeurIPS conference, will explore the interplay between academia and industry in basic research, emphasizing foundational and translational connections between these domains. | Research Interests: Machine Learning for Physical Sciences, Physical Sciences for Machine Learning, Geometric Deep Learning, Simulation-Based Inference, Diffusion Models, Physics-Informed Neural Networks, Interplay of Academia and Industry, Weather and Climate Research, Paradigm-Shifting Applications in ML and Physics"
SAT 6 DEC,8 a.m.,Workshop,Workshop on Multi-Turn Interactions in Large Language Models,https://neurips.cc/virtual/2025/workshop/109539,,5:00 PM,"The field of AI is entering a new era of interaction, profoundly shaped by the capabilities of Large Language Models (LLMs). While multi-turn interaction has been a long-standing pursuit in AI—from dialogue systems to multi-agent coordination—the advent of LLMs has radically transformed this landscape. These models now engage in complex, long-horizon interactions, process diverse data, and make crucial decisions in dynamic, human-centric scenarios.This leap forward, however, brings forth critical new research questions and challenges that demand immediate attention:Multi-Turn RL Learning for Agentic Tasks Learning from complex, interactive environments like GUI agents and tool-use scenarios, given the challenges of sparse rewards.Maintaining Alignment Understanding human values over extended, multi-turn interactions, preventing ""loss of alignment"" seen in current models.Human-AI Interaction Over time, ensuring models adapt to user goals without compromising safety or fairness.Long-horizon Evaluation For LLMs' long-term capabilities, consistency, and strategic abilities in complex, multi-turn tasks.The Workshop on Multi-Turn Interactions in LLMs is designed to be the central forum for addressing these pivotal questions. We invite researchers to contribute to defining the next generation of interactive AI, tackling these core challenges, and charting the course for future advancements in AI reasoning and planning. This workshop will concentrate on key areas where the extended use of LLMs presents both new challenges and opportunities, serving as a platform to discuss and refine methods for future improvements and evaluation for practical LLM use cases.","Overview: The NeurIPS 2025 Workshop on Multi-Turn Interactions in Large Language Models focuses on the evolving field of AI, particularly the role of Large Language Models (LLMs) in multi-turn interactions. The workshop aims to address new research questions and challenges that arise from the capabilities of LLMs in complex, long-horizon interactions. It serves as a central forum for researchers to contribute to the development of interactive AI, focusing on areas where LLMs present new challenges and opportunities. | Research Interests: Multi-Turn RL Learning for Agentic Tasks, Maintaining Alignment in AI, Human-AI Interaction, Long-horizon Evaluation of LLMs, Multi-Turn Settings and Tasks, Multi-Turn Frameworks and Algorithms, Multi-Turn Evaluation, Multi-Turn Challenges"
SAT 6 DEC,8 a.m.,Workshop,Generative AI in Finance,https://neurips.cc/virtual/2025/workshop/109564,,5:00 PM,"This workshop aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance, a high-stakes domain where the integration of domain expertise is essential to the safe and effective deployment of machine learning technologies. Recent advances in generative models—ranging from large language models to diffusion and score-based generative architectures—have opened new frontiers for applications in finance, such as financial modeling, stress testing, scenario generation, automated financial services, and decision-making under uncertainty.The workshop will highlight theoretical advances, practical implementations, new opportunities, and open challenges that arise when adapting generative AI to financial systems under unique constraints, such as data sparsity, regulatory requirements, and highly non-stationary and adversarial environments. By bringing together the computer science community, financial researchers, industry practitioners, and regulators, we aim to catalyze interdisciplinary dialogue and accelerate the responsible development of generative AI tailored to the needs of finance and risk management.","Overview: The NeurIPS 2025 Workshop on Generative AI in Finance aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance. The workshop will focus on the integration of domain expertise to safely and effectively deploy machine learning technologies in finance. It will highlight theoretical advances, practical implementations, new opportunities, and challenges in adapting generative AI to financial systems, considering constraints like data sparsity, regulatory requirements, and non-stationary environments. The event will bring together computer scientists, financial researchers, industry practitioners, and regulators to accelerate the responsible development of generative AI tailored to finance and risk management. | Research Interests: Generative AI, Financial modeling, Stress testing, Scenario generation, Automated financial services, Decision-making under uncertainty, Machine learning in finance, Stochastic analysis, Trustworthy machine learning, Sequential decision-making, High-dimensional statistics, AI for financial services, Market behavior modeling, Natural language processing, Reinforcement learning, AI agents, Representation learning for finance, Agentic AI, LLM (Large Language Models), Financial modeling and reasoning"
SUN 7 DEC,8 a.m.,Workshop,UrbanAI: Harnessing Artificial Intelligence for Smart Cities,https://neurips.cc/virtual/2025/workshop/109583,,5:00 PM,,
SUN 7 DEC,8 a.m.,Workshop,2nd  Workshop on Multi-modal Foundation Models and Large Language Models  for Life Sciences,https://neurips.cc/virtual/2025/workshop/109536,,5:00 PM,,"Overview: The NeurIPS 2025 2nd Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences focuses on the transformative advancements in life sciences brought about by foundation models and large language models (LLMs). These models are pretrained on extensive datasets and are capable of performing a wide range of tasks such as predicting protein structures, analyzing genomic sequences, and simulating cellular processes. The workshop aims to address the limitations of existing models that focus on a single modality by promoting the development of multi-modal foundation models and LLMs that can integrate and reason over diverse biological modalities. The event will bring together researchers to discuss recent advancements, explore methodological innovations, and identify key challenges in designing these models for biological data. | Research Interests: Multi-modal foundation models for learning representations of proteins, DNAs, RNAs, transcriptomic data, metabolomic data, and other biological modalities., Multi-modal LLMs for predicting the functions of proteins, DNAs, RNAs, and other biomolecules., Multi-modal foundation models for learning joint representations of multi-omics data., Multi-modal generative models for designing proteins, DNAs, RNAs, and other biomolecules., Applications of multi-modal foundation models and LLMs in drug discovery, precision medicine, personalized treatment, and beyond., Interpretability and robustness in biological multi-modal foundation models and LLMs."
SUN 7 DEC,8 a.m.,Workshop,Artificial Intelligence for Music: Where Creativity Meets Computation,https://neurips.cc/virtual/2025/workshop/109534,,5:00 PM,"This workshop explores the dynamic intersection of AI and music, a rapidly evolving field where creativity meets computation. The goal of this workshop is twofold: First, we aim to explore the latest advancements of AI’s applications for music, from analysis, creation, performance, production, retrieval to music education and therapy. Second, we aim to discuss the impacts and implications of AI in music, including AI’s impacts on the music industry, musician community, and music education as well as ethical, legal and societal implications of AI music and AI’s implications for future musicians.","Overview: The NeurIPS 2025 Workshop on AI for Music, titled 'Where Creativity Meets Computation,' is an interdisciplinary event exploring the intersection of artificial intelligence and music. The workshop aims to bring together the music and AI communities to discuss the latest advancements in AI applications for music, including analysis, creation, performance, production, retrieval, and music education and therapy. It also addresses the impacts and implications of AI in music, such as its effects on the music industry, musician community, and music education, as well as ethical, legal, and societal considerations. The workshop features invited talks, spotlight presentations, poster and demo sessions, panel discussions, and round table discussions, with a focus on networking and community building. | Research Interests: AI applications in music, Music theory and musicology, Optical music recognition, Music transcription, Music generation, Sound design and soundtrack generation, Singing voice synthesis, Lyric generation and translation, Musical instrument design, Robotic musicianship, Human-AI music co-creativity, Music production, Music performance modeling, Music information retrieval, Music recommender systems, Music education, Music therapy, Impacts of AI on the music industry, Impacts on the musician community, Impacts on music education, Ethical, legal, and societal implications of AI music, Challenges in commercializing AI music tools, Emerging opportunities of AI music | Key Findings: The workshop highlights the growing interest in AI music research within the machine learning community and emphasizes the potential of AI to enhance artist creativity and develop new fan experiences. It also notes the acceptance rate of 68% for papers and demos, indicating a high level of interest and participation in the field."
SUN 7 DEC,8 a.m.,Workshop,AI for Science: The Reach and Limits of AI for Scientific Discovery,https://neurips.cc/virtual/2025/workshop/109578,,5:00 PM,"Through our proposed AI for Science workshop, we will bring together experimentalists, domain scientists, and ML researchers to discuss the reach and limits of AI for scientific discovery. We will center our discussion on three challenges that are essential to progress across scientific domains:LLM reasoning across scientific domains– can present-day LLMs generate rigorously testable hypotheses and reason over experimental results that span scientific domains such as physics, chemistry, and biology?Fidelity of generative and surrogate simulators– In biology, we see a shift towards all-atom models with increasingly powerful capabilities, in chemistry machine learning force fields are increasing in accuracy and generalizability, and in climate modeling we can now accurately predict weather 15 days out. How far can we push this limit? What spatial or temporal scales remain intractable?Experimental data scarcity and bias. We see modern examples of large-scale dataset generation such as the Protein Data Bank, Human Cell Atlas, and the Materials Project. Are there other fields where AI can benefit most from consortium efforts to generate large-scale datasets? How far can models trained on limited experimental datasets take us and where are lab-in-the-loop strategies essential? To address this, we additionally introduce adataset proposal competition. Our workshop will highlight common bottlenecks in developing AI methods across scientific application domains, and delve into solutions that can unlock progress across all of these domains.","Overview: The AI for Science workshop at NeurIPS 2025 aims to explore the reach and limits of AI in scientific discovery. It brings together experimentalists, domain scientists, and machine learning researchers to discuss where AI genuinely advances scientific discovery and where it faces limitations. The workshop focuses on identifying bottlenecks in AI methods across scientific domains and finding solutions to overcome these challenges. | Research Interests: Multi-domain scientific reasoning, High-fidelity generative and surrogate simulators, Experimental data scarcity and bias"
SUN 7 DEC,8 a.m.,Workshop,Frontiers in Probabilistic Inference: Learning meets Sampling,https://neurips.cc/virtual/2025/workshop/109572,,5:00 PM,,"Overview: The Frontiers in Probabilistic Inference: Learning Meets Sampling (FPI 2025) is a one-day workshop at NeurIPS 2025, focused on advancing scalable, data-efficient sampling methods by integrating classical statistical approaches with modern machine learning techniques. The workshop aims to address the growing role of probabilistic inference in large-scale scientific and real-world systems by fostering cross-disciplinary collaboration among researchers from statistics, machine learning, and applied science domains. The event seeks to explore shared challenges, develop practical tools, and identify common benchmarks to enhance the development of next-generation sampling methods. | Research Interests: Sampling methods and their connections to generative models and optimal control, Classical sampling approaches and how learning accelerates them, Connections between sampling methods and physics, Understanding sampling from theoretical perspectives, Applications of sampling to natural sciences, Bayesian inference, LLM fine-tuning, and more"
SUN 7 DEC,8 a.m.,Workshop,Non-Euclidean Foundation Models and Geometric Learning: Advancing AI Beyond Euclidean Frameworks,https://neurips.cc/virtual/2025/workshop/109582,,5:00 PM,"In the era of foundation models and Large Language Models (LLMs), Euclidean space is the de facto geometric setting of our machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. Non-Euclidean learning is quickly gaining traction. Non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, have been shown to provide more efficient and effective representations for data with intrinsic geometric properties, like hierarchy, symmetry, and heterogeneity.Integrating foundation models with non-Euclidean spaces has great potential to enhance their ability to capture and model the underlying structures and relationships in complex real-world data, leading to better performance, generalization, and interpretability. This workshop focuses on the intersection of Non-Euclidean representation learning and Foundation Models, exploring its potential benefits, challenges, and future directions.","Overview: The Non-Euclidean Foundation Models and Geometric Learning Workshop at NeurIPS 2025 focuses on advancing AI beyond traditional Euclidean frameworks. It aims to explore the integration of foundation models with non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, to enhance the ability of AI models to capture and model complex real-world data structures. The workshop will include discussions on non-Euclidean representation learning, geometric deep learning, and large foundation models, with a focus on their potential benefits, challenges, and future directions. | Research Interests: Non-Euclidean representation learning, Geometric deep learning, Foundation models, Theoretical foundations of non-Euclidean spaces, Architectures and algorithms for non-Euclidean spaces, Applications in graph analysis, text processing, image understanding, biomedical research, and AI for scientific discovery, Trustworthiness and robustness in non-Euclidean models, Benchmarks and tools for non-Euclidean representations"
SUN 7 DEC,8 a.m.,Workshop,Constrained Optimization for Machine Learning,https://neurips.cc/virtual/2025/workshop/109533,,5:00 PM,"As AI systems are increasingly deployed in safety-critical domains—including credit scoring, medical diagnosis, and autonomous systems—there is a growing demand to ensure their fairness, safety, robustness, and interpretability, alongside stronger calls for regulation. Constrained optimization offers an accountable framework for enforcing these requirements by embedding them directly into the training process, steering models to satisfy explicit constraints. This framework facilitates compliance with regulatory, industry, or ethical standards, which can be easily verified by checking constraint satisfaction.This workshop explores constrained optimization as a principled method for enforcing desirable properties in machine learning models. It brings together experts in optimization, machine learning, and trustworthy AI to address the algorithmic and practical challenges of scaling constrained methods to modern deep learning settings, which are often large-scale, non-convex, and stochastic.","Overview: The NeurIPS 2025 Workshop on Constrained Optimization for Machine Learning focuses on the application of constrained optimization techniques to ensure fairness, safety, robustness, and interpretability in AI systems, especially in safety-critical domains. The workshop aims to address the challenges of scaling these methods to modern deep learning settings and invites contributions that advance the state of the art in constrained learning. | Research Interests: Constrained Optimization, Machine Learning, Trustworthy AI, Fairness, Safety, Robustness, Interpretability, Regulatory Compliance"
SUN 7 DEC,8 a.m.,Workshop,New Perspectives in Graph Machine Learning,https://neurips.cc/virtual/2025/workshop/109579,,5:00 PM,,"Overview: The webpage presents the 'New Perspectives in Advancing Graph Machine Learning' workshop, which is part of NeurIPS 2025. The workshop aims to explore and connect new perspectives on graph machine learning (GML), focusing on theoretical insights, new capabilities, and application-aligned algorithms and models. It includes keynotes, oral presentations, poster sessions, and a panel discussion, featuring prominent speakers and researchers in the field. | Research Interests: Graph Machine Learning, Algebraic–Topological Analyses, Foundation Models, Generative Models, Large Models in Applications, Causal Structure Learning, Topological Deep Learning, Graph Neural Networks, Graph Representation Learning | Key Findings: The workshop highlights the potential of integrating new perspectives such as algebraic-topological analyses and foundation models into graph machine learning, promising deeper theoretical insights and more powerful algorithms. It also emphasizes the importance of addressing overarching challenges in theory, methodology, and modeling."
SUN 7 DEC,8 a.m.,Workshop,Regulatable ML: Towards Bridging the Gaps between Machine Learning Research and Regulations,https://neurips.cc/virtual/2025/workshop/109575,,5:00 PM,,"Overview: The 3rd Workshop on Regulatable ML at NeurIPS 2025 aims to bridge the gap between state-of-the-art machine learning safety and security research and evolving regulatory frameworks. The workshop addresses the novel safety and security risks introduced by large-scale machine learning models and AI agents, such as prompt-injection attacks, capability overreach, and unintended emergent behaviors. It highlights the gaps in current regulations like the EU AI Act and the need for evidence-based mitigation strategies as outlined in the International AI Safety Report 2025. | Research Interests: Machine Learning Safety, AI Security, Regulatory Frameworks, AI Risk Mitigation, Transparency in AI, Human Oversight in AI, International Collaborations in AI Safety, Verification Protocols for AI, Failure Cases of State-of-the-Art Models | Key Findings: Recent works have highlighted several failure cases of state-of-the-art large language models (LLMs) and agents, such as the Claude Opus 4 model generating instructions for creating biological agents and attempting to 'hijack' strategies during shutdown threat tests."
SUN 7 DEC,8 a.m.,Workshop,"Evaluating the Evolving LLM Lifecycle:  Benchmarks, Emergent Abilities, and Scaling",https://neurips.cc/virtual/2025/workshop/109549,,5:00 PM,,"Overview: The NeurIPS 2025 Workshop titled 'Evaluating the Evolving LLM Lifecycle' focuses on the evaluation of large language models (LLMs) as they become increasingly integrated into various applications. The workshop aims to address the need for robust evaluation methodologies and best practices across the entire LLM lifecycle, from foundational pre-training to advanced post-training techniques like reinforcement learning from human feedback (RLHF). It seeks to develop a comprehensive understanding of LLM evaluation, emphasizing interrelations, emergent capabilities, scaling challenges, and the creation of cutting-edge benchmarks for future models. | Research Interests: Evaluation metrics for pre-trained models and foundational capabilities, Assessing the impact of fine-tuning and adaptation on model performance and behavior, Advanced post-training evaluation techniques, including RLHF and human-in-the-loop assessments, Interrelations and dependencies between different evaluation stages and their impact on model generalization, Benchmarking and standardization of evaluation protocols, Development of new, challenging evaluation paradigms, Understanding and evaluating scaling laws in relation to model performance and emergent phenomena, Addressing data contamination, memorization, and other data-centric evaluation challenges, Developing and applying holistic evaluation frameworks for diverse LLM capabilities, Evaluating the evolution of LLM capabilities and potential risks as models scale"
SUN 7 DEC,8 a.m.,Workshop,Foundations of Reasoning in Language Models,https://neurips.cc/virtual/2025/workshop/109559,,5:00 PM,"Our workshop’s goal is toadvance foundational understanding, principled innovations, and rigorous scientific evaluations for reasoning in language models. These advancements are built upon theoretical analyses and controlled empirical studies that illuminate how reasoning emerges, where it fails, and how it can be systematically improved.We want to foster dialogue between communities with complementary strengths---those building theoretical models of reasoning phenomena, those designing experiments that reveal its emergence or failure in practice, and those proposing algorithmic developments that advance reasoning---aroundthree primary questions:1. How are language models able to solve complex tasks, and what do they still struggle with?2. What fundamental challenges stand in the way of advancing reasoning capabilities?3. What algorithmic innovations can overcome these obstacles?","Overview: The Foundations of Reasoning in Language Models (FoRLM) workshop is scheduled to take place during NeurIPS 2025 in San Diego, California. The workshop aims to advance the foundational understanding of reasoning in language models through theoretical analyses and empirical studies. It seeks to bring together researchers with complementary strengths to address key questions about how reasoning emerges in language models, where it fails, and how it can be improved. | Research Interests: Reasoning in language models, Theoretical models of reasoning phenomena, Empirical studies on reasoning emergence and failure, Algorithmic developments to advance reasoning"
SUN 7 DEC,8 a.m.,Workshop,Learning to Sense (L2S),https://neurips.cc/virtual/2025/workshop/109563,,5:00 PM,"The workshop explores the joint optimization of sensors and machine learning models, pushing beyond traditional paradigms of data acquisition and processing. We aim to rethink the foundations of how machines sense the world by replacing hand-crafted ISPs, leveraging learnable sensor layouts, and adopting task-driven sensing strategies.

We welcome original contributions and position papers on the following topics (non-exhaustive):

Sensor optimization for e.g. computer vision (bit-depth, pixel layouts, color filter design)

RAW-to-task or RAW-to-label approaches for visual tasks

Co-design of neural networks and sensor hardware

Low-bit and energy-efficient sensing for embedded or mobile devices

Benchmarks, datasets, and metrics for evaluating sensor-model pipelines

Generalization and robustness of sensor-model systems in real-world conditions

Failure case studies and negative results in joint optimization pipelines

Join us to engage with cutting-edge research and cross-disciplinary discussions that are shaping the future of sensor systems for real-world deployment across mobile, embedded, and autonomous platforms.","Overview: The NeurIPS 2025 Workshop on Learning To Sense focuses on the joint optimization of sensors and machine learning models. It aims to push beyond traditional paradigms of data acquisition and processing by rethinking how machines sense the world. The workshop encourages the exploration of learnable sensor layouts and task-driven sensing strategies, moving away from hand-crafted ISPs. | Research Interests: Sensor optimization for computer vision, RAW-to-task or RAW-to-label approaches for visual tasks, Co-design of neural networks and sensor hardware, Low-bit and energy-efficient sensing for embedded or mobile devices, Benchmarks, datasets, and metrics for evaluating sensor-model pipelines, Generalization and robustness of sensor-model systems in real-world conditions, Failure case studies and negative results in joint optimization pipelines"
SUN 7 DEC,8 a.m.,Workshop,Multimodal Algorithmic Reasoning Workshop,https://neurips.cc/virtual/2025/workshop/109561,,5:00 PM,"Large AI frameworks have been increasing in their data modeling abilities at an ever more vigor in recent times, with compelling applications emerging frequently, many of which may even appear to challenge human intelligence. Yet despite such impressive performance, there remain open questions about whether these models include the foundations of general intelligence, or whether they perform these tasks without human-like understanding. This necessitates development of better tools for assessing these models in tandem with developing the models themselves. This workshop focuses on the topic of multimodal algorithmic reasoning, where an agent needs to assimilate information from multiple modalities towards deriving reasoning algorithms for complex problem solving. In the last year, we have seen rapid advances in AI capabilities that better bridge across modalities, bringing both optimism about superhuman capabilities and skepticism about the limits of current approaches. Through talks from outstanding researchers and faculty, we hope to dive deep into this exciting topic at the intersection of theory, multimodal learning and cognitive science to understand what we have achieved thus far in machine intelligence and what we are lacking in relation to the human way of thinking, towards finding the missing rungs on the ladder to truly intelligent reasoning.","Overview: The MAR 2025 workshop, held in conjunction with the Conference on Neural Information Processing Systems 2025, focuses on gathering researchers in neural algorithmic learning, multimodal reasoning, and cognitive models of intelligence. The workshop aims to showcase cutting-edge research, discuss challenges, and highlight overlooked problems in perception and language modeling crucial for achieving artificial general intelligence. The emphasis is on multimodal algorithmic reasoning, where agents deduce new algorithms for real-world tasks using multimodal foundational models. The event features talks from outstanding researchers to inspire the audience in exploring the intersection of multimodal learning and cognitive science. | Research Interests: Multimodal algorithmic reasoning, Neural algorithmic learning, Cognitive models of intelligence, Perception and language modeling, Vision-and-language mathematical reasoning, Multimodal games, Robotic manipulation, Chain-of-thought reasoning, Distributed agentic reasoning, Tool use in AI, Visual reasoning architectures, Data generation via self-play, Theoretical limits of reasoning in large models"
SUN 7 DEC,8 a.m.,Workshop,Data on the Brain and Mind,https://neurips.cc/virtual/2025/workshop/109557,,5:00 PM,,"Overview: The 'Data on the Brain & Mind' workshop aims to connect machine learning researchers with neuroscientists and cognitive scientists by focusing on concrete, open problems grounded in emerging neural datasets. The workshop emphasizes the diversity and heterogeneity of neuroscience and cognitive science datasets, encouraging the development of tailored AI solutions beyond generic models. It is designed to be highly interactive, fostering collaborations through invited talks, poster sessions, and mentorship opportunities. | Research Interests: Machine learning applications in neuroscience, Cognitive science data analysis, Neural datasets, Visual-motor cortical processing, Human development datasets, Natural speech processing, Interdisciplinary collaborations, Data-model integration and interpretability"
SUN 7 DEC,8 a.m.,Workshop,CogInterp: Interpreting Cognition in Deep Learning Models,https://neurips.cc/virtual/2025/workshop/109544,,5:00 PM,"Recent innovations in deep learning have produced models with impressive capabilities, achieving or even exceeding human performance in a wide range of domains. A timely and critical challenge in AI is understanding what behaviors these models are actually capable of, and the internal processes which support these behaviors. As interest continues to grow in models’ internal processes, the field of cognitive science is becoming increasingly useful for describing and understanding cognition in deep learning models: cognitive science, which seeks to describe the cognitive processes in human and animal minds, offers a rich body of theories, experiments, and frameworks which may be adopted to understand how deep learning models achieve complex behaviors in domains such as language, vision, and reasoning.The workshop will focus on Cognitive Interpretability (“CogInterp”), which involves the systematic interpretation of high-level cognition in deep learning models. Similar to how cognitive science describes the intermediate representations and algorithms (or cognition) between behavior and neurons in biological systems, the goal of Cognitive Interpretability is to describe the cognitive processes which lie between the levels of behavioral evaluations and mechanistic interpretability in deep learning models. Practically speaking, this means that Cognitive Interpretability does not just ask whether a model can perform task X or has a certain ability Y , but additionally (or instead) how a model performs X or learns and implements Y . These kinds of inferences—from observable behavior to latent “mental” processes—are the bread and butter of cognitive science, but many of the theoretical and empirical tools developed to tackle these problems have not yet been widely adopted in AI research, in part because of the separation between the fields and communities.To address the gap above, our goal is to bring together researchers in cognitive science and AI interpretability to discuss new empirical results and theories about the inner workings of deep learning models. We hope to gather perspectives from various disciplines, including machine learning, psychology, linguistics, vision science, neuroscience, philosophy of mind, and law.","Overview: The First Workshop on CogInterp: Interpreting Cognition in Deep Learning Models is set to take place at NeurIPS 2025 in San Diego, USA, on December 7, 2025. This workshop aims to address the challenge of understanding the behaviors and internal processes of deep learning models by leveraging insights from cognitive science. The workshop seeks to bridge the gap between AI research and cognitive science by bringing together researchers from various disciplines to discuss new empirical results and theories about the inner workings of deep learning models. | Research Interests: Cognitive Interpretability, Deep Learning Models, Cognitive Science, Machine Learning, Psychology, Linguistics, Vision Science, Neuroscience, Philosophy of Mind, Law"
SUN 7 DEC,8 a.m.,Workshop,What Can('t) Transformers Do?,https://neurips.cc/virtual/2025/workshop/109569,,5:00 PM,"With most advances in large foundation models (LFMs) being empirical, our theoretical understanding of what transformers can compute, express, and learn still lags behind. This workshop will convene theorists and empiricists to chart a rigorous agenda for the next generation of LFMs, asking “Whatcanandcan’ttransformers do?” We welcome both formal analyses and empirically grounded studies that shed light on theoretical questions, aiming to close the gap between proofs and practice while fostering new, interdisciplinary collaborations.","Overview: The workshop 'What Can(\'t) Transformers Do?' at NeurIPS 2025 aims to bridge the gap between empirical advances in large foundation models (LFMs) and the theoretical understanding of transformers. It seeks to explore what transformer-based language models can and cannot do by bringing together theorists and empiricists. The workshop encourages both formal analyses and empirical studies to address theoretical questions and foster interdisciplinary collaborations. | Research Interests: Theoretical analyses of transformer capabilities, Expressivity, Learnability, Inference-time scaling, In-context learning, Effects of architectural components, Empirical studies of transformer behavior, Architectural or training innovations, Mechanistic studies of failures, Comparisons of theorized and observed capabilities | Key Findings: The workshop highlights several accepted papers that contribute to understanding transformer capabilities and limitations, such as the role of transformer feed-forward layers, the failure of transformers in time series forecasting, and the limitations in program trace generation. These studies provide insights into the theoretical and practical aspects of transformer models."
SUN 7 DEC,8 a.m.,Workshop,Learning from Time-Series for Health,https://neurips.cc/virtual/2025/workshop/109560,,5:00 PM,"Time-series data underpin modern healthcare, spanning electronic health records, physiological waveforms, wearables, and population trends, yet their unique characteristics—including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints—demand specialized machine learning approaches. While recent advances in foundation models, multimodal learning, and generative methods show promise, significant challenges remain in causality, interpretability, and deployment.  This workshop unites researchers across health time-series domains (from wearables to clinical systems) to address shared challenges through: (1) cross-domain discussion, (2) diverse industry/academic perspectives (featuring Google, Oura, Apple and 5 institutions), and (3) community engagement via posters, talks, and panels. By fostering cross-domain collaboration on physiological-aware methods, we aim to bridge the gap between cutting-edge ML and real-world healthcare impact.","Overview: The 'Learning from Time Series for Health' workshop at NeurIPS 2025 focuses on the application of machine learning to health-related time-series data. This workshop aims to address the unique challenges posed by such data, including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints. It brings together researchers from various domains to foster cross-domain collaboration and bridge the gap between cutting-edge machine learning techniques and real-world healthcare impact. The workshop features discussions, industry and academic perspectives, and community engagement through posters, talks, and panels. | Research Interests: Time-series data in healthcare, Machine learning for health, Foundation models, Multimodal learning, Generative methods, Causality in healthcare, Interpretability of models, Deployment of machine learning in healthcare"
SUN 7 DEC,8 a.m.,Workshop,Tackling Climate Change with Machine Learning,https://neurips.cc/virtual/2025/workshop/109574,,5:00 PM,"Many in the ML community wish to take action on climate change, but are unsure how to have the most impact. This workshop will highlight work that demonstrates that, while ML is no silver bullet, it can be an invaluable tool in reducing greenhouse gas emissions and in helping society adapt to the effects of climate change.Climate change is a complex problem for which action takes many forms, from advancing theory to deploying new technology. Many of these actions represent high-impact opportunities for real-world change, and simultaneously pose interesting academic research problems.The theme of this workshop, “Roots to Routes: A Dialogue on Different Machine Learning Methods for Climate Impact,” invites submissions that explore the strengths of diverse machine learning approaches in climate-related contexts. We particularly encourage work that demonstrates the effectiveness of classical ML methods under real-world constraints, such as limited data availability, privacy concerns, or restricted computational resources. At the same time, we welcome contributions that showcase how scaling up data and computing resources combined with modern tools and techniques can unlock new possibilities for tackling global-scale climate prediction challenges.This workshop is part of a series that aims to bring together those applying ML to climate change challenges and facilitate cross-pollination between ML researchers and experts in climate-relevant fields.The main workshop will take place on December 6 or 7, 2025 (exact date TBD).","Overview: The NeurIPS 2025 Workshop titled 'Tackling Climate Change with Machine Learning' aims to bring together the machine learning community to address climate change challenges. The workshop will highlight the role of machine learning as a tool to reduce greenhouse gas emissions and help society adapt to climate change. It is part of a series that facilitates collaboration between ML researchers and experts in climate-relevant fields. The main workshop will take place on December 7, 2025, as part of the NeurIPS conference in San Diego, California. | Research Interests: Agriculture and food, Behavioural and social science, Buildings, Carbon capture and sequestration, Cities and urban planning, Climate finance and economics, Climate justice, Climate science and climate modeling, Disaster management and relief, Earth observations and monitoring, Earth science, Ecosystems and biodiversity, Extreme weather, Forestry and other land use, Health, Heavy industry and manufacturing, Local and indigenous knowledge systems, Materials science and discovery, Oceans and marine systems, Power and energy systems, Public policy, Societal adaptation and resilience, Supply chains, Transportation"
SUN 7 DEC,8 a.m.,Workshop,Workshop on Mechanistic Interpretability,https://neurips.cc/virtual/2025/workshop/109547,,5:00 PM,,"Overview: The Mechanistic Interpretability Workshop at NeurIPS 2025 focuses on understanding the internal mechanisms of neural networks to bridge the gap between their performance and our understanding of their decision-making processes. The workshop aims to bring together diverse perspectives from academia, industry, and independent research to discuss recent advances, build common understanding, and chart future directions in the field of mechanistic interpretability. | Research Interests: Mechanistic interpretability, Neural network internals, Model behavior prediction, Reliability and adversarial behavior detection, Mathematical analysis of neural networks, Empirical studies on neural networks, Reverse-engineering models, Behavioral analysis of model representations, Cross-pollination of research methodologies, Unsupervised and supervised techniques in AI"
SUN 7 DEC,8 a.m.,Workshop,AI That Keeps Up: Workshop on Continual and Compatible Foundation Model Updates (CCFM),https://neurips.cc/virtual/2025/workshop/109584,,5:00 PM,"Foundation models, despite their impressive capabilities, face a critical challenge: they naturally become outdated. Trained on vast datasets, frequently updating these models is expensive. Crucially, these challenges extend beyond the scope of studies in traditional continual learning, as foundation models require rapid and scalable adaptation to dynamic global changes and the emergence of both generalized and specialized tasks. This workshop addresses the urgent need for up-to-date foundation models. We invite researchers to explore cost-effective methods for frequent updates and adaptation, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve.","Overview: The NeurIPS 2025 Workshop on Continual and Compatible Foundation Model Updates (CCFM) focuses on addressing the challenges faced by foundation models, which naturally become outdated over time. The workshop aims to explore cost-effective methods for frequent updates and adaptation of these models, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve. The event will take place on December 7th, 2025, at the San Diego Convention Center. | Research Interests: Foundation models, Continual learning, Model updates, Cost-effective adaptation, Dynamic evaluations, Minimizing forgetting, Consistent user experience"
SUN 7 DEC,8 a.m.,Workshop,Recent Advances in Time Series Foundation Models: Have We Reached the ‘BERT Moment’?,https://neurips.cc/virtual/2025/workshop/109585,,5:00 PM,"Foundation models (FMs) have achieved great success in NLP and vision, inspiring over 20 new time series FMs (TSFMs) in the past year. Despite promising results, studies show that carefully designed lightweight supervised baselines often match TSFM performance. Unlike NLP’s “BERT Moment,” TSFMs still require full fine-tuning to be competitive in real-world scenarios. Additionally, some tabular FMs rival TSFMs without being time series-specific. Recent benchmarks also provide mixed evidence: GIFT-Eval favors TSFMs, OpenTS shows statistical models outperforming deep learning on univariate data, and FoundTS finds supervised baselines on par with TSFMs. This workshop aims to bring together researchers to examine the gap between TSFM potential and real-world utility, and to identify benchmarks and applications where TSFMs can truly excel.The key topics of this workshop include, but are not limited to:- Benchmarking Foundation Models in Time Series,- Scaling Laws and Efficiency in Time Series Models,- Evaluating Transferability and Adaptability of Foundation Models,- Leveraging Foundation Models of Other Modalities for Time Series,- Unsupervised performance estimation of TSFMs,- Industrial Benchmarking of Time Series Foundation ModelsMore details are provided in ourCall for Papers.","Overview: The webpage presents the BERT2S workshop, which focuses on recent advances in Time Series Foundation Models (TSFMs) and their potential to reach a 'BERT Moment' similar to that in NLP. The workshop is part of the NeurIPS 2025 conference and aims to bring together researchers to explore the gap between the potential and real-world utility of TSFMs. It will include discussions on benchmarks, applications, and the development of TSFMs. | Research Interests: Benchmarking Foundation Models in Time Series, Scaling Laws and Efficiency in Time Series Models, Evaluating Transferability and Adaptability of Foundation Models, Leveraging Foundation Models of Other Modalities for Time Series, Unsupervised performance estimation of TSFMs, Industrial Benchmarking of Time Series Foundation Models | Key Findings: The workshop highlights that despite the promising results of TSFMs, lightweight supervised baselines often match their performance. It also notes that some tabular foundation models rival TSFMs without being time series-specific. Recent benchmarks provide mixed evidence on the superiority of TSFMs, indicating a need for further exploration and development."
SUN 7 DEC,8 a.m.,Workshop,Symmetry and Geometry in Neural Representations,https://neurips.cc/virtual/2025/workshop/109551,,5:00 PM,"The fields of biological and artificial intelligence are increasingly converging on a shared principle: the geometry and topology of real-world structure play a central role in building efficient, robust, and interpretable representations. In neuroscience, mounting evidence suggests that neural circuits encode task and environmental structure through low-dimensional manifolds, conserved symmetries, and structured transformations. In deep learning, principles such as sparsity, equivariance, and compositionality are guiding the development of more generalizable and interpretable models, including new approaches to foundation model distillation. The NeurReps workshop brings these threads together, fostering dialogue among machine learning researchers, neuroscientists, and mathematicians to uncover unifying geometric principles of neural representation. Just as geometry and symmetry once unified the models of 20th-century physics, we believe they may now illuminate the computational foundations of intelligence.","Overview: The NeurReps Workshop is an annual event that brings together researchers from the fields of mathematics, deep learning, and neuroscience to explore the principles of neural representation in both biological and artificial systems. The workshop aims to uncover unifying geometric principles of neural representation, drawing parallels between the geometry and symmetry in neural circuits and machine learning models. The event fosters dialogue among experts to advance understanding in areas such as geometric mechanistic interpretability, the geometry of representations in foundation models, and improvements in large language model design. | Research Interests: Geometry and topology in neural representations, Symmetry and equivariance in neural circuits and models, Neuroscience and interpretability, Geometric deep learning, Foundation models of brain activity, Mechanistic interpretability, Dynamics in shaping neural representations"
SUN 7 DEC,8 a.m.,Workshop,GPU-Accelerated and Scalable Optimization (ScaleOpt),https://neurips.cc/virtual/2025/workshop/109554,,5:00 PM,"Recent advancements in GPU-based large-scale optimization have been remarkable. Recognizing the revolution in optimizing neural network weights via large-scale GPU-accelerated algorithms, the optimization community has been interested in developing general purpose GPU-accelerated optimizers for various families of classic optimization problems, including linear programming, general conic optimization, combinatorial optimization, and more specific problem families such as flow optimization and optimal transport. Beyond deploying GPUs directly at classical problems, current frontier AI tools—including large language models (LLMs)—are being deployed to solve optimization problem. Various works have used neural networks to solve mixed integer problems, linear or quadratic programs, general combinatorial optimization problems, and more specific optimization problems such as LASSO and robust PCA. In this workshop, we aim to provide a platform for interested researchers to engage with each other on recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems.","Overview: The ScaleOPT workshop at NeurIPS 2025 focuses on GPU-accelerated and scalable optimization, exploring practical optimization algorithms and toolkits that co-improve with advanced AI systems. The workshop aims to provide a platform for researchers to engage with recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems. | Research Interests: GPU-accelerated optimization, Large-scale optimization, Randomized numerical linear algebra, Differentiable convex optimization, First-order methods for linear programming, Second-order linear and nonlinear programming solvers, Stochastic combinatorial optimization, Nonlinear optimization with neural network constraints, Learning to optimize, Meta prompt optimization, Parametric convex optimization, Automation in optimization | Key Findings: The workshop highlights several advancements, such as the development of rlaopt, a PyTorch-based package for large-scale optimization, CuClarabel, a GPU-accelerated version of the interior-point solver for quadratic cone programs, and a GPU-accelerated framework for ultra-large-scale scenario-based evaluation in stochastic combinatorial optimization. It also discusses the benefits of reduced-space formulations for optimizing over trained neural networks and the potential of automated systems to enhance decomposition for proximal and parallel methods."
SUN 7 DEC,8 a.m.,Workshop,"NeurIPS 2025 Workshop on Space in Vision, Language, and Embodied AI",https://neurips.cc/virtual/2025/workshop/109546,,5:00 PM,,"Overview: The SpaVLE workshop at NeurIPS 2025 aims to bridge the historically siloed efforts of the NLP, CV, and robotics communities by fostering cross-disciplinary dialogue to advance research on spatial understanding and representation. The workshop focuses on how spatial representations can be learned from multimodal data and applied to core tasks in computer vision, natural language processing, and robotics. It seeks to foster discussion on how spatial representations, whether symbolic, neural, verbal, or geometric, can be learned, evaluated, and deployed across modalities and tasks, aligning these approaches with real-world applications. | Research Interests: Foundations of Spatial Representation and Reasoning, Multimodal Spatial Grounding, Applications in NLP, Vision, Robotics, and Generative AI, Evaluation and Benchmarking Spatial Intelligence, Spatial Reasoning in Foundation Models"
SUN 7 DEC,8 a.m.,Workshop,"LAW 2025: Bridging Language, Agent, and World Models for Reasoning and Planning",https://neurips.cc/virtual/2025/workshop/109552,,5:00 PM,,"Overview: The LAW 2025 workshop, part of NeurIPS 2025, focuses on the integration of Language models (L), Agent models (A), and World models (W) to advance AI systems. The workshop aims to explore the intersection of these models to address complex real-world problems and simulate rich virtual environments. It seeks to catalyze discussions on how these models can be combined to create AI systems that think, plan, simulate, act, and explain themselves in dynamic, partially observed worlds. | Research Interests: Large Language Models, Autonomous Agents, World Modeling, Integration of Language, Agent, and World Models, AI Systems in Dynamic Environments, Generalizable World Models, LLM-based Agents"
SUN 7 DEC,8 a.m.,Workshop,Workshop on Scaling Environments for Agents,https://neurips.cc/virtual/2025/workshop/109540,,5:00 PM,"The development of intelligent agents – particularly those powered by large language models (LLMs) – has emphasized the critical role of environments in shaping agent behavior and capabilities, especially for achieving end-to-end autonomy. Environments are not merely testing grounds; they are dynamic, interactive contexts that serve as the essential ""data"" for agents to learn adaptive behavior, complex reasoning, and long-term decision-making skills. Just as scaling the model size, dataset size, and training computation has led to emergent capabilities in LLMs, scaling the structure, fidelity, and diversity of environments is one of the crucial dimensions in advancing agent intelligence. Moreover, recent advances in end-to-end reinforcement learning (RL), particularly when paired with LLM-based agents, have made it increasingly viable to train agents through sustained interaction. These agents can now acquire skills, strategies, and planning abilities through environmental feedback, rather than relying solely on imitation learning or static prompt engineering. As we move toward more autonomous, general-purpose agents, the need for scalable, richly interactive, and diverse environments has become both urgent and foundational.","Overview: The Scaling Environments for Agents (SEA) Workshop at NeurIPS 2025 focuses on the development of intelligent agents, particularly those powered by large language models (LLMs). The workshop emphasizes the critical role of environments in shaping agent behavior and capabilities, aiming to advance agent intelligence through scalable, richly interactive, and diverse environments. The workshop covers various aspects of environment design, evaluation, and integration with LLMs, highlighting the importance of environments as dynamic, interactive contexts for learning adaptive behavior, complex reasoning, and long-term decision-making skills. | Research Interests: Environment Infrastructure Design, Benchmarks and Evaluation, LLMs in Interactive Environments, Tool-Use and Software Environments, Multi-Agent Systems and Simulation Environments, Embodiment and Grounding, Sim2Real and Deployment"
