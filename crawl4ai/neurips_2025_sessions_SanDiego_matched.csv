date,time,type,title,url,speaker,end_time,abstract,overview,匹配团队,关注方向,推荐理由
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Telling Stories at Scale: Multimodal ML in the Global Media Landscape,https://neurips.cc/virtual/2025/128652,,9:30 AM,"Netflix has long been recognized as a pioneer in personalization, leveraging member preference data to recommend the most engaging shows, movies, and games. In recent years, we have expanded our use of machine learning and data-driven approaches to support a wide array of upstream creative and operational workflows. In this talk, we will discuss how modern AI methods – contrastive learning, transformers, cross-modal retrieval, graph neural networks, etc. – are transforming the curation, localization, promotion, and launch of stories on a global scale. A distinctive aspect of our work is the integration of highly creative assets—text, images, video, and speech—alongside traditional tabular datasets. We will highlight unique challenges that arise at the intersection of multimedia, personalization, and web-scale products, and share how advanced ML/AI techniques are addressing these challenges to connect great stories with our worldwide audience.",,CBG; 海思; 诺亚,CBG: 3DAIGC; 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,CBG: Session涉及多模态机器学习技术（文本、图像、视频、语音等）在全球媒体故事讲述中的应用，CBG团队关注视频中运动物体分割、3D/4D稀疏重建及长视频生成一致性，session中提到的跨模态检索、transformers等现代AI方法可为其视频生成和多模态内容处理难题提供技术思路。; 海思: Session强调多模态融合（文本、图像、视频、语音）及大规模个性化推荐，海思团队关注多模态条件融合延迟和长上下文推理复杂度，session中提到的transformers和跨模态检索技术可为其多模态融合和低延迟推理提供解决方案。; 诺亚: Session聚焦多模态机器学习在全球媒体内容的应用，涉及文本、图像、视频、语音等多模态数据的融合与处理，诺亚团队关注长序列及多模态长序列模型的架构演进和计算瓶颈，session中提到的现代AI方法（如transformers、对比学习）直接关联其多模态长序列模型优化难题。
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Data Scout: “From Prompt to Corpus: Accelerating Domain-Specific Data Collection with LLMGuided Discovery”,https://neurips.cc/virtual/2025/128656,,9:30 AM,"Training large language models for specialized disciplines such as advanced mathematics, molecular biology, or legal reasoning is limited by the scarcity of large, high quality, domain specific corpora. Most publicly available datasets are dominated by general purpose web text. When available, specialized data are fragmented across diverse sources such as preprints, conference papers, forums, lecture notes, and digitized books. No single source offers comprehensive real-world coverage across scientific domains. Consequently, scaling up authentic domain data remains a bottleneck: collecting a subset of relevant tokens often requires downloading and filtering hundreds of terabytes of raw web material, a process that is both time consuming and costly.x000Dx000DWe introduce Data Scout, a modular, LLM powered pipeline that turns a high-level user intent (e.g., “I need data for advanced mathematics”) into a vetted, list of seed URLs in minutes. The system first expands the original intent using an LLM that generates a hierarchical subgraph of related concepts; this taxonomy drives a diversified set of search queries that systematically cover the target domain while respecting known licensing signals. Candidate URLs are then filtered by the same LLM using chain of thought prompting based on topical relevance, licensing clarity, and crawlability. Our results show that that the list of selected candidate URLs when crawled can yield a high percentage of relevant pages (40%+) related to the user’s intended topic or query, compared to less than 1 percent in general web-scale corpora. Data Scout is available with both CLI and GUI front ends. By democratizing domain specific data acquisition, Data Scout enables researchers without dedicated crawling infrastructure to bootstrap large, high-fidelity corpora, accelerating the development of specialized LLMs across various niche domains fields.",,nan,nan,nan
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Multimodal Data Foundation at Industry-Scale,https://neurips.cc/virtual/2025/128659,,9:30 AM,"Pre-training is fundamental to foundation models, enabling them to acquire broad knowledge that gives rise to emerging capabilities at later training stages, and scaling is the key for pre-training. In this talk, we present a recipe for building and curating pre-training, multimodal image-text paired data from scratch on a global scale, enabling mutual benefits between English and non-English data. We would like to share our key observations and insights with the community on: (1) why scaling matters, including the foundational role of data and key principles to hold for scaling; (2) how to design simple yet scalable data algorithms that enable industry-scale data collection and training without data filters, serving both research and production needs; (3) how the scaling improves Meta’s products at conventional and frontier machine learning areas. Submission is facilitated by Cogs & Marvel but is entirely organized, executed, and implemented by Meta.",,诺亚; 诺亚,诺亚: 大模型长序列，多模态长序列; 诺亚: 大模型后训练Reasoning，RL,诺亚: Session重点介绍了多模态图文配对数据的规模化预训练和数据算法设计，直接关联多模态长序列模型的训练数据构建和规模化问题，有助于解决团队关注的多模态长文本推理计算瓶颈和长序列架构优化。; 诺亚: Session中提到的预训练数据规模化和多模态数据设计为后训练阶段的推理和强化学习提供了基础数据支持，能为团队在自博弈与learning from experience训练框架及latent reasoning提供数据层面的支撑和思路。
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Toward General Full Autonomy: Open Research Challenges in Scalable Self-Driving,https://neurips.cc/virtual/2025/128661,,9:30 AM,"Speaker: Ben Snyder, Director of AI Research for Autonomous Vehicles, General Motorsx000Dx000DGM’s driver-assistance systems now power millions of vehicles across North America, logging over half a billion hands-free miles with zero reported crashes—demonstrating the safety and scalability of autonomy at unprecedented consumer scale. Following GM’s acquisition of Cruise earlier this year, the combined teams now bring together a decade of experience to accelerate progress toward full, generalized autonomy. This talk will dive into the open research challenges ahead—from model architecture and the balance between imitation and reinforcement learning, to leveraging vision-language models for long-tail, common-sense reasoning, and advancing the training, deployment, and simulation infrastructure needed to scale truly generalized autonomy.",,温哥华云; 多伦多云; 计算; 计算; 计算,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 计算: 高效模型架构; 计算: 训推新范式; 计算: 前沿应用负载,温哥华云: Session讨论了在自动驾驶中平衡模仿学习与强化学习的挑战，直接对应温哥华云团队关注的强化学习在视觉语言模型和大语言模型中的实际应用问题，能为提升强化学习的样本效率、性能和可扩展性提供思路。; 多伦多云: Session涉及实现通用完全自主驾驶的开放研究挑战，包括模型架构、训练与部署基础设施，这与多伦多云团队关注的提升AI Agent行为可靠性、自主学习与持续优化机制高度相关，能为Agent的规划、多步执行能力及优化提供技术支持。; 计算: Session提到模型架构设计与训练、部署基础设施的挑战，特别是针对自动驾驶的规模化自主性，这与计算团队关注的模型架构对计算架构的影响及未来模型结构演进趋势密切相关，有助于理解自动驾驶领域对高效模型架构的需求。; 计算: Session强调训练、部署和仿真基础设施的进展与挑战，涉及模仿学习与强化学习的平衡，直接关联计算团队关注的训练推理新范式的演进及负载特征理解，能为未来训推范式的设计提供参考。; 计算: Session聚焦于实现通用完全自主驾驶的规模化挑战，涉及多模态模型和Agentic系统的训练与部署，这与计算团队关注的Agentic和多模态模型负载演进及其对计算架构的新诉求高度契合。
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Beyond Benchmarks: Rethinking Reasoning in Language Models,https://neurips.cc/virtual/2025/128665,,9:30 AM,"Reasoning is often described as the next frontier for AI, but what does it really mean for a model to “reason”, and how should we measure it? Popular benchmarks like GSM8K suggest steady progress, yet controlled studies reveal that models can fail dramatically under small changes—such as swapping numbers or adding irrelevant details. Large Reasoning Models (LRMs), which generate explicit chains of thought, raise new optimism but also expose clear limits: they often underperform standard models on simple tasks, improve briefly at medium complexity, and then collapse on harder ones despite having unused compute. Crucially, reasoning is not the same as knowledge recall, tool use, or agent-like behavior. True reasoning involves solving novel problems, decomposing them into steps, generalizing to new contexts, recombining partial results, and finally generating novel hypotheses—capabilities current systems largely lack. Today’s evaluations, focused on final answers and contaminated benchmarks, risk giving a misleading sense of progress. This talk will provide a critical review of reasoning in language models, highlight why current evaluations can be deceptive, and emphasize that reasoning is not just about “what"" models answer, but “how"" they solve problems.",,多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: Session聚焦于语言模型中的推理能力，强调推理不仅是知识回忆，而是解决新问题、分解步骤、生成新假设等能力，这与多伦多云团队关注的提升AI Agent评估准确性、行为可靠性及具备planning与多步执行能力的L3+ agent持续优化密切相关，session内容可为其提供推理能力评估和优化的新思路。; 诺亚: Session深入探讨语言模型推理的本质及其评估方法，强调当前模型在复杂推理任务上的局限性，诺亚团队关注的自博弈与learning from experience训练框架及Latent Reasoning直接涉及提升模型推理能力和训练范式，session内容可为其提供对推理本质的理解及评估方法的改进思路。
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,Foundational Generative Recommendations for E-Commerce,https://neurips.cc/virtual/2025/128667,,9:30 AM,"Modern commerce platforms face the challenge of delivering personalized recommendations across billions of items to users with diverse intents, temporal dynamics, and cold-start scenarios. We present a generative foundation model for commerce built on Hierarchical Sequential Transduction Units (HSTU) that integrates Liquid Foundation Models (LFM) for rich textual product representations and custom CUDA kernels developed in collaboration with Nvidia for efficient training and online serving. Our approach demonstrates that generative methods unlock substantial gains through three key innovations: (1) large-scale contrastive learning with hard negative sampling; (2) temporal mechanisms that fuse multi-scale time signals (session, day, season) with commerce-specific features; and (3) optimized training and inference kernels. By treating LFM embeddings as auxiliary features rather than end-to-end fine-tuning, we maintain modularity while capturing semantic relationships. While results are promising, significant challenges remain in handling non-stationary preferences, multi-objective optimization, and ensuring fairness in generative retrieval—we discuss our roadmap toward truly foundational commerce models that generalize across domains and market conditions.",,存储; 海思,存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速,存储: Session介绍了基于自定义CUDA内核的高效训练和在线推理服务，涉及多模型系统中模型加载、卸载及调度的优化，与团队关注的多模型推理中存储系统访问模式和调度新变化直接相关。; 海思: Session中提到利用Liquid Foundation Models的文本表示和优化训练推理内核，涉及多模态特征融合和低延迟推理，能够为团队在多模态条件融合延迟和长上下文推理复杂度优化提供技术参考。
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,From Research to Markets: Applying Cutting-Edge Machine Learning in Quantitative Finance,https://neurips.cc/virtual/2025/128670,,9:30 AM,"In modern quantitative finance, the boundaries between academic machine learning research and real-world trading strategies are rapidly dissolving. In this talk, we will share how researchers at G-Research apply advances in deep learning, probabilistic modelling, reinforcement learning, and large-scale optimization to some of the most challenging problems in global financial markets. Our work transforms vast, noisy, and non-stationary data into predictive signals, demanding innovations that extend the state of the art in both theory and practice. This includes sequence modelling for high-frequency data, scalable Bayesian inference for uncertainty quantification, generative modelling for scenario analysis, and reinforcement learning for adaptive portfolio construction. Operating at the intersection of rigorous science and high-performance computing, we thrive in an environment where milliseconds matter and model generalization is paramount.x000Dx000DCome and see how cutting-edge machine learning meets the realities of global financial markets at G-Research.",,温哥华云,温哥华云: Reinforcement fine tuning (RFT),温哥华云: Session中提到利用reinforcement learning进行adaptive portfolio construction，直接涉及强化学习在实际金融场景中的应用，能够为团队在提升sample efficiency、性能和可扩展性等实际问题提供解决思路。
TUE 2 DEC,8:30 a.m.,Expo Talk Panel,GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection,https://neurips.cc/virtual/2025/128668,,9:30 AM,"The rapid integration of LLMs for synthetic data generation offers a powerful solution for data scarcity, a critical issue for training machine learning models. However, the resulting data quality is often questionable, requiring costly and time-consuming manual review. This oversight is especially challenging in the crucial domain of trustworthy and safe AI.x000Dx000DA significant need here is the automated identification of adversarial and harmful inputs, a process known as red-teaming, to improve guardrailing systems before deployment. Developing an effective, fully automated red-teaming approach capable of generating diverse, out-of-domain harmful content has been a long-standing challenge.x000Dx000DTo address data scarcity in harmful text detection & the challenge of automated red-teaming, we introduce GRAID (Geometric & Reflective AI-Driven Data Augmentation), a novel, versatile, & dynamic multi-agent framework.x000Dx000DGRAID operates in two stages:x000D1) Geometric Generation: A constrained, fine-tuned LLM generates geometrically controlled examples to diversify content within the original embedding space.x000D2) Reflective Augmentation: A multi-agentic reflective process promotes stylistic diversity & uncovers difficult edge cases.x000Dx000DThis combination ensures both reliable coverage of the input space & nuanced exploration of harmful content. We demonstrate that augmenting a harmful text classification dataset with GRAID significantly improves the performance of downstream real-world guardrail models. Furthermore, GRAID captures data variability in new geometric domains while preserving data relationships.x000Dx000DWhile initially focused on harmful text detection, GRAID’s modular design makes it an inherently domain-agnostic framework adaptable to various applications beyond classification. In this talk, we will detail how GRAID distinguishes itself from existing solutions, discuss its building blocks, & share insights on its easy adaptation for diverse synthetic data generation needs.",,多伦多云,多伦多云: AI Agent,多伦多云: Session介绍了多智能体反思机制（Reflective Augmentation）和自动化红队测试（red-teaming）技术，这与多伦多云团队关注的提升AI Agent行为可靠性、管控与校验，以及自主学习与持续优化机制高度相关。GRAID框架中的多智能体协作和生成多样化有害内容的能力，能够为该团队在Agent评估和行为优化提供技术支持。
TUE 2 DEC,9:30 a.m.,Tutorial,Planning in the Era of Language Models,https://neurips.cc/virtual/2025/109596,,12:00 PM,"For over six decades, the field of automated planning has been at the heart of AI, empowering intelligent systems to reason, act, and achieve goals in complex, dynamic environments. From robotics and logistics to space exploration, planning research has fueled autonomous decision-making in real-world applications.Today, as large language models redefine what’s possible in AI, the principles and methodologies of planning are more vital than ever. The planning community brings decades of experience in designing, benchmarking, and interpreting intelligent behavior; expertise that can accelerate the development of powerful, trustworthy, and general-purpose LLM-based agents.Participants will gain a clear understanding of what planning truly entails, what has been learned (and sometimes forgotten) in the shift toward LLM-based approaches, and how foundational insights from the planning community can inform the creation of stronger, more reliable, and more scalable LLM-powered planners.","Overview: The webpage presents a tutorial titled 'Planning in the Era of Language Models' scheduled for December 2nd, 2025, at NeurIPS in San Diego, CA. The tutorial focuses on the integration of automated planning with large language models (LLMs). It highlights the importance of planning in AI, especially as LLMs redefine AI capabilities. The tutorial aims to provide participants with insights into planning methodologies and how these can enhance the development of LLM-based agents. | Research Interests: Automated planning, Large language models, AI reasoning and decision-making, Planning formalisms and languages, Evaluation of planning tools, Human-aware AI systems",多伦多云,多伦多云: AI Agent,多伦多云: Session聚焦于自动规划与LLM结合，强调规划社区经验对构建更强大、可靠的LLM驱动规划器的贡献，直接对应该团队关注的具备planning与多步执行能力的L3+ agent的持续优化难题，能为提升Agent行为的可靠性、规划能力及自主学习机制提供方法论和技术支持。
TUE 2 DEC,9:30 a.m.,Tutorial,Foundations of Tensor/Low-Rank Computations for AI,https://neurips.cc/virtual/2025/109591,,12:00 PM,,,nan,nan,nan
TUE 2 DEC,9:30 a.m.,Tutorial,"Human-AI Alignment: Foundations, Methods, Practice, and Challenges",https://neurips.cc/virtual/2025/109592,,12:00 PM,,,多伦多云; 温哥华云; 诺亚,多伦多云: AI Agent; 温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,多伦多云: 该session主题为Human-AI Alignment，直接涉及AI Agent的行为可靠性、评估准确性及自主学习机制等问题，能为团队提升Agent行为的可靠性和管控提供方法和技术支持。; 温哥华云: Human-AI Alignment涵盖强化学习在大模型中的应用，session内容可为团队解决强化学习在实际应用中理论与生产落地的差距、样本效率和性能提升等难题提供基础方法和实践经验。; 诺亚: 该session关注Human-AI Alignment的基础与实践，涉及自博弈与经验学习等训练框架，与团队在大模型后训练推理和强化学习的研究方向高度契合，有助于解决其在推理和训练框架上的挑战。
TUE 2 DEC,9:30 a.m.,Tutorial,"Model Merging: Theory, Practice and Applications",https://neurips.cc/virtual/2025/109593,,12:00 PM,,,nan,nan,nan
TUE 2 DEC,9:30 a.m.,Tutorial,New Frontiers of Hyperparameter Optimization: Recent advances and open challenges in theory and practice,https://neurips.cc/virtual/2025/109594,,12:00 PM,,,nan,nan,nan
TUE 2 DEC,9:30 a.m.,Tutorial,"Explain AI Models: Methods and Opportunities in Explainable AI, Data-Centric AI, and Mechanistic Interpretability",https://neurips.cc/virtual/2025/109599,,1:30 PM,,,nan,nan,nan
TUE 2 DEC,9:30 a.m.,Tutorial,Energy and Power as First-Class ML Design Metrics,https://neurips.cc/virtual/2025/109589,,12:00 PM,,"Overview: The tutorial titled 'Energy and Power as First-Class ML Design Metrics' at NeurIPS 2025 focuses on addressing energy as a critical bottleneck in machine learning. It provides practical measurements, a primer on power and energy as computing resources, and optimizations from kernels to clusters. The event is a collaboration between The ML.ENERGY Initiative at the University of Michigan and NVIDIA, featuring a series of sessions and an industry panel discussion. | Research Interests: Energy efficiency in machine learning, Power and energy as computing resources, Performance optimization under power constraints, Energy optimization with performance considerations, Industry applications of power and energy in ML",海思; 计算; 计算; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构; 计算: 训推新范式; 计算: 前沿应用负载,海思: Session聚焦于能耗和功率作为机器学习设计的核心指标，提供从内核到集群的性能优化方法，能够为海思团队在实现低延迟实时推理响应和多模态条件融合延迟优化中，提供能耗和功率约束下的优化思路和技术支持。; 计算: Session强调能耗和功率作为计算资源的关键指标，涵盖性能优化与功耗约束，能帮助计算团队理解和应对低精度训练推理对计算架构的能耗影响，支持其对模型架构演进趋势及计算系统需求的准确预判。; 计算: Session内容涉及能耗和功率优化，能够为计算团队在跟踪和预测训练推理新范式负载特征时，提供基于能耗和功率的性能优化方法，帮助准确定义未来负载的能耗特性。; 计算: Session聚焦于能耗和功率作为机器学习设计指标，能为计算团队研究Agentic和多模态模型应用负载的快速演进提供能耗优化视角，支持软硬件系统在能耗约束下的导入和优化。
TUE 2 DEC,noon,Expo Demonstration,Multimodal AI Forensic Search for Video Surveillance,https://neurips.cc/virtual/2025/128632,,3:00 PM,"Video surveillance often requires searching for specific targets from long-duration videos using multiple cameras. Traditional tracking‑and‑detection pipelines demand heavy manual filtering, and even recent multimodal approaches such as using CLIP remain limited to shallow visual attributes (e.g., clothing color) and weak temporal reasoning. This makes forensic search labor‑intensive.x000Dx000DWe present ForeSea, a novel AI forensic search system that supports rich multimodal queries (text + image) and returns timestamped evidence of key events. ForeSea is organized as a multi‑stage pipeline that couples tracking and retrieval with time‑aware VideoLLM reasoning: (1) uses tracking model to filter out irrelevant segments (e.g., frames without people) and produces person‑centric clips; (2) retrieval constructs an index over tracked clips to form a searchable database; and (3) during inference, the multimodal query is embedded to retrieve the top N candidate clips, which are then fed into a time-aware VideoLMM that performs temporal grounding and generates precise answers from concise input. Through ForeSea's multi-stage pipeline, we can search for targets using both image and text queries (e.g., asking 'When does this person get involved in a fight?' with an image of the person). This approach eliminates the need for detailed textual descriptions and enables effective temporal understanding across long videos.x000Dx000DTo evaluate LMM based forensic search, we introduce AI Forensic‑QA, a benchmark for multimodal video question answering with temporal grounding. On this benchmark, ForeSea achieves an 8.6 % accuracy improvement and a 6.9 (IoU) gain over strong baselines. To the best of our knowledge, this is the first benchmark in this domain to support multimodal queries evaluation. Our live demo showcases multimodal search, timestamped evidence visualization, and side‑by‑side comparisons with SOTA models.",,nan,nan,nan
TUE 2 DEC,noon,Expo Demonstration,Efficient LiDAR Processing with AI Models Leveraging Heterogeneous Compute,https://neurips.cc/virtual/2025/128633,,3:00 PM,"This demo showcases heterogeneous compute execution of a LiDAR model running in real time on an edge device. The LiDAR processing, specifically 3D sparse convolution (spconv3d) network, runs on the Qualcomm Adreno GPU, while the Region Proposal Network (RPN) executes on the Qualcomm Hexagon NPU.  This division of labor across specialized processors reduces on-device inference latency and maximizes overall efficiency. Additionally, a lightweight, learnable voxel removal layer that hierarchically prunes redundant voxels further reduces inference time without compromising detection accuracy.x000Dx000D""This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.""x000Dx000DImplementation challenge that we tacklex000Dx000DLiDAR models often combine different types of operations: irregular, sparse computations (e.g., SpConv3D) and dense convolutional layers (e.g., CNNs). These operations have distinct hardware affinities—SpConv3D is better suited for SIMT-style GPUs, while CNNs benefit from SIMD-style NPUs. Efficient execution requires mapping each part of the model to the most appropriate compute unit.x000Dx000DAnother challenge is the variability in voxel density across LiDAR frames. Not all voxels contribute meaningfully to object detection, many represent ground planes or distant background and can be safely discarded. However, identifying and removing these in a lightweight, learnable way is non-trivial.",,nan,nan,nan
TUE 2 DEC,noon,Expo Demonstration,Parallel generation with verification on device,https://neurips.cc/virtual/2025/128634,,3:00 PM,"In this work, we address the challenges of efficiently generating and verifying multiple responses from large language models (LLMs) directly on device. While sampling with non-zero temperature often yields improved responses compared to greedy approaches, selecting the best response requires generating several candidates and evaluating them without incurring significant latency or resource overhead. Cloud-based solutions often rely on separate verification models, which are impractical for on-device deployment due to resource constraints. Our proposed solution leverages multi-stream execution graphs and parallel LLM generation, enabling joint generation and verification within a unified framework. Combined with post-processing techniques such as majority voting, this approach minimizes latency and optimizes the selection of high-quality responses, paving the way for more effective on-device LLM inference.x000Dx000DSpecific challenge that we tackle (research/implementation-wise)x000Dx000DUsing non-zero temperature sampling with language models can result in higher-quality responses compared to greedy sampling, although this is not always assured. Achieving optimal output often requires generating multiple candidate responses and selecting the most suitable one for the user. This technique is widely adopted to enhance inference-time performance. When implemented on device, however, it presents two primary challenges: minimizing the latency associated with generating several responses and determining a resource-efficient method for selecting the best response from the generated set.",,海思,海思: 大语言模型和扩散模型的加速,海思: Session聚焦于在设备端实现多候选响应的并行生成与验证，解决了低延迟和资源受限环境下的推理效率问题，直接对应海思团队关于如何实现低延迟实时推理响应的难题。
TUE 2 DEC,noon,Expo Demonstration,Soft Prompts for On-Device Content Moderation,https://neurips.cc/virtual/2025/128635,,3:00 PM,"We demonstrate the first on-device integration of a safety-aligned large language model (LLM) using soft prompt distillation, powered by our proposed TV-DiSP framework. Our system showcases how a mobile device can run a quantized LLM equipped with learned soft prompts to moderate harmful or toxic content in real-time. The demo highlights the difference in LLM outputs with and without our soft prompts when subjected to adversarial or unsafe inputs, enabling efficient and safe deployment of LLMs on edge devices.x000Dx000DLLMs are known to produce unsafe or toxic outputs when prompted harmfully. Traditional safety mechanisms rely on dual-model architectures—pairing a base LLM with a separate guard model—which are memory and computationally expensive and unsuitable for deployment on resource-constrained devices like smartphones. The challenge is to achieve robust safety alignment without compromising latency, memory, or model utility in edge environments.",,海思,海思: 大语言模型和扩散模型的加速,海思: Session展示了如何在移动设备上运行量化的大语言模型并使用软提示实现实时内容审核，直接涉及低延迟实时推理响应的挑战，与团队关注的保持对话质量和上下文一致性前提下实现低延迟推理高度相关。
TUE 2 DEC,noon,Expo Demonstration,Generating group photos of multiple people from text and reference images,https://neurips.cc/virtual/2025/128636,,3:00 PM,"Reference-based multi-human image generation is emerging as a critical capability for personalization, synthetic data creation, and benchmarking generative models. Unlike single-subject generation, this task requires compositional reasoning to place multiple individuals—each with distinct identities—into a coherent scene guided by a text prompt. Existing models often fail to preserve identities or maintain spatial fidelity, which limits their applicability for real-world scenarios such as social content creation or training vision systems.x000Dx000DOur demo addresses these challenges by showcasing a state-of-the-art system for reference-based multi-human generation. The system takes reference images of multiple individuals and a text description of the desired scene, then produces a high-quality image featuring all participants in context. Built on the Flux-Kontext backbone and trained using synthetic data from DisCo (arXiv:2510.01399), our RL-based approach optimizes multiple rewards including Human Preference Score (HPS3) and Average ID Similarity. Evaluation on MultiHuman-Testbench (arXiv:2506.20879) confirms state-of-the-art performance.x000Dx000DThis demo showcases fast generation on a laptop powered by a Snapdragon processor, highlighting the efficiency and scalability of our solution.",,温哥华云,温哥华云: Reinforcement fine tuning (RFT),温哥华云: 该session采用了基于强化学习（RL-based approach）优化多重奖励（Human Preference Score和Average ID Similarity），直接对应团队关注的Reinforcement fine tuning技术，展示了强化学习在多人体图像生成中的实际应用，能为团队解决强化学习理论到生产落地的差距及性能提升提供具体案例和思路。
TUE 2 DEC,noon,Expo Demonstration,Reasoning through Multimodal End-to-End Decision Transformer Networks and Vision Language Action (VLA) models,https://neurips.cc/virtual/2025/128637,,3:00 PM,"This demonstration showcases the live output and visualization capabilities of an edge-integrated VLA model for path planning in automated driving scenarios. By harnessing raw multimodal sensor inputs, including visual and voice data, the VLA model processes information in real time to generate safe, explainable, and repeatable driving trajectories. The system operates on a Snapdragon Ride Elite SoC platform and incorporates safety guardrails, enabling robust decision-making and transparent reasoning. Attendees will observe how end-to-end AI networks interpret complex environmental cues to deliver actionable driving paths, with a special focus on complex use cases involving vulnerable road users and other actors on the road. This demonstration highlights advances in multimodal reasoning and edge deployment for next-generation intelligent mobility solutions.",,海思; 计算; 诺亚,海思: 大语言模型和扩散模型的加速; 计算: 前沿应用负载; 诺亚: 大模型后训练Reasoning，RL,海思: Session聚焦多模态端到端决策Transformer网络和视觉语言动作模型，涉及多模态条件融合和实时推理，直接对应海思团队关于多模态条件融合延迟大和实时推理响应低延迟的难题，session中展示的边缘端VLA模型和安全决策推理技术可为其提供具体的加速和优化思路。; 计算: Session展示了多模态模型在自动驾驶路径规划中的实时决策和复杂环境理解，涉及Agentic AI系统和多模态推理，符合计算团队关注的Agentic和多模态模型应用负载的快速演进及其对计算架构的新诉求，session内容可帮助其理解和应对未来软硬件系统的负载挑战。; 诺亚: Session强调端到端AI网络的推理能力和透明决策过程，涉及复杂环境下的推理和决策，契合诺亚团队关于后训练推理和强化学习（RL）框架的研究方向，session中多模态推理和安全决策机制可为其提供具体的技术参考。
TUE 2 DEC,noon,Expo Demonstration,Disaggregated LLM Serving on AI Accelerators,https://neurips.cc/virtual/2025/128638,,3:00 PM,"This demo showcases disaggregated serving on Qualcomm Cloud AI 100 Ultra Card, a power-efficient AI inference accelerator purpose-built for large language models (LLMs) serving. The accelerator has been deployed across multiple cloud service providers (CSPs) globally and is actively serving state-of-the-art LLMs and other generative AI workloads.x000Dx000DLLM inference typically involves two distinct stages: prefill and decode. The prefill stage is compute bound, while the decode stage is memory bound. Applying uniform parallelism strategies across both stages often results in suboptimal performance, particularly in key metrics such as Time to First Token (TTFT) and Requests Per Minute (RPM) at the cluster level.x000Dx000DThis demo highlights the performance benefits of disaggregated parallelism strategies tailored to the unique characteristics of each stage. By optimizing the execution of prefill and decode independently, we demonstrate significant improvements in TTFT and overall throughput.x000Dx000DKey benefits:x000Dx000DImproved TTFT: Faster initial response times for LLM queries.x000Dx000DHigher throughput: Increased number of requests served per minute at the cluster level.x000Dx000DOptimized resource utilization: Efficient mapping of compute and memory resources to match workload characteristics.x000Dx000DSLA-adherent performance: Maintains service quality and responsiveness within strict latency and throughput requirements.",,海思; 存储; DCN,海思: 大语言模型和扩散模型的加速; 存储: 单/多模型推理; DCN: Network4AI 与 AI4Network,海思: Session聚焦于LLM推理的分阶段（prefill和decode）优化及加速，特别是低延迟实时推理和高效资源利用，直接对应海思团队关于低延迟实时推理响应和长上下文推理复杂度优化的难题。; 存储: Session中提到的分阶段并行策略和资源优化涉及内存与计算资源的高效调度，与存储团队关注的多模型系统中KV Cache加载卸载及内存与存储协调利用的新方法高度相关。; DCN: Session展示了在云服务提供商环境下的AI加速器部署和集群级别的吞吐量提升，涉及计算、存储与网络资源的协同优化，契合DCN团队关于数据中心AI训练推理网络基础设施优化与协同设计的关注。
TUE 2 DEC,noon,Expo Demonstration,SwiftEdit: Fast Text-guided Image Editing via One-step Diffusion on a Mobile Device,https://neurips.cc/virtual/2025/128639,,3:00 PM,"In this demo, we show an on-device inference of our one-step diffusion image editing model (SwiftEdit) [1] that performs interactive image editing based on the user’s source image and text prompt, running on an Android smartphone powered by Qualcomm Technologies’ latest Snapdragon Mobile Platform. On A100 GPUs, this technique can run in real-time with 0.23s per single edit operation. We expect SwiftEdit to perform each edit operation in seconds on the smartphone, demonstrating efficient and responsive on-device diffusion inference.x000Dx000DScientific Challenge that we tacklex000Dx000DExisting text-guided image editing methods fell short of the speed demands required for real-world and on-device applications due to the costly multi-step inversion and sampling process involved. In response to this, we developed SwiftEdit that performed image editing using just one-step inversion and one-step image reconstruction.x000Dx000DEfficiently running SwiftEdit requires concurrently on-boarding multiple deep models, including IP-Adapter (Vision Encoder and Image Projection), SwiftBrush (U-Net, VAE, Text Encoder), and SwiftBrush-based Inversion Network. This poses significant challenges for efficient execution and inter-module communication, while enabling an interactive image editing experience for the user — with all computation performed entirely on the edge device.",,海思,海思: 大语言模型和扩散模型的加速,海思: 该session介绍了SwiftEdit在移动设备上实现的一步扩散模型推理，直接涉及扩散模型的高效推理和多模态条件融合，能够为海思团队关于多模态条件融合延迟大和低延迟实时推理响应的难题提供技术参考和解决思路。
TUE 2 DEC,noon,Expo Demonstration,Mobile Video Diffusion Transformers,https://neurips.cc/virtual/2025/128640,,3:00 PM,"We demonstrate Neogradon, the first video diffusion transformer (DiT) designed to run on low-power NPUs in mobile devices, such as phones and laptops. Despite DiTs huge memory and computation cost due to the quadratic attention over thousands of video tokens, we show that mobile devices can run these models when being designed for efficiency. To achieve this level of efficiency:x000Dx000DWe replace the original large text encoder with a much smaller one with minimal quality loss through our novel distillation framework, which doesn’t require any image or video data.x000Dx000DWe propose an asymmetric decoder distillation approach, which allows us to replace the native codec-latent-VAE decoder with a more efficient one, without disturbing the generative latent-space of the video generation pipeline.x000Dx000DWith our block pruning strategy, we remove entire blocks from the MMDiT denoiser based on their relative importance and recover the original performance through a two-stage distillation process.x000Dx000DWe reduce the diffusion sampling cost using our novel extended version of DMD (distribution matching distillation) for the pyramidal flow-matching objective.x000Dx000DNeodragon generates 49 frames of 640x1024 resolution within 7.6 seconds on the Qualcomm Hexagon NPU with the VBench total score of 81.61, setting a new state of the art for mobile video generation.x000Dx000D""This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.""",,海思,海思: 大语言模型和扩散模型的加速,海思: 该session展示了针对移动设备上视频扩散变换器的高效设计与推理优化方法，包括文本编码器蒸馏、解码器蒸馏、块剪枝和扩散采样成本降低，这些技术直接对应海思关注的扩散模型加速难题，尤其是如何在保持质量的前提下实现低延迟实时推理和多模态条件融合的效率提升。
TUE 2 DEC,noon,Expo Demonstration,Pushing the boundaries of chemical synthesis with RetroChimera,https://neurips.cc/virtual/2025/128641,,3:00 PM,"Retrosynthesis - the task of planning chemical reaction recipes to synthesize complex molecules - remains a bottleneck in the discovery of novel pharmaceuticals. We recently released RetroChimera - a model for predicting chemical reactions - which demonstrated robustness well outside of training distribution by transferring zero-shot to internal reaction data at a major pharmaceutical company. We also found that industrial organic chemists prefer predictions from RetroChimera over real patented reactions in terms of quality, revealing a high degree of alignment. In this demo, we will showcase the model, let attendees query it live, and show them how to interpret the results.",,nan,nan,nan
TUE 2 DEC,noon,Expo Demonstration,BeeAI,https://neurips.cc/virtual/2025/128642,,3:00 PM,"The BeeAI Framework is an open-source project for building reliable AI agents that combine autonomy with control. Current agent frameworks focus primarily on prompting and orchestration, leaving critical questions of predictability and safety unaddressed. BeeAI fills this gap with a lightweight framework that enables developers to build agents whose reasoning abilities are preserved while execution is constrained by declarative, rule-based requirements. At the core of the framework is the RequirementAgent, a novel agent design that enforces deterministic, controlled behaviors across heterogeneous language models. With RequirementAgent, developers can ensure consistent and reliable execution patterns regardless of differences in model reasoning, tool-calling abilities, or stochastic variation. This approach provides practitioners with a unified abstraction layer that simplifies the deployment of complex AI systems into production settings. As an incubating Linux Foundation AI project, BeeAI is gaining adoption in open source and enterprise contexts as organizations seek robust ways to operationalize AI agents at scale. At NeurIPS EXPO, we will showcase BeeAI’s architecture, real-world use cases, and lessons learned from applying declarative control to agent autonomy.",,多伦多云,多伦多云: AI Agent,多伦多云: Session介绍的BeeAI框架专注于构建具备自治性且受控的AI Agent，强调Agent行为的可预测性和安全性，特别是RequirementAgent设计用于保证Agent行为的确定性和受控执行，直接对应该团队关注的提升Agent行为可靠性、行为管控与校验的难题。
TUE 2 DEC,noon,Expo Demonstration,ContextForge,https://neurips.cc/virtual/2025/128643,,3:00 PM,"The rapid rise of autonomous AI agents across enterprises is creating a new class of security and governance challenges that are not adequately addressed with today’s technology. Context Forge MCP Gateway is an open-source, security-focused middleware that provides fine-grained control and extensibility for agent operations. With over 2.6k GitHub stars and a rapidly growing user community, Context Forge addresses emerging threat classes including prompt injection, data leakage, and misuse of sensitive resources. At its core, Context Forge introduces a plugin architecture modeled after Linux Security Modules, embedding reusable security hooks at critical points in agent execution (e.g., prompt handling, tool invocation, data transformation). This modular foundation enables organizations to enforce contextual policies at scale—ranging from PII redaction and provenance tagging to prompt injection detection and policy-based access control. With 39 plugins already available, Context Forge is establishing a standards-aligned ecosystem for securing agent workflows in real-world enterprise deployments. By blending research-driven design with open-source adoption it creates a practical path for organizations to advance agent trustworthiness, safety, and compliance.",,多伦多云,多伦多云: AI Agent,多伦多云: ContextForge作为一个安全中间件，提供细粒度控制和插件架构，能够帮助解决AI Agent系统中行为管控与校验的问题，特别是针对prompt注入、数据泄漏和敏感资源滥用的安全治理，直接对应该团队关于提升Agent行为可靠性及管控的难题。
TUE 2 DEC,noon,Expo Demonstration,LLM-Powered Intelligent Data Engineering: From Workflow Design to Ingestion andQuality Assurance,https://neurips.cc/virtual/2025/128644,,3:00 PM,"Modern enterprises depend on efficient data engineering pipelines to unlock value from diverse and large-scale datasets. Yet, current processes for workflow design, schema ingestion, and data quality validation remain complex, error-prone, and dependent on technical expertise. This creates barriers for non-expert users, slows down development, and introduces risks of data inconsistency.x000Dx000DWe present a suite of LLM-powered frameworks that reimagine enterprise data engineering across three critical dimensions: (i) From Natural Language to Executable ETL Flows, enabling intuitive pipeline creation with natural language specifications and automatic operator/property inference, (ii) All You Can Ingest, an end-to-end schema mapping and transformation framework that unifies semantic alignment, code synthesis, and robust validation, and (iii) Quality Assessment of Tabular Data, a scalable approach for auto-generating interpretable quality rules and executable validators tailored to specific datasets.x000Dx000DTogether, these innovations demonstrate how Large Language Models (LLMs), augmented with retrieval, code synthesis, reasoning, and guardrails, can transform the data engineering lifecycle into a more accessible, adaptive, and trustworthy process, reducing manual effort, accelerating time-to-value, and ensuring data fidelity at enterprise scale.",,nan,nan,nan
TUE 2 DEC,noon,Expo Demonstration,ALICE: Agentic Logic for Incident and Codebug Elimination,https://neurips.cc/virtual/2025/128646,,3:00 PM,"Modern incident root-cause analysis (RCA) is constrained by partial observability, symptom-centric signals, and the overwhelming noise present in logs, traces, and metrics. Diagnosing production failures often depends on instrumentation quality and human expertise, while latent software defects, configuration errors, and zero-day failure modes remain difficult to pinpoint. To address these challenges, we demonstrate a multi-agent system for incident diagnostics that augments observability data with application source code and static analysis signals.x000Dx000DOur system introduces two cooperating agents: the Code Context Agent (COCOA), which builds a knowledge graph of program dependencies, control/data flows, and caller–callee relationships; and the Incident Diagnostics Agent (IDA), which performs agentic reasoning over an entity topology graph enriched with observability streams. Together, these agents extend topology-aware planning (TAP) to simultaneously operate on program dependency graphs and infrastructure entity graphs, thereby linking runtime symptoms with underlying code-level causes.x000Dx000DThis demo showcases how multi-agent collaboration enables deeper, context-sensitive RCA. We walk through real-world inspired scenarios—including incidents where critical log lines are hidden in noisy observability streams or where latent defects emerge only after system updates—illustrating how the system surfaces root causes that would otherwise remain invisible. By bridging program analysis with runtime observability, our approach moves beyond symptom-driven diagnostics toward a more reliable, automated framework for incident management.",,多伦多云,多伦多云: AI Agent,多伦多云: Session介绍了一个多Agent系统（COCOA和IDA）协作进行根因分析，涉及agentic reasoning和多Agent协同，这与团队关注的AI Agent行为可靠性、评估准确性及多步执行能力的持续优化密切相关，session中多Agent协同诊断和推理的技术可以为团队提升Agent行为的可靠性和规划能力提供具体方法。
TUE 2 DEC,noon,Expo Demonstration,AI or Human,https://neurips.cc/virtual/2025/128647,,3:00 PM,"This demo from Sound Patrol will ask the audience to guess whether content is AI or Human, challenging the limits of human perception while showcasing an audio foundation model with multiple task heads, fine-tuned to classify and attribute the source of AI content",,nan,nan,nan
TUE 2 DEC,noon,Expo Demonstration,Who Needs Attention Anyway? Real-Time Control from Learned State Geometry,https://neurips.cc/virtual/2025/128648,,3:00 PM,"Large language models changed how we reason with data, not how we act under constraints. Their latency grows with context, adaptation depends on retraining, and safety is emergent rather than measurable. For robots, simulators, and industrial systems that must react now, this compute model is the wrong fit.CurvOS offers an alternative: a real-time operating layer where streaming state-space models (SSMs) meet geometry and reinforcement learning to deliver stable, on-device intelligence. At its core, CurvOS runs a fast streaming SSM coupled to a local Riemannian planner derived from decoder sensitivities. Each step predicts the next state, estimates local curvature (how small perturbations bend predicted dynamics), and moves a short distance along a geodesic within a trust radius.Compute per step stays fixed, so latency and adaptation remain bounded. Unlike streaming SSMs such as Mamba, CurvOS learns geometry online to steer predictions safely without retraining. The result is a compact, measurable control stack that reasons in real time, adapts continuously, and meets physical or chemical objectives under fixed budgets. CurvOS turns sequence models into predictable decision engines for systems where timing and safety matter most.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session聚焦于实时控制和物理系统的安全、低延迟决策，采用流式状态空间模型和几何强化学习，直接对应物理或具身AI领域对实时反应和安全控制的需求，能为团队在物理AI的实时控制和安全适应性难题提供技术思路和解决方案。
TUE 2 DEC,noon,Expo Demonstration,"PRIME Guardrails in Action: A Live Demonstration of an Agentic, Multi-Layered Safety Framework for Generative AI",https://neurips.cc/virtual/2025/128650,,3:00 PM,"The rapid proliferation of large-scale Generative AI systems has created an urgent need for safety frameworks that are both robust and performant. Existing solutions often present a false dichotomy: simple, low-latency filters that are easily circumvented by adversarial inputs, or powerful, semantically-aware models that introduce prohibitive latency for real-time applications. This demonstration introduces a live, practical instantiation of the PRIME (Policy, Risk, Intervention, Monitoring, Evaluation) framework, a novel, modality-agnostic architecture designed to resolve this trade-off. We will showcase a production-grade, multi-layered “Defense in Depth” safety system that utilizes an agentic workflow to intelligently orchestrate heterogeneous guardrail models. The system combines the deep contextual reasoning of large proprietary models (e.g., Google’s Gemini) for nuanced threat assessment with the speed of specialized, open-source classifiers for rapid, early-exit filtering of common violations. Through a series of live, interactive examples, we will demonstrate the system's ability to detect and neutralize a range of adversarial inputs in real-time across both text and image modalities. Attendees will witness the framework successfully identifying and blocking prompt injection attacks, harmful content requests, and policy violations, thereby proving the efficacy of a hybrid, agentic approach to building safer, more trustworthy Generative AI experiences at scale.",,多伦多云; 存储; 海思,多伦多云: AI Agent; 存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速,多伦多云: Session介绍了PRIME框架中agentic多层安全防护系统，涉及agent行为的管控与校验，能够为提升AI Agent行为可靠性和多步执行能力的持续优化机制提供直接技术支持。; 存储: Session中提到的agentic工作流智能调度多模型异构守护模型，涉及多模型系统中模型加载、调度和快速响应，能够为该团队关于多模型系统中模型加载、卸载及调度的新变化提供实践参考。; 海思: Session强调了结合大模型深度语义理解与快速开源分类器实现低延迟实时检测，契合该团队关注的如何在保证对话质量和上下文一致性前提下实现低延迟实时推理响应的难题。
TUE 2 DEC,noon,Expo Workshop,Creative and Protective AI for Music and Entertainment,https://neurips.cc/virtual/2025/128679,,1:30 PM,"Generative AI is reshaping how we create, experience, and safeguard music and entertainment. This workshop presents technologies that expand creative expression while honoring responsibility. On the creative side, we share collaborative artworks with leading sound artists, neural engines for sound design and performance, and automatic mixing that adapts to musical intent. We also present a large multimodal dataset for multishot speech video that supports research on coherent and controllable speech, together with specialized language models that orchestrate camera transitions, gestures, vocal cues, and sound effects. On the protective side, we advance AI methods for data attribution, traceability, and responsible model behavior that safeguard creative data and prevent unintended memorization, ensuring fairness, transparency, and respect for creators’ rights. Together, these threads outline an ecosystem in which AI amplifies artistic practice while preserving the integrity of human contribution.",,nan,nan,nan
TUE 2 DEC,noon,Expo Workshop,Large-Scale Real-World Physical AI Systems,https://neurips.cc/virtual/2025/128672,,1:30 PM,"Motivation and Scopex000Dx000DPhysical AI systems comprise of four things: namely sensors like cameras and lidar, mechanical and electronic control unit, AI models to reason about the environment, and actuators to convert decisions to physical actions. It marries multiple domains like sensor design, perception, low-power real-time hardware design, and control loop action design. Autonomous driving is the most mature physical AI domain deployed for over 10 years, but it still has many open challenges. Humanoid robots are an emerging physical AI domain with potential for near term commercial deployment. One of the major challenges in physical AI is to scale to all real-world scenarios including corner cases in a safe manner. A scalable AI data flywheel is the most critical module to achieve this. Traditional physical AI models have a modular decomposition of perception and action tasks, but the community is increasingly moving towards a single end-to-end AI model.  Furthermore, recent advancements in LLMs and VLMs are leading to VLA (Vision-Language-Action) based end-to-end models. In the future, there will likely be a convergence of physical AI models across different domains like driving and robotics.  The proposed workshop covers the latest research and best practices in industrial research of physical AI by leaders in the domain. It also covers emerging technologies like VLA based foundation models, AI data flywheel, and cross-embodiment learning focused on Physical AI.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session聚焦于Physical AI系统及其在真实世界中的大规模应用，涵盖了物理AI的感知、控制、执行等多个环节，与团队关注的Embodied AI研究方向高度契合，且session内容中提到的跨体现学习和VLA基础模型等新技术可为团队解决物理AI系统的实际部署和扩展难题提供技术思路。
TUE 2 DEC,noon,Expo Workshop,Checkmate: Fine-tune your own small language model for real-time chess reasoning and gameplay on AWS Trainium,https://neurips.cc/virtual/2025/128680,,1:30 PM,"In this hands-on workshop, participants will leverage AWS Trainium to fine-tune and deploy their own chess-playing language models. Building on recent research showing language models' effectiveness in reasoning, attendees will work with various chess datasets to create AI models that not only play chess but explain their strategic thinking through natural language. The 90-minute session will cover model fine-tuning techniques, optimization strategies specific to Trainium's architecture, and real-time deployment to a chess engine. The workshop culminates in a live tournament where participants' models compete against each other, providing immediate feedback on their implementations. Participants will leave with a working chess reasoning model, practical experience in fine-tuning language models on Trainium, and transferable skills for similar tasks. Python programming experience and familiarity with LLM concepts are required, in addition to a basic understanding of the rules of chess. Workshop materials and AWS credits will be provided.",,nan,nan,nan
TUE 2 DEC,noon,Expo Workshop,Workshop on multimodal Superintelligence,https://neurips.cc/virtual/2025/128681,,1:30 PM,"Multimodal machine learning is among the most promising directions of artificial intelligence. With remarkable progress in academia and industry on this topic, we are at the cusp of building next-generation multimodal models, i.e. multimodal superintelligence. These models can be defined as being able to observe, think, and act across several modalities. At this important junction, our workshop provides a forum for researchers to align and cross-polinate ideas. The Workshop on Multimodal Superintelligence will provide a venue where the community can gather to discuss the current state of multimodal machine learning science. Together, we will attempt to overcome the current barriers of modeling several modalities at once. We will also focus on topics such as cross-modal reasoning, alignment, fusion and co-learning.",,海思; 诺亚; 多伦多云,海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列; 多伦多云: AI Agent,海思: Session聚焦多模态超级智能，强调多模态条件融合和跨模态推理，直接对应海思团队关于多模态条件（文本、图像、草图、深度图）融合延迟大、如何统一特征空间实现快速条件生成的难题，Workshop提供的跨模态融合和对齐技术可为其提供解决思路。; 诺亚: Session强调多模态模型的跨模态推理与融合，正好对应诺亚团队关于长序列图文多模态模型演进及突破多模态长文本推理计算瓶颈的难题，Workshop讨论的多模态超智能模型设计与推理策略能为其提供技术支持。; 多伦多云: Session提及多模态超智能模型具备观察、思考和行动能力，涵盖Agentic AI系统的跨模态推理与融合，直接关联多伦多云团队关于提升AI Agent评估准确性、行为可靠性及多步执行能力的难题，Workshop内容有助于提升Agent的多模态理解与推理能力。
TUE 2 DEC,noon,Expo Demonstration,Interpretable AI for Risk-Based Human Rights Assessment in Global Supply Chains,https://neurips.cc/virtual/2025/128649,,3:00 PM,"Amazon’s responsible sourcing efforts aim to protect people across its global supply chain. Yet detecting human rights risks such as forced labor or unsafe conditions across hundreds of thousands of suppliers is challenging. Auditing every site is costly and impractical, making a risk-based approach essential focusing resources where the likelihood and severity of issues are greatest. To address this, Amazon developed PRISM AI (Predictive Risk Intelligence for Supplier Management), an interpretable machine learning system that predicts and explains supplier-level risk across global supply chains. Trained on over 70,000 internal and third-party audit records, PRISM integrates signals from self-assessment questionnaires, grievance reports, adverse media, and geo-sector risk indices. These inputs help detect both documented and emerging risks in near real time. The model supports three supplier types: those with audit histories, limited data, or none. It adapts using transfer learning, rule-based heuristics, and domain-specific indicators. Each prediction includes transparent attribution, showing which factors such as safety violations or country-sector exposure, most influenced the score. Built with monotonic constraints, the system ensures logically consistent, explainable outputs for regulatory and operational use.x000DThis demo gives NeurIPS participants a hands-on view of how AI research can be operationalized for real-world impact. Already in production at Amazon, PRISM helps compliance teams prioritize audits, onboard suppliers, and escalate risks thereby reducing review time and improving oversight. For researchers, it highlights methods for building interpretable models under data imbalance and integrating structured and unstructured signals. For practitioners, PRISM shows how AI can scale responsible business practices and drive innovation across environmental and social sustainability domains.",,nan,nan,nan
TUE 2 DEC,noon,Expo Demonstration,Build verifiable apps using Generative AI and Automated Reasoning,https://neurips.cc/virtual/2025/128651,,3:00 PM,"Recent advancements in Generative AI have enabled customers to use LLMs to generate infrastructure code using AWS CLI commands. Because humans can make mistakes, when deployed such LLM-generated infrastructure code can have negative impacts, including on security.x000DMotivated by this challenge, this demonstration introduces participants to automated reasoning tooling that enhanced security in production for Amazon Q chat.x000DAWS Q Chat enables natural language interaction with AWS resources while employing automated reasoning to verify every generated API call against comprehensive semantic logic models. This prevents potentially harmful operations before execution and suggests corrections, creating a feedback loop that iterates until verifiably correct code is produced. Through this work, we demonstrate how organizations can leverage GenAI's efficiency while maintaining the rigorous verification standards required for production environments and participants will learn how to integrate these tools into their workflows to prevent security regressions and ensure reliable infrastructure management. This tutorial Scientists, Engineers, Security professionals and anyone interested in applying formal verification to their infrastructure.",,多伦多云,多伦多云: AI Agent,多伦多云: Session介绍了利用自动推理工具验证生成的基础设施代码，防止潜在有害操作并进行纠正，这与团队关注的提升Agent行为可靠性、尤其是写操作的可靠性及对Agent行为进行管控与校验高度相关，能为其提供具体的自动验证和纠错技术思路。
TUE 2 DEC,noon,Expo Workshop,CausalFairness: An Open-Source Python Library for Causal Fairness Analysis,https://neurips.cc/virtual/2025/128677,,1:30 PM,"As machine learning (ML) systems are increasingly deployed in high-stakes domains, the need for robust methods to assess fairness has become more critical. While statistical fairness metrics are widely used due to their simplicity, they are limited in their ability to explain why disparities occur, as they rely on associative relationships in the data. In contrast, causal fairness metrics aim to uncover the underlying data-generating mechanisms that lead to observed disparities, enabling a deeper understanding of the influence of sensitive attributes and their proxies. Despite their promise, causal fairness metrics have seen limited adoption due to their technical and computational complexity. To address this gap, we present CausalFairness, the first open-source Python package designed to compute a diverse set of causal fairness metrics at both the group and individual levels. The metrics implemented are broadly applicable across classification and regression tasks (with easy extensions for intersectional analysis) and were selected for their significance in the fairness literature. We also demonstrate how standard statistical fairness metrics can be decomposed into their causal components, providing a complementary view of fairness grounded in causal reasoning. In this active learning talk participants will learn how to quantify bias using CausalFairness at the group (Counterfactual Equalized Odds , Counterfactual Effects) and individual (Counterfactual Fairness) levels by applying each method to three datasets - 1) the Adult Income dataset, 2) the COMPAS dataset, 3) Law School Admission Council (LSAC) Dataset. The session will elucidate on the intuition for computing and interpreting each metric, and conclude with a discussion of their limitations.",,nan,nan,nan
TUE 2 DEC,noon,Expo Demonstration,Learning to Steer LLMs with AI Steerability 360 and In-Context Explainability 360,https://neurips.cc/virtual/2025/128645,,3:00 PM,"Current algorithms for aligning LLM behavior are often implemented for narrow settings, making it difficult for researchers and developers to understand their effectiveness across model architectures, datasets, and tasks. To help provide a more informed and principled approach to steering model behavior, we present the AI Steerability 360 (AISteer360) and In-Context Explainability 360 (ICX360) toolkits. Participants will first be guided through a conceptual overview for how model behavior can be influenced across four model control surfaces: input (prompting), structural (weights/architecture), state (activations/attentions), and output (decoding). After the conceptual overview, we will guide attendees through how to apply some recently developed explainability tools (from ICX360) for understanding why models produce given, potentially undesirable, outputs and how this information is used to design targeted steering inventions (via AISteer360). Closing the loop, we will evaluate if the baseline behavior (of the original, unsteered model) was successfully mitigated by the selected steering inventions and investigate if steering introduced any unintended behavioral side-effects. All of the experiments throughout the demonstration will be facilitated solely by the tools in the two toolkits, illustrating their power to design end-to-end steering workflows. Attendees will come away with a practical understanding of how to apply these toolkits to their own alignment challenges.",,多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: Session介绍了AI Steerability 360和In-Context Explainability 360工具包，帮助理解和设计针对LLM行为的精准控制和解释，这直接对应多伦多云团队在AI Agent中提升Agent行为可靠性、管控与校验，以及持续优化机制的需求。该session提供了端到端的模型行为调控和解释方法，有助于解决Agent行为的管控与校验难题。; 诺亚: Session中关于通过解释性工具理解模型产生不良输出的原因，并基于此设计针对性调控手段，与诺亚团队关注的后训练推理和强化学习（RL）框架中自博弈与learning from experience训练方法高度相关。该session的工具和方法可为优化大模型推理行为和训练策略提供技术支持。
TUE 2 DEC,noon,Expo Workshop,Introduction to Generative Computing,https://neurips.cc/virtual/2025/128678,,1:30 PM,"This hands-on workshop introduces a proposal that treats LLMs as computing elements governed by established software development principles—particularly task decomposition and modularization—at both the programming model (Mellea) and model level (LLM intrinsics).x000Dx000DLLM outputs are often unpredictable and incorrect. Agentic frameworks and prompt optimization libraries attempt to manage this by giving control to the LLM, but this leads to systems that are hard to debug, maintain, and scale. Mellea offers an alternative: a programming model that restores developer control through modular design, information hiding, and compositional contracts. This enables predictable fault models, better portability, and lower inference costs. Attendees will gain hands-on experience building applications using the Melleaic approach.x000Dx000DExtending these principles to the model level, the workshop introduces a modularization framework for LLMs using activated LoRAs. These produce components—LLM intrinsics—that match fine-tuned model accuracy for specific tasks but with significantly lower inference costs and latency, thanks to KV cache reuse. Participants will build applications using a pre-built library of RAG LLM intrinsics and learn how to train their own.x000Dx000DPresented by the creators of Mellea and the inventors of LLM intrinsics and aLoRA, this workshop equips attendees with foundational skills for scalable model/application co-design.",,存储; 海思; 多伦多云; 计算,存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速; 多伦多云: AI Agent; 计算: 前沿应用负载,存储: Session介绍了通过模块化设计和LLM intrinsics降低推理成本和延迟，直接关联多模型系统中KV Cache加载、卸载及调度的新变化，提供了可操作的编程模型和模块化框架，有助于解决该团队关于多模型系统推理效率和存储访问模式的难题。; 海思: Session中提出的模块化LLM设计和利用activated LoRAs实现低延迟推理，与该团队关注的低延迟实时推理响应和长上下文推理复杂度优化高度相关，提供了降低推理延迟和计算复杂度的具体方法。; 多伦多云: Session讨论了通过模块化设计恢复开发者对LLM的控制，解决Agentic框架中难以调试和维护的问题，直接对应该团队关于提升Agent行为可靠性和多步执行能力的需求，提供了可复用的模块和编程模型支持Agent系统的可控性和扩展性。; 计算: Session涉及模型与应用的协同设计和模块化范式，针对Agentic和多模态模型应用负载的可控性和扩展性提供了新思路，符合该团队对前沿负载演进及软硬件系统导入需求的关注。
TUE 2 DEC,noon,Expo Workshop,Exploring Trust and Reliability in LLM Evaluation,https://neurips.cc/virtual/2025/128673,,1:30 PM,"The current paradigm of Large Language Model (LLM) evaluation faces a crisis of reliability. Traditional leaderboards—built on static benchmarks and surface-level metrics—have become increasingly distorted by benchmark contamination, prompt overfitting, and evaluation methodologies that fail to reflect model behavior in real-world use. As reasoning models emerge that generate detailed internal thought processes (e.g.,traces) before producing answers, existing evaluation practices—especially for multiple-choice and generation tasks—have become fundamentally inadequate.x000Dx000DThis lack of rigor not only undermines scientific progress and cross-model comparability, but also poses significant enterprise and societal risks, as evaluation results inform model selection, deployment safety, and governance in high-stakes environments.x000Dx000DThis workshop aims to reassert rigor in LLM evaluation by convening researchers and practitioners to address three intertwined challenges: (1) developing fair and consistent evaluation methods for reasoning and non-reasoning models, (2) confronting widespread contamination across public benchmarks and open-weight models, and (3) defining robust data curation and validation practices to prevent future contamination in both pretraining and post-training pipelines.x000Dx000DBy combining empirical findings, methodological advances, and practical case studies, this session—led by Capital One in collaboration with leading AI labs—seeks to chart a concrete path toward trustworthy, contamination-proof, and utility-aligned LLM evaluation frameworks.x000Dx000DThis 1.5-hour workshop will be structured around three highly focused, 25-minute talks, followed by a moderated discussion aimed at forging actionable paths forward for the community:x000Dx000DTalk 1: Robust Evaluation for Reasoning & Non-Reasoning Modelsx000Dx000DTalk 2: Benchmark Contamination — Detection, Measurement, & Findingsx000Dx000DTalk 3: Preventing Contamination — Building Clean & Reliable Data Pipelines",,多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: Session聚焦于LLM评估中的信任与可靠性问题，特别是针对推理模型的评估方法和数据污染问题，直接对应该团队关注的提升AI Agent评估准确性与覆盖范围，以及Agent行为可靠性和管控的难题。该session提出的公平一致的评估方法和污染检测技术能为该团队提供切实的解决思路。; 诺亚: Session中强调了对推理模型（reasoning models）评估方法的革新，特别是针对生成详细内部思考过程的模型，和防止数据污染的策略，能够帮助该团队解决其在自博弈与learning from experience训练框架以及Latent Reasoning方面对评估可靠性和数据质量的需求。
TUE 2 DEC,1:30 p.m.,Tutorial,Foundations of Imitation Learning: From Language Modeling to Continuous Control,https://neurips.cc/virtual/2025/109590,,4:00 PM,,,温哥华云; 温哥华云; 多伦多云,温哥华云: Reinforcement fine tuning (RFT); 温哥华云: Embodied AI; 多伦多云: AI Agent,温哥华云: Session主题为“Foundations of Imitation Learning: From Language Modeling to Continuous Control”，涵盖了模仿学习基础，涉及语言模型和连续控制，直接关联强化学习微调（RFT）技术，可为团队解决如何将理论应用于生产环境、提升样本效率和性能等难题提供方法和思路。; 温哥华云: Session涵盖从语言模型到连续控制的模仿学习基础，Embodied AI正是结合物理环境中的连续控制与智能体学习，团队关注的具身AI与session内容高度契合，session内容有助于解决具身AI中模仿学习的基础理论和技术难题。; 多伦多云: Session涉及模仿学习基础，涵盖语言模型和连续控制，AI Agent的行为评估、可靠性及自主学习机制与模仿学习密切相关，session内容可为团队提供模仿学习相关的理论和技术支持，帮助解决Agent行为优化与持续改进难题。
TUE 2 DEC,1:30 p.m.,Tutorial,Scale Test-Time Compute on Modern Hardware,https://neurips.cc/virtual/2025/109595,,3:00 PM,,,海思; 计算; 计算; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构; 计算: 训推新范式; 计算: 前沿应用负载,海思: Session主题为“Scale Test-Time Compute on Modern Hardware”，直接涉及在现代硬件上扩展测试时计算能力，能够为海思团队解决低延迟实时推理响应、多模态条件融合延迟和长上下文推理复杂度过高等难题提供硬件层面和计算优化思路。; 计算: 该session关注现代硬件上的测试时计算扩展，能够帮助计算团队理解和应对模型架构演进对计算系统的影响，尤其是如何利用现代硬件提升推理效率，降低计算系统冲击，解决其关注的模型架构与计算架构的匹配难题。; 计算: Session涉及现代硬件上的测试时计算扩展，有助于计算团队跟踪和理解训练推理新范式带来的负载特征变化，提供硬件适配和优化方案，解决其对未来负载准确定义的需求。; 计算: 该session聚焦现代硬件上推理计算的扩展，能够为计算团队提前应对Agentic和多模态模型应用负载快速演进带来的计算架构新诉求提供技术支持。
TUE 2 DEC,1:30 p.m.,Tutorial,Autoregressive Models Beyond Language,https://neurips.cc/virtual/2025/109587,,3:00 PM,,,nan,nan,nan
TUE 2 DEC,1:30 p.m.,Tutorial,"Recent Developments in Geometric Machine Learning: Foundations, Models, and More",https://neurips.cc/virtual/2025/109600,,3:00 PM,,,nan,nan,nan
TUE 2 DEC,1:30 p.m.,Tutorial,Theoretical Insights on Training Instability in Deep Learning,https://neurips.cc/virtual/2025/109597,,3:00 PM,,"Overview: The NeurIPS 2025 tutorial titled 'Theoretical Insights on Training Instability in Deep Learning' explores the oscillatory, spiky, and unstable nature of the optimization process in deep learning. This tutorial aims to provide theoretical insights into the benign nature of these training instabilities, offering perspectives from both optimization and statistical learning. The work challenges classical optimization theory by demonstrating that the best training configurations often operate in unstable regimes. | Research Interests: Gradient-based optimization, Training instability in deep learning, Large stepsizes in optimization, Statistical learning perspectives, Benign nature of instabilities, Optimization efficiency, Overfitting prevention, Implicit bias in optimization, Edge of stability in gradient descent | Key Findings: The tutorial highlights that large stepsizes can accelerate optimization and prevent overfitting, providing a new understanding of the implicit bias and stability in deep learning models. It also discusses the role of training at the edge of stability and how it can lead to efficient optimization and generalization.",计算,计算: 训推新范式,计算: 该session深入探讨了深度学习训练中的不稳定性及其理论本质，特别是大步长优化和训练边缘稳定性，这与该团队关注的训练新范式中负载特征和训练优化密切相关，能为其理解和预测训推范式演进机理提供理论支持。
TUE 2 DEC,1:30 p.m.,Tutorial,"The Science of Benchmarking: What’s Measured, What’s Missed, and What’s Next",https://neurips.cc/virtual/2025/109598,,3:00 PM,,,nan,nan,nan
TUE 2 DEC,1:30 p.m.,Tutorial,"Data Privacy, Memorization, & Legal Implications in  Generative AI: A Practical Guide",https://neurips.cc/virtual/2025/109588,,3:00 PM,,,nan,nan,nan
TUE 2 DEC,4 p.m.,Expo Talk Panel,Recent developments in embodied AI,https://neurips.cc/virtual/2025/128653,,5:00 PM,"Embodied AI is the study of systems that can perceive and interact with the physical world in real time. Real-world interactions pose unique challenges for AI systems since they naturally require a deep understanding of the physical world and/or its inhabitants. This understanding is often taken for granted in humans, where it is typically labelled as “intuitive physics” or “common sense”.x000Dx000DIt is widely agreed that solving this challenge would be as rewarding as it is hard, since it would be equivalent to creating truly capable “world models”, with countless applications in robotics, human-computer interaction, and even in advancing language modeling through concept grounding. Like other areas in AI, embodied AI has seen dramatic advances in recent years, fueled by the success of using pre-trained large language models as a central ingredient to allow for end-to-end training. While this development stands as one of many examples of the power of pre-trained language models, recently the converse has come true as well: embodied AI is increasingly being drawn on to understand real-world common sense and concept grounding in language models themselves, bringing back its early vision as a way to understand human-like cognition and world models.x000Dx000DThis talk will provide an in-depth discussion of embodied AI, with a focus on recent advances based on multi-modal large language models. It will discuss how end-to-end training has made it possible to instill key aspects of real-world common sense in a model and how this had enabled highly ambitious use-cases, such as generalist (“common sense”) robot control and real-world visual interaction (“chatbots that can see and hear you”). The talk will also discuss practical considerations, such as streaming inference at the edge, end-to-end training data generation and the role of reinforcement learning, as well as open challenges in state tracking and long-term memory.",,温哥华云,温哥华云: Embodied AI,温哥华云: 该session专注于embodied AI的最新发展，特别是多模态大语言模型在具身智能中的应用，直接对应团队关注的物理或具身AI研究领域，且讨论了端到端训练、强化学习及状态跟踪等关键难题，能够为团队在物理AI战略投资和技术突破提供前沿思路和方法。
TUE 2 DEC,4 p.m.,Expo Talk Panel,Distributed Orthonormal Updates for Large-Scale Training,https://neurips.cc/virtual/2025/128655,,5:00 PM,"We propose a 50-minute technical talk on recent advances in orthonormal update methods for large-scale AI model training. This topic is rapidly gaining attention in the community, emerging as a strong successor to AdamW following the success of orthonormal optimizers in training production-scale models such as Kimi-K2 and GLM-4.5.x000DThe talk will center on the design and practice of orthonormal updates, focusing on optimizers such as Muon and Dion. While we will briefly discuss their theoretical foundations, the emphasis will be on practical usage: how to integrate these optimizers into modern training pipelines, interpret their algorithmic components, and leverage the implementation guidelines provided in our open-source codebase at github.com/microsoft/dion.x000DThe talk is designed to engage both researchers and practitioners in the NeurIPS community:x000DAcademic perspective: presents a new class of optimizers grounded in theory along with how they interact with distributed training.x000DIndustrial perspective: highlights how orthonormal updates are implemented in practice and what best practices are.x000DThis topic lies   at the intersection of optimization theory, scalable systems, and large-model training—an area of growing importance for both the research and applied machine learning communities.",,计算; 计算,计算: 高效模型架构; 计算: 训推新范式,计算: Session聚焦于正交更新优化器及其在大规模训练中的应用，直接涉及优化算法和训练效率，能够为团队关注的模型架构对计算架构影响及大模型训练优化提供具体的优化方法和实践指导。; 计算: Session介绍了正交更新优化器在大规模训练中的实践和分布式训练中的应用，符合团队对训练新范式负载特征演进的关注，能帮助理解和预测新型优化器对训练负载的影响。
TUE 2 DEC,4 p.m.,Expo Talk Panel,Ling 2.0 and Ling-1T: Scaling Knowledge-Enhanced Large Language Models for Reasoning and Efficiency,https://neurips.cc/virtual/2025/128657,,5:00 PM,"The Ling 2.0 series represents a new generation of large language models designed around knowledge enhancement, reasoning efficiency, and scalable architecture innovation. Built upon trillion-scale sparse MoE foundations, Ling-1T achieves ~50B active parameters per token with FP8 mixed-precision pipelines and 1F1B interleaved scheduling, realizing over 40% training-throughput gains with negligible accuracy loss (<0.1%).x000DThis talk presents the technical journey behind Ling-mini, Ling-flash, and Ling-1T, focusing on (1) efficient large-scale training systems for trillion-parameter models; (2) the Ling Scaling Law and its implications for cross-domain reasoning; (3) hybrid attention and RL-based alignment strategies that enable both concise reasoning and long-context understanding; and (4) how these architectural and algorithmic advances empower industrial applications such as financial risk modeling and knowledge-grounded agents.x000DWe will conclude with open-sourced implementations (inclusionAI on Hugging Face and ModelScope) and future research directions toward trustworthy, efficient, and domain-enhanced LLMs.",,海思; 计算; 计算; 温哥华云; 多伦多云; 诺亚,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构; 计算: 训推新范式; 温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,海思: Session中介绍了基于稀疏MoE架构和混合精度（FP8）训练的高效大模型训练和推理技术，特别提到稀疏注意力和长上下文理解，直接对应海思关注的长上下文推理注意力复杂度过高问题及稀疏注意力与分块缓存的解决思路。; 计算: Session重点讲解了基于trillion-scale sparse MoE架构的模型设计与训练效率提升，涵盖了模型架构对计算系统的影响和训练吞吐量提升，能够帮助计算BU理解和预判大模型架构演进趋势，降低未来模型结构对计算系统的冲击。; 计算: Session中涉及FP8混合精度训练、1F1B调度等新型训练范式，及RL-based alignment策略，能够为计算BU理解和跟踪训推范式演进机理提供技术参考。; 温哥华云: Session介绍了基于RL的alignment策略用于提升模型推理和长上下文理解能力，与RFT关注的强化学习在LLM中的应用和实际问题紧密相关，能为温哥华云团队提供强化学习实用技术和优化思路。; 多伦多云: Session提及基于RL的alignment策略和知识增强模型架构，能够支持AI Agent的推理能力和行为优化，尤其是提升Agent的多步推理和规划能力，契合多伦多云团队关注的Agent行为可靠性和持续优化机制。; 诺亚: Session重点介绍了知识增强大模型的推理效率和RL-based alignment策略，直接对应诺亚团队关注的后训练推理能力提升和基于自博弈与经验学习的训练框架。
TUE 2 DEC,4 p.m.,Expo Talk Panel,Agentic AI/RL,https://neurips.cc/virtual/2025/128662,,5:00 PM,"The transition from static language models to agentic AI systems driven by reinforcement learning (RL) places environments at the center of research and deployment. Environments provide the substrate where agents act, learn, and are evaluated—ranging from lightweight simulators and synthetic tasks to rich multi-agent ecosystems and real-world interfaces. Building and scaling these environments requires specialized tools and systems: standardized hubs for discovery and sharing, interfaces for reproducibility, and infrastructure that connects environments seamlessly to trainers, inference engines, and evaluation pipelines.x000Dx000DThis workshop will highlight the tools, environments, and system innovations enabling the next generation of agentic AI. Topics will include scalable RL environment frameworks, benchmarks for safety and robustness, high-performance simulators optimized for heterogeneous hardware, and environment–trainer integration at scale. We will also explore how environments interface with large-model post-training workflows, providing the data and feedback loops necessary for reward shaping, alignment, and deployment in production systems.x000Dx000DBy convening researchers, environment developers, and systems engineers, the workshop will create a venue to examine how environments, tools, and infrastructure together shape the future of agentic AI.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DPyTorch native RL and agentic development at scalex000DEnvironments for everyone - how open environments can democratize RL post training at scalex000DSafety in the new era of Agents",,温哥华云; 多伦多云; 诺亚; 计算,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL; 计算: 前沿应用负载,温哥华云: Session聚焦Agentic AI系统中强化学习环境的构建与集成，直接对应温哥华云团队关注的Reinforcement learning在VLMs/LLMs上的实际应用问题，尤其是解决理论到生产的落地难题、样本效率和性能扩展性，能为其提供环境搭建和训练基础设施的技术支持。; 多伦多云: Session强调Agentic AI系统中环境与训练器的集成、评估机制以及安全性话题，直接关联多伦多云团队关注的AI Agent评估准确性、行为可靠性及自主学习优化机制，能为其提供环境标准化、评估基准和安全性保障的系统创新思路。; 诺亚: Session中强化学习环境和训练流程的系统创新，特别是奖励塑造和对齐机制，契合诺亚团队关注的自博弈与经验学习训练框架及latent reasoning，能为其提供环境设计和训练集成的技术支持。; 计算: Session讨论了Agentic和多模态模型应用负载的环境搭建和系统集成，直接对应计算BU关注的Agentic和多模态模型负载演进及其对计算架构的新诉求，能为其提供软硬件系统协同设计的环境和工具支持。
TUE 2 DEC,4 p.m.,Expo Talk Panel,"Neural Arms Race: Authenticity, Infringement Analysis, and Attribution in the Age of AI Music",https://neurips.cc/virtual/2025/128669,,5:00 PM,"The same neural architectures powering music generation have become critical infrastructure for content moderation—creating a technological arms race where AI both threatens and protects creative rights. This talk presents Sound Patrol's production-scale response across three dimensions: (1) Authenticity Detection: Analyzing AI content in the wild begins with binary classification—was a given song created by AI or humans? Using MuQ and ResNet backbones with auxiliary task heads, we show how careful dataset construction and model ensembling enables attribution of when AI was used, where in a track (vocal vs instrumental), and which genAI platform generated it. (2) Infringement Analysis: Once identified as AI, content requires infringement screening. We combine singer deepfake detection via RawNet3, Burrows-Wheeler alignment-derived comparisons of MIDI transcripts, lyrics analysis via a combination of neural embeddings and LLMs, and neural fingerprinting achieving 88%+ accuracy under adversarial transforms. These analyses are orchestrated through dynamic expert routing, enabling sophisticated tagging and automated musicology reports. (3) Attribution Framework: We end with a pragmatic discussion of what it means for a piece of training data to influence a model output. We propose a set of principles guiding how fractional royalty models could be derived by examining prompts, training sets, and model outputs. Drawing from production deployments and industry evaluations, we offer the NeurIPS community technical blueprints for turning this arms race into equitable innovation—exploring how the same AI enabling infringement might ensure fair compensation to the artists whose work powers it all.",,nan,nan,nan
TUE 2 DEC,4 p.m.,Expo Talk Panel,Building an AI Ecosystem for Multiscale Biological Discovery,https://neurips.cc/virtual/2025/128658,,5:00 PM,"Understanding biological systems requires resolving their structure and organization across scales, from tissues to individual molecules. Advances in imaging and molecular profiling now generate vast multimodal datasets that capture biological architecture and dynamics with unprecedented fidelity. Unlocking insights from this data demands computational approaches capable of linking observations across spatial, temporal, and molecular dimensions.At the Chan Zuckerberg Imaging Institute (CZII), we are building the infrastructure, datasets, and community connections to enable this transformation. Our cryo-electron tomography (cryoET) processing pipeline supports high-throughput reconstruction and standardized metadata integration, forming the foundation for reproducible, machine-learning–ready datasets. The CryoET Data Portal (cryoetdataportal.czscience.com) provides open access to raw data, reconstructions, and curated annotations contributed by leading structural biology labs worldwide. Its programmatic API tools support segmentation, particle picking, and model benchmarking, creating a foundation for AI-driven structural discovery.To catalyze progress in automated molecular identification, the CZ Imaging Institute recently organized a Kaggle challenge inviting participants to develop models for detecting and labeling macromolecular complexes in real-world cryoET data. Building on this success, upcoming challenges organized by the CZI & CZ Biohub Network will extend this approach to datasets spanning different biological scales, from tissue architecture and cellular organization to subcellular and molecular structure.Together, these efforts form an open, interoperable ecosystem for machine learning in biological imaging. By combining standardized data infrastructure, scalable computation, and community-driven innovation, we aim to bridge the worlds of imaging and AI and accelerate the discovery of life’s organization across all scales.",,nan,nan,nan
TUE 2 DEC,4 p.m.,Expo Talk Panel,Building Foundational Models for Robotics at Tesla,https://neurips.cc/virtual/2025/128654,,5:00 PM,"Tesla's robots, both wheeled and legged, are developed with the goal of achieving general-purpose capability, analogous to the versatility observed in humans and animals. These systems rely primarily on scalable sensing modalities such as vision, audio etc, enabling robust performance within stringent power and cost constraints.x000Dx000DThis talk will describe the principles and methodology behind constructing foundation models for robotics at Tesla. We will discuss the architecture, data and training of large-scale multimodal models that control these robots in an end-to-end pixels-to-actuation fashion. We will also examine evaluation protocols, safety considerations, and strategies for reliable real-world deployment. Finally, we project the transformational benefits to society that widespread deployment of such advanced robotic systems can deliver.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session专注于Tesla机器人基础模型的构建，涉及多模态感知和端到端像素到执行的控制，直接对应Embodied AI领域的物理或具身智能研究，能为团队在机器人感知与控制模型设计提供方法论和实践经验。
WED 3 DEC,8:30 a.m.,Invited Talk,Rich Sutton_The Oak Architecture: A Vision of SuperIntelligence from Experience,https://neurips.cc/virtual/2025/invited-talk/109601,Rich Sutton,9:30 AM,"As AI has become a huge industry, to an extent it has lost its way. What is needed to get us back on track to true intelligence? We need agents that learn continually. We need world models and planning. We need knowledge that is high-level and learnable. We need to meta-learn how to generalize. The Oak architecture is one answer to all these needs. It is a model-based RL architecture with three special features: 1) all of its components learn continually, 2) each learned weight has a dedicated step-size parameter that is meta-learned using online cross-validation, and 3) abstractions in state and time are continually created in a five-step progression: Feature Construction, posing a SubTask based on the feature, learning an Option to solve the subtask, learning a Model of the option, and Planning using the option’s model (the FC-STOMP progression). The Oak architecture is rather meaty; in this talk we give an outline and point to the many works, prior and contemporaneous, that are contributing to its overall vision of how superintelligence can arise from an agent’s experience.",,温哥华云; 多伦多云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session介绍了Oak架构是一个基于模型的强化学习架构，强调持续学习、元学习和规划，直接对应团队关注的强化学习在大模型微调中的实际应用问题，能为提升样本效率、性能和可扩展性提供理论和方法支持。; 多伦多云: Oak架构中提出的特征构建、子任务设定、选项学习及规划（FC-STOMP）与AI Agent的多步执行和规划能力高度相关，能为提升Agent行为的可靠性、自主学习与持续优化机制提供具体的架构思路和技术方法。; 诺亚: Oak架构强调基于经验的持续学习和元学习，涉及自博弈和从经验中学习的训练框架，与团队关注的后训练推理和强化学习技术高度契合，能为解决latent reasoning和自博弈训练框架提供理论和实践指导。
WED 3 DEC,noon,Expo Workshop,"AI Assistants in the Wild: Agents, Adaptation, and Memory-Augmented Deployment",https://neurips.cc/virtual/2025/128671,,1:30 PM,"Motivation and Scopex000Dx000DGenerative AI is evolving from offline, single modality models into interactive agentic systems that perceive, decide, and act in the real world. This shift marks a transition from static generation to dynamic, context-aware interaction. As these systems move toward deployment on edge devices such as mobile phones, augmented reality glasses, and robots, they face constraints in compute, memory, and latency. Beyond efficiency and responsiveness, a new frontier is emerging: agents equipped with persistent memory that enables long-term adaptation and personalization.x000Dx000DThis workshop explores a timely and focused question. How do we build generative agents that are not only efficient and responsive but also able to accumulate, recall, and adapt based on personal memory over time? We aim to bring together perspectives from generative modeling, agentic learning, efficient model design, and memory systems to close the gap between lab scale prototypes and real-world deployment.x000Dx000DKey Themesx000DPersonal Memory Systems for AI Assistants: Architectures for persistent memory, retrieval-augmented generation, and long-term personalization.x000DReal-World Adaptation Few-shot generalization, continual learning, and task inference for evolving agent behavior.x000DGrounded and Trustworthy Generation: Techniques for hallucination mitigation, constraint-aware generation, and safety under uncertainty.x000DDeployment on Edge Platforms: Challenges and solutions for deploying generative agents on mobile, AR, and robotics platforms.x000Dx000DThis focused workshop aligns with emerging themes at NeurIPS including agentic learning, trustworthy AI, efficient multimodal generation, and embodied intelligence. It will spotlight the systems, algorithms, and design decisions needed to make generative AI truly adaptive and persistent, outside the data center and into the wild.",,存储; 海思; 多伦多云; 诺亚,存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速; 多伦多云: AI Agent; 诺亚: 大模型长序列，多模态长序列,存储: Session讨论了Agentic AI系统中记忆系统（如MemOS）和RAG（检索增强生成）对存储系统的访问模式及调度，这直接对应团队关注的Agentic AI系统中RAG和记忆系统对存储访问模式的难题，以及多模型系统中KV Cache的加载卸载和调度新变化。; 海思: Session强调了在边缘设备上部署生成式代理时的低延迟响应和长上下文记忆管理，涉及长时间记忆的积累与调用，这与团队关注的如何在保持对话质量和上下文一致性的前提下实现低延迟推理，以及利用稀疏注意力和缓存机制优化长上下文推理复杂度高度相关。; 多伦多云: Session聚焦于生成式代理的持续适应和个性化记忆系统，涉及agent行为的长期适应、记忆积累和多步执行能力，这与团队关注的提升AI Agent评估准确性、行为可靠性及自主学习和持续优化机制的难题直接相关。; 诺亚: Session探讨了持久记忆系统和长时间适应能力，涉及长序列模型的记忆积累和调用机制，能够为团队关注的长序列架构演化、模型内置记忆更新机制改进及多模态长文本推理计算瓶颈提供技术思路。
WED 3 DEC,noon,Expo Workshop,On Device/Edge AI,https://neurips.cc/virtual/2025/128674,,1:30 PM,"From smartphones and wearables to autonomous vehicles, robots, and AR/VR systems, the demand for models that are efficient, private, and adaptive in real-time has never been higher. Yet deploying state-of-the-art AI at the edge remains challenging: researchers and practitioners must navigate heterogeneous hardware, memory and power constraints, compression and distillation trade-offs, as well as privacy, safety, and reliability requirements.x000Dx000DThis workshop will bring together researchers, practitioners, and industry leaders to explore the frontiers of Edge AI. Topics will include lightweight model architectures, compiler/toolchain optimizations (e.g., quantization, pruning, sparsity), advances in frameworks such as ExecuTorch and TensorRT, distributed learning across devices, privacy-preserving training, and emerging applications where latency and trust are critical. Beyond technical advances, we will examine the broader implications for democratizing AI—enabling billions of devices to act as intelligent, personalized agents while reducing dependence on the cloud.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DOptimized AI on iOSx000DLeveraging ExecuTorch as a platform for mixed reality at scalex000DReal-time reasoning at the edgex000DMamba and SSM running at the edge",,存储; 海思; 计算; 计算,存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构; 计算: 前沿应用负载,存储: Session涉及边缘设备上多模型系统的推理优化，包括模型加载、卸载及调度等问题，直接对应该团队关注的多模型系统中模型和KV Cache加载、卸载及调度的新变化。; 海思: Session强调低延迟实时推理和边缘设备上的高效模型推理，涵盖了模型压缩、稀疏性和优化工具链，能够为该团队在保持对话质量前提下实现低延迟推理提供技术支持。; 计算: Session关注轻量级模型架构和编译器优化技术（如量化、剪枝、稀疏性），与该团队对模型架构对计算架构影响及低精度训练推理的研究高度相关，有助于其理解和应对未来模型结构对计算系统的冲击。; 计算: Session涉及边缘设备上实时推理和分布式学习，关注延迟和信任问题，契合该团队对Agentic和多模态模型应用负载快速演进及其对计算架构新诉求的研究。
WED 3 DEC,noon,Expo Workshop,Multi-Agent Systems in Industry: From Research to Real-World Impact,https://neurips.cc/virtual/2025/128675,,1:30 PM,"This workshop will bridge the gap between the theoretical advancements in multi-agent systems and their practical applications in industry. The session will feature a series of poster presentations showcasing state-of-the-art, real-world multi-agent systems that are driving innovation across various sectors. We will delve into the challenges and opportunities of deploying these systems at scale, covering topics such as:x000DHuman-in-the-loop collaboration: Designing systems where AI agents and human experts work in synergy.x000DScalability and efficiency: Architecting multi-agent systems for large-scale industrial applications.x000DSafety and reliability: Ensuring the robustness and predictability of autonomous agents in critical systems.x000DDomain-specific applications: Highlighting successful implementations in areas such as software engineering, scientific research, and creative content generation.x000DThe goal of this workshop is to foster a discussion on the practical challenges and future directions of multi-agent systems, providing attendees with actionable insights and a deeper understanding of how these technologies are shaping the future of industry.",,多伦多云,多伦多云: AI Agent,多伦多云: Session聚焦多智能体系统在工业中的实际应用，涵盖human-in-the-loop协作、系统的安全性与可靠性以及多步执行能力等，直接对应该团队关注的提升AI Agent行为可靠性、管控校验以及具备planning与多步执行能力的L3+ agent持续优化难题。
WED 3 DEC,noon,Expo Workshop,Using the Virtual Cell Platform to Accelerate Machine Learning in Biology,https://neurips.cc/virtual/2025/128676,,1:30 PM,"Biology presents some of the most complex and high-impact challenges for machine learning, and single-cell transcriptomics is at the frontier of this work. In this workshop, we introduce the Virtual Cell Platform (VCP), a unified environment designed to accelerate model development and evaluation in biology. Using single-cell transcriptomics as a case study, we will demonstrate how the VCP enables researchers to train, benchmark, and interpret models in a reproducible and biologically meaningful way.    Participants will gain a primer on single-cell transcriptomics and learn how to evaluate models with cz-benchmarks, an open-source Python package providing standardized, community-driven tasks and metrics. Through the VCP CLI, attendees will pull datasets, run packaged models, and compare results programmatically. Hands-on exercises will guide participants through interactive visualizations, side-by-side model comparisons, and deep dives into model behavior using VCP’s no-code interface and BYOD (Bring Your Own Data) module.    By the end of the session, attendees will understand how to use the VCP to actively test and refine models during development, ensure biological relevance, and contribute models and benchmarks back to the community. This workshop highlights how the Virtual Cell Platform transforms ML infrastructure into a one-stop, researcher-friendly ecosystem, empowering the NeurIPS community to push the boundaries of AI in biology.",,nan,nan,nan
WED 3 DEC,2:30 p.m.,Invited Talk,Are We Having the Wrong Nightmares About AI?,https://neurips.cc/virtual/2025/invited-talk/109606,Zeynep Tufekci,3:30 PM,"Though seemingly opposite, doom and optimism regarding generative AI's spectacular rise both center on AGI or even superintelligence as a pivotal moment. But generative AI operates in a distinct manner from human intelligence, and it’s not a less intelligent human on a chip slowly getting smarter anymore than cars were mere horseless carriages. It must be understood on its own terms. And even if Terminator isn’t coming to kill us or superintelligence isn’t racing to save us, generative AI does bring profound challenges, well-beyond usual worries such as employment effects.  Technology facilitates progress by transforming the difficult into easy, the rare into ubiquitous, the scarce into abundant, the manual into automated, and the artisan into mass-produced. While potentially positive long-term, these inversions are extremely destabilizing during the transition, shattering the correlations and assumptions of our social order that relied on superseded difficulties as mechanisms of proof, filtering, sorting and signaling. For example, while few would dispute the value of the printing press or books, their introduction led to such destructive upheaval that the resulting religious wars caused proportionally more deaths than all other major wars and pandemics since combined. Historically, a new technology's revolutionary impact comes from making what's already possible and desired cheap, easy, fast, and large-scale, not from outdated or ill-fitting benchmarks that technologists tend to focus on. As such, Artificial Good-Enough Intelligence can unleash chaos and destruction long before, or if ever, AGI is reached. Existing AI is good enough to blur or pulverize our existing mechanisms of proof of accuracy, effort, veracity, authenticity, sincerity, and even humanity. The tumult from such a transition will require extensive technological, regulatory, and societal effort to counter. But the first step to getting started is having the right nightmares.",,多伦多云; 温哥华云,多伦多云: AI Agent; 温哥华云: Reinforcement fine tuning (RFT),多伦多云: Session讨论了生成式AI带来的社会机制和信任机制的颠覆，涉及AI Agent行为的可靠性、管控与校验，正对应团队关注的提升Agent行为可靠性及管控难题。; 温哥华云: Session强调现有AI足够强大带来的挑战和转型需要，涉及技术与社会层面的适应，契合团队关注的如何将强化学习技术从理论到生产落地，提升样本效率和性能的实际问题。
WED 3 DEC,4:30 p.m.,Expo Talk Panel,"Juries, Not Judges! Industry-Scale Evaluation of Trustworthy AI via Dynamic LLM Panels",https://neurips.cc/virtual/2025/128660,,5:30 PM,"As Large Language Models (LLMs) become central to high-stakes applications, the reliability of their evaluation systems is under intense scrutiny, especially in the financial industry. Traditional approaches - human annotation, single LLM judges, and static model juries - struggle to balance scalability, cost, and trustworthiness. We will discuss a promising framework: LLM Jury-on-Demand, a dynamic, learning-based framework that assembles an optimal panel of LLM evaluators for each task instance, leveraging predictive modeling to select and weight judges based on context-specific reliability. Our system adapts in real time, outperforming static ensembles and single judges in alignment with human expert judgment across summarization and retrieval-augmented generation benchmarks. This talk will showcase how adaptive LLM juries can transform evaluation of AI systems, offering robust, scalable, and context-aware solutions for industry and research. Attendees will gain practical insights into building trustworthy LLM evaluation pipelines, see live demos, and discuss future directions for reliable AI assessment in critical domains.",,多伦多云,多伦多云: AI Agent,多伦多云: Session介绍了利用动态LLM评审团对AI系统进行可信评估，特别强调了通过上下文相关的评审员选择和加权机制提升评估的可靠性和准确性，直接对应该团队关注的提升AI Agent评估准确性与覆盖范围、行为可靠性及管控的难题。
WED 3 DEC,4:30 p.m.,Expo Talk Panel,"Frontier Open-Weight Models: Building Transparent, Secure, and Sovereign AI",https://neurips.cc/virtual/2025/128664,,5:30 PM,"The next generation of AI will be defined not just by scale, but by openness. As the frontier in model capabilities accelerates, researchers and enterprises alike face a critical question: how do we advance state-of-the-art intelligence while preserving transparency, control, and security?x000Dx000DThis panel brings together leaders from open research, industry, and infrastructure to explore the emerging ecosystem of open-weight frontier models—systems that can be fully run, audited, and customized within private or sovereign environments. Discussion topics will include the research challenges behind training and aligning open models at scale, implications for reproducibility and safety, and how open access can enable new forms of collaboration between academia, government, and enterprise.x000Dx000DAttendees will gain insight into how the open frontier movement is reshaping AI research culture, infrastructure design, and deployment strategy worldwide.",,多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: Session讨论开放权重前沿模型的训练、对齐和安全性，直接涉及AI Agent的行为可靠性、管控校验及持续优化机制，开放模型的透明性和可定制性有助于提升Agent评估准确性和行为管控。; 诺亚: Session强调开放模型的训练与对齐挑战，涉及安全性和可审计性，能为诺亚团队在自博弈、learning from experience训练框架及Latent Reasoning提供开放透明的模型环境和协作平台，促进模型安全与可控性研究。
WED 3 DEC,4:30 p.m.,Expo Talk Panel,The Co-X Framework: Versatile AI Agents for Automating and Augmenting Professional Workflows,https://neurips.cc/virtual/2025/128666,,5:30 PM,"Beyond monolithic models, the future of AI in industry lies in specialized agents that collaborate with human experts. This talk introduces the ""Co-X"" framework, a novel approach for creating a diverse ecosystem of collaborative agents tailored to specific professional domains. We will present four key agents built on this framework: the Co-AI Researcher, the Co-ML Engineer for automating software development cycles, the Co-Data Scientist for automating data analysis and insight generation, and the Co-Director for augmenting creative content generation. We will discuss the foundational technologies that enable this versatility—including long-term memory, tool use, and human-in-the-loop feedback—and demonstrate how the Co-X framework is poised to redefine productivity and innovation across industries.",,多伦多云; 存储,多伦多云: AI Agent; 存储: 单/多模型推理,多伦多云: Session介绍了Co-X框架中多种协作AI Agent（如Co-AI Researcher、Co-ML Engineer、Co-Data Scientist、Co-Director），直接对应团队关注的AI Agent评估、行为可靠性及持续优化机制等难题，提供了Agent协作、长期记忆、工具使用和人机反馈等技术手段，有助于提升Agent的评估准确性、行为管控和自主学习能力。; 存储: Session强调了多模型协作Agent生态系统及其长期记忆和工具使用能力，涉及多模型系统中模型加载、卸载、调度及记忆系统的访问模式，直接关联团队关于Agentic AI系统中RAG、Vector DB访问模式及MemOS记忆系统调度的难题，提供了多模型协作和记忆管理的框架思路。
WED 3 DEC,4:30 p.m.,Expo Talk Panel,Cosmos World Foundation Model Platform for Physical AI,https://neurips.cc/virtual/2025/128663,,5:30 PM,"Abstract: In this talk, I will introduce NVIDIA Cosmos, our World Foundation Model platform designed to advance Physical AI. Cosmos is built around three core pillars: Predict, Transfer, and Reason. I will provide updates on the latest releases—Predict 2.5 and Transfer 2.5—highlighting key improvements in generalization, efficiency, and scalability. In addition, I will share a preview of ongoing research directions that extend Cosmos toward richer world modeling and reasoning capabilities. Together, these developments aim to push the boundaries of how AI perceives, simulates, and interacts with complex real-world environments.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session介绍了NVIDIA Cosmos平台，专注于Physical AI的感知、模拟和交互，直接对应团队关注的Physical or Embodied AI领域，且分享了世界建模和推理能力的研究方向，可为团队在Physical AI方面的技术发展和研究提供具体思路和方法。
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1A,https://neurips.cc/virtual/2025/session/122546,,11:00 AM,,,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference,https://neurips.cc/virtual/2025/oral/118170,,11:00 AM,"Large Language Models (LLMs) are now integral across various domains and have demonstrated impressive performance. Progress, however, rests on the premise that benchmark scores are both accurate and reproducible. We demonstrate that the reproducibility of LLM performance is fragile: changing system configuration, such as evaluation batch size, GPU count, and GPU version, can introduce significant differences in the generated responses. This issue is especially pronounced in reasoning models, where minor rounding differences in early tokens can cascade into divergent chains of thought, ultimately affecting accuracy. For instance, under bfloat16 precision with greedy decoding, a reasoning model like DeepSeek-R1-Distill-Qwen-7B can exhibit up to 9\% variation in accuracy and 9,000 tokens difference in response length due to differences in GPU count, type, and evaluation batch size.We trace the root cause of this variability to the non-associative nature of floating-point arithmetic under limited numerical precision. This work presents the first systematic investigation into how numerical precision affects reproducibility in LLM inference. Through carefully controlled experiments across various hardware, software, and precision settings, we quantify when and how model outputs diverge.Our analysis reveals that floating-point precision—while critical for reproducibility—is often neglected in evaluation practices.Inspired by this, we develop a lightweight inference pipeline, dubbed LayerCast, that stores weights in 16-bit precision but performs all computations in FP32, balancing memory efficiency with numerical stability. Code is available at https://github.com/nanomaoli/llm_reproducibility.",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构,海思: Session聚焦于LLM推理中数值非确定性问题及其缓解方法，尤其涉及推理阶段的数值精度和硬件配置对结果的影响。海思团队关注如何在保证对话质量和上下文一致性的前提下实现低延迟实时推理，session中提出的LayerCast轻量推理管线通过FP32计算提升数值稳定性，能为海思团队解决推理阶段的数值稳定性和准确性难题提供技术参考。; 计算: Session系统性分析了数值精度对LLM推理结果复现性的影响，强调浮点计算的非结合性导致结果差异。计算BU关注模型架构对计算架构的影响及低精度训练推理的挑战，session中关于数值精度和硬件配置对推理结果的影响与该团队难题高度相关，有助于理解和设计更稳定的模型架构和计算方案。
WED 3 DEC,10:00-11:00,Oral Paper,  → Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond),https://neurips.cc/virtual/2025/oral/121422,,11:00 AM,"Large language models (LMs) often struggle to generate diverse, human-like creative content, raising concerns about the long-term homogenization of human thought through repeated exposure to similar outputs. Yet scalable methods for evaluating LM output diversity remain limited, especially beyond narrow tasks such as random number or name generation, or beyond repeated sampling from a single model. To address this gap, we introduce Infinity-Chat, a large-scale dataset of 26K diverse, real-world, open-ended user queries that admit a wide range of plausible answers with no single ground truth. We introduce the first comprehensive taxonomy for characterizing the full spectrum of open-ended prompts posed to LMs, comprising 6 top-level categories (e.g., creative content generation, brainstorm & ideation) that further breaks down to 17 subcategories. Using Infinity-Chat, we present a large-scale study of mode collapse in LMs, revealing a pronounced Artificial Hivemind effect in open-ended generation of LMs, characterized by (1) intra-model repetition, where a single model consistently generates similar responses, and more so (2) inter-model homogeneity, where different models produce strikingly similar outputs. Infinity-Chat also includes 31,250 human annotations, across absolute ratings and pairwise preferences, with 25 independent human annotations per example. This enables studying collective and individual-specific human preferences in response to open-ended queries. Our findings show that state-of-the-art LMs, reward models, and LM judges are less well calibrated to human ratings on model generations that elicit differing idiosyncratic annotator preferences, despite maintaining comparable overall quality. Overall, INFINITY-CHAT presents the first large-scale resource for systematically studying real-world open-ended queries to LMs, revealing critical insights to guide future research for mitigating long-term AI safety risks posed by the Artificial Hivemind.",,多伦多云,多伦多云: AI Agent,多伦多云: Session聚焦于大语言模型生成内容的多样性和人工蜂群效应，涉及对开放式查询的多样化回答及人类偏好校准，直接关联AI Agent的评估准确性与覆盖范围难题，特别是提升Agent行为可靠性和持续优化机制，提供了丰富的用户查询数据集和人类注释，有助于改进Agent评估和行为管控。
WED 3 DEC,10:00-11:00,Oral Paper,  → SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing,https://neurips.cc/virtual/2025/oral/115002,,11:00 AM,"3D spatial reasoning in dynamic, audio-visual environments is a cornerstone of human cognition yet remains largely unexplored by existing Audio-Visual Large Language Models (AV-LLMs) and benchmarks, which predominantly focus on static or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D spatial reasoning in dynamic scenes with synchronized spatial audio. SAVVY-Bench is comprised of thousands of carefully curated question–answer pairs probing both directional and distance relationships involving static and moving objects, and requires fine-grained temporal grounding, consistent 3D localization, and multi-modal annotation. To tackle this challenge, we propose SAVVY, a novel training-free reasoning pipeline that consists of two stages: (i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as other audio-visual methods to track the trajectories of key objects related to the query using both visual and spatial audio cues, and (ii) Dynamic Global Map Construction, which aggregates multi-modal queried object trajectories and converts them into a unified global dynamic map. Using the constructed map, a final QA answer is obtained through a coordinate transformation that aligns the global map with the queried viewpoint. Empirical evaluation demonstrates that SAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a new standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.",,CBG; 温哥华云,CBG: 3DAIGC; 温哥华云: Embodied AI,CBG: Session聚焦于3D空间推理和动态音视频环境下的多模态信息融合，涉及动态场景中运动物体的空间定位和轨迹跟踪，直接对应该团队关于视频中运动物体快速准确分割及基于单目视频进行3D/4D稀疏重建的难题，SAVVY提出的多模态轨迹估计和动态全局地图构建方法可为其提供技术思路。; 温哥华云: Session探讨动态3D空间推理和音视频多模态感知，属于具身AI关键技术范畴，涉及环境感知与空间认知，能够为该团队在物理具身AI领域的空间理解和多模态感知提供前沿方法和基准，助力其战略投资方向。
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1B,https://neurips.cc/virtual/2025/session/122547,,11:00 AM,,,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → Optimal Mistake Bounds for Transductive Online Learning,https://neurips.cc/virtual/2025/oral/119099,,11:00 AM,"We resolve a 30-year-old open problem concerning the power of unlabeled data in online learning by tightly quantifying the gap between transductive and standard online learning. We prove that for every concept class $\mathcal{H}$ with Littlestone dimension $d$, the transductive mistake bound is at least $\Omega(\sqrt{d})$. This establishes an exponential improvement over previous lower bounds of $\Omega(\log \log d)$, $\Omega(\sqrt{\log d})$, and $\Omega(\log d)$, respectively due to Ben-David, Kushilevitz, and Mansour (1995, 1997) and Hanneke, Moran, and Shafer (2023). We also show that our bound is tight: for every $d$, there exists a class of Littlestone dimension $d$ with transductive mistake bound $O(\sqrt{d})$. Our upper bound also improves the previous best known upper bound of $(2/3) \cdot d$ from Ben-David et al. (1997). These results demonstrate a quadratic gap between transductive and standard online learning, thereby highlighting the benefit of advanced access to the unlabeled instance sequence. This stands in stark contrast to the PAC setting, where transductive and standard learning exhibit similar sample complexities.",,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → High-Dimensional Calibration from Swap Regret,https://neurips.cc/virtual/2025/oral/117761,,11:00 AM,"We study the online calibration of multi-dimensional forecasts over an arbitrary convex set $\mathcal{P} \subset \mathbb{R}^d$ relative to an arbitrary norm $\Vert\cdot\Vert$. We connect this with the problem of external regret minimization for online linear optimization, showing that if it is possible to guarantee $O(\sqrt{\rho T})$ worst-case regret after $T$ rounds when actions are drawn from $\mathcal{P}$ and losses are drawn from the dual $\Vert \cdot \Vert_*$ unit norm ball, then it is also possible to obtain $\epsilon$-calibrated forecasts after $T = \exp(O(\rho /\epsilon^2))$ rounds. When $\mathcal{P}$ is the $d$-dimensional simplex and $\Vert \cdot \Vert$ is the $\ell_1$-norm, the existence of $O(\sqrt{T\log d})$ algorithms for learning with experts implies that it is possible to obtain $\epsilon$-calibrated forecasts after $T = \exp(O(\log{d}/\epsilon^2)) = d^{O(1/\epsilon^2)}$ rounds, recovering a recent result of Peng 2025.Interestingly, our algorithm obtains this guarantee without requiring access to any online linear optimization subroutine or knowledge of the optimal rate $\rho$ -- in fact, our algorithm is identical for every setting of $\mathcal{P}$ and $\Vert \cdot \Vert$. Instead, we show that the optimal regularizer for the above OLO problem can be used to upper bound the above calibration error by a swap regret, which we then minimize by running the recent TreeSwap algorithm with Follow-The-Leader as a subroutine. The resulting algorithm is highly efficient and plays a distribution over simple averages of past observations in each round.Finally, we prove that any online calibration algorithm that guarantees $\epsilon T$ $\ell_1$-calibration error over the $d$-dimensional simplex requires $T \geq \exp(\mathrm{poly}(1/\epsilon))$ (assuming $d \geq \mathrm{poly}(1/\epsilon)$). This strengthens the corresponding $d^{\Omega(\log{1/\epsilon})}$ lower bound of Peng 2025, and shows that an exponential dependence on $1/\epsilon$ is necessary.",,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → Does Stochastic Gradient really succeed for bandits?,https://neurips.cc/virtual/2025/oral/116754,,11:00 AM,"Recent works of Mei et al. (2023, 2024) have deepened the theoretical understanding of the *Stochastic Gradient Bandit* (SGB) policy, showing that using a constant learning rate guarantees asymptotic convergence to the optimal policy, and that sufficiently *small* learning rates can yield logarithmic regret. However, whether logarithmic regret holds beyond small learning rates remains unclear. In this work, we take a step towards characterizing the regret *regimes* of SGB as a function of its learning rate. For two--armed bandits, we identify a sharp threshold, scaling with the sub-optimality gap $\Delta$, below which SGB achieves *logarithmic* regret on all instances, and above which it can incur *polynomial* regret on some instances. This result highlights the necessity of knowing (or estimating) $\Delta$ to ensure logarithmic regret with a constant learning rate.For general $K$-armed bandits, we further show the learning rate must scale inversely with $K$ to avoid polynomial regret. We introduce novel techniques to derive regret upper bounds for SGB, laying the groundwork for future advances in the theory of gradient-based bandit algorithms.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session聚焦于Stochastic Gradient Bandit (SGB)策略的理论分析，特别是关于学习率与regret的关系，直接涉及强化学习中的策略优化和样本效率问题。温哥华云团队关注强化学习在大模型微调中的实际应用问题，session中关于SGB的收敛性和regret界的理论进展可为其提升样本效率和性能提供理论支持和方法指导。; 诺亚: 该session深入探讨基于梯度的bandit算法的理论性质，涉及强化学习中策略优化的数学基础。诺亚团队关注大模型后训练中的强化学习和推理，session中关于学习率调节与策略收敛性的研究成果可为其自博弈与经验学习训练框架提供理论依据和优化思路。
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1C,https://neurips.cc/virtual/2025/session/122548,,11:00 AM,,,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → Adjoint Schrödinger Bridge Sampler,https://neurips.cc/virtual/2025/oral/115787,,11:00 AM,"Computational methods for learning to sample from the Boltzmann distribution—where the target distribution is known only up to an unnormalized energy function—have advanced significantly recently. Due to the lack of explicit target samples, however, prior diffusion-based methods, known asdiffusion samplers, often require importance-weighted estimation or complicated learning processes. Both trade off scalability with extensive evaluations of the energy and model, thereby limiting their practical usage. In this work, we proposeAdjoint Schrödinger Bridge Sampler (ASBS), a new diffusion sampler that employs simple and scalable matching-based objectives yet without the need to estimate target samples during training. ASBS is grounded on a mathematical model—the Schrödinger Bridge—which enhances sampling efficiency via kinetic-optimal transportation. Through a new lens of stochastic optimal control theory, we demonstrate how SB-based diffusion samplers can be learned at scale via Adjoint Matching and prove convergence to the global solution. Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to arbitrary source distributions by relaxing the so-called memoryless condition that largely restricts the design space. Through extensive experiments, we demonstrate the effectiveness of ASBS on sampling from classical energy functions, amortized conformer generation, and molecular Boltzmann distributions. Codes are available at https://github.com/facebookresearch/adjoint_samplers",,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → Rethinking Joint Maximum Mean Discrepancy for Visual Domain Adaptation,https://neurips.cc/virtual/2025/oral/117477,,11:00 AM,"In domain adaption (DA), joint maximum mean discrepancy (JMMD), as a famous distribution-distance metric, aims to measure joint probability distribution difference between the source domain and target domain, while it is still not fully explored and especially hard to be applied into a subspace-learning framework as its empirical estimation involves a tensor-product operator whose partial derivative is difficult to obtain. To solve this issue, we deduce a concise JMMD based on the Representer theorem that avoids the tensor-product operator and obtains two essential findings. First, we reveal the uniformity of JMMD by proving that previous marginal, class conditional, and weighted class conditional probability distribution distances are three special cases of JMMD with different label reproducing kernels. Second, inspired by graph embedding, we observe that the similarity weights, which strengthen the intra-class compactness in the graph of Hilbert Schmidt independence criterion (HSIC), take opposite signs in the graph of JMMD, revealing why JMMD degrades the feature discrimination. This motivates us to propose a novel loss JMMD-HSIC by jointly considering JMMD and HSIC to promote discrimination of JMMD. Extensive experiments on several cross-domain datasets could demonstrate the validity of our revealed theoretical results and the effectiveness of our proposed JMMD-HSIC.",,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → Class-wise Balancing Data Replay for Federated Class-Incremental Learning,https://neurips.cc/virtual/2025/oral/117265,,11:00 AM,"Federated Class Incremental Learning (FCIL) aims to collaboratively process continuously increasing incoming tasks across multiple clients. Among various approaches, data replay has become a promising solution, which can alleviate forgetting by reintroducing representative samples from previous tasks. However, their performance is typically limited by class imbalance, both within the replay buffer due to limited global awareness and between replayed and newly arrived classes. To address this issue, we propose a class-wise balancing data replay method for FCIL (FedCBDR), which employs a global coordination mechanism for class-level memory construction and reweights the learning objective to alleviate the aforementioned imbalances. Specifically, FedCBDR has two key components: 1) the global-perspective data replay module reconstructs global representations of prior task knowledge in a privacy-preserving manner, which then guides a class-aware and importance-sensitive sampling strategy to achieve balanced replay; 2) Subsequently, to handle class imbalance across tasks, the task-aware temperature scaling module adaptively adjusts the temperature of logits at both class and instance levels based on task dynamics, which reduces the model’s overconfidence in majority classes while enhancing its sensitivity to minority classes. Experimental results verified that FedCBDR achieves balanced class-wise sampling under heterogeneous data distributions and improves generalization under task imbalance between earlier and recent tasks, yielding a 2%-15% Top-1 accuracy improvement over six state-of-the-art methods.",,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1D,https://neurips.cc/virtual/2025/session/122549,,11:00 AM,,,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think,https://neurips.cc/virtual/2025/oral/116345,,11:00 AM,"REPA and its variants effectively mitigate training challenges in diffusion models by incorporating external visual representations from pretrained models, through alignment between the noisy hidden projections of denoising networks and foundational clean image representations. We argue that the external alignment, which is absent during the entire denoising inference process, falls short of fully harnessing the potential of discriminative representations. In this work, we propose a straightforward method called \textit{\textbf{R}epresentation \textbf{E}ntanglement for \textbf{G}eneration} (\textbf{REG}), which entangles low-level image latents with a single high-level class token from pretrained foundation models for denoising. REG acquires the capability to produce coherent image-class pairs directly from pure noise, substantially improving both generation quality and training efficiency.This is accomplished with negligible additional inference overhead, requiring only one single additional token for denoising (<0.5\% increase in FLOPs and latency).The inference process concurrently reconstructs both image latents and their corresponding global semantics, where the acquired semantic knowledge actively guides and enhances the image generation process.On ImageNet 256$\times$256, SiT-XL/2 + REG demonstrates remarkable convergence acceleration, achieving $\textbf{63}\times$ and $\textbf{23}\times$ faster training than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively, SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA trained for 4M iterations ($\textbf{10}\times$ longer). Code is available at: https://github.com/Martinser/REG.",,海思; 计算; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构; 计算: 训推新范式,海思: 该session提出的Representation Entanglement for Generation (REG)方法显著提升了扩散模型的训练效率和生成质量，且推理开销极低，直接对应海思关注的扩散模型加速难题，尤其是多模态条件融合和长上下文推理的效率提升，REG通过融合高层语义token优化了生成过程，有助于解决多模态条件融合延迟大及推理复杂度高的问题。; 计算: 该session介绍的REG方法通过引入语义token与图像潜变量的纠缠，极大加速了扩散模型训练收敛速度，体现了模型架构设计对训练效率和推理性能的深远影响，符合计算BU对模型架构演进趋势和对计算系统需求的关注，有助于其洞察新型高效模型架构对计算系统的影响。; 计算: REG方法提出了一种新的训练范式，通过语义与图像潜变量的纠缠实现更高效的训练和推理，显著缩短训练时间，符合计算BU对训练推理新范式演进机理的关注，有助于理解和预测未来训推负载特征的变化。
WED 3 DEC,10:00-11:00,Oral Paper,  → On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity,https://neurips.cc/virtual/2025/oral/116379,,11:00 AM,"Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods, such as diffusion and flow matching techniques, generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the noisy nature of the loss as a key factor driving generalization in flow matching.First, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.",,海思,海思: 大语言模型和扩散模型的加速,海思: 该session聚焦于flow matching的闭式解及其对生成模型泛化能力的影响，直接涉及扩散模型和flow matching技术。海思团队关注多模态条件融合和长上下文推理的复杂度问题，session中关于闭式解提升性能和减少随机性影响的研究，能为海思团队在扩散模型加速及优化推理效率提供理论依据和方法支持。
WED 3 DEC,10:00-11:00,Oral Paper,  → Why Diffusion Models Don’t Memorize:  The Role of Implicit Dynamical Regularization in Training,https://neurips.cc/virtual/2025/oral/119373,,11:00 AM,"Diffusion models have achieved remarkable success across a wide range of generative tasks. A key challenge is understanding the mechanisms that prevent their memorization of training data and allow generalization. In this work, we investigate the role of the training dynamics in the transition from generalization to memorization. Through extensive experiments and theoretical analysis, we identify two distinct timescales: an early time $\tau_\mathrm{gen}$ at which models begin to generate high-quality samples, and a later time $\tau_\mathrm{mem}$ beyond which memorization emerges. Crucially, we find that $\tau_\mathrm{mem}$ increases linearly with the training set size $n$, while $\tau_\mathrm{gen}$ remains constant. This creates a growing window of training times with $n$ where models generalize effectively, despite showing strong memorization if training continues beyond it. It is only when $n$ becomes larger than a model-dependent threshold that overfitting disappears at infinite training times.These findings reveal a form of implicit dynamical regularization in the training dynamics, which allow to avoid memorization even in highly overparameterized settings. Our results are supported by numerical experiments with standard U-Net architectures on realistic and synthetic  datasets, and by a theoretical analysis using a tractable random features model studied in the high-dimensional limit.",,海思,海思: 大语言模型和扩散模型的加速,海思: Session深入探讨了扩散模型训练中隐式动力学正则化机制，揭示了模型如何避免记忆训练数据并实现泛化，这对于海思团队关注的扩散模型加速及保持模型质量和一致性的难题具有直接技术指导意义。理解训练动态有助于优化模型训练策略，降低推理延迟并提升多模态条件融合效率。
WED 3 DEC,10:00-11:00,Oral Session,Oral Session 1E,https://neurips.cc/virtual/2025/session/122550,,11:00 AM,,,nan,nan,nan
WED 3 DEC,10:00-11:00,Oral Paper,  → Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation,https://neurips.cc/virtual/2025/oral/115716,,11:00 AM,"Vision-and-Language Navigation (VLN) is a core task where embodied agents leverage their spatial mobility to navigate in 3D environments toward designated destinations based on natural language instructions. Recently, video-language large models (Video-VLMs) with strong generalization capabilities and rich commonsense knowledge have shown remarkable performance when applied to VLN tasks. However, these models still encounter the following challenges when applied to real-world 3D navigation: 1) Insufficient understanding of 3D geometry and spatial semantics; 2) Limited capacity for large-scale exploration and long-term environmental memory; 3) Poor adaptability to dynamic and changing environments.To address these limitations, we propose Dynam3D, a dynamic layered 3D representation model that leverages language-aligned, generalizable, and hierarchical 3D representations as visual input to train 3D-VLM in navigation action prediction. Given posed RGB-D images, our Dynam3D projects 2D CLIP features into 3D space and constructs multi-level 3D patch-instance-zone representations for 3D geometric and semantic understanding with a dynamic and layer-wise update strategy.  Our Dynam3D is capable of online encoding and localization of 3D instances, and dynamically updates them in changing environments to provide large-scale exploration and long-term memory capabilities for navigation. By leveraging large-scale 3D-language pretraining and task-specific adaptation, our Dynam3D sets new state-of-the-art performance on VLN benchmarks including R2R-CE, REVERIE-CE and NavRAG-CE under monocular settings. Furthermore, experiments for pre-exploration, lifelong memory, and real-world robot validate the effectiveness of practical deployment.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session聚焦于Vision-and-Language Navigation (VLN)中的3D环境导航，涉及具身智能体在动态3D环境中的感知与导航，直接对应该团队关注的Physical or Embodied AI领域，且提出的Dynam3D动态3D表示和长期记忆机制为具身智能体的导航和环境适应难题提供了先进的技术方案。
WED 3 DEC,10:00-11:00,Oral Paper,  → Perception Encoder: The best visual embeddings are not at the output of the network,https://neurips.cc/virtual/2025/oral/118806,,11:00 AM,"We introduce Perception Encoder (PE), a family of state-of-the-art vision encoders for image and video understanding. Traditionally, vision encoders have relied on a variety of pretraining objectives, each excelling at different downstream tasks. Surprisingly, after scaling a carefully tuned image pretraining recipe and refining with a robust video data engine, we find that contrastive vision-language training alone can produce strong, general embeddings for all of these downstream tasks. There is only one caveat: these embeddings are hidden within the intermediate layers of the network. To draw them out, we introduce two alignment methods: language alignment for multimodal language modeling, and spatial alignment for dense prediction. Together, our PE family of models achieves state-of-the-art results on a wide variety of tasks, including zero-shot image and video classification and retrieval; document, image, and video Q&A; and spatial tasks such as detection, tracking, and depth estimation. We release our models, code, and novel dataset of synthetically and human-annotated videos: https://github.com/facebookresearch/perception_models",,CBG,CBG: 3DAIGC,CBG: Session介绍了Perception Encoder在视频理解中的视觉编码，尤其包括视频中运动物体的检测、跟踪和空间任务，这与CBG团队关注的快速准确分割视频中运动物体和3D/4D稀疏重建高度相关，Perception Encoder的中间层视觉嵌入和空间对齐方法可为其难题提供新的技术思路。
WED 3 DEC,10:00-11:00,Oral Paper,  → Interactive Cross-modal Learning for Text-3D Scene Retrieval,https://neurips.cc/virtual/2025/oral/116803,,11:00 AM,"Text-3D Scene Retrieval (T3SR) aims to retrieve relevant scenes using linguistic queries. Although traditional T3SR methods have made significant progress in capturing fine-grained associations, they implicitly assume that query descriptions are information-complete. In practical deployments, however, limited by the capabilities of users and models, it is difficult or even impossible to directly obtain a perfect textual query suiting the entire scene and model, thereby leading to performance degradation. To address this issue, we propose a novel Interactive Text-3D Scene Retrieval Method (IDeal), which promotes the enhancement of the alignment between texts and 3D scenes through continuous interaction. To achieve this, we present an Interactive Retrieval Refinement framework (IRR), which employs a questioner to pose contextually relevant questions to an answerer in successive rounds that either promote detailed probing or encourage exploratory divergence within scenes. Upon the iterative responses received from the answerer, IRR adopts a retriever to perform both feature-level and semantic-level information fusion, facilitating scene-level interaction and understanding for more precise re-rankings. To bridge the domain gap between queries and interactive texts, we propose an Interaction Adaptation Tuning strategy (IAT). IAT mitigates the discriminability and diversity risks among augmented text features that approximate the interaction text domain, achieving contrastive domain adaptation for our retriever. Extensive experimental results on three datasets demonstrate the superiority of IDeal.",,CBG; 海思; 诺亚,CBG: 3DAIGC; 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,CBG: Session聚焦于Text-3D Scene Retrieval，通过交互式文本与3D场景的对齐提升检索精度，直接涉及3D场景理解与多模态交互，能为团队在3D/4D稀疏重建和视频中运动物体分割等3D相关任务提供新的交互式检索和语义理解方法。; 海思: Session提出了交互式文本-3D场景检索方法，涉及多轮交互文本特征融合及跨域适配，涉及多模态条件融合和长上下文交互，能为团队解决多模态条件融合延迟大和长上下文推理复杂度高的问题提供技术思路。; 诺亚: Session中提出的交互式检索框架涉及多轮文本交互和多模态信息融合，符合团队关注的多模态长序列模型演进及输入范式层面突破多模态长文本推理瓶颈的研究方向，能为团队提供交互式多模态信息融合的具体实现方案。
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2A,https://neurips.cc/virtual/2025/session/122551,,4:30 PM,,,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → Agnostic Active Learning Is Always Better Than Passive Learning,https://neurips.cc/virtual/2025/oral/117512,,4:30 PM,"We sharply characterize the optimal first-order query complexity of agnostic active learning for all concept classes, and propose a new general active learning algorithm which achieves it. Remarkably, the optimal query complexity admits a leading term which is always strictly smaller than the sample complexity of passive supervised learning (by a factor proportional to the best-in-class error rate). This was not previously known to be possible in the agnostic setting. For comparison, in all previous general analyses, the leading term exhibits an additional factor, such as the disagreement coefficient or related complexity measure, and therefore only provides improvements over passive learning in restricted cases. The present work completely removes such factors from the leading term, implying that every concept class benefits from active learning in the non-realizable case. The results established in this work resolve an important long-standing open question central to the past two decades of research on the theory of agnostic active learning.",,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → Tighter CMI-Based Generalization Bounds via Stochastic Projection and Quantization,https://neurips.cc/virtual/2025/oral/117680,,4:30 PM,"In this paper, we leverage stochastic projection and lossy compression to establish new conditional mutual information (CMI) bounds on the generalization error of statistical learning algorithms. It is shown that these bounds are generally tighter than the existing ones. In particular, we prove that for certain problem instances for which existing MI and CMI bounds were recently shown in Attias et al. [2024] and Livni [2023] to become vacuous or fail to describe the right generalization behavior, our bounds yield suitable generalization guarantees of the order of $\mathcal{O}(1/\sqrt{n})$, where $n$ is the size of the training dataset. Furthermore, we use our bounds to investigate the problem of data ""memorization"" raised in those works, and which asserts that there are learning problem instances for which any learning algorithm that has good prediction there exist distributions under which the algorithm must ""memorize'' a big fraction of the training dataset. We show that for every learning algorithm, there exists an auxiliary algorithm that does not memorize and which yields comparable generalization error for any data distribution. In part, this shows that memorization is not necessary for good generalization.",,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks,https://neurips.cc/virtual/2025/oral/118768,,4:30 PM,"Understanding the inductive bias and generalization properties of large overparametrized machine learning models requires to characterize the dynamics of the training algorithm.  We study the learning dynamics of large two-layer neural networks via dynamical mean field theory, a well established technique of non-equilibrium statistical physics. We show that, for large network width $m$,and large number of samples per input dimension $n/d$, the training dynamics exhibits a separation of timescales which implies:$(i)$ The emergence of a slow time scale associated with the growth in Gaussian/Rademacher complexity of the network;$(ii)$ Inductive bias towards small complexity if the initialization has small enough complexity;$(iii)$ A dynamical decoupling between feature learning and overfitting regimes; $(iv)$ A non-monotone behavior of the test error, associated  `feature unlearning' regime at large times.",,计算; 计算,计算: 高效模型架构; 计算: 训推新范式,计算: 该session深入分析了大规模两层神经网络训练动态，揭示了训练过程中复杂度增长与泛化能力的动态解耦机制，直接对应团队关注的模型架构演进趋势及其对计算系统的影响，有助于理解训练动态对模型结构和泛化性能的根本驱动力，进而指导计算架构设计。; 计算: session中关于训练动态的分时尺度分析及特征学习与过拟合的动态解耦，为理解不同训练范式下负载特征和训练行为提供理论基础，契合团队对训推范式演进机理的关注，有助于预测和定义未来训练负载。
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2B,https://neurips.cc/virtual/2025/session/122552,,4:30 PM,,,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → PhySense: Sensor Placement Optimization for Accurate Physics Sensing,https://neurips.cc/virtual/2025/oral/115066,,4:30 PM,"Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered. Code is available at this repository: https://github.com/thuml/PhySense.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session PhySense聚焦于物理传感器布局优化和物理场重建，直接对应物理或具身AI领域的核心问题，能为团队在物理感知和传感器优化方面提供先进的深度学习方法和理论保障。
WED 3 DEC,3:30-4:30,Oral Paper,  → TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability,https://neurips.cc/virtual/2025/oral/117509,,4:30 PM,"Vehicle GPS trajectories provide valuable movement information that supports various downstream tasks and applications. A desirable trajectory learning model should be able to transfer across regions and tasks without retraining, avoiding the need to maintain multiple specialized models and subpar performance with limited training data. However, each region has its unique spatial features and contexts, which are reflected in vehicle movement patterns and are difficult to generalize. Additionally, transferring across different tasks faces technical challenges due to the varying input-output structures required for each task. Existing efforts towards transferability primarily involve learning embedding vectors for trajectories, which perform poorly in region transfer and require retraining of prediction modules for task transfer.To address these challenges, we propose $\textit{TransferTraj}$, a vehicle GPS trajectory learning model that excels in both region and task transferability. For region transferability, we introduce RTTE as the main learnable module within TransferTraj. It integrates spatial, temporal, POI, and road network modalities of trajectories to effectively manage variations in spatial context distribution across regions. It also introduces a TRIE module for incorporating relative information of spatial features and a spatial context MoE module for handling movement patterns in diverse contexts. For task transferability, we propose a task-transferable input-output scheme that unifies the input-output structure of different tasks into the masking and recovery of modalities and trajectory points. This approach allows TransferTraj to be pre-trained once and transferred to different tasks without retraining. We conduct extensive experiments on three real-world vehicle trajectory datasets under various transfer settings, including task transfer, zero-shot region transfer, and few-shot region transfer. Experimental results demonstrate that TransferTraj significantly outperforms state-of-the-art baselines in different scenarios, validating its effectiveness in region and task transfer. Code is available at https://github.com/wtl52656/TransferTraj.",,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata,https://neurips.cc/virtual/2025/oral/121612,,4:30 PM,"Accurate visual localization from aerial views is a fundamental problem with applications in mapping, large-area inspection, and search-and-rescue operations. In many scenarios, these systems require high-precision localization while operating with limited resources (e.g., no internet connection or GNSS/GPS support), making large image databases or heavy 3D models impractical. Surprisingly, little attention has been given to leveraging orthographic geodata as an alternative paradigm, which is lightweight and increasingly available through free releases by governmental authorities (e.g., the European Union). To fill this gap, we propose OrthoLoC, the first large-scale dataset comprising 16,425 UAV images from Germany and the United States with multiple modalities. The dataset addresses domain shifts between UAV imagery and geospatial data. Its paired structure enables fair benchmarking of existing solutions by decoupling image retrieval from feature matching, allowing isolated evaluation of localization and calibration performance. Through comprehensive evaluation, we examine the impact of domain shifts, data resolutions, and covisibility on localization accuracy. Finally, we introduce a refinement technique called AdHoP, which can be integrated with any feature matcher, improving matching by up to 95% and reducing translation error by up to 63%. The dataset and code are available at: https://deepscenario.github.io/OrthoLoC .",,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2C,https://neurips.cc/virtual/2025/session/122553,,4:30 PM,,,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → A multiscale analysis of mean-field transformers in the moderate interaction regime,https://neurips.cc/virtual/2025/oral/117616,,4:30 PM,"In this paper, we study the evolution of tokens through the depth of encoder-only transformer models at inference time by modeling them as a system of particles interacting in a mean-field way and studying the corresponding dynamics. More specifically, we consider this problem in the moderate interaction regime, where the number $N$ of tokens is large and the inverse temperature parameter $\beta$ of the model scales together with $N$. In this regime, the dynamics of the system displays a multiscale behavior: a fast phase, where the token empirical measure collapses on a low-dimensional space, an intermediate phase, where the measure further collapses into clusters, and a slow one, where such clusters sequentially merge into a single one. We provide a rigorous characterization of the limiting dynamics in each of these phases and prove convergence in the above mentioned limit, exemplifying our results with some simulations.",,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → The emergence of sparse attention: impact of data distribution and benefits of repetition,https://neurips.cc/virtual/2025/oral/116475,,4:30 PM,"Emergence is a fascinating property of large language models and neural networks more broadly: as models scale and train for longer, they sometimes develop new abilities in sudden ways. Despite initial studies, we still lack a comprehensive understanding of how and when these abilities emerge. To address this gap, we study the emergence over training of sparse attention, a critical and frequently observed attention pattern in Transformers. By combining theoretical analysis of a toy model with empirical observations on small Transformers trained on a linear regression variant, we uncover the mechanics driving sparse attention emergence and reveal that emergence timing follows power laws based on task structure, architecture, and optimizer choice. We additionally find that repetition can greatly speed up emergence. Finally, we confirm these results on a well-studied in-context associative recall task. Our findings provide a simple, theoretically grounded framework for understanding how data distributions and model design influence the learning dynamics behind one form of emergence.",,海思,海思: 大语言模型和扩散模型的加速,海思: Session聚焦于Transformer中稀疏注意力的出现机制及其对训练和推理效率的影响，直接对应海思团队关注的长上下文推理中注意力复杂度过高问题。利用稀疏注意力与分块缓存实现线性或次线性复杂度的技术，与session中关于稀疏注意力的理论分析和训练加速（重复加速出现）高度相关，可为海思团队提供理论基础和实践方法。
WED 3 DEC,3:30-4:30,Oral Paper,  → From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer Training Dynamics,https://neurips.cc/virtual/2025/oral/116706,,4:30 PM,"Although transformer-based models have shown exceptional empirical performance, the fundamental principles governing their training dynamics are inadequately characterized beyond configuration-specific studies. Inspired by empirical evidence showing improved reasoning capabilities under small initialization scales in language models, we employ the gradient flow analytical framework established in \cite{zhou2022towards} to systematically investigate linearized Transformer training dynamics. Our theoretical analysis dissects the dynamics of attention modules into two distinct stages. In the first stage, asymmetric weight perturbations from random initialization sustain non-degenerate gradient dynamics in parameter matrices, facilitating systematic escape from small initialization regimes. Subsequently, these matrices undergo condensation, progressively aligning toward the target orientation. In the second stage, the previously static key-query matrices actively participate in training, driving the normalized matrices toward asymptotic rank collapse. This two-stage framework generalizes classical directional convergence results.",,计算; 计算,计算: 高效模型架构; 计算: 训推新范式,计算: 该session深入分析Transformer训练动态的两阶段机制，揭示了模型训练过程中权重矩阵的演变规律，这对理解和预测大模型结构演进趋势及其对计算架构的影响具有重要意义，直接帮助解决团队关注的模型架构对计算架构影响的难题。; 计算: session通过理论框架系统分析Transformer训练过程中的梯度动态和矩阵秩塌陷现象，为理解训练新范式下模型负载特征的演变机理提供了理论支持，能够帮助团队跟踪和预测训推范式的演进，解决其关注的训推范式演进机理难题。
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2D,https://neurips.cc/virtual/2025/session/122554,,4:30 PM,,,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models,https://neurips.cc/virtual/2025/oral/119904,,4:30 PM,"Preference-based reinforcement learning (PbRL) has emerged as a promising paradigm for teaching robots complex behaviors without reward engineering. However, its effectiveness is often limited by two critical challenges: the reliance on extensive human input and the inherent difficulties in resolving query ambiguity and credit assignment during reward learning. In this paper, we introduce PRIMT, a PbRL framework designed to overcome these challenges by leveraging foundation models (FMs) for multimodal synthetic feedback and trajectory synthesis. Unlike prior approaches that rely on single-modality FM evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy, integrating the complementary strengths of vision-language models (VLMs) and large language models (LLMs) in evaluating robot behaviors for more reliable and comprehensive feedback. PRIMT also incorporates foresight trajectory generation to warm-start the trajectory buffer with bootstrapped samples, reducing early-stage query ambiguity, and hindsight trajectory augmentation for counterfactual reasoning with a causal auxiliary loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6 manipulation tasks on various benchmarks, demonstrating superior performance over FM-based and scripted baselines. Website at https://primt25.github.io/.",,温哥华云; 温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 温哥华云: Embodied AI; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session主题为Preference-based Reinforcement Learning，涉及利用foundation models进行多模态反馈和轨迹合成，直接对应团队关注的强化学习在VLMs/LLMs上的应用及实际问题，能为提升样本效率、性能和可扩展性提供新方法。; 温哥华云: Session涉及机器人复杂行为学习和轨迹生成，属于物理具身AI范畴，PRIMT框架通过多模态反馈和轨迹合成解决具身智能中的奖励学习难题，能为团队的物理AI研究提供技术支持。; 诺亚: Session中提出的利用foundation models进行多模态反馈和因果辅助损失的强化学习方法，与团队关注的自博弈和基于经验学习训练框架高度相关，能为后训练强化学习和推理提供新思路。
WED 3 DEC,3:30-4:30,Oral Paper,  → Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks,https://neurips.cc/virtual/2025/oral/116055,,4:30 PM,"Neuromorphic computing systems are set to revolutionize energy-constrained robotics by achieving orders-of-magnitude efficiency gains, while enabling native temporal processing. Spiking Neural Networks (SNNs) represent a promising algorithmic approach for these systems, yet their application to complex control tasks faces two critical challenges: (1) the non-differentiable nature of spiking neurons necessitates surrogate gradients with unclear optimization properties, and (2) the stateful dynamics of SNNs require training on sequences, which in reinforcement learning (RL) is hindered by limited sequence lengths during early training, preventing the network from bridging its warm-up period.We address these challenges by systematically analyzing surrogate gradient slope settings, showing that shallower slopes increase gradient magnitude in deeper layers but reduce alignment with true gradients. In supervised learning, we find no clear preference for fixed or scheduled slopes. The effect is much more pronounced in RL settings, where shallower slopes or scheduled slopes lead to a $\times2.1$ improvement in both training and final deployed performance. Next, we propose a novel training approach that leverages a privileged guiding policy to bootstrap the learning process, while still exploiting online environment interactions with the spiking policy. Combining our method with an adaptive slope schedule for a real-world drone position control task, we achieve an average return of 400 points, substantially outperforming prior techniques, including Behavioral Cloning and TD3BC, which achieve at most –200 points under the same conditions. This work advances both the theoretical understanding of surrogate gradient learning in SNNs and practical training methodologies for neuromorphic controllers demonstrated in real-world robotic systems.",,温哥华云; 温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 温哥华云: Embodied AI; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session聚焦于强化学习中序列训练及代理梯度的适应性调整，直接涉及强化学习训练范式的优化，能够为团队关注的强化学习在实际云服务中样本效率、性能和可扩展性问题提供理论和方法支持。; 温哥华云: Session中的脉冲神经网络在机器人控制中的应用，特别是针对能效和时序处理的优化，契合物理或具身AI领域对高效控制算法和实时训练方法的需求，能够为团队在物理AI领域的研究提供先进的训练策略和理论基础。; 诺亚: Session深入探讨了强化学习中代理梯度的适应性调整及序列训练问题，符合团队对强化学习及自博弈、经验学习框架的关注，提供了新的训练方法和理论分析，有助于解决团队在RL后训练中的优化难题。
WED 3 DEC,3:30-4:30,Oral Paper,  → SAGE: A Unified Framework for Generalizable Object State Recognition with State-Action Graph Embedding,https://neurips.cc/virtual/2025/oral/116465,,4:30 PM,"Recognizing the physical states of objects and their transformations within videos is crucial for structured video understanding and enabling robust real-world applications, such as robotic manipulation. However, pretrained vision-language models often struggle to capture these nuanced dynamics and their temporal context, and specialized object state recognition frameworks may not generalize to unseen actions or objects. We introduce SAGE (State-Action Graph Embeddings), a novel framework that offers a unified model of physical state transitions by decomposing states into fine-grained, language-described visual concepts that are sharable across different objects and actions. SAGE initially leverages Large Language Models to construct a State-Action Graph, which is then multimodally refined using Vision-Language Models. Extensive experiments show that our method significantly outperforms baselines, generalizes effectively to unseen objects and actions in open-world settings. SAGE improves the prior state-of-the-art by as much as 14.6% on novel state recognition with less than 5% of its inference time.",,温哥华云,温哥华云: Embodied AI,温哥华云: 该session聚焦于通过State-Action Graph Embedding实现物体状态识别和状态转换的统一模型，直接对应物理或具身AI领域的关键问题，能够为团队在物理AI中状态理解和动作关联提供先进的多模态建模方法和泛化能力。
WED 3 DEC,3:30-4:30,Oral Session,Oral Session 2E,https://neurips.cc/virtual/2025/session/122555,,4:30 PM,,,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing,https://neurips.cc/virtual/2025/oral/121634,,4:30 PM,"Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats. To study this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE). RISEBench focuses on four key reasoning categories: Temporal, Causal, Spatial, and Logical Reasoning. We curate high-quality test cases for each category and propose an robust evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and the LMM-as-a-judge approach. We conducted experiments evaluating nine prominent visual editing models, comprising both open-source and proprietary models. The evaluation results demonstrate that current models face significant challenges in reasoning-based editing tasks.  Even the most powerful model evaluated, GPT-image-1, achieves an accuracy of merely 28.8%. RISEBench effectively highlights the limitations of contemporary editing models, provides valuable insights,  and indicates potential future directions for the field of reasoning-aware visual editing. Our code and data have been released at https://github.com/PhoenixZ810/RISEBench.",,CBG; 海思; 诺亚,CBG: 3DAIGC; 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型后训练Reasoning，RL,"CBG: Session聚焦于视觉编辑中的推理能力（Temporal, Causal, Spatial, Logical Reasoning），而CBG团队关注视频中运动物体的快速准确分割和基于单目视频的3D/4D稀疏重建，这些都涉及视觉内容的理解和编辑，RISEBench提供的推理驱动视觉编辑评测框架和数据集可帮助CBG团队评估和提升其视觉生成与编辑模型在复杂推理任务中的表现。; 海思: Session涉及多模态模型在视觉编辑中的推理能力和复杂指令执行，海思团队关注多模态条件融合和长上下文推理的效率问题，RISEBench中对多模态视觉编辑模型的推理能力评估及挑战揭示，能够为海思团队优化多模态模型推理性能和提升推理质量提供具体的测试基准和技术方向。; 诺亚: Session强调视觉编辑中推理能力的评测和提升，诺亚团队关注大模型后训练中的推理能力和强化学习，RISEBench提出的推理驱动视觉编辑任务及评估框架为诺亚团队研究视觉领域的后训练推理能力和强化学习优化提供了具体应用场景和基准，有助于推动其推理能力的提升。"
WED 3 DEC,3:30-4:30,Oral Paper,  → CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding,https://neurips.cc/virtual/2025/oral/121509,,4:30 PM,"Coral reefs are vital yet vulnerable ecosystems that require continuous monitoring to support conservation. While coral reef images provide essential information in coral monitoring, interpreting such images remains challenging due to the need for domain expertise. Visual Question Answering (VQA), powered by Large Vision-Language Models (LVLMs), has great potential in user-friendly interaction with coral reef images. However, applying VQA to coral imagery demands a dedicated dataset that addresses two key challenges: domain-specific annotations and multidimensional questions. In this work, we introduce CoralVQA, the first large-scale VQA dataset for coral reef analysis. It contains 12,805 real-world coral images from 67 coral genera collected from 3 oceans, along with 277,653 question-answer pairs that comprehensively assess ecological and health-related conditions. To construct this dataset, we develop a semi-automatic data construction pipeline in collaboration with marine biologists to ensure both scalability and professional-grade data quality. CoralVQA presents novel challenges and provides a comprehensive benchmark for studying vision-language reasoning in the context of coral reef images. By evaluating several state-of-the-art LVLMs, we reveal key limitations and opportunities. These insights form a foundation for future LVLM development, with a particular emphasis on supporting coral conservation efforts.",,nan,nan,nan
WED 3 DEC,3:30-4:30,Oral Paper,  → OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model,https://neurips.cc/virtual/2025/oral/120304,,4:30 PM,"Understanding and synthesizing realistic 3D hand-object interactions (HOI) is critical for applications ranging from immersive AR/VR to dexterous robotics. Existing methods struggle with generalization, performing well on closed-set objects and predefined tasks but failing to handle unseen objects or open-vocabulary instructions. We introduce OpenHOI, the first framework for open-world HOI synthesis, capable of generating long-horizon manipulation sequences for novel objects guided by free-form language commands. Our approach integrates a 3D Multimodal Large Language Model (MLLM) fine-tuned for joint affordance grounding and semantic task decomposition, enabling precise localization of interaction regions (e.g., handles, buttons) and breakdown of complex instructions (e.g., “Find a water bottle and take a sip”) into executable sub-tasks. To synthesize physically plausible interactions, we propose an affordance-driven diffusion model paired with a training-free physics refinement stage that minimizes penetration and optimizes affordance alignment.Evaluations across diverse scenarios demonstrate OpenHOI’s superiority over state-of-the-art methods in generalizing to novel object categories, multi-stage tasks, and complex language instructions.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session聚焦于3D手-物体交互的开放世界合成，涉及物理可行的交互动作生成和多模态语言指令解析，直接对应Embodied AI领域中物理交互和多模态理解的核心难题，能够为团队在物理智能体交互和多模态任务分解方面提供先进的技术思路和方法。
THU 4 DEC,8:30 a.m.,Invited Talk,The Art of (Artificial) Reasoning,https://neurips.cc/virtual/2025/invited-talk/109603,Yejin Choi,9:30 AM,"Scaling laws suggest that “more is more” — brute-force scaling of data and compute leads to stronger AI capabilities. However, despite rapid progress on benchmarks, state-of-the-art models still exhibit ""jagged intelligence,"" indicating that current scaling approaches may have limitations in terms of sustainability and robustness. Additionally, while the volume of papers on arXiv continues to grow rapidly, our scientific understanding of artificial intelligence hasn't kept pace with engineering advances, and the current literature presents seemingly contradictory findings that can be difficult to reconcile. In this talk, I will discuss key insights into the strengths and limitations of LLMs, examine when reinforcement learning succeeds or struggles in reasoning tasks, and explore methods for enhancing reasoning capabilities in smaller language models to help them close the gap against their larger counterparts in specific domains.",,温哥华云; 多伦多云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session中讨论了reinforcement learning在推理任务中的成功与挑战，直接对应该团队关注的Reinforcement learning在LLMs/VLMs中的实际应用问题，能为解决其理论到生产的落地难题、提升样本效率和性能提供思路。; 多伦多云: Session涉及Agentic AI系统中推理能力的提升及强化学习的应用，特别是探讨如何增强小型语言模型的推理能力，与该团队关注的AI Agent行为可靠性、评估准确性及持续优化机制高度相关。; 诺亚: Session重点讨论了LLMs的推理能力限制及强化学习在推理任务中的应用，直接对应该团队关注的后训练阶段的Reasoning和强化学习技术，能为其自博弈和latent reasoning等难题提供理论和方法支持。
THU 4 DEC,2:30 p.m.,Invited Talk,"On the Science of “Alien Intelligences”: Evaluating Cognitive Capabilities in Babies, Animals, and AI",https://neurips.cc/virtual/2025/invited-talk/109607,Melanie Mitchell,3:30 PM,"Today’s generative AI systems—termed by some researchers as “alien intelligences”—have exceeded human performance on many benchmarks meant to test humanlike cognitive capabilities.  However, these systems still struggle in unhumanlike ways on real-world tasks requiring these capabilities.  This disconnect may be due in part to neglect in the AI community of well-founded experimental protocols for evaluating cognition.  In this talk I will summarize several recommendations on experimental methods from developmental and comparative psychology—fields that study the “alien intelligences” of babies and non-human animals—and demonstrate the application of such methods in two case studies of cognitive abilities in LLMs: analogical reasoning and visual abstraction.",,多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: Session聚焦于评估认知能力的方法，尤其是借鉴发展心理学和比较心理学的实验协议，直接关联多伦多云团队在AI Agent评估准确性与覆盖范围的难题，提供了科学的评估方法和实验设计思路，有助于提升Agent行为的可靠性和评估体系。; 诺亚: Session中提到对LLM认知能力的案例研究（类比推理和视觉抽象）与诺亚团队关注的大模型后训练推理和强化学习密切相关，尤其是session强调的实验方法和认知评估可为其自博弈与learning from experience训练框架提供科学的评估和验证手段。
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3A,https://neurips.cc/virtual/2025/session/122556,,11:00 AM,,,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → Identifiability of Deep Polynomial Neural Networks,https://neurips.cc/virtual/2025/oral/118427,,11:00 AM,"Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability-a key property for ensuring interpretability-remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly compared to the activation degrees. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. We also settle an open conjecture on the dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach the expected dimension.",,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → Depth-Bounds for Neural Networks via the Braid Arrangement,https://neurips.cc/virtual/2025/oral/117519,,11:00 AM,"We contribute towards resolving the open question of how many hidden layers are required in ReLU networks for exactly representing all continuous and piecewise linear functions on $\mathbb{R}^d$. While the question has been resolved in special cases, the best known lower bound in general is still 2. We focus on neural networks that are compatible with certain polyhedral complexes, more precisely with the braid fan.  For such neural networks, we prove a non-constant lower bound of $\Omega(\log\log d)$ hidden layers required to exactly represent the maximum of $d$ numbers. Additionally, we provide a combinatorial proof that neural networks satisfying this assumption require three hidden layers to compute the maximum of 5 numbers; this had only been verified with an excessive computation so far.Finally, we show that a natural generalization of the best known upper bound to maxout networks is not tight, by demonstrating that a rank-3 maxout layer followed by a rank-2 maxout layer is sufficient to represent the maximum of 7 numbers.",,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → Learning Linear Attention in Polynomial Time,https://neurips.cc/virtual/2025/oral/118143,,11:00 AM,"Previous research has explored the expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the efficient learnability of Transformers from data has remained an open question.  Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention.  We show that learning the optimal multi head linear attention can be recast as finding the optimal kernel predictor in a suitably defined RKHS.  Moving to generalization, we construct an algorithm that, given a dataset, checks in polynomial time whether the set of best fit multi head linear attention networks on this data all perform an identical computation--a powerful notion for out of distribution generalization.  We empirically validate our theoretical findings on several canonical tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformer models.",,海思,海思: 大语言模型和扩散模型的加速,海思: Session研究了单层Transformer中线性注意力的多头学习及其多项式时间可学习性，特别关注线性注意力的高效学习与泛化。海思团队关注长上下文推理中注意力复杂度过高的问题，如何利用稀疏注意力与分块缓存实现线性或次线性复杂度。该session的理论与算法成果直接对应海思团队关于线性注意力学习和推理复杂度优化的难题，能为其提供理论基础和算法设计思路。
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3B,https://neurips.cc/virtual/2025/session/122557,,11:00 AM,,,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts,https://neurips.cc/virtual/2025/oral/117276,,11:00 AM,"Current image fusion methods struggle with real-world composite degradations and lack the flexibility to accommodate user-specific needs. To address this, we propose ControlFusion, a controllable fusion network guided by language-vision prompts that adaptively mitigates composite degradations. On the one hand, we construct a degraded imaging model based on physical mechanisms, such as the Retinex theory and atmospheric scattering principle, to simulate composite degradations and provide a data foundation for addressing realistic degradations. On the other hand, we devise a prompt-modulated restoration and fusion network that dynamically enhances features according to degradation prompts, enabling adaptability to varying degradation levels. To support user-specific preferences in visual quality, a text encoder is incorporated to embed user-defined degradation types and levels as degradation prompts. Moreover, a spatial-frequency collaborative visual adapter is designed to autonomously perceive degradations from source images, thereby reducing complete reliance on user instructions. Extensive experiments demonstrate that ControlFusion outperforms SOTA fusion methods in fusion quality and degradation handling, particularly under real-world and compound degradations.",,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables,https://neurips.cc/virtual/2025/oral/118251,,11:00 AM,"Recently, deep learning-based pan-sharpening algorithms have achieved notable advancements over traditional methods. However, deep learning-based methods incur substantial computational overhead during inference, especially with large images. This excessive computational demand limits the applicability of these methods in real-world scenarios, particularly in the absence of dedicated computing devices such as GPUs and TPUs. To address these challenges, we propose Pan-LUT, a novel learnable look-up table (LUT) framework for pan-sharpening that strikes a balance between performance and computational efficiency for large remote sensing images. Our method makes it possible to process 15K$\times$15K remote sensing images on a 24GB GPU. To finely control the spectral transformation, we devise the PAN-guided look-up table (PGLUT) for channel-wise spectral mapping. To effectively capture fine-grained spatial details, we introduce the spatial details look-up table (SDLUT). Furthermore, to adaptively aggregate channel information for generating high-resolution multispectral images, we design an adaptive output look-up table (AOLUT). Our model contains fewer than 700K parameters and processes a 9K$\times$9K image in under 1 ms using one RTX 2080 Ti GPU, demonstrating significantly faster performance compared to other methods. Experiments reveal that Pan-LUT efficiently processes large remote sensing images in a lightweight manner, bridging the gap to real-world applications. Furthermore, our model surpasses SOTA methods in full-resolution scenes under real-world conditions, highlighting its effectiveness and efficiency.",,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution,https://neurips.cc/virtual/2025/oral/117604,,11:00 AM,"Accurate, high-resolution ocean forecasting is crucial for maritime operations and environmental monitoring. While traditional numerical models are capable of producing sub-daily, eddy-resolving forecasts, they are computationally intensive and face challenges in maintaining accuracy at fine spatial and temporal scales. In contrast, recent data-driven approaches offer improved computational efficiency and emerging potential, yet typically operate at daily resolution and struggle with sub-daily predictions due to error accumulation over time.We introduce FuXi-Ocean, the first data-driven global ocean forecasting model achieving six-hourly predictions at eddy-resolving 1/12° spatial resolution, reaching depths of up to 1500 meters. The model architecture integrates a context-aware feature extraction module with a predictive network employing stacked attention blocks. The core innovation is the Mixture-of-Time (MoT) module, which adaptively integrates predictions from multiple temporal contexts by learning variable-specific reliability, mitigating cumulative errors in sequential forecasting. Through comprehensive experimental evaluation, FuXi-Ocean demonstrates superior skill in predicting key variables, including temperature, salinity, and currents, across multiple depths.",,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3C,https://neurips.cc/virtual/2025/session/122558,,11:00 AM,,,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → Auto-Compressing Networks,https://neurips.cc/virtual/2025/oral/116934,,11:00 AM,"Deep neural networks with short residual connections have demonstrated remarkable success across domains, but increasing depth often introduces computational redundancy without corresponding improvements in representation quality. We introduce Auto-Compressing Networks (ACNs), an architectural variant where additive long feedforward connections from each layer to the output replace traditional short residual connections. By analyzing the distinct dynamics induced by this modification, we reveal a unique property we coin asauto-compression—the ability of a network to organically compress information during training with gradient descent, through architectural design alone. Through auto-compression, information is dynamically ""pushed"" into early layers during training, enhancing their representational quality and revealing potential redundancy in deeper ones. We theoretically show that this property emerges from layer-wise training patterns found only in ACNs, where layers are dynamically utilized during training based on task requirements. We also find that ACNs exhibit enhanced noise robustness compared to residual networks, superior performance in low-data settings, improved transfer learning capabilities, and  mitigate catastrophic forgetting suggesting that they learn representations that generalize better despite using fewer parameters. Our results demonstrate up to 18\% reduction in catastrophic forgetting and 30-80\% architectural compression while maintaining accuracy across vision transformers, MLP-mixers, and BERT architectures. These findings establish ACNs as a practical approach to developing efficient neural architectures that automatically adapt their computational footprint to task complexity, while learning robust representations suitable for noisy real-world tasks and continual learning scenarios.",,计算; 计算,计算: 高效模型架构; 计算: 训推新范式,计算: Session介绍了Auto-Compressing Networks (ACNs)，一种通过架构设计实现模型自动压缩和提升表示质量的方法，直接关联高效模型架构的研究。该方法通过减少计算冗余和参数数量，同时保持准确率，契合团队关注的模型架构对计算架构的影响及降低未来模型结构对计算系统冲击的需求。; 计算: ACNs通过层级动态利用和训练模式的改变，展现了新型的训练范式特征，能够提升模型的泛化能力和抗灾难遗忘性能。此创新训练范式与团队关注的训练推理新范式演进机理高度相关，有助于理解和预测未来训推负载特征。
THU 4 DEC,10:00-11:00,Oral Paper,  → Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks,https://neurips.cc/virtual/2025/oral/119732,,11:00 AM,"Deployment of neural networks on resource-constrained devices demands models that are both compact and robust to adversarial inputs. However, compression and adversarial robustness often conflict. In this work, we introduce a dynamical low-rank training scheme enhanced with a novel spectral regularizer that controls the condition number of the low-rank core in each layer. This approach mitigates the sensitivity of compressed models to adversarial perturbations without sacrificing clean accuracy. The method is model- and data-agnostic, computationally efficient, and supports rank adaptivity to automatically compress the network at hand. Extensive experiments across standard architectures, datasets, and adversarial attacks show the regularized networks can achieve over 94 compression while recovering or improving adversarial accuracy relative to uncompressed baselines.",,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression,https://neurips.cc/virtual/2025/oral/116595,,11:00 AM,"The hypothesis that Convolutional Neural Networks (CNNs) are inherently texture-biased has shaped much of the discourse on feature use in deep learning. We revisit this hypothesis by examining limitations in the cue-conflict experiment by Geirhos et al. To address these limitations, we propose a domain-agnostic framework that quantifies feature reliance through systematic suppression of shape, texture, and color cues, avoiding the confounds of forced-choice conflicts. By evaluating humans and neural networks under controlled suppression conditions, we find that CNNs are not inherently texture-biased but predominantly rely on local shape features. Nonetheless, this reliance can be substantially mitigated through modern training strategies or architectures (ConvNeXt, ViTs). We further extend the analysis across computer vision, medical imaging, and remote sensing, revealing that reliance patterns differ systematically: computer vision models prioritize shape, medical imaging models emphasize color, and remote sensing models exhibit a stronger reliance on texture. Code is available at https://github.com/tomburgert/feature-reliance.",,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3D,https://neurips.cc/virtual/2025/session/122559,,11:00 AM,,,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,  → State Entropy Regularization for Robust Reinforcement Learning,https://neurips.cc/virtual/2025/oral/115740,,11:00 AM,"State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session聚焦于state entropy regularization在强化学习中的鲁棒性及理论保证，直接对应团队关注的强化学习在实际应用中样本效率和性能提升的难题，能为解决理论与实际应用间的差距提供方法支持。; 诺亚: session中关于state entropy regularization提升强化学习鲁棒性的理论分析，与团队关注的自博弈与learning from experience训练框架及强化学习相关，能为团队在RL训练框架的鲁棒性和理论保障提供有价值的参考和技术支持。
THU 4 DEC,10:00-11:00,Oral Paper,  → A Clean Slate for Offline Reinforcement Learning,https://neurips.cc/virtual/2025/oral/119623,,11:00 AM,"Progress in offline reinforcement learning (RL) has been impeded by ambiguous problem definitions and entangled algorithmic designs, resulting in inconsistent implementations, insufficient ablations, and unfair evaluations. Although offline RL explicitly avoids environment interaction, prior methods frequently employ extensive, undocumented online evaluation for hyperparameter tuning, complicating method comparisons. Moreover, existing reference implementations differ significantly in boilerplate code, obscuring their core algorithmic contributions. We address these challenges by first introducing a rigorous taxonomy and a transparent evaluation protocol that explicitly quantifies online tuning budgets. To resolve opaque algorithmic design, we provide clean, minimalistic, single-file implementations of various model-free and model-based offline RL methods, significantly enhancing clarity and achieving substantial speed-ups. Leveraging these streamlined implementations, we propose Unifloral, a unified algorithm that encapsulates diverse prior approaches and enables development within a single, comprehensive hyperparameter space. Using Unifloral with our rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR (model-free) and MoBRAC (model-based) - which substantially outperform established baselines. Our implementation is publicly available at https://github.com/EmptyJackson/unifloral.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该Session聚焦于离线强化学习的严谨定义、评估协议和统一算法实现，直接对应温哥华云团队关注的强化学习在大模型微调中的实际应用问题，尤其是提升样本效率和性能的需求，提供了统一算法Unifloral及新算法TD3-AWR和MoBRAC，能为团队解决理论到生产的落地难题提供技术支持。; 诺亚: Session中提出的离线强化学习统一算法和严格评估框架，与诺亚团队关注的后训练强化学习及自博弈学习框架高度契合，有助于团队在latent reasoning和learning from experience训练框架中采用更规范和高效的离线RL方法，推动其研究进展。
THU 4 DEC,10:00-11:00,Oral Paper,  → Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies,https://neurips.cc/virtual/2025/oral/117976,,11:00 AM,"Reinforcement learning (RL) systems have countless applications, from energy-grid management to protein design. However, such real-world scenarios are often extremely difficult, combinatorial in nature, and require complex coordination between multiple agents. This level of complexity can cause even state-of-the-art RL systems, trained until convergence, to hit a performance ceiling which they are unable to break out of with zero-shot inference. Meanwhile, many digital or simulation-based applications allow for an inference phase that utilises a specific time and compute budget to explore multiple attempts before outputting a final solution. In this work, we show that such an inference phase employed at execution time, and the choice of a corresponding inference strategy, are key to breaking the performance ceiling observed in complex multi-agent RL problems. Our main result is striking: we can obtain up to a 126% and, on average, a 45% improvement over the previous state-of-the-art across 17 tasks, using only a couple seconds of extra wall-clock time during execution. We also demonstrate promising compute scaling properties, supported by over 60k experiments, making it the largest study on inference strategies for complex RL to date. We make all of our experimental data and code available.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session聚焦于强化学习中突破性能瓶颈的推理策略，直接涉及强化学习的推理阶段优化，与温哥华云团队关注的强化学习在实际应用中的性能提升、样本效率和可扩展性问题高度相关，能为其解决强化学习实际部署中的性能瓶颈提供具体的推理策略和实验数据支持。; 诺亚: session强调通过推理策略突破复杂多智能体强化学习的性能上限，涉及自博弈与经验学习等训练框架，与诺亚团队关注的大模型后训练中的推理和强化学习方法直接相关，能够为其在强化学习推理策略和性能提升方面提供技术思路和实验验证。
THU 4 DEC,10:00-11:00,Oral Session,Oral Session 3E,https://neurips.cc/virtual/2025/session/122560,,11:00 AM,,,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,"  → Position: If Innovation in AI systematically Violates Fundamental Rights, Is It Innovation at All?",https://neurips.cc/virtual/2025/oral/126305,,11:00 AM,"Artificial intelligence (AI) now permeates critical infrastructures and decisionmaking systems where failures produce social, economic, and democratic harm. This position paper challenges the entrenched belief that regulation and innovation are opposites. As evidenced by analogies from aviation, pharmaceuticals, and welfare systems and recent cases of synthetic misinformation, bias and unaccountable decision-making, the absence of well-designed regulation has already created immeasurable damage. Regulation, when thoughtful and adaptive, is not a brake on innovation—it is its foundation. The present position paper examines the EU AI Act as a model of risk-based, responsibility-driven regulation that addresses the Collingridge Dilemma: acting early enough to prevent harm, yet flexibly enough to sustain innovation. Its adaptive mechanisms—regulatory sandboxes, small and medium enterprises (SMEs) support, real-world testing, fundamental rights impact assessment (FRIA)—demonstrate how regulation can accelerate responsibly, rather than delay, technological progress. The position paper summarises how governance tools transform perceived burdens into tangible advantages: legal certainty, consumer trust, and ethical competitiveness. Ultimately, the paper reframes progress: innovation and regulation advance together. By embedding transparency, impact assessments, accountability, and AI literacy into design and deployment, the EU framework defines what responsible innovation truly means—technological ambition disciplined by democratic values and fundamental rights.",,多伦多云,多伦多云: AI Agent,多伦多云: Session聚焦AI创新与基本权利保护的监管框架，强调责任驱动和问责机制，与多伦多云团队关注的AI Agent行为可靠性、管控与校验，以及自主学习与持续优化机制紧密相关。该session中关于透明度、影响评估和责任机制的讨论可为提升Agent行为的可靠性和管控提供理论支持和实践指导。
THU 4 DEC,10:00-11:00,Oral Paper,  → More effort is needed to protect pedestrian privacy in the era of AI,https://neurips.cc/virtual/2025/oral/126301,,11:00 AM,"In the era of artificial intelligence (AI), pedestrian privacy is increasingly at risk. In research areas such as autonomous driving, computer vision, and surveillance, large datasets are often collected in public spaces, capturing pedestrians without consent or anonymization. These datasets are used to train systems that can identify, track, and analyze individuals, often without their knowledge. Although various technical methods and regional regulations have been proposed to address this issue, existing solutions are either insufficient to protect privacy or compromise data utility, thereby limiting their effectiveness for research. In this paper, we argue that more effort is needed to protect pedestrian privacy in the era of AI while maintaining data utility. We call on the AI and computer vision communities to take pedestrian privacy seriously and to rethink how pedestrian data are collected and anonymized. Collaboration with experts in law and ethics will also be essential for the responsible development of AI. Without stronger action, it will become increasingly difficult for individuals to protect their privacy, and public trust in AI may decline.",,nan,nan,nan
THU 4 DEC,10:00-11:00,Oral Paper,"  → Real-Time Hyper-Personalized Generative AI Should Be Regulated to Prevent the Rise of ""Digital Heroin""",https://neurips.cc/virtual/2025/oral/126308,,11:00 AM,"This position paper argues that real-time generative AI has the potential to become the next wave of addictive digital media, creating a new class of digital content akin to ``digital heroin'' with severe implications for mental health and youth development. By shortening the content-generation feedback loop to mere seconds, these advanced models will soon be able to hyper-personalize outputs on the fly. When paired with misaligned incentives (e.g., maximizing user engagement), this will fuel unprecedented compulsive consumption patterns with far-reaching consequences for mental health, cognitive development, and social stability. Drawing on interdisciplinary research, from clinical observations of social media addiction to neuroscientific studies of dopamine-driven feedback, we illustrate how real-time tailored content generation may erode user autonomy, foment emotional distress, and disproportionately endanger vulnerable groups, such as adolescents. Due to the rapid advancement of generative AI and its potential to induce severe addiction-like effects, we call for strong government oversight akin to existing controls on addictive substances, particularly for minors. We further urge the machine learning community to act proactively by establishing robust design guidelines, collaborating with public health experts, and supporting targeted policy measures to ensure responsible and ethical deployment, rather than paving the way for another wave of unregulated digital dependence.",,nan,nan,nan
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4A,https://neurips.cc/virtual/2025/session/122561,,4:30 PM,,,nan,nan,nan
THU 4 DEC,3:30-4:30,Oral Paper,  → A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders,https://neurips.cc/virtual/2025/oral/118059,,4:30 PM,"Sparse Autoencoders (SAEs) aim to decompose the activation space of large language models (LLMs) into human-interpretable latent directions or features. As we increase the number of features in the SAE, hierarchical features tend to split into finer features (“math” may split into “algebra”, “geometry”, etc.), a phenomenon referred to as feature splitting. However, we show that sparse decomposition and splitting of hierarchical features is not robust. Specifically, we show that seemingly monosemantic features fail to fire where they should, and instead get “absorbed” into their children features. We coin this phenomenon feature absorption, and show that it is caused by optimizing for sparsity in SAEs whenever the underlying features form a hierarchy. We introduce a metric to detect absorption in SAEs, and validate our findings empirically on hundreds of LLM SAEs. Our investigation suggests that varying SAE sizes or sparsity is insufficient to solve this issue. We discuss the implications of feature absorption in SAEs and some potential approaches to solve the fundamental theoretical issues before SAEs can be used for interpreting LLMs robustly and at scale.",,nan,nan,nan
THU 4 DEC,3:30-4:30,Oral Paper,"  → Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free",https://neurips.cc/virtual/2025/oral/120217,,4:30 PM,"Gating mechanisms have been widely utilized, from early models like LSTMs and Highway Networks to recent state space models, linear attention, and also softmax attention.Yet, existing literature rarely examines the specific effects of gating.In this work, we conduct comprehensive experiments to systematically investigate gating-augmented softmax attention variants.Specifically, we perform a comprehensive comparison over 30 variants of 15B Mixture-of-Experts (MoE) models and 1.7B dense models trained on a 3.5 trillion token dataset.Our central finding is that a simple modification—applying a head-specific sigmoid gate after the Scaled Dot-Product Attention (SDPA)—consistently improves performance.This modification also enhances training stability, tolerates larger learning rates, and improves scaling properties.By comparing various gating positions and computational variants, we attribute this effectiveness to two key factors: (1) introducing non-linearity upon the low-rank mapping in the softmax attention, and (2) applying query-dependent sparse gating scores to modulate the SDPA output.Notably, we find this sparse gating mechanism mitigatesmassive activation,attention sinkand enhances long-context extrapolation performance. We also release related codes (https://github.com/qiuzh20/gatedattention}) and models (https://huggingface.co/QwQZh/gatedattention) to facilitate future research.Furthermore, the most effective SDPA output gating is used in the Qwen3-Next models (https://huggingface.co/collections/Qwen/qwen3-next).",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构,海思: Session聚焦于大语言模型中基于门控机制的注意力改进，特别是通过引入非线性和稀疏门控机制提升长上下文推理性能和训练稳定性，直接对应海思关注的长上下文推理中注意力复杂度过高问题，提供了利用稀疏注意力与门控机制实现高效推理的技术思路。; 计算: Session提出的头特异性sigmoid门控机制对Scaled Dot-Product Attention的改进，体现了模型架构中非线性和稀疏性的创新，帮助理解和预判大模型结构演进趋势，符合计算BU对模型架构演进及其对计算系统影响的关注，有助于降低未来模型结构对计算系统的冲击。
THU 4 DEC,3:30-4:30,Oral Paper,  → Superposition Yields Robust Neural Scaling,https://neurips.cc/virtual/2025/oral/116347,,4:30 PM,"The success of today's large language models (LLMs) depends on the observation that larger models perform better. However, the origin of this neural scaling law, that loss decreases as a power law with model size, remains unclear. We propose that representation superposition, meaning that LLMs represent more features than they have dimensions, can be a key contributor to loss and cause neural scaling. Based on Anthropic's toy model, we use weight decay to control the degree of superposition, allowing us to systematically study how loss scales with model size. When superposition is weak, the loss follows a power law only if data feature frequencies are power-law distributed. In contrast, under strong superposition, the loss generically scales inversely with model dimension across a broad class of frequency distributions, due to geometric overlaps between representation vectors. We confirmed that open-sourced LLMs operate in the strong superposition regime and have loss scaling inversely with model dimension, and that the Chinchilla scaling laws are also consistent with this behavior. Our results identify representation superposition as a central driver of neural scaling laws, providing insights into questions like when neural scaling laws can be improved and when they will break down.",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构,海思: Session探讨了大语言模型中表示的叠加(superposition)现象及其对神经网络规模定律的影响，揭示了模型维度与loss的关系，这对于优化长上下文推理中注意力复杂度过高的问题，以及实现低延迟实时推理响应提供了理论基础和技术启示。; 计算: Session深入分析了神经规模定律的根本驱动力——表示叠加，揭示了模型结构与性能的内在关系，有助于理解和预测大模型结构演进趋势，从而指导计算架构设计，降低未来模型结构对计算系统的冲击，解决团队关注的模型架构对计算架构影响的难题。
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4B,https://neurips.cc/virtual/2025/session/122562,,4:30 PM,,,nan,nan,nan
THU 4 DEC,3:30-4:30,Oral Paper,  → In Search of Adam’s Secret Sauce,https://neurips.cc/virtual/2025/oral/119298,,4:30 PM,"Understanding the remarkable efficacy of Adam when training transformer-based language models has become a central research topic within the optimization community. To gain deeper insights, several simplifications of Adam have been proposed, such as the signed gradient and signed momentum methods. In this work, we conduct an extensive empirical study — training over 1,500 language models across different data configurations and scales — comparing Adam to several known simplified variants. We find that signed momentum methods are faster than SGD, but consistently underperform relative to Adam, even after careful tuning of momentum, clipping setting and learning rates. However, our analysis reveals a compelling option that preserves near-optimal performance while allowing for new insightful reformulations: constraining the Adam momentum parameters to be equal, β 1 = β 2 . Beyond robust performance, this choice affords new theoretical insights, highlights the ""secret sauce"" on top of signed momentum, and grants a precise statistical interpretation: we show that Adam in this setting implements a natural online algorithm for estimating the mean and variance of gradients—one that arises from a mean-field Gaussian variational inference perspective.",,计算,计算: 训推新范式,计算: 该Session深入探讨Adam优化器及其简化变体在训练Transformer语言模型中的表现和理论基础，直接涉及训练新范式的优化方法。团队关注训推新范式的演进机理，Session中关于Adam动量参数约束及其统计解释提供了新的训练优化视角，有助于理解和预测训练范式的演进，解决团队关注的训推负载差异问题。
THU 4 DEC,3:30-4:30,Oral Paper,  → Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions,https://neurips.cc/virtual/2025/oral/117576,,4:30 PM,"As the economic and environmental costs of training and deploying large vision or language models increase dramatically, analog in-memory computing (AIMC) emerges as a promising energy-efficient solution. However, the training perspective, especially its training dynamic, is underexplored. In AIMC hardware, the trainable weights are represented by the conductance of resistive elements and updated using consecutive electrical pulses.  While the conductance changes by a constant in response to each pulse, in reality, the change is scaled by asymmetric and non-linear response functions, leading to a non-ideal training dynamic. This paper provides a theoretical foundation for gradient-based training on AIMC hardware with non-ideal response functions.  We demonstrate that asymmetric response functions negatively impact Analog SGD by imposing an implicit penalty on the objective. To overcome the issue, we propose residual learning algorithm, which provably converges exactly to a critical point by solving a bilevel optimization problem. We show that the proposed method can be extended to deal with other hardware imperfections like limited response granularity. As far as we know, it is the first paper to investigate the impact of a class of generic non-ideal response functions. The conclusion is supported by simulations validating our theoretical insights.",,nan,nan,nan
THU 4 DEC,3:30-4:30,Oral Paper,"  → Generalized Gradient Norm Clipping & Non-Euclidean(L0,L1)-Smoothness",https://neurips.cc/virtual/2025/oral/115789,,4:30 PM,"This work introduces a hybrid non-Euclidean optimization method which generalizes gradient norm clipping by combining steepest descent and conditional gradient approaches. The method achieves the best of both worlds by establishing a descent property under a generalized notion of ($L_0$,$L_1$)-smoothness. Weight decay is incorporated in a principled manner by identifying a connection to the Frank-Wolfe short step. In the stochastic case, we show an order optimal $O(n^{-1/4})$ convergence rate by leveraging a momentum based gradient estimator. We discuss how to instantiate the algorithms for deep learning, which we dub Clipped Scion, and demonstrate their properties on image classification and language modeling. The code is available at https://github.com/LIONS-EPFL/ClippedScion.",,计算; 计算,计算: 高效模型架构; 计算: 训推新范式,"计算: 该session提出了基于非欧几里得(L0,L1)-光滑性的混合优化方法，结合了梯度范数裁剪和条件梯度方法，能够提升模型训练中的优化效率和收敛性，直接对应该团队关注的模型架构对计算架构的影响及低精度训练推理的需求。; 计算: session中介绍的Clipped Scion算法及其在深度学习中的应用，为训练和推理新范式提供了新的优化思路，特别是利用动量梯度估计器实现的最优收敛率，有助于该团队理解和预测训推范式的演进机理。"
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4C,https://neurips.cc/virtual/2025/session/122563,,4:30 PM,,,nan,nan,nan
THU 4 DEC,3:30-4:30,Oral Paper,  → MaxSup: Overcoming Representation Collapse in Label Smoothing,https://neurips.cc/virtual/2025/oral/116897,,4:30 PM,"Label Smoothing (LS) is widely adopted to reduce overconfidence in neural network predictions and improve generalization. Despite these benefits, recent studies reveal two critical issues with LS. First, LS induces overconfidence in misclassified samples. Second, it compacts feature representations into overly tight clusters, diluting intra-class diversity, although the precise cause of this phenomenon remained elusive. In this paper, we analytically decompose the LS-induced loss, exposing two key terms: (i) a regularization term that dampens overconfidence only when the prediction is correct, and (ii) an error-amplification term that arises under misclassifications. This latter term compels the network to reinforce incorrect predictions with undue certainty, exacerbating representation collapse. To address these shortcomings, we propose Max Suppression (MaxSup), which applies uniform regularization to both correct and incorrect predictions by penalizing the top-1 logit rather than the ground-truth logit. Through extensive feature-space analyses, we show that MaxSup restores intra-class variation and sharpens inter-class boundaries. Experiments on large-scale image classification and multiple downstream tasks confirm that MaxSup is a more robust alternative to LS.Code and reproducibility scripts are available at https://github.com/ZhouYuxuanYX/Maximum-Suppression-Regularization.",,nan,nan,nan
THU 4 DEC,3:30-4:30,Oral Paper,  → Advancing Expert Specialization for Better MoE,https://neurips.cc/virtual/2025/oral/116507,,4:30 PM,"Mixture-of-Experts (MoE) models enable efficient scaling of large language models (LLMs) by activating only a subset of experts per input. However, we observe that the commonly used auxiliary load balancing loss often leads to expert overlap and overly uniform routing, which hinders expert specialization and degrades overall performance during post-training.To address this, we propose a simple yet effective solution that introduces two complementary objectives: (1) an orthogonality loss to encourage experts to process distinct types of tokens, and (2) a variance loss to encourage more discriminative routing decisions.Gradient-level analysis demonstrates that these objectives are compatible with the existing auxiliary loss and contribute to optimizing the training process.Experimental results over various model architectures and across multiple benchmarks show that our method significantly enhances expert specialization. Notably, our method improves classic MoE baselines with auxiliary loss by up to 23.79\%, while also maintaining load balancing in downstream tasks, without any architectural modifications or additional components. We will release our code to contribute to the community.",,计算; 计算,计算: 高效模型架构; 计算: 训推新范式,计算: Session提出的通过正交性损失和方差损失提升MoE模型专家专门化的方法，直接涉及模型架构优化，能够为团队关注的模型架构演进趋势及其对计算系统影响提供具体的训练优化技术和思路。; 计算: Session中针对MoE模型训练中路由和专家负载均衡的优化方法，能够为团队关注的训练推理新范式负载特征演进提供具体的训练目标设计和优化策略，有助于理解和预测未来训推范式的演进机理。
THU 4 DEC,3:30-4:30,Oral Paper,  → Learning to Learn with Contrastive Meta-Objective,https://neurips.cc/virtual/2025/oral/115718,,4:30 PM,"Meta-learning enables learning systems to adapt quickly to new tasks, similar to humans.Different meta-learning approaches all work under/with the mini-batch episodic training framework. Such framework naturally gives the information about task identity, which can serve as additional supervision for meta-training to improve generalizability. We propose to exploit task identity as additional supervision in meta-training, inspired by the alignment and discrimination ability which is is intrinsic in human's fast learning.This is achieved by contrasting what meta-learners learn, i.e., model representations.The proposed ConML is evaluating and optimizing the contrastive meta-objective under a problem- and learner-agnostic meta-training framework.We demonstrate that ConML integrates seamlessly with existing meta-learners, as well as in-context learning models, and brings significant boost in performance with small implementation cost.",,温哥华云; 多伦多云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session提出的Contrastive Meta-Objective在meta-learning框架下优化模型的泛化能力，与温哥华云团队关注的Reinforcement fine tuning (RFT)中提升样本效率和性能的目标高度契合，能够为解决实际强化学习中样本效率和训练稳定性问题提供新的对比学习思路。; 多伦多云: 该session强调利用任务身份作为额外监督信号，通过对比学习提升meta-learner的表示能力，这与多伦多云团队关注的AI Agent持续优化机制和多步执行能力的训练优化需求直接相关，能够为Agent的自主学习和行为优化提供新的训练范式和技术支持。; 诺亚: session中提出的Contrastive Meta-Objective及其在问题和学习者无关的meta-training框架中应用，能够为诺亚团队关注的自博弈与learning from experience训练框架提供新的对比学习方法，提升后训练阶段的推理和强化学习效果。
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4D,https://neurips.cc/virtual/2025/session/122564,,4:30 PM,,,nan,nan,nan
THU 4 DEC,3:30-4:30,Oral Paper,  → Exploring Diffusion Transformer Designs via Grafting,https://neurips.cc/virtual/2025/oral/119280,,4:30 PM,"Designing model architectures requires decisions such as selecting operators (e.g., attention, convolution) and configurations (e.g., depth, width). However, evaluating the impact of these decisions on model quality requires costly pretraining, limiting architectural investigation.Inspired by how new software is built on existing code, we ask: can new architecture designs be studied using pretrained models? To this end, we present *grafting*, a simple approach for editing pretrained diffusion transformers (DiTs) to materialize new architectures under small compute budgets. Informed by our analysis of activation behavior and attention locality, we construct a testbed based on the DiT-XL/2 design to study the impact of grafting on model quality. Using this testbed, we develop a family of hybrid designs via grafting: replacing softmax attention with gated convolution, local attention, and linear attention, and replacing MLPs with variable expansion ratio and convolutional variants. Notably, many hybrid designs achieve good quality (FID: 2.38–2.64 vs. 2.27 for DiT-XL/2)using < 2 % pretraining compute. We then graft a text-to-image model (PixArt- Σ ), achieving a 1.43 × speedup with less than a 2% drop in GenEval score. Finally, we present a case study that restructures DiT-XL/2 by converting every pair of sequential transformer blocks into parallel blocks via grafting. This reduces model depth by 2 × and yields better quality (FID: 2.77) than other models of comparable depth. Together, we show that new diffusion model designs can be explored by grafting pretrained DiTs, with edits ranging from operator replacement to architecture restructuring. Code and grafted models: https://grafting.stanford.edu.",,海思; 计算,海思: 大语言模型和扩散模型的加速; 计算: 高效模型架构,海思: Session聚焦于扩散Transformer模型架构设计与优化，通过grafting技术实现预训练模型架构的高效编辑和加速，直接对应海思团队在扩散模型加速、注意力机制复杂度优化及多模态条件融合延迟降低的难题。; 计算: Session提出通过grafting方法探索和重构扩散Transformer架构，研究不同算子替换对模型质量和计算成本的影响，契合计算BU对模型架构演进趋势的洞察需求及对计算系统冲击的预判。
THU 4 DEC,3:30-4:30,Oral Paper,  → Deep Compositional Phase Diffusion for Long Motion Sequence Generation,https://neurips.cc/virtual/2025/oral/116419,,4:30 PM,"Recent research on motion generation has shown significant progress in generating semantically aligned motion with singular semantics. However, when employing these models to create composite sequences containing multiple semantically generated motion clips, they often struggle to preserve the continuity of motion dynamics at the transition boundaries between clips, resulting in awkward transitions and abrupt artifacts. To address these challenges, we present Compositional Phase Diffusion, which leverages the Semantic Phase Diffusion Module (SPDM) and Transitional Phase Diffusion Module (TPDM) to progressively incorporate semantic guidance and phase details from adjacent motion clips into the diffusion process. Specifically, SPDM and TPDM operate within the latent motion frequency domain established by the pre-trained Action-Centric Motion Phase Autoencoder (ACT-PAE). This allows them to learn semantically important and transition-aware phase information from variable-length motion clips during training. Experimental results demonstrate the competitive performance of our proposed framework in generating compositional motion sequences that align semantically with the input conditions, while preserving phase transitional continuity between preceding and succeeding motion clips. Additionally, motion inbetweening task is made possible by keeping the phase parameter of the input motion sequences fixed throughout the diffusion process, showcasing the potential for extending the proposed framework to accommodate various application scenarios. Codes are available athttps://github.com/asdryau/TransPhase.",,CBG,CBG: 3DAIGC,CBG: Session聚焦于长运动序列生成中的连续性和过渡问题，涉及视频中运动物体的语义连续生成和长序列一致性，直接对应CBG团队关注的长视频生成一致性难题，且提出的Compositional Phase Diffusion方法可为其长视频运动连续性提供技术支持。
THU 4 DEC,3:30-4:30,Oral Paper,  → Mean Flows for One-step Generative Modeling,https://neurips.cc/virtual/2025/oral/115488,,4:30 PM,"We propose a principled and effective framework for one-step generative modeling. We introduce the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods. A well-defined identity between average and instantaneous velocities is derived and used to guide neural network training. Our method, termed the \textit{MeanFlow} model, is self-contained and requires no pre-training, distillation, or curriculum learning. MeanFlow demonstrates strong empirical performance: it achieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet 256 × 256 trained from scratch, significantly outperforming previous state-of-the-art one-step diffusion/flow models. Our study substantially narrows the gap between one-step diffusion/flow models and their multi-step predecessors, and we hope it will motivate future research to revisit the foundations of these powerful models.",,海思,海思: 大语言模型和扩散模型的加速,海思: 该session提出的MeanFlow模型是一种高效的单步生成模型，显著提升了扩散模型的生成速度和质量，直接对应海思团队关注的扩散模型加速难题，尤其是在保持生成质量的前提下实现低延迟推理。
THU 4 DEC,3:30-4:30,Oral Session,Oral Session 4E Position Paper Track Panels,https://neurips.cc/virtual/2025/session/122565,,4:30 PM,,,nan,nan,nan
FRI 5 DEC,8:30 a.m.,Invited Talk,From Benchmarks to Problems - A Perspective on Problem Finding in AI,https://neurips.cc/virtual/2025/invited-talk/109605,Kyunghyun Cho,9:30 AM,"During the past 15 years or so, I have worked on a series of seemingly distinct but eventually related problems, including machine learning algorithms, generative modeling with neural networks, machine translation, language modeling, medical imaging, a bit of healthcare, protein modeling and a bit of drug discovery. I chose to work on some of these problems intentionally, while it was pure serendipity that I worked on some others. It was only in hindsight that these seemingly different problems turned out to be closely related to each other from both technical, social and personal perspectives. In this talk, I plan to do my own retrospective on my own choices, be them intentional or not, on these problems and share with you my thoughts what our own discipline, which is sometimes called computer science, data science, machine learning or artificial intelligence, is.",,nan,nan,nan
FRI 5 DEC,2:30 p.m.,Invited Talk,Demystifying depth: Principles of learning in deep neural networks,https://neurips.cc/virtual/2025/invited-talk/109602,Andrew Saxe,3:30 PM,"Deep neural networks have revolutionized artificial intelligence, yet their inner workings remain poorly understood. This talk presents mathematical analyses of the nonlinear dynamics of learning in several solvable deep network models, offering theoretical insights into the role of depth. These models reveal how learning algorithms, data structure, initialization schemes, and architectural choices interact to produce hidden representations that afford complex generalization behaviors. A recurring theme across these analyses is a neural race: competing pathways within a deep network vie to explain the data, with an implicit bias toward shared representations. These shared representations in turn shape the network’s capacity for systematic generalization, multitasking, and transfer learning. I will show how such principles manifest across diverse architectures—including feedforward, recurrent, and linear attention networks. Together, these results provide analytic foundations for understanding how environmental statistics, network architecture, and learning dynamics jointly structure the emergence of neural representations and behavior.",,计算; 计算; 诺亚,计算: 高效模型架构; 计算: 训推新范式; 诺亚: 大模型后训练Reasoning，RL,计算: Session深入分析深度神经网络的学习动态和架构选择如何影响隐藏表示和泛化能力，直接对应团队关注的模型架构演进趋势及其对计算架构的影响，能为理解和预判大模型结构演进趋势提供理论基础。; 计算: Session探讨学习算法、初始化方案和架构选择如何共同作用于深度网络学习过程，能够为团队理解和预测训练推理新范式的演进机理及负载特征变化提供数学分析和理论支持。; 诺亚: Session中关于深度网络中隐含的学习动态和共享表示的分析，有助于理解自博弈与经验学习训练框架中隐含的学习机制，支持团队在后训练推理和强化学习方面的研究。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5A,https://neurips.cc/virtual/2025/session/122566,,11:00 AM,,,nan,nan,nan
FRI 5 DEC,10:00-11:00,Oral Paper,  → EvoLM: In Search of Lost Language Model Training Dynamics,https://neurips.cc/virtual/2025/oral/119409,,11:00 AM,"Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage.We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session中提到对训练阶段包括reinforcement learning的系统性分析，特别是fine-tuning和RL阶段的训练动态，直接对应该团队关注的Reinforcement learning在大模型中的实际应用和性能提升问题。; 诺亚: Session强调了包括supervised fine-tuning和reinforcement learning在内的后训练阶段对模型推理能力的影响，能为该团队关于自博弈、learning from experience训练框架和latent reasoning的研究提供系统训练动态的分析方法和数据支持。
FRI 5 DEC,10:00-11:00,Oral Paper,  → Large Language Diffusion Models,https://neurips.cc/virtual/2025/oral/118609,,11:00 AM,"The capabilities of large language models (LLMs) are widely regarded as relying on autoregressive models (ARMs). We challenge this notion by introducingLLaDA, a diffusion model trained from scratch under the pre-training and supervised fine-tuning (SFT) paradigm. LLaDA employs a forward data masking process and a reverse generation process, parameterized by a Transformer to predict masked tokens. It provides a principled generative approach for probabilistic inference by optimizing a likelihood lower bound. Across extensive benchmarks on general tasks, math, code, and so on, LLaDA demonstrates strongscalabilityand performs comparably to our self-constructed ARM baselines. Remarkably, LLaDA 8B is competitive with strong LLMs like LLaMA3 8B inin-context learningand, after SFT, exhibits impressiveinstruction-followingabilities in case studies such as multi-turn dialogue. Moreover, LLaDA addresses the reversal curse, surpassing GPT-4o in a reversal poem completion task. Our findings show the promise of diffusion models for language modeling at scale and challenge the common assumption that core LLM capabilities discussed above inherently depend on ARMs. Project page and codes: \url{https://ml-gsai.github.io/LLaDA-demo/}.",,海思,海思: 大语言模型和扩散模型的加速,海思: Session介绍了基于扩散模型的LLaDA大语言模型，涉及扩散模型在语言建模中的应用和推理过程，直接对应海思团队关注的大语言模型和扩散模型的加速问题，尤其是如何实现低延迟实时推理和保持对话质量与上下文一致性。
FRI 5 DEC,10:00-11:00,Oral Paper,  → Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?,https://neurips.cc/virtual/2025/oral/119945,,11:00 AM,"Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly in mathematics and programming tasks. It is widely believed that, similar to how traditional RL helps agents to explore and learn new strategies, RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed the capacity of the corresponding base models. In this study, we take a critical look at \textit{the current state of RLVR} by systematically probing the reasoning capability boundaries of RLVR-trained LLMs across diverse model families, RL algorithms, and math/coding/visual reasoning benchmarks, using pass@\textit{k} at large \textit{k} values as the evaluation metric.While RLVR improves sampling efficiency towards the correct path, we surprisingly find that current training does \emph{not} elicit fundamentally new reasoning patterns.We observe that while RLVR-trained models outperform their base models at smaller values of k (\eg, k =1), base models achieve higher pass@ k score when k is large.Moreover, we observe that the reasoning capability boundary of LLMs often narrows as RLVR training progresses.Further coverage and perplexity analysis shows that the reasoning paths generated by RLVR models are already included in the base models' sampling distribution, suggesting that their reasoning abilities originate from and are \textit{bounded} by the base model. From this perspective, treating the base model as an upper bound, our quantitative analysis shows that six popular RLVR algorithms perform similarly and remain far from optimal in fully leveraging the potential of the base model.In contrast, we find that distillation can introduce new reasoning patterns from the teacher and genuinely expand the model’s reasoning capabilities.Taken together, our findings suggest that current RLVR methods have not fully realized the potential of RL to elicit genuinely novel reasoning abilities in LLMs. This underscores the need for improved RL paradigms—such as continual scaling and multi-turn agent-environment interaction—to unlock this potential.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session深入探讨了基于强化学习的微调（RLVR）在提升大语言模型推理能力方面的实际效果和局限，直接对应团队关注的Reinforcement learning在LLMs/VLMs中的应用及其样本效率、性能和可扩展性等实际问题，能为团队解决理论到生产的差距提供具体的分析和改进方向。; 诺亚: Session聚焦于强化学习微调对大模型推理能力的影响及其边界，涉及自博弈和经验学习等训练框架，与团队关注的后训练阶段的推理能力提升及强化学习方法高度相关，能为团队在latent reasoning和训练框架设计上提供理论验证和改进思路。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5B,https://neurips.cc/virtual/2025/session/122567,,11:00 AM,,,nan,nan,nan
FRI 5 DEC,10:00-11:00,Oral Paper,  → WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch,https://neurips.cc/virtual/2025/oral/121452,,11:00 AM,"LLM‑based agents have demonstrated great potential in generating and managing code within complex codebases. In this paper, we introduce WebGen-Bench, a novel benchmark designed to measure an LLM-based agent's ability to create multi-file website codebases from scratch. It contains diverse instructions for website generation, created through the combined efforts of human annotators and GPT-4o. These instructions span three major categories and thirteen minor categories, encompassing nearly all important types of web applications.To assess the quality of the generated websites, we generate test cases targeting each functionality described in the instructions. These test cases are then manually filtered, refined, and organized to ensure accuracy, resulting in a total of 647 test cases. Each test case specifies an operation to be performed on the website and the expected outcome of the operation.To automate testing and improve reproducibility, we employ a powerful web-navigation agent to execute test cases on the generated websites and determine whether the observed responses align with the expected results.We evaluate three high-performance code-agent frameworks—Bolt.diy, OpenHands, and Aider—using multiple proprietary and open-source LLMs as engines. The best-performing combination, Bolt.diy powered by DeepSeek-R1, achieves only 27.8\% accuracy on the test cases, highlighting the challenging nature of our benchmark.Additionally, we construct WebGen-Instruct, a training set consisting of 6,667 website-generation instructions. Training Qwen2.5-Coder-32B-Instruct on Bolt.diy trajectories generated from a subset of the training set achieves an accuracy of 38.2\%, surpassing the performance of the best proprietary model.We release our data-generation, training, and testing code, along with both the datasets and model weights at https://github.com/mnluzimu/WebGen-Bench.",,多伦多云,多伦多云: AI Agent,多伦多云: Session聚焦于基于LLM的agent生成和管理复杂代码库，特别是多文件网站代码生成与自动化测试，直接对应团队关注的提升AI Agent评估准确性与覆盖范围、行为可靠性及管控校验等难题。WebGen-Bench提供了具体的benchmark和测试用例，有助于提升Agent行为的可靠性和评估体系。
FRI 5 DEC,10:00-11:00,Oral Paper,  → QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training,https://neurips.cc/virtual/2025/oral/117310,,11:00 AM,"Clinical decision‑making routinely demands reasoning over heterogeneous data, yet existing multimodal language models (MLLMs) remain largely vision‑centric and fail to generalize across clinical specialties. To bridge this gap, we introduce QoQ-Med-7B/32B, the first open generalist clinical foundation model that jointly reasons across medical images, time‑series signals, and text reports. QoQ-Med is trained with Domain‑aware Relative Policy Optimization (DRPO), a novel reinforcement‑learning objective that hierarchically scales normalized rewards according to domain rarity and modality difficulty, mitigating performance imbalance caused by skewed clinical data distributions. Trained on 2.61 million instruction tuning pairs spanning 9 clinical domains, we show that DRPO training boosts diagnostic performance by 43% in macro‑F1 on average across all visual domains as compared to other critic-free training methods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation data, it is able to highlight salient regions related to the diagnosis, with an IoU 10x higher than open models while reaching the performance of OpenAI o4-mini. To foster reproducibility and downstream research, we release (i) the full model weights, (ii) the modular training pipeline, and (iii) all intermediate reasoning traces.",,温哥华云; 诺亚; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL; 诺亚: 大模型长序列，多模态长序列,温哥华云: 该session提出了Domain-aware Relative Policy Optimization (DRPO)作为一种新型强化学习训练目标，用于提升多模态临床基础模型的性能，直接对应温哥华云团队关注的强化学习在多模态模型中的实际应用问题，尤其是提升样本效率和性能，帮助解决理论到生产的落地难题。; 诺亚: 该session中DRPO强化学习训练方法和多模态临床模型的后训练推理能力，与诺亚团队关注的自博弈与learning from experience训练框架及latent reasoning密切相关，提供了具体的强化学习优化手段和多模态推理提升思路。; 诺亚: 该session涉及多模态临床数据（图像、时间序列信号、文本报告）的联合推理，符合诺亚团队对多模态长序列模型演进和推理计算瓶颈的研究方向，提供了跨模态联合训练和推理的具体实践和技术方案。
FRI 5 DEC,10:00-11:00,Oral Paper,  → NOVA: A Benchmark for Rare Anomaly Localization and Clinical Reasoning in Brain MRI,https://neurips.cc/virtual/2025/oral/121771,,11:00 AM,"In many real-world applications, deployed models encounter inputs that differ from the data seen during training. Open-world recognition ensures that such systems remain robust as ever-emerging, previously _unknown_ categories appear and must be addressed without retraining.Foundation and vision-language models are pre-trained on large and diverse datasets with the expectation of broad generalization across domains, including medical imaging.However, benchmarking these models on test sets with only a few common outlier types silently collapses the evaluation back to a closed-set problem, masking failures on rare or truly novel conditions encountered in clinical use.We therefore present NOVA, a challenging, real-life _evaluation-only_ benchmark of $\sim$900 brain MRI scans that span 281 rare pathologies and heterogeneous acquisition protocols. Each case includes rich clinical narratives and double-blinded expert bounding-box annotations. Together, these enable joint assessment of anomaly localisation, visual captioning, and diagnostic reasoning. Because NOVA is never used for training, it serves as an _extreme_ stress-test of out-of-distribution generalisation: models must bridge a distribution gap both in sample appearance and in semantic space.  Baseline results with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B) reveal substantial performance drops, with approximately a 65\% gap in localisation compared to natural-image benchmarks and 40\% and 20\% gaps in captioning and reasoning, respectively, compared to resident radiologists. Therefore, NOVA establishes a testbed for advancing models that can detect, localize, and reason about truly unknown anomalies.",,nan,nan,nan
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5C,https://neurips.cc/virtual/2025/session/122568,,11:00 AM,,,nan,nan,nan
FRI 5 DEC,10:00-11:00,Oral Paper,  → High-dimensional neuronal activity from low-dimensional latent dynamics: a solvable model,https://neurips.cc/virtual/2025/oral/117112,,11:00 AM,"Computation in recurrent networks of neurons has been hypothesized to occur at the level of low-dimensional latent dynamics, both in artificial systems and in the brain. This hypothesis seems at odds with evidence from large-scale neuronal recordings in mice showing that neuronal population activity is high-dimensional. To demonstrate that low-dimensional latent dynamics and high-dimensional activity can be two sides of the same coin, we present an analytically solvable recurrent neural network (RNN) model whose dynamics can be exactly reduced to a low-dimensional dynamical system, but generates an activity manifold that has a high linear embedding dimension. This raises the question: Do low-dimensional latents explain the high-dimensional activity observed in mouse visual cortex? Spectral theory tells us that the covariance eigenspectrum alone does not allow us to recover the dimensionality of the latents, which can be low or high, when neurons are nonlinear. To address this indeterminacy, we develop Neural Cross-Encoder (NCE), an interpretable, nonlinear latent variable modeling method for neuronal recordings, and find that high-dimensional neuronal responses to drifting gratings and spontaneous activity in visual cortex can be reduced to low-dimensional latents, while the responses to natural images cannot. We conclude that the high-dimensional activity measured in certain conditions, such as in the absence of a stimulus, is explained by low-dimensional latents that are nonlinearly processed by individual neurons.",,nan,nan,nan
FRI 5 DEC,10:00-11:00,Oral Paper,  → Task-Optimized Convolutional Recurrent Networks Align with Tactile Processing in the Rodent Brain,https://neurips.cc/virtual/2025/oral/116232,,11:00 AM,"Tactile sensing remains far less understood in neuroscience and less effective in artificial systems compared to more mature modalities such as vision and language.We bridge these gaps by introducing a novel Encoder-Attender-Decoder (EAD) framework to systematically explore the space of task-optimized temporal neural networks trained on realistic tactile input sequences from a customized rodent whisker-array simulator. We identify convolutional recurrent neural networks (ConvRNNs) as superior encoders to purely feedforward and state-space architectures for tactile categorization. Crucially, these ConvRNN-encoder-based EAD models achieve neural representations closely matching rodent somatosensory cortex, saturating the explainable neural variability and revealing a clear linear relationship between supervised categorization performance and neural alignment.Furthermore, contrastive self-supervised ConvRNN-encoder-based EADs, trained with tactile-specific augmentations, match supervised neural fits, serving as an ethologically-relevant, label-free proxy.For neuroscience, our findings highlight nonlinear recurrent processing as important for general-purpose tactile representations in somatosensory cortex, providing the first quantitative characterization of the underlying inductive biases in this system. For embodied AI, our results emphasize the importance of recurrent EAD architectures to handle realistic tactile inputs, along with tailored self-supervised learning methods for achieving robust tactile perception with the same type of sensors animals use to sense in unstructured environments.",,温哥华云,温哥华云: Embodied AI,温哥华云: 该session聚焦于具身AI中的触觉感知，提出了基于卷积递归神经网络的时序模型，能够有效处理真实触觉输入并与啮齿动物大脑的触觉处理对齐，直接对应具身AI领域对物理感知和多模态感知的研究需求，能为团队在物理AI感知模型设计和自监督学习方法提供具体技术方案。
FRI 5 DEC,10:00-11:00,Oral Paper,  → Memory Mosaics at scale,https://neurips.cc/virtual/2025/oral/118784,,11:00 AM,"Memory Mosaics, networks of associative memories, have demonstrated appealing compositional and in-context learning capabilities on medium-scale networks (GPT-2 scale) and synthetic small datasets. This work shows that these favorable properties remain when we scale memory mosaics to large language model sizes (llama-8B scale) and real-world datasets. To this end, we scale memory mosaics to 10B size, we train them on one trillion tokens, we introduce a couple architectural modifications (memory mosaics v2), we assess their capabilities across three evaluation dimensions: training-knowledge storage, new-knowledge storage, and in-context learning. Throughout the evaluation, memory mosaics v2 match transformers on the learning of training knowledge (first dimension) and significantly outperforms transformers on carrying out new tasks at inference time (second and third dimensions). These improvements cannot be easily replicated by simply increasing the training data for transformers. A memory mosaics v2 trained on one trillion tokens still perform better on these tasks than a transformer trained on eight trillion tokens.",,计算; 计算,计算: 高效模型架构; 计算: 训推新范式,计算: Session介绍了Memory Mosaics v2在大规模语言模型（10B参数，训练一万亿token）上的架构改进和性能提升，直接涉及大模型架构演进。该团队关注模型架构对计算架构的影响，理解Memory Mosaics的架构创新及其对计算需求的影响，有助于识别未来计算系统的需求，解决其难题中关于把握大模型结构演进趋势和计算系统需求的挑战。; 计算: Session展示了Memory Mosaics在训练知识存储和推理时新知识存储及上下文学习能力上的显著提升，体现了新的训练和推理范式。该团队关注训推新范式的演进及负载特征，Memory Mosaics v2的训练和推理机制提供了具体的新范式案例，有助于理解和预测训推范式演进机理，解决其难题中对训推范式演进的跟踪和理解。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5D,https://neurips.cc/virtual/2025/session/122569,,11:00 AM,,,nan,nan,nan
FRI 5 DEC,10:00-11:00,Oral Paper,  → InfinityStar: Uniﬁed Spacetime AutoRegressive Modeling for Visual Generation,https://neurips.cc/virtual/2025/oral/118709,,11:00 AM,"We introduce InfinityStar, a unified spacetime autoregressive framework for high-resolution image and dynamic video synthesis. Building on the recent success of autoregressive modeling in both vision and language, our purely discrete approach jointly captures spatial and temporal dependencies within a single architecture. This unified design naturally supports a variety of generation tasks such as text-to-image, text-to-video, image-to-video, and long-duration video synthesis via straightforward temporal autoregression. Through extensive experiments, InfinityStar scores 83.74 on VBench, outperforming all autoregressive models by large margins, even surpassing diffusion competitors like HunyuanVideo. Without extra optimizations, our model generates a 5s, 720p video approximately 10 × faster than leading diffusion-based methods. To our knowledge, InfinityStar is the first discrete autoregressive video generator capable of producing industrial-level 720p videos. We release all code and models to foster further research in efficient, high-quality video generation.",,CBG,CBG: 3DAIGC,CBG: Session介绍了InfinityStar用于高分辨率图像和动态视频合成，特别强调了长时视频生成的一致性，这与CBG团队关注的长视频生成一致性难题直接相关。此外，视频中运动物体的分割和基于视频的3D/4D稀疏重建也与视频生成技术密切相关，InfinityStar的统一时空自回归框架可为这些问题提供新的建模思路。
FRI 5 DEC,10:00-11:00,Oral Paper,  → PlayerOne: Egocentric World Simulator,https://neurips.cc/virtual/2025/oral/118938,,11:00 AM,"We introduce PlayerOne, the first egocentric realistic world simulator, facilitating immersive and unrestricted exploration within vividly dynamic environments. Given an egocentric scene image from the user, PlayerOne can accurately construct the corresponding world and generate egocentric videos that are strictly aligned with the real-scene human motion of the user captured by an exocentric camera. PlayerOne is trained in a coarse-to-fine pipeline that first performs pretraining on large-scale egocentric text-video pairs for coarse-level egocentric understanding, followed by finetuning on synchronous motion-video data extracted from egocentric-exocentric video datasets with our automatic construction pipeline. Besides, considering the varying importance of different components, we design a part-disentangled motion injection scheme, enabling precise control of part-level movements. In addition, we devise a joint reconstruction framework that progressively models both the 4D scene and video frames, ensuring scene consistency in the long-form video generation. Experimental results demonstrate its great generalization ability in precise control of varying human movements and world-consistent modeling of diverse scenarios. It marks the first endeavor into egocentric real-world simulation and can pave the way for the community to delve into fresh frontiers of world modeling and its diverse applications.",,CBG; 温哥华云,CBG: 3DAIGC; 温哥华云: Embodied AI,CBG: Session介绍了PlayerOne作为首个以第一人称视角的真实世界模拟器，涉及基于单目视频的3D/4D稀疏重建、相机轨迹控制的视频生成以及长视频生成的一致性保证，直接对应CBG团队关注的快速准确分割运动物体、3D/4D稀疏重建和长视频一致性难题。; 温哥华云: PlayerOne实现了基于用户第一人称视角的世界构建和动作生成，属于具身AI范畴，能够推动物理具身智能的研究和应用，契合温哥华云团队对Embodied AI的战略投资方向。
FRI 5 DEC,10:00-11:00,Oral Paper,  → BEDLAM2.0: Synthetic humans and cameras in motion,https://neurips.cc/virtual/2025/oral/121503,,11:00 AM,"Inferring 3D human motion from video remains a challenging problem with many applications. While traditional methods estimate the human in image coordinates, many applications require human motion to be estimated in world coordinates. This is particularly challenging when there is both human and camera motion. Progress on this topic has been limited by the lack of rich video data with ground truth human and camera movement. We address this with BEDLAM2.0, a new dataset that goes beyond the popular BEDLAM dataset in important ways. In addition to introducing more diverse and realistic cameras and camera motions, BEDLAM2.0 increases diversity and realism of body shape, motions, clothing, hair, and 3D environments. Additionally, it adds shoes, which were missing in BEDLAM. BEDLAM has become a key resource for training 3D human pose and motion regressors today and we show that BEDLAM2.0 is significantly better, particularly for training methods that estimate humans in world coordinates. We compare state-of-the art methods trained on BEDLAM and BEDLAM2.0, and find that BEDLAM2.0 significantly improves accuracy over BEDLAM.  For research purposes, we provide the rendered videos, ground truth body parameters, and camera motions. We also provide the 3D assets to which we have rights and links to those from third parties.",,CBG; 温哥华云,CBG: 3DAIGC; 温哥华云: Embodied AI,CBG: Session聚焦于从视频中推断3D人体运动，涉及相机运动和人体运动的联合估计，且提供了丰富的合成数据集BEDLAM2.0，直接对应团队难题中关于如何基于单目视频快速准确进行3D/4D稀疏重建（点云，位姿）及相机轨迹控制的视频生成，能为其提供高质量训练数据和方法验证。; 温哥华云: Session关注3D人体运动和相机运动的联合估计，属于物理具身AI范畴，提供了丰富的合成数据和真实感模拟，有助于提升物理具身AI中对人体运动感知和环境交互的研究，直接支持团队在Embodied AI领域的研究投入。
FRI 5 DEC,10:00-11:00,Oral Session,Oral Session 5E,https://neurips.cc/virtual/2025/session/122570,,11:00 AM,,,nan,nan,nan
FRI 5 DEC,10:00-11:00,Oral Paper,  → Boosting Knowledge Utilization in Multimodal Large Language Models via Adaptive Logits Fusion and Attention Reallocation,https://neurips.cc/virtual/2025/oral/115856,,11:00 AM,"Despite their recent progress, Multimodal Large Language Models (MLLMs) often struggle in knowledge-intensive tasks due to the limited and outdated parametric knowledge acquired during training. Multimodal Retrieval Augmented Generation addresses this issue by retrieving contextual knowledge from external databases, thereby enhancing MLLMs with expanded knowledge sources. However, existing MLLMs often fail to fully leverage the retrieved contextual knowledge for response generation. We examine representative MLLMs and identify two major causes, namely, attention bias toward different tokens and knowledge conflicts between parametric and contextual knowledge. To this end, we design Adaptive Logits Fusion and Attention Reallocation (ALFAR), a training-free and plug-and-play approach that improves MLLM responses by maximizing the utility of the retrieved knowledge. Specifically, ALFAR tackles the challenges from two perspectives. First, it alleviates attention bias by adaptively shifting attention from visual tokens to relevant context tokens according to query-context relevance. Second, it decouples and weights parametric and contextual knowledge at output logits, mitigating conflicts between the two types of knowledge. As a plug-and-play method, ALFAR achieves superior performance across diverse datasets without requiring additional training or external tools. Extensive experiments over multiple MLLMs and benchmarks show that ALFAR consistently outperforms the state-of-the-art by large margins. Our code and data are available at https://github.com/Lackel/ALFAR.",,海思; 诺亚,海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,海思: Session提出的Adaptive Logits Fusion和Attention Reallocation方法，针对多模态大语言模型中注意力偏差和知识冲突问题，能够提升多模态条件下模型对上下文知识的利用效率，直接关联海思关注的多模态条件融合延迟大和长上下文推理注意力复杂度过高的难题，提供了无需额外训练即可优化推理响应质量的技术思路。; 诺亚: 该Session聚焦于提升多模态大语言模型对检索知识的利用效率，涉及对多模态长序列中注意力分配和知识融合的优化，契合诺亚团队关注的多模态长序列推理计算瓶颈和模型内置记忆更新机制改进，提供了通过自适应注意力重分配和输出层融合技术解决长序列多模态知识利用不足的具体方法。
FRI 5 DEC,10:00-11:00,Oral Paper,  → HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models,https://neurips.cc/virtual/2025/oral/118373,,11:00 AM,"Multi-modal large language models (MLLMs) have emerged as a transformative approach for aligning visual and textual understanding. They typically require extremely high computational resources (e.g., thousands of GPUs) for training to achieve cross-modal alignment at multi-granularity levels. We argue that a key source of this inefficiency lies in the vision encoders they widely equip with, e.g., CLIP and SAM, which lack the alignment with language at multi-granularity levels. To address this issue, in this paper, we leverage hyperbolic space, which inherently models hierarchical levels and thus provides a principled framework for bridging the granularity gap between visual and textual modalities at an arbitrary granularity level. Concretely, we propose an efficient training paradigm for MLLMs, dubbed as \blg, which can optimize visual representations to align with their textual counterparts at an arbitrary granularity level through dynamic hyperbolic radius adjustment in hyperbolic space. \alg employs learnable matrices with M\""{o}bius multiplication operations, implemented via three effective configurations: diagonal scaling matrices, block-diagonal matrices, and banded matrices, providing a flexible yet efficient parametrization strategy. Comprehensive experiments across multiple MLLM benchmarks demonstrate that \alg consistently improves both existing pre-training and fine-tuning MLLMs clearly with less than 1\% additional parameters.",,海思; 诺亚,海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,海思: 该session提出了在超曲空间中高效训练多模态大语言模型的方法，解决了多模态条件融合和跨模态对齐问题，能够有效降低训练复杂度和参数量，直接对应海思关注的多模态条件融合延迟大和如何统一特征空间实现快速条件生成的难题。; 诺亚: session利用超曲空间的层级建模能力优化视觉与文本多粒度对齐，提供了一种新的多模态长序列表示和训练范式，有助于解决诺亚团队关于多模态长序列模型演进和输入范式突破多模态长文本推理计算瓶颈的难题。
FRI 5 DEC,10:00-11:00,Oral Paper,  → Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion,https://neurips.cc/virtual/2025/oral/118167,,11:00 AM,"Multimodal learning (MML) is significantly constrained by modality imbalance, leading to suboptimal performance in practice. While existing approaches primarily focus on balancing the learning of different modalities to address this issue, they fundamentally overlook the inherent disproportion in model classification ability, which serves as the primary cause of this phenomenon. In this paper, we propose a novel multimodal learning approach to dynamically balance the classification ability of weak and strong modalities by incorporating the principle of boosting. Concretely, we first propose a sustained boosting algorithm in multimodal learning by simultaneously optimizing the classification and residual errors. Subsequently, we introduce an adaptive classifier assignment strategy to dynamically facilitate the classification performance of the weak modality. Furthermore, we theoretically analyze the convergence property of the cross-modal gap function, ensuring the effectiveness of the proposed boosting scheme. To this end, the classification ability of strong and weak modalities is expected to be balanced, thereby mitigating the imbalance issue. Empirical experiments on widely used datasets reveal the superiority of our method through comparison with various state-of-the-art (SOTA) multimodal learning baselines. The source code is available at https://github.com/njustkmg/NeurIPS25-AUG.",,海思; 诺亚,海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,海思: Session提出的多模态学习中平衡强弱模态分类能力的boosting方法，能够为海思关注的多模态条件融合延迟大、如何统一特征空间以实现快速条件生成提供新的算法思路，直接对应其多模态融合难题。; 诺亚: Session针对多模态学习中模态间分类能力不平衡问题提出动态平衡方法，有助于解决诺亚团队关注的多模态长文本推理计算瓶颈和多模态模型演进中的性能优化问题，技术关联明确。
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6A,https://neurips.cc/virtual/2025/session/122571,,4:30 PM,,,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Paper,  → An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds,https://neurips.cc/virtual/2025/oral/117790,,4:30 PM,"Bandeira et al. (2022) introduced the Franz-Parisi (FP) criterion for characterizing the computational hard phases in statistical detection problems. The FP criterion, based on an annealed version of the celebrated Franz-Parisi potential from statistical physics, was shown to be equivalent to low-degree polynomial (LDP) lower bounds for Gaussian additive models, thereby connecting two distinct approaches to understanding the computational hardness in statistical inference. In this paper, we propose a refined FP criterion that aims to better capture the geometric ``overlap"" structure of statistical models. Our main result establishes that this optimized FP criterion is equivalent to Statistical Query (SQ) lower bounds---another foundational framework in computational complexity of statistical inference.  Crucially, this equivalence holds under a mild, verifiable assumption satisfied by a broad class of statistical models, including Gaussian additive models, planted sparse models, as well as non-Gaussian component analysis (NGCA), single-index (SI) models, and convex truncation detection settings. For instance, in the case of convex truncation tasks, the assumption is equivalent with the Gaussian correlation inequality (Royen, 2014) from convex geometry. In addition to the above, our equivalence not only unifies and simplifies the derivation of several known SQ lower bounds—such as for the NGCA model (Diakonikolas et al., 2017) and the SI model (Damian et al., 2024)—but also yields new SQ lower bounds of independent interest, including for the computational gaps in mixed sparse linear regression (Arpino et al., 2023) and convex truncation (De et al., 2023).",,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Paper,  → Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy,https://neurips.cc/virtual/2025/oral/119076,,4:30 PM,"A central challenge in machine learning is to understand how noise or measurement errors affect low-rank approximations, particularly in the spectral norm. This question is especially important in differentially private low-rank approximation, where one aims to preserve the top-$p$ structure of a data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius norm error or changes in reconstruction quality, but these metrics can over- or under-estimate true subspace distortion. The spectral norm, by contrast, captures worst-case directional error and provides the strongest utility guarantees. We establish new high-probability spectral-norm perturbation bounds for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem and explicitly capture interactions between a matrix $A \in \mathbb{R}^{n \times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and norm conditions, our bounds yield sharp estimates for $\| (A + E)_p - A_p \|$, where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up to a factor of $\sqrt{n}$. As an application, we derive improved utility guarantees for differentially private PCA, resolving an open problem in the literature. Our analysis relies on a novel contour bootstrapping method from complex analysis and extends it to a broad class of spectral functionals, including polynomials and matrix exponentials. Empirical results on real-world datasets confirm that our bounds closely track the actual spectral error under diverse perturbation regimes.",,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Paper,  → Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization,https://neurips.cc/virtual/2025/oral/116693,,4:30 PM,"This paper addresses the Bayesian optimization problem (also referred to as the Bayesian setting of the Gaussian process bandit), where the learner seeks to minimize the regret under a function drawn from a known Gaussian process (GP). Under a Mat\'ern kernel with some extent of smoothness, we show that the Gaussian process upper confidence bound (GP-UCB) algorithm achieves $\tilde{O}(\sqrt{T})$ cumulative regret with high probability. Furthermore, our analysis yields $O(\sqrt{T \ln^2 T})$ regret under a squared exponential kernel. These results fill the gap between the existing regret upper bound of GP-UCB and the current best upper bound provided by Scarlett [2018]. The key idea in our proof is to capture the concentration behavior of the input sequence realized by GP-UCB, enabling us to handle GP's information gain in a refined manner.",,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6B,https://neurips.cc/virtual/2025/session/122572,,4:30 PM,,,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Paper,  → GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability,https://neurips.cc/virtual/2025/oral/116902,,4:30 PM,"Graph Neural Networks (GNNs) are widely used for node classification, yet their opaque decision-making limits trust and adoption. While local explanations offer insights into individual predictions, global explanation methods—those that characterize an entire class—remain underdeveloped. Existing global explainers rely on motif discovery in small graphs, an approach that breaks down in large, real-world settings where subgraph repetition is rare, node attributes are high-dimensional, and predictions arise from complex structure-attribute interactions. We propose GnnXemplar, a novel global explainer inspired from Exemplar Theory from cognitive science. GnnXemplar identifies representative nodes in the GNN embedding space—exemplars—and explains predictions using natural language rules derived from their neighborhoods. Exemplar selection is framed as a coverage maximization problem over reverse $k$-nearest neighbors, for which we provide an efficient greedy approximation. To derive interpretable rules, we employ a self-refining prompt strategy using large language models (LLMs). Experiments across diverse benchmarks show that GnnXemplar significantly outperforms existing methods in fidelity, scalability, and human interpretability, as validated by a user study with 60 participants.",,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Paper,  → RAG4GFM: Bridging Knowledge Gaps in Graph Foundation Models through Graph Retrieval Augmented Generation,https://neurips.cc/virtual/2025/oral/115563,,4:30 PM,"Graph Foundation Models (GFMs) have demonstrated remarkable potential across graph learning tasks but face significant challenges in knowledge updating and reasoning faithfulness. To address these issues, we introduce the Retrieval-Augmented Generation (RAG) paradigm for GFMs, which leverages graph knowledge retrieval. We propose RAG4GFM, an end-to-end framework that seamlessly integrates multi-level graph indexing, task-aware retrieval, and graph fusion enhancement. RAG4GFM implements a hierarchical graph indexing architecture, enabling multi-granular graph indexing while achieving efficient logarithmic-time retrieval. The task-aware retriever implements adaptive retrieval strategies for node, edge, and graph-level tasks to surface structurally and semantically relevant evidence. The graph fusion enhancement module fuses retrieved graph features with query features and augments the topology with sparse adjacency links that preserve structural and semantic proximity, yielding a fused graph for GFM inference.Extensive experiments conducted across diverse GFM applications demonstrate that RAG4GFM significantly enhances both the efficiency of knowledge updating and reasoning faithfulness\footnote{Code: \url{https://github.com/Matrixmax/RAG4GFM}.}.",,存储,存储: 单/多模型推理,存储: Session中提出的RAG4GFM框架采用检索增强生成技术，涉及多层次图索引和任务感知检索，相关于Agentic AI系统中RAG和Vector DB对存储系统访问模式的研究，能为该团队在存储系统访问模式及调度提供新的技术思路和优化方向。
FRI 5 DEC,3:30-4:30,Oral Paper,  → Discovering Opinion Intervals from Conflicts in Signed Graphs,https://neurips.cc/virtual/2025/oral/115063,,4:30 PM,"Online social media provide a platform for people to discuss current events and exchange opinions with their peers. While interactions are predominantly positive, in recent years, there has been a lot of research to understand the conflicts in social networks and how they are based on different views and opinions.  In this paper, we ask whether the conflicts in a network reveal a small and interpretable set of prevalent opinion ranges that explain the users' interactions.  More precisely, we consider signed graphs, where the edge signs indicate positive and negative interactions of node pairs, and our goal is to infer opinion intervals that are consistent with the edge signs.  We introduce an optimization problem that models this question, and we give strong hardness results and a polynomial-time approximation scheme by utilizing connections to interval graphs and the Correlation Clustering problem.  We further provide scalable heuristics and show that in experiments they yield more expressive solutions than Correlation Clustering baselines. We also present a case study on a novel real-world dataset from the German parliament, showing that our algorithms can recover the political leaning of German parties based on co-voting behavior.",,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6C,https://neurips.cc/virtual/2025/session/122573,,4:30 PM,,,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Paper,  → Generalized Linear Mode Connectivity for Transformers,https://neurips.cc/virtual/2025/oral/118595,,4:30 PM,"Understanding the geometry of neural network loss landscapes is a central question in deep learning, with implications for generalization and optimization. A striking phenomenon is $\textit{linear mode connectivity}$ (LMC), where independently trained models can be connected by low- or zero-barrier paths, despite appearing to lie in separate loss basins. However, this is often obscured by symmetries in parameter space—such as neuron permutations—which make functionally equivalent models appear dissimilar. Prior work has predominantly focused on neuron reordering through permutations, but such approaches are limited in scope and fail to capture the richer symmetries exhibited by modern architectures such as Transformers. In this work, we introduce a unified framework that captures four symmetry classes—permutations, semi-permutations, orthogonal transformations, and general invertible maps—broadening the set of valid reparameterizations and subsuming many previous approaches as special cases. Crucially, this generalization enables, for the first time, the discovery of low- and zero-barrier linear interpolation paths between independently trained Vision Transformers and GPT-2 models. Furthermore, our framework extends beyond pairwise alignment, to multi-model and width-heterogeneous settings, enabling alignment across architectures of different sizes. These results reveal deeper structure in the loss landscape and underscore the importance of symmetry-aware analysis for understanding model space geometry.",,计算,计算: 高效模型架构,计算: 该session提出了针对Transformer模型的广义线性模式连通性框架，揭示了模型空间的对称性和重参数化方式，能够帮助团队理解和预测大模型结构演进趋势，进而准确把握模型架构对计算系统的影响，解决其关注的模型架构演进驱动力和计算系统需求识别难题。
FRI 5 DEC,3:30-4:30,Oral Paper,  → On Linear Mode Connectivity of Mixture-of-Experts Architectures,https://neurips.cc/virtual/2025/oral/118036,,4:30 PM,"Linear Mode Connectivity (LMC) is a notable phenomenon in the loss landscapesof neural networks, wherein independently trained models have been observed tobe connected—up to permutation symmetries—by linear paths in parameter spacealong which the loss remains consistently low. This observation challenges classicalviews of non-convex optimization and has implications for model ensembling,generalization, and our understanding of neural loss geometry. Inspired by recentstudies on LMC in standard neural networks, we systematically investigate thisphenomenon within Mixture-of-Experts (MoE) architectures—a class of modelsknown for their scalability and computational efficiency, which combine traditionalneural networks—referred to as experts—through a learnable gating mechanism.We begin by conducting a comprehensive analysis of both dense and sparse gatingregimes, demonstrating that the symmetries inherent to MoE architectures arefully characterized by permutations acting on both the expert components and thegating function. Building on these foundational findings, we propose a matchingalgorithm that enables alignment between independently trained MoEs, therebyfacilitating the discovery of LMC. Finally, we empirically validate the presence ofLMC using our proposed algorithm across diverse MoE configurations—includingdense, sparse, and shared-expert variants—under a wide range of model settingsand datasets of varying scales and modalities. Our results confirm the existenceof LMC in MoE architectures and offer fundamental insights into the functionallandscape and optimization dynamics of deep learning models.",,计算; 计算,计算: 高效模型架构; 计算: 训推新范式,计算: 该session深入研究Mixture-of-Experts架构中的线性模式连通性（LMC），提供了对模型架构优化和训练动态的基础性理解，有助于团队理解大模型结构演进趋势及其对计算架构的影响，直接对应团队关注的模型架构对计算架构的深远影响和识别未来模型结构需求的难题。; 计算: Session提出的匹配算法和对MoE架构训练中模式连通性的分析，有助于团队理解不同训练范式下模型参数空间的关系和优化动态，能够为团队跟踪、理解和预测训练推理新范式的演进机理提供技术支持，解决团队关注的训推范式负载特征差异问题。
FRI 5 DEC,3:30-4:30,Oral Paper,  → Learning (Approximately) Equivariant Networks via Constrained Optimization,https://neurips.cc/virtual/2025/oral/118376,,4:30 PM,"Equivariant neural networks are designed to respect symmetries through their architecture, boosting generalization and sample efficiency when those symmetries are present in the data distribution. Real-world data, however, often departs from perfect symmetry because of noise, structural variation, measurement bias, or other symmetry-breaking effects. Strictly equivariant models may struggle to fit the data, while unconstrained models lack a principled way to leverage partial symmetries. Even when the data is fully symmetric, enforcing equivariance can hurt training by limiting the model to a restricted region of the parameter space. Guided by homotopy principles, where an optimization problem is solved by gradually transforming a simpler problem into a complex one, we introduce Adaptive Constrained Equivariance (ACE), a constrained optimization approach that starts with a flexible, non-equivariant model and gradually reduces its deviation from equivariance. This gradual tightening smooths training early on and settles the model at a data-driven equilibrium, balancing between equivariance and non-equivariance. Across multiple architectures and tasks, our method consistently improves performance metrics, sample efficiency, and robustness to input perturbations compared with strictly equivariant models and heuristic equivariance relaxations.",,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6D,https://neurips.cc/virtual/2025/session/122574,,4:30 PM,,,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Paper,  → A Snapshot of Influence: A Local Data Attribution Framework for Online Reinforcement Learning,https://neurips.cc/virtual/2025/oral/115686,,4:30 PM,"Online reinforcement learning (RL) excels in complex, safety-critical domains but suffers from sample inefficiency, training instability, and limited interpretability. Data attribution provides a principled way to trace model behavior back to training samples, yet existing methods assume fixed datasets, which is violated in online RL where each experience both updates the policy and shapes future data collection.In this paper, we initiate the study of data attribution for online RL, focusing on the widely used Proximal Policy Optimization (PPO) algorithm. We start by establishing alocalattribution framework, interpreting model checkpoints with respect to the records in the recent training buffer. We design two target functions, capturing agent action and cumulative return respectively, and measure each record's contribution through gradient similarity between its training loss and these targets. We demonstrate the power of this framework through three concrete applications: diagnosis of learning, temporal analysis of behavior formation, and targeted intervention during training. Leveraging this framework, we further propose an algorithm, iterative influence-based filtering (IIF), for online RL training that iteratively performs experience filtering to refine policy updates. Across standard RL benchmarks (classic control, navigation, locomotion) to RLHF for large language models, IIF reduces sample complexity, speeds up training, and achieves higher returns. Together, these results open a new direction for making online RL more interpretable, efficient, and effective.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session聚焦于在线强化学习中的数据归因框架和样本效率提升，直接对应温哥华云团队关注的强化学习在大模型微调中的实际问题，尤其是提升样本效率和训练性能，session中提出的局部数据归因和迭代影响过滤算法（IIF）为解决温哥华云团队难题提供了具体方法。; 诺亚: session内容涉及基于PPO算法的在线强化学习数据归因与训练优化，契合诺亚团队关注的强化学习及learning from experience训练框架，session提出的局部归因框架和迭代影响过滤算法可为诺亚团队在自博弈和经验学习中提升训练效率和模型解释性提供技术支持。
FRI 5 DEC,3:30-4:30,Oral Paper,  → 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities,https://neurips.cc/virtual/2025/oral/115732,,4:30 PM,"Scaling up self-supervised learning has driven breakthroughs in language and vision, yet comparable progress has remained elusive in reinforcement learning (RL). In this paper, we study building blocks for self-supervised RL that unlock substantial improvements in scalability, with network depth serving as a critical factor. Whereas most RL papers in recent years have relied on shallow architectures (around 2 -- 5 layers), we demonstrate that increasing the depth up to 1024 layers can significantly boost performance.Our experiments are conducted in an unsupervised goal-conditioned setting, where no demonstrations or rewards are provided, so an agent must explore (from scratch) and learn how to maximize the likelihood of reaching commanded goals.Evaluated on simulated locomotion and manipulation tasks, our approach increases performance on the self-supervised contrastive RL algorithm by $2\times$ -- $50\times$, outperforming other goal-conditioned baselines.Increasing the model depth not only increases success rates but also qualitatively changes the behaviors learned.",,温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session聚焦于自监督强化学习（self-supervised RL）中通过极深网络（1000层）提升性能，直接涉及强化学习的可扩展性和性能提升，能够为团队在提升RL样本效率、性能和可扩展性方面的难题提供新的网络架构和训练方法。; 诺亚: session研究了深度网络在无监督目标条件强化学习中的作用，涉及自博弈与learning from experience训练框架，能够为团队在强化学习和推理训练框架的研究提供技术思路，尤其是通过增加网络深度来提升RL表现的具体方法。
FRI 5 DEC,3:30-4:30,Oral Paper,  → Learning long range dependencies through time reversal symmetry breaking,https://neurips.cc/virtual/2025/oral/115363,,4:30 PM,"Deep State Space Models (SSMs) reignite physics-grounded compute paradigms, as RNNs could natively be embodied into dynamical systems. This calls for dedicated learning algorithms obeying to core physical principles,  with efficient techniques to simulate these systems and guide their design. We propose \emph{Recurrent Hamiltonian Echo Learning} (RHEL), an algorithm which provably computes loss gradients as finite differences of physical trajectories of non-dissipative, \emph{Hamiltonian systems}. In ML terms, RHEL only requires three ``forward passes'' irrespective of model size, without explicit Jacobian computation, nor incurring any variance in the gradient estimation. Motivated by the potential to implement our algorithm in non-digital physical systems, we first introduce RHEL in \emph{continuous time} and demonstrate its formal equivalence with the continuous adjoint state method.To facilitate the simulation of Hamiltonian systems trained by RHEL, we propose a \emph{discrete-time} version of RHEL which is equivalent to Backpropagation Through Time (BPTT) when applied to a class of recurrent modules which we call \emph{Hamiltonian Recurrent Units} (HRUs). This setting allows us to demonstrate the scalability of RHEL by generalizing these results to hierarchies of HRUs, which we call \emph{Hamiltonian SSMs} (HSSMs). We apply RHEL to train HSSMs with linear and nonlinear dynamics on a variety of time-series tasks ranging from mid-range to long-range classification and regression with sequence length reaching $\sim 50k$. We show that RHEL consistently matches the performance of BPTT across all models and tasks. This work opens new doors for the design of scalable, energy-efficient physical systems endowed with self-learning capabilities for sequence modelling.",,温哥华云,温哥华云: Embodied AI,温哥华云: Session提出的Recurrent Hamiltonian Echo Learning (RHEL)算法基于物理系统的动力学原理，适合实现非数字物理系统中的自学习序列建模，直接契合物理或具身AI领域对物理系统建模与学习算法的需求，能为团队在物理AI研究中提供高效、可扩展的学习方法。
FRI 5 DEC,3:30-4:30,Oral Session,Oral Session 6E,https://neurips.cc/virtual/2025/session/122575,,4:30 PM,,,nan,nan,nan
FRI 5 DEC,3:30-4:30,Oral Paper,  → KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction,https://neurips.cc/virtual/2025/oral/118742,,4:30 PM,"Transformer-based large language models (LLMs) cache context as key-value (KV) pairs during inference. As context length grows, KV cache sizes expand, leading to substantial memory overhead and increased attention latency. This paper introduces \textit{KVzip}, a query-agnostic KV cache eviction method enabling effective reuse of compressed KV caches across diverse queries. KVzip quantifies the importance of a KV pair using the underlying LLM to reconstruct original contexts from cached KV pairs, subsequently evicting pairs with lower importance. Extensive empirical evaluations demonstrate that KVzip reduces KV cache size by $3$-$4\times$ and FlashAttention decoding latency by approximately $2\times$, with negligible performance loss in question-answering, retrieval, reasoning, and code comprehension tasks. Evaluations include various models such as LLaMA3.1, Qwen2.5, and Gemma3, with context lengths reaching up to 170K tokens. KVzip significantly outperforms existing query-aware KV eviction methods, which suffer from performance degradation even at a 90\% cache budget ratio under multi-query scenarios.",,存储; 海思; 诺亚,存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,存储: Session介绍了KVzip，一种针对Transformer大模型推理中KV缓存的压缩与重用方法，直接涉及KV Cache的加载、卸载及调度优化，能够有效减少内存占用和推理延迟，契合该团队关注的多模型系统中KV Cache加载、卸载及调度的新变化难题。; 海思: Session提出的KVzip通过压缩KV缓存显著降低推理延迟，且支持长上下文推理，解决了长上下文推理中注意力复杂度过高和缓存管理难题，直接对应该团队关注的如何实现低延迟实时推理响应及长上下文推理的注意力复杂度优化。; 诺亚: KVzip针对长上下文（最高170K token）KV缓存的压缩与重用，解决了长序列推理中缓存膨胀和计算瓶颈问题，符合该团队关注的长序列架构优化及缓存与计算量优化方向。
FRI 5 DEC,3:30-4:30,Oral Paper,  → MokA: Multimodal Low-Rank Adaptation for MLLMs,https://neurips.cc/virtual/2025/oral/116048,,4:30 PM,"In this paper, we reveal that most current efficient multimodal fine-tuning methods are hindered by a key limitation: they are directly borrowed from LLMs, often neglecting the intrinsic differences of multimodal scenarios and even affecting the full utilization of all modalities. Inspired by our empirical observation, we argue that unimodal adaptation and cross-modal adaptation are two essential parts for the effective fine-tuning of MLLMs. From this perspective, we propose Multimodal Low-rank Adaptation (MokA), a multimodal-aware efficient fine-tuning strategy that takes multimodal characteristics into consideration. It compresses unimodal information by modality-specific parameters while explicitly enhancing cross-modal interaction, ensuring both unimodal and cross-modal adaptation. Extensive experiments cover three representative multimodal scenarios (audio-visual-text, visual-text, and speech-text), and multiple LLM backbones (LLaMA2, Qwen2, Qwen2.5-VL, etc). Consistent improvements indicate the efficacy and versatility of the proposed method. Ablation studies and efficiency evaluation are also conducted to fully asses our method. Overall, we think MokA provides a more targeted solution for efficient adaptation of MLLMs, paving the way for further exploration.",,海思; 诺亚,海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,海思: Session提出的MokA方法针对多模态大语言模型的高效微调，特别是通过模态特异性参数压缩和跨模态交互增强，直接对应海思团队关注的多模态条件融合延迟大和统一特征空间以实现快速条件生成的难题。MokA的多模态低秩适配策略可为海思团队在保持对话质量与上下文一致性前提下，实现低延迟实时推理提供有效技术思路。; 诺亚: 该Session聚焦多模态大语言模型（MLLMs）的高效微调，涉及视觉、语音、文本等多模态信息的联合适配，契合诺亚团队关于多模态长文本推理计算瓶颈的关注。MokA通过显式增强跨模态交互，有助于解决多模态长序列模型在输入范式和计算效率上的挑战，提供了针对多模态长序列模型演进的具体技术方案。
FRI 5 DEC,3:30-4:30,Oral Paper,  → ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism,https://neurips.cc/virtual/2025/oral/117338,,4:30 PM,"Multimodal large language models (MLLMs) extend LLMs to handle images, videos, and audio by incorporating feature extractors and projection modules. However, these additional components—combined with complex inference pipelines and heterogeneous workloads—introduce significant inference overhead. Therefore, efficiently serving MLLMs remains a major challenge. Current tightly coupled serving architectures struggle to distinguish between mixed request types or adapt parallelism strategies to different inference stages, leading to increased time-to-first-token (TTFT) and poor resource utilization. To address this, we introduce Elastic Multimodal Parallelism (EMP), a new serving paradigm that elastically adapts to resource heterogeneity across request types and inference stages. Building upon EMP, we develop ElasticMM, an MLLM serving system that (1) separates requests into independent modality groups with dynamic resource allocation via a modality-aware load balancer; (2) decouples inference stages and enables parallelism adjustment and adaptive scaling via elastic partition scheduling; and (3) improves inference efficiency through unified multimodal prefix caching and non-blocking encoding. Experiments on diverse real-world datasets show that ElasticMM outperforms state-of-the-art (SOTA) serving systems, reducing TTFT by up to 4.2 × and achieving 3.2–4.5 × higher throughput while meeting service-level objectives (SLOs).",,存储; 海思; 计算; 诺亚,存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速; 计算: 前沿应用负载; 诺亚: 大模型长序列，多模态长序列,存储: Session介绍了Elastic Multimodal Parallelism (EMP)和ElasticMM系统，通过动态资源分配、弹性调度和多模态推理阶段的并行调整，显著提升多模态大模型推理效率，直接对应该团队关注的多模型系统中模型加载、卸载及调度的新变化，提供了具体的资源调度和负载均衡技术方案。; 海思: Session聚焦多模态大语言模型推理的低延迟和高吞吐量，提出了统一多模态前缀缓存和非阻塞编码技术，有助于解决该团队关注的多模态条件融合延迟大和实时推理响应的难题，提供了具体的推理加速和资源弹性管理方法。; 计算: Session针对多模态大模型推理中的异构请求和复杂推理阶段，提出了弹性并行和动态资源分配机制，直接对应该团队关注的多模态模型应用负载快速演进及其对计算架构的新诉求，提供了软硬件协同优化的思路。; 诺亚: Session提出了多模态推理阶段的解耦和弹性调度，结合多模态前缀缓存技术，能够有效缓解多模态长序列推理中的计算瓶颈，契合该团队关注的多模态长文本推理计算瓶颈问题，提供了具体的推理效率提升方案。
SAT 6 DEC,8 a.m.,Workshop,Structured Probabilistic Inference and Generative Modeling,https://neurips.cc/virtual/2025/workshop/109570,,5:00 PM,,"Overview: The NeurIPS 2025 Workshop on Structured Probabilistic Inference & Generative Modeling focuses on the theory, methodology, and application of structured probabilistic inference and generative modeling. The workshop aims to address challenges in probabilistic methods, especially when applied to highly structured data, and to foster collaboration and discussion among experts from academia and industry. The event will explore the intersection of probabilistic inference and foundation models, providing a platform for discussing applications and challenges in encoding domain knowledge. | Research Interests: Generative methods for graphs, 3D, time series, text, video, and other structured modalities, Probabilistic inference in models for reward fine-tuning, alignment, acceleration, watermarking, Scaling and accelerating inference and generative models, Uncertainty quantification in AI systems, Applications in sampling, optimization, decision making, Applications and practical implementations of existing methods to areas in science, Empirical analysis comparing different architectures for a given data modality and application, Relevance of probabilistic inference in the era of foundation models",温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session关注于probabilistic inference在reward fine-tuning和alignment中的应用，直接对应该团队在Reinforcement learning应用于VLMs/LLMs的研究，能为提升sample efficiency和scalability提供方法论支持。; 诺亚: Session涉及probabilistic inference和generative modeling在reward fine-tuning和latent reasoning中的应用，契合该团队在自博弈与learning from experience训练框架及latent reasoning的研究需求。
SAT 6 DEC,8 a.m.,Workshop,Reliable ML from Unreliable Data,https://neurips.cc/virtual/2025/workshop/109580,,5:00 PM,"Distributions shift, chatbots get jail‑broken, users game algorithms — how do we build reliable machine learning when data are missing, corrupted, or strategically manipulated?This workshop bridges theory and practice to tackle these challenges, bringing together researchers working on distribution shift, adversarial robustness, and strategic behaviour to chart principled yet deployable solutions for Reliable ML from Unreliable Data.","Overview: The Reliable ML 2025 workshop, held at NeurIPS 2025 in San Diego, focuses on developing reliable machine learning systems from unreliable data. It addresses challenges such as distribution shifts, adversarial robustness, and strategic behavior in socio-technical systems. The workshop aims to bridge theory and practice by bringing together researchers to propose principled and deployable solutions for robust and reliable machine learning under imperfect data conditions. | Research Interests: Distribution shift and transfer learning, Adversarial robustness and defenses, Strategic behavior in socio-technical systems, Learning with missing or biased data, Causal inference beyond overlap, with confounders, or with errors, LLM safety and alignment, Robustness in interactive environments",多伦多云; 温哥华云,多伦多云: AI Agent; 温哥华云: Reinforcement fine tuning (RFT),多伦多云: Session关注于可靠机器学习在不可靠数据环境下的应用，特别强调战略行为和模型行为的可靠性，与团队关注的提升Agent行为的可靠性及管控校验直接相关。; 温哥华云: Session涉及分布式偏移、鲁棒性和策略行为，能为团队在强化学习微调中解决理论到生产的差距、提升样本效率和模型可靠性提供理论和实践支持。
SAT 6 DEC,8 a.m.,Workshop,GenProCC: 1st Workshop on Generative and Protective AI for Content Creation,https://neurips.cc/virtual/2025/workshop/109545,,5:00 PM,"Recent advancements in generative AI (GenAI) have empowered machines to create high-quality content across diverse modalities - text, image, audio, and video - with impressive fluency and creativity. From GPT-4o and Stable Diffusion to Sora and MMAudio, the explosion of X-to-X generation (e.g., text-to-image, video-to-audio) is unlocking new frontiers in science, education, entertainment, and art.While GenAI has shown significant potential in creative applications (e.g., music, films, arts), these breakthroughs also raise pressing concerns related to safety, copyright, and ethical use. Generative models can be exploited to spread misinformation, violate intellectual property rights, or diminish human agency in creative processes. As such, there is an increasing need to balance innovation with protection, ensuring that AI-powered creative tools are used responsibly and ethically.This workshop, GenProCC: Generative and Protective AI for Content Creation, brings together researchers, creators, and practitioners at the intersection of content generation and IP protection. By uniting the generative AI and creator communities, the GenProCC workshop aims to explore the latest advances, challenges, and opportunities in the rapidly evolving field.","Overview: The GenProCC NeurIPS 2025 Workshop focuses on the intersection of generative and protective AI for content creation. It aims to explore the advancements in generative AI technologies that enable machines to create high-quality content across various modalities such as text, image, audio, and video. The workshop addresses the potential of these technologies in creative applications while also highlighting the ethical, safety, and copyright concerns they raise. The event seeks to balance innovation with protection, ensuring responsible and ethical use of AI-powered creative tools. | Research Interests: Controllable Generative AI for Content Creation, Protective AI Approaches for Content Creation, Creative Practices with Generative AI, Controllable X-to-X generation, Interactive or iterative generation pipelines, Evaluations and benchmarks for controllability, Applications of controllability/protection in creative practices, Digital watermarking, fingerprinting, and provenance tracking, Benchmarks for evaluating protection in generative systems, Case studies and design research for content creation, Human-in-the-loop approaches for real-world GenAI creation workflows, Emerging applications of GenAI in content creation",CBG; 海思,CBG: 3DAIGC; 海思: 大语言模型和扩散模型的加速,CBG: Session聚焦于多模态内容生成（文本、图像、音频、视频）及其控制与保护，CBG团队关注视频中运动物体分割、3D/4D稀疏重建、相机轨迹控制的视频生成及长视频生成一致性，均属于内容生成和控制范畴，GenProCC中关于可控生成和多模态生成技术及评估方法能为其视频生成一致性和控制难题提供技术思路。; 海思: Session涉及多模态条件生成（文本、图像、音频、视频）及其可控性，海思团队关注多模态条件融合延迟及长上下文推理复杂度问题，GenProCC中关于多模态生成和交互式生成管线的研究可为其多模态融合和实时推理提供算法和系统设计参考。
SAT 6 DEC,8 a.m.,Workshop,What Makes a Good Video: Next Practices in Video Generation and Evaluation,https://neurips.cc/virtual/2025/workshop/109548,,5:00 PM,"This workshop aims to explore how real-world advances in video generation increasingly rely on forwardlooking evaluation frameworks and to collaboratively shape the next generation of high-quality video synthesis. Through a combination of invited talks, academic presentations, and expert discussions featuring leading voices from both academia and industry, the workshop bridges academic foundations and industrial insights across the modeling, evaluation, and deployment of video generation. We welcome contributions from computer vision, generative modeling, video-language learning, evaluation methodology, and human-centered AI to shape the next generation of high-quality video synthesis collaboratively.","Overview: The 'What Makes a Good Video: Next Practices in Video Generation and Evaluation' workshop at NeurIPS 2025 aims to explore the evolution of video generation models. It focuses on understanding the limitations of current video models and identifying future research directions. The workshop features discussions on video generation, understanding, benchmarks, and applications, with insights from experts in academia and industry. | Research Interests: Video Generation Models, Benchmarks & Evaluation, Applications",CBG,CBG: 3DAIGC,CBG: 该session聚焦视频生成与评估，CBG团队关注视频中运动物体分割、基于单目视频的3D/4D稀疏重建、相机轨迹控制的视频生成及长视频生成一致性，均与视频生成模型及其评估密切相关。session中关于视频生成模型的最新实践和评估方法可直接为其难题提供解决思路。
SAT 6 DEC,8 a.m.,Workshop,ML x OR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making,https://neurips.cc/virtual/2025/workshop/109555,,5:00 PM,"Much of traditional decision-making science is grounded in the mathematical formulations and analyses of structured systems to recommend decisions that are optimized, robust, and uncertainty-aware. This scientific approach, rooted in the field of Operations Research (OR), has evolved through decades of advancements in stochastic modeling, computational simulation and optimization, and exhibits key strengths in methodological rigor and uncertainty encoding. On the other hand, recent advances in the AI/ML space have eschewed this model-based paradigm and increasingly embraced, to great success, model-free algorithmic design frameworks. This workshop, which is the first NeurIPS workshop explicitly themed and structured on ML-OR synergization, aspires to present recent developments, challenges and emerging research to accelerate ML-OR synthesis. By integrating ML into established OR methodologies, we have the opportunities to produce more data-centric and adaptive solutions for complex decision-making tasks that could propel, in a much faster-paced manner, the frontier of ""optimality"" across many relevant applications. Concomitantly, the goal is also to explore how model-based principled OR approaches can help alleviate issues revolving around ""black box"" systems, and provide paths to enhance interpretability, trust, and performance analysis.","Overview: The ML×OR Workshop at NeurIPS 2025 focuses on the integration of Machine Learning (ML) and Operations Research (OR) to enhance uncertainty-aware decision-making. This interdisciplinary workshop aims to explore the synergy between ML and OR, presenting recent developments, discussing challenges, and highlighting emerging research opportunities in data-centric decision-making. The workshop encourages contributions from researchers and practitioners across various fields and includes keynote talks, panel discussions, and poster sessions. | Research Interests: Embedding OR modeling insights into ML, Uncertainty mitigation at the interface of data, model, and decision, Sequential decision-making and online learning from an OR perspective, Generative AI for decision-making",温哥华云; 多伦多云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session强调ML与OR结合以实现不确定性感知的决策制定，特别关注序贯决策和在线学习，这与温哥华云团队在强化学习微调（Reinforcement fine tuning）中解决理论到生产的差距、提升样本效率和性能的需求高度契合。ML×OR的数学基础和不确定性建模方法能为其提供理论支持和优化方案。; 多伦多云: Session中提到通过ML与OR的融合提升决策的最优性和鲁棒性，特别关注序贯决策和生成式AI辅助决策，这与多伦多云团队在AI Agent评估准确性、行为可靠性及自主学习优化机制的难题直接相关。该session的模型基OR方法可帮助提升Agent行为的解释性、信任度及性能分析。; 诺亚: Session强调将ML与传统OR方法结合，提升不确定性感知的决策能力，特别涉及序贯决策和基于经验学习，这与诺亚团队在自博弈与基于经验学习的训练框架及潜在推理的研究方向高度相关。该session可为其提供数学基础和方法论支持，促进RL与OR方法的融合。
SAT 6 DEC,8 a.m.,Workshop,Deep Learning for Code in the Agentic Era,https://neurips.cc/virtual/2025/workshop/109562,,5:00 PM,"Deep learning for code has progressed from focused tasks—such as completion, repair, synthesis, and explanation to tackling complex, end-to-end software–engineering problems.  A key recent breakthrough is the rise of coding agents. Unlike single-shot models, these systems plan, reason, explore, and invoke external tools to assist throughout the software-development lifecycle: adding features, refactoring, debugging, finding vulnerabilities, optimizing performance, summarizing code, and answering repository-level questions.  Their growing versatility demands rigorous evaluation and a deeper understanding of their capabilities, limits, risks, and broader social impact.Building on momentum from both academia and industry (e.g. Google, OpenAI, Anthropic, SWE-Agent, OpenHands), we propose the 4th Deep Learning for Code (DL4C) workshop with a dedicated focus on coding agents. This workshop will provide a timely forum where researchers and practitioners can design and stress-test robust coding agents, discover novel applications and emergent behaviors, establish principled benchmarks and evaluation methods, study human–agent collaboration at scale, and advance the responsible, safe deployment of autonomous coding tools.","Overview: The 4th Deep Learning for Code (DL4C) Workshop, titled 'Deep Learning For Code in the Agentic Era,' is scheduled to take place at NeurIPS 2025 in San Diego, CA. This workshop follows three successful previous installations at ICLR in 2022, 2023, and 2025. The event aims to bring together researchers and practitioners to discuss advancements and challenges in applying deep learning techniques to code-related tasks. | Research Interests: Deep Learning, Code Analysis, Machine Learning for Software Engineering, AI in Software Development",多伦多云; 存储; 计算,多伦多云: AI Agent; 存储: 单/多模型推理; 计算: 前沿应用负载,多伦多云: Session聚焦于coding agents的设计、评估和优化，直接对应团队关注的AI Agent评估准确性、行为可靠性及持续优化机制，提供了设计和评测agent的前沿技术和方法。; 存储: Session强调coding agents调用外部工具和多模型系统，涉及Agentic AI系统中RAG和多模型调度，正好对应团队关于Agentic AI系统中存储访问模式及多模型加载卸载调度的难题。; 计算: Session关注agentic时代的深度学习代码应用，涉及Agentic和多模态模型的复杂应用负载，契合团队对agentic和多模态模型应用负载演进及计算架构诉求的研究。
SAT 6 DEC,8 a.m.,Workshop,Differentiable Learning of Combinatorial Algorithms: From Theory To Practice,https://neurips.cc/virtual/2025/workshop/109535,,5:00 PM,,,nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG @ NeurIPS’25),https://neurips.cc/virtual/2025/workshop/109576,,5:00 PM,"The field of wireless communications and networking is undergoing a paradigm shift, driven by the growing potential of Artificial Intelligence (AI) and Machine Learning (ML) to redefine traditional system design principles. This workshop aims to catalyze interest and foster collaboration between the AI/ML and wireless communications communities. The timing of this workshop is especially significant, as the next-generation (NextG) wireless standardization efforts (such as 6G and WiFi 9) are just getting started, with AI-native technologies expected to play a central role across all aspects of the wireless ecosystem – from radio access to network management and edge intelligence. NextG represents a foundational shift in global infrastructure, enabling ultra-fast, low-latency, and intelligent connectivity that will power future applications in AI, robotics, immersive environments, and autonomous systems. These technologies offer unprecedented opportunities to both drive and benefit many applications, from healthcare and transportation to industrial automation and environmental monitoring. The economic and societal implications are vast: NextG networks will underlie trillions in global GDP impact, bridge digital divides, and shape how billions of people interact with technology and each other in the decades to come.Despite the clear promise, a significant disconnect exists between the AI/ML and wireless research communities. AI/ML experts often lack an understanding of the unique physical, algorithmic, and architectural constraints inherent in wireless systems, while wireless researchers tend to adopt generic, off-the-shelf AI/ML models that are not optimized for the intricacies of wireless environments. Wireless environments are inherently dynamic, high-dimensional, and partially observable. These unique characteristics make them ideal testbeds for developing robust learning algorithms, particularly in areas like online learning, reinforcement learning, and in-context learning. At the same time, AI/ML techniques are becoming essential for managing the growing complexity of modern wireless networks, including resource allocation, interference mitigation, and cross-layer optimization. Bridging the gap between the two communities is not only necessary for meaningful technological advances but also critical for realizing the full societal impact of intelligent wireless systems.This workshop aims to bring together researchers and practitioners at the intersection of artificial intelligence (AI), machine learning (ML), and wireless to address the unique challenges and opportunities posed by Next-Generation (NextG) wireless systems. As the 6G era begins to take shape, AI-native designs have emerged as a cornerstone of wireless innovation, with the potential to transform the performance, efficiency, and adaptability of communication systems. The integration of AI/ML is poised to influence every layer of the network stack, from physical-layer signal processing to network control and resource management.","Overview: The AI4NextG workshop at NeurIPS 2025 focuses on the integration of Artificial Intelligence (AI) and Machine Learning (ML) in next-generation wireless communications and networking. The workshop aims to bridge the gap between AI/ML and wireless research communities to address the challenges and opportunities posed by Next-Generation (NextG) wireless systems, such as 6G and WiFi 9. It seeks to foster collaboration and innovation in AI-native designs that can transform the performance, efficiency, and adaptability of communication systems. | Research Interests: AI-native protocol and architecture design for 6G and WiFi 8/9, Reinforcement learning for dynamic spectrum access and resource allocation, Gen AI and foundation models for physical-layer communication tasks, Online learning and adaptation under real-time and uncertain wireless environments, Data-efficient learning and representation for sparse, high-dimensional wireless signals, AI for network planning, self-optimization, and fault prediction in wireless networks, Cross-layer ML-driven optimizations for joint sensing, control, and communication, Co-design of hardware and ML algorithms for low-power and real-time wireless AI, Trustworthy and explainable AI in high-stakes communication systems",DCN; 温哥华云,DCN: Network4AI 与 AI4Network; 温哥华云: Reinforcement fine tuning (RFT),DCN: 该session聚焦于AI/ML与无线通信网络的融合，特别是网络管理、资源分配和跨层优化，直接对应DCN团队关注的数据中心网络基础设施优化及AI训练推理对网络的影响，能为其网络优化与演进提供AI驱动的技术思路。; 温哥华云: Session强调强化学习在动态频谱访问和资源分配中的应用，适合温哥华云团队在强化学习样本效率和性能提升方面的难题，尤其是在无线环境下的在线学习和适应性优化。
SAT 6 DEC,8 a.m.,Workshop,"The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance",https://neurips.cc/virtual/2025/workshop/109566,,5:00 PM,"Generative AI (GenAI) has emerged as a transformative force in healthcare, yet public trust remains limited due to safety concerns and policy misalignment. Build- ing on last year’s successful GenAI4Health workshop, the field has rapidly evolved from exploratory research to real-world clinical deployments, accompanied by FDA regulatory involvement and expanding global governance frameworks. This second workshop convenes machine learning researchers, healthcare professionals, and policy experts to address the critical intersection of GenAI innovation and regula- tory compliance in health applications. We will examine trustworthiness challenges in large language models and multimodal foundation models, explore mitigation strategies, and foster dialogue between technical and policy communities. Our goal is to advance safe, effective, and ethically-compliant GenAI integration in healthcare systems, improving patient outcomes and clinical research capabilities.","Overview: The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance (GenAI4Health2025) is a workshop held at NeurIPS 2025 in San Diego, California. It aims to bring together AI4Health practitioners, safety researchers, and policy experts to address critical challenges in developing robust and policy-compliant Generative AI technologies for healthcare. The workshop will cover topics such as generative AI applications in healthcare, AI trust and reliability in medical settings, policy compliance and regulatory frameworks, clinical AI implementation strategies, and AI safety in healthcare environments. | Research Interests: Generative AI applications in healthcare, AI trust and reliability in medical settings, Policy compliance and regulatory frameworks, Clinical AI implementation strategies, AI safety in healthcare environments",nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,CauScien: Uncovering Causality in Science,https://neurips.cc/virtual/2025/workshop/109550,,5:00 PM,,"Overview: The CauScien Workshop, part of NeurIPS 2025, is focused on uncovering causality in science. It aims to bridge the gap between theoretical causal reasoning and practical application in scientific research. The workshop fosters collaboration across various disciplines, including ecology, biology, and social sciences, to explore the integration of causal inference with domain expertise and real-world data. The event will address the challenges of applying causal learning techniques to accelerate scientific discovery and promote a bottom-up research paradigm. | Research Interests: Causal inference in applied science, Integration of causality with domain expertise, Causal learning techniques, Translational gap in causal reasoning, Causal benchmark tasks, Collaboration between domain experts and machine learning researchers, Causality in experimental design and planning",nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,Algorithmic Collective Action,https://neurips.cc/virtual/2025/workshop/109567,,5:00 PM,"The study of collective action has a long history in economics and sociology as a way for groups of people to impact markets and the political arena. Algorithmic collective action focuses on the study of such coordinated efforts in algorithmically-mediated sociotechnical systems. How can participants of AI systems coordinate towards socially beneficial outcomes? We offer a platform to discuss new ideas and help define the foundational research directions for this emerging topic through interdisciplinary discussions between core ML researchers, scholars from the social sciences, community stakeholders and advocates.","Overview: The Algorithmic Collective Action workshop is co-located with NeurIPS 2025 and will take place on December 6 at the San Diego Convention Center. The workshop focuses on exploring collective strategies for shaping outcomes in socio-technical systems from a grassroots perspective. It invites contributions that examine algorithmic collective action through various lenses, including machine learning, statistics, optimization, economics, and the humanities. The goal is to advance understanding of how coordinated efforts can influence the development and deployment of AI systems. | Research Interests: Algorithmic collective action, Socio-technical systems, Machine learning, Statistics, Optimization, Economics, Humanities, AI system development, AI system deployment",多伦多云,多伦多云: AI Agent,多伦多云: Session聚焦算法集体行动及AI系统中参与者如何协调以实现社会效益，直接关联AI Agent团队关注的Agent行为可靠性、管控与持续优化机制，提供跨学科视角和算法工具，有助于提升Agent的协调与规划能力。
SAT 6 DEC,8 a.m.,Workshop,"Lock-LLM Workshop: Prevent Unauthorized Knowledge Use from Large Language Models - Deep Dive into Un-Distillate, Un-Finetunable, Un-Compressible, Un-Editable, and Un-Usable",https://neurips.cc/virtual/2025/workshop/109568,,5:00 PM,"Large Language Models (LLMs) have emerged as transformative tools across research and industry, revolutionizing how we interact with information. However, their immense capabilities bring critical security challenges—the same features that drive innovation can be exploited for malicious purposes through unauthorized distillation, fine-tuning, compression, or editing. These vulnerabilities pose severe threats, including intellectual property theft, the generation of sophisticated disinformation, the bypass of safety alignments, and the erosion of user trust in AI systems.This workshop aims to bring together researchers and practitioners from academia and industry who are advancing the frontiers of LLM security and protection. We seek to confront the unauthorized use of LLMs head-on by exploring novel and robust mechanisms designed to make these models inherently resistant to exploitation while maintaining their beneficial capabilities. The workshop also hosts the 2025 TrustAI Rising Star Award.Topics of interest include, but are not limited to:1. Un-Distillable LLMs: Preventing unauthorized model replication and intellectual property theft2. Un-Finetunable LLMs: Resisting malicious parameter updates and behavior alterations3. Un-Compressible LLMs: Maintaining model integrity against unauthorized compression4. Un-Editable LLMs: Safeguarding against knowledge tampering and misinformation injection5. Un-Usable LLMs: Ensuring traceability and preventing misuse through watermarking and verification","Overview: The Lock-LLM workshop, part of NeurIPS 2025, focuses on addressing the security challenges posed by Large Language Models (LLMs). These models, while transformative, are vulnerable to unauthorized use such as distillation, fine-tuning, compression, and editing, which can lead to intellectual property theft, misinformation, and erosion of trust. The workshop aims to bring together researchers and practitioners to explore robust mechanisms that make LLMs resistant to exploitation while preserving their beneficial capabilities. The event also includes the 2025 TrustAI Rising Star Award to honor early-career researchers in the field. | Research Interests: Un-Distillable LLMs, Un-Finetunable LLMs, Un-Compressible LLMs, Un-Editable LLMs, Un-Usable LLMs, Theoretical Foundations, Evaluation Frameworks, Real-world Applications, Ethical and Societal Implications",nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,AI4Mat-NeurIPS-2025: NeurIPS 2025 Workshop on AI for Accelerated Materials Design,https://neurips.cc/virtual/2025/workshop/109538,,5:00 PM,"AI4Mat-NeurIPS-2025 explores applications of artificial intelligence (AI) to materials via: 1. AI-Guided Materials Design; 2. Automated Chemical Synthesis; 3. Automated Material Characterization. AI4MatNeurIPS-2025 emphasizes structured, expert-driven dialogue on making advanced machine learning more impactful for real-world materials discovery. To that end, AI4Mat-RLSF (Research Learning from Speaker Feedback) creates a new structured discussion format where spotlight presenters receive curated, in-depth feedback from invited discussants. Further, the AI4Mat Frontiers & Benchmarking session brings together a diverse and distinguished set of speakers to critically examine current benchmarks, present state-of-the-art methods, and identify emerging opportunities and current limitations in AI-driven materials design.","Overview: The AI4Mat workshop at NeurIPS 2025 is a platform for AI researchers and material scientists to collaborate on AI-driven materials discovery and development. It aims to foster interdisciplinary discussions and address challenges in automated materials discovery, including AI-guided design, synthesis, and characterization. The workshop has been a leading venue for exchanging ideas since its inception at NeurIPS 2022, and it continues to build a global research community focused on AI-enabled materials innovation. | Research Interests: AI-driven materials discovery, Automated materials design, AI-guided synthesis, Automated material characterization, Foundation models in materials science, Representation learning for materials, Benchmarking in machine learning for materials science",nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,AI for non-human animal communication,https://neurips.cc/virtual/2025/workshop/109586,,5:00 PM,"The past few years have seen an unprecedented surge in both the availability of bioacoustic data and the sophistication of AI/machine learning models. This convergence presents a unique window of opportunity to revolutionize our understanding of animal communication and biodiversity. However, achieving this requires a conscious effort to integrate the disciplines of AI/Machine Learning and Ethology.    This workshop will explore the intersection of artificial intelligence (AI) and bioacoustics, aiming to address challenges in processing complex bioacoustic data and interpreting animal signals in order to advance our understanding of non-human animal communication. Join us for a poster session, keynote talks and a panel discussion as we explore key opportunities to use AI to decipher animal languages and thus deepen our understanding of the natural world.","Overview: The AI for Non-Human Animal Communication NeurIPS 2025 Workshop aims to explore the intersection of artificial intelligence and bioacoustics to advance the understanding of non-human animal communication. The workshop will address challenges in processing complex bioacoustic data and interpreting animal signals, with the goal of revolutionizing our understanding of animal communication and biodiversity. It will feature a poster session, keynote talks, and a panel discussion. | Research Interests: Bioacoustic data processing, AI and machine learning models, Animal communication, Biodiversity, Multimodal learning, Transfer learning, Large-language models, Unsupervised, self-supervised, or supervised models, Ecological impact and conservation monitoring, Communication and cognition, Linguistics, Information encoding, Ethics in AI",nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET),https://neurips.cc/virtual/2025/workshop/109542,,5:00 PM,"Recent progress in reinforcement learning (RL) has powered breakthroughs in various real-world problems, gathering considerable attention and investment. However, it has also exposed a significant gap between theoretical and experimental developments.RL theory has grown significantly in the past two decades. Research has characterized the inherent difficulty of various settings and has designed a wide variety of algorithms to reach optimal performances. Furthermore, a huge leap has been made in understanding how to handle large state spaces using function approximation techniques, identifying key structural properties that enable efficient learning.Despite theoretical guarantees, applying RL algorithms to complex problems faces challenges. Theoretical algorithms often focus on simplified settings, making them hard to apply to real-world complexities. Furthermore, optimizing for worst-case scenarios, which include unlikely situations, can lead to algorithms that perform poorly on practical tasks. Yet, while specialized algorithms offer empirical success, they might not translate to other problems due to their specific design, and the reliance on heuristics and engineering fixes further widens the gap between theory and practice.A prominent area that has seen a surge of interest in RL is generative language modeling. Pre-training these models can be viewed as a form of imitation learning, while post-training typically implements RL algorithms for purposes like instruction tuning with RL from human feedback or enhancing reasoning capabilities. While these successes make the practical utility of RL undeniable, the RL community finds itself at a crossroads. The algorithms employed are frequently variants of classical methods, and exploring beyond these presents a key challenge. Conversely, the success of these models prompts new questions for RL theory, suggesting that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions.Following the success of the ICML 2024 edition, the Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) aims to bridge this discrepancy and promote collaboration. By bringing together experts from both sides, we want to facilitate meaningful discussions and draw a path for future RL research. Motivated by the take-home messages from the previous edition, we seek to encourage: (i) theorists to ask experimentalists for concrete problems to solve, and (ii) experimentalists to seek theoretical guidance on how to approach these problems.","Overview: The Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) Workshop at NeurIPS 2025 aims to bridge the gap between theoretical and experimental developments in reinforcement learning (RL). The workshop will feature a panel discussion on the current state of RL, an idea track for problem submissions, and a research track for solution submissions. The event will bring together researchers to foster collaboration and explore new paradigms in RL, particularly focusing on leveraging pre-trained models over traditional learning methods. | Research Interests: Reinforcement Learning, Theoretical and Experimental Developments in RL, Function Approximation Techniques, Large State Spaces, Pre-trained Models, Instruction Tuning with RL, Human Feedback in RL, Enhancing Reasoning Capabilities | Key Findings: The workshop highlights the significant gap between theoretical and experimental RL developments and suggests that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions.",温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: 该session聚焦于强化学习理论与实验之间的差距，特别强调利用预训练模型进行RL微调，这与团队关注的VLMs/LLMs的强化学习微调密切相关，能够为提升样本效率、性能和可扩展性等难题提供理论指导和实践经验。; 诺亚: session中提到的强化学习理论与实验结合、利用预训练模型替代传统从零学习的框架，直接对应团队在自博弈与learning from experience训练框架以及latent reasoning方面的研究需求，有助于解决其强化学习相关难题。
SAT 6 DEC,8 a.m.,Workshop,The First Workshop on Efficient Reasoning,https://neurips.cc/virtual/2025/workshop/109556,,5:00 PM,"Recent progress in large reasoning models (LRMs), like OpenAI o1 and Deepseek R1, has been pivotal for tackling complex applications, from mathematical and code reasoning to advanced symbolic and agentic planning. Their success often relies on test-time scaling, which involves increasing the generation length or depth. However, these approaches incur significant efficiency bottlenecks during training and inference. To overcome these limitations, further advancements are needed in data, algorithms, and systems applicable across various domains, as exemplified by work such as s1, Z1, and verl. The proposed workshop will bring together researchers and practitioners to rethink efficient reasoning under tight compute, memory, latency, throughput, and cost budgets, with the goal of translating theoretical breakthroughs into practical, deployable solutions.","Overview: The 1st Workshop on Efficient Reasoning at NeurIPS 2025 focuses on advancing large reasoning models (LRMs) to tackle complex applications efficiently. The workshop aims to address efficiency bottlenecks in training and inference by bringing together researchers and practitioners to explore data, algorithms, and systems that can operate under tight compute, memory, latency, throughput, and cost constraints. The goal is to translate theoretical breakthroughs into practical, deployable solutions. | Research Interests: Dataset Curation, Algorithmic Innovation, System Deployment, Application of LRMs in resource-constrained scenarios, Efficient training algorithms, Efficient inference methods, Dynamic KV-cache placement, Quantized graph execution, On-device knowledge distillation",存储; 海思; 诺亚; 诺亚,存储: 单/多模型推理; 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列; 诺亚: 大模型后训练Reasoning，RL,存储: Session关注于高效推理和推理中KV Cache的动态管理，团队难题涉及多模型系统中KV Cache加载、卸载及调度，session中提到的动态KV-cache placement和高效推理方法能直接为该团队提供解决思路。; 海思: Session强调在资源受限环境下实现高效推理，团队关注低延迟实时推理和长上下文推理的效率瓶颈，session中关于稀疏注意力、分块缓存及高效推理算法的探讨与团队难题高度契合。; 诺亚: Session关注长序列推理的效率瓶颈及模型内存和计算优化，团队难题涉及长序列架构演化、缓存与计算优化，session中关于高效推理和内存管理的内容能为其提供具体技术支持。; 诺亚: Session聚焦于大模型推理效率及推理算法创新，团队关注后训练推理和latent reasoning，session中提到的算法创新和推理效率提升可为其后训练推理框架和自博弈训练提供方法论支持。
SAT 6 DEC,8 a.m.,Workshop,UniReps: Unifying Representations in Neural Models,https://neurips.cc/virtual/2025/workshop/109553,,5:00 PM,"When, how and why do different neural models learn the same representations?New findings in neuroscience and artificial intelligence reveal a shared pattern: whether in biological brains or artificial models, different learning systems tend to create similar representations when subject to similar stimuli.The emergence of these similar representations is igniting a growing interest in the fields of neuroscience and artificial intelligence, with both fields offering promising directions for their theoretical understanding. These include analyzing the learning dynamics in neuroscience and studying the problem of identifiability in the functional and parameter space in artificial intelligence.While the theoretical aspects already demand investigation, the practical applications are equally compelling: aligning representations allows for model merging, stitching and reuse, while also playing a crucial role in multi-modal scenarios. Furthermore, studying the features that are universally highlighted by different learning processes brings us closer to pinpoint the invariances that naturally emerge from learning models, possibly suggesting ways to enforce them.The objective of the workshop is to discuss theoretical findings, empirical evidence and practical applications of this phenomenon, benefiting from the cross-pollination of different fields (ML, Neuroscience, Cognitive Science) to foster the exchange of ideas and encourage collaborations.In conclusion, our primary focus is to delve into the underlying reasons, mechanisms, and extent of similarity in internal representations across distinct neural models, with the ultimate goal of unifying them into a single cohesive whole.","Overview: The UniReps Workshop focuses on the unification of representations in neural models, exploring how and why different neural models, whether biological or artificial, tend to learn similar representations when exposed to similar stimuli. The workshop aims to discuss theoretical findings, empirical evidence, and practical applications of this phenomenon, encouraging cross-disciplinary collaboration among fields such as machine learning, neuroscience, and cognitive science. | Research Interests: Unifying representations in neural models, Learning dynamics in neuroscience, Identifiability in artificial intelligence, Model merging and reuse, Multi-modal scenarios, Invariances in learning models | Key Findings: The workshop highlights the shared pattern of similar representations emerging in different learning systems, both biological and artificial, when exposed to similar stimuli. This phenomenon is of growing interest in neuroscience and artificial intelligence, with potential applications in model merging, stitching, and reuse, as well as in multi-modal scenarios.",海思; 诺亚,海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列,海思: Session聚焦于统一多模态模型的内部表示，特别提到多模态条件融合和特征空间统一，这与海思团队关注的多模态条件融合延迟大、如何统一特征空间以实现快速条件生成高度相关，session中关于对不同神经模型表示的统一和对多模态场景的应用讨论可为海思团队提供理论基础和实践方法。; 诺亚: Session强调不同神经模型在多模态场景下学习相似表示，涉及多模态长序列模型的表示统一和不变性，这与诺亚团队关注的大模型多模态长序列推理瓶颈及输入范式突破密切相关，session中关于表示统一和模型合并的讨论可为其长序列多模态模型的优化和架构设计提供新思路。
SAT 6 DEC,8 a.m.,Workshop,MATH-AI: The 5th Workshop on Mathematical Reasoning and AI,https://neurips.cc/virtual/2025/workshop/109565,,5:00 PM,,"Overview: The 5th Workshop on Mathematical Reasoning and AI, part of NeurIPS 2025, focuses on the intersection of deep learning and mathematical reasoning, particularly with large language models. The workshop aims to explore the extent to which machine learning models can comprehend mathematics and the potential applications of this capability. It seeks to bring together diverse participants to foster dialogue on various related topics. | Research Interests: Comparative study of human-level mathematical reasoning and AI techniques, Designing benchmarks for evaluating mathematical reasoning abilities, Advancing beyond current mathematical reasoning techniques, Role of deep learning models in mathematics education, Applications of AI in software verification, sciences, engineering, finance, education, and mathematics",多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: Session关注大语言模型和数学推理能力，涉及AI Agent的推理和规划能力提升，能够为团队提升Agent行为的可靠性、规划与多步执行能力的持续优化提供技术思路。; 诺亚: Session聚焦数学推理与AI，特别是大语言模型的数学理解能力，与团队关注的后训练推理和强化学习（RL）紧密相关，有助于提升模型的数学推理能力和训练框架。
SAT 6 DEC,8 a.m.,Workshop,ML for Systems,https://neurips.cc/virtual/2025/workshop/109537,,5:00 PM,"The 9th Machine Learning for Systems (ML for Systems) workshop brings together researchers and practitioners applying machine learning to core computer systems challenges. This year, we focus on three themes: (1) using LLMs and agentic workflows for systems tasks such as program synthesis and adaptive optimization; (2) applying ML to manage the complexity of large-scale training and serving of multimodal and reasoning models; and (3) leveraging ML for sustainable computing, including energy-, power-, and carbon-aware optimization. The workshop will feature invited talks, contributed presentations, and discussions aimed at advancing the frontier of ML for Systems research.","Overview: The ML for Systems workshop focuses on the application of machine learning techniques to computer systems problems. It aims to replace traditional heuristics with machine learning approaches, such as supervised learning and reinforcement learning, to address a wide range of systems-related tasks. The workshop serves as an interdisciplinary venue for experts in ML and systems to collaborate and push the boundaries of this emerging field. It also emphasizes the development of best practices, methodologies, and benchmarks for ML in systems, with a particular focus on the challenges and opportunities presented by Large Language Models (LLMs). | Research Interests: Machine Learning for computer systems, Supervised learning, Reinforcement learning, Designing new data structures, Integrated circuits, Design verification, Control algorithms for compilers, Databases, Memory management, ML frameworks, Large Language Model (LLM) training and serving, Scheduling and compiling, Interdisciplinary collaboration between ML and systems | Key Findings: The workshop highlights the importance of ML in solving systems problems and the need for developing best practices and benchmarks. It also identifies the rise of LLMs as a significant trend, presenting both challenges and opportunities for the field. The workshop aims to foster connections between ML and systems communities and to stimulate new research directions.",存储; DCN; 海思; 计算; 计算; 温哥华云; 多伦多云,存储: 单/多模型推理; DCN: Network4AI 与 AI4Network; 海思: 大语言模型和扩散模型的加速; 计算: 训推新范式; 计算: 前沿应用负载; 温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent,存储: Session聚焦于使用LLMs和agentic workflows进行系统任务（如程序合成和自适应优化），以及多模型系统中模型加载、卸载和调度的新变化，直接对应团队关于Agentic AI系统中RAG与存储访问模式、多模型系统中KV Cache调度等难题，能提供针对存储系统访问和调度的ML方法和优化思路。; DCN: Session强调ML在管理大规模训练和推理系统复杂性中的应用，特别是多模态和推理模型的训练与服务，涵盖数据中心AI训练推理网络基础设施优化和计算存储协同设计，能为团队关于数据中心网络优化和AI技术助力网络发展的难题提供机器学习方法和系统协同设计思路。; 海思: Session重点关注LLM训练和服务的复杂性管理及可持续计算优化，特别是利用ML优化大模型推理性能和资源利用，能帮助团队解决低延迟实时推理、多模态条件融合延迟及长上下文推理复杂度过高的问题。; 计算: Session强调ML替代传统系统启发式方法，管理大规模训练和推理复杂性，特别关注大模型和推理范式的演进，能为团队理解和预测训练推理负载演进机理、定义未来负载特征提供机器学习方法和系统设计视角。; 计算: Session涵盖Agentic和多模态模型在系统中的应用，强调ML在系统任务中的集成与优化，直接对应团队关注的Agentic和多模态模型负载对计算架构的新诉求，能提供前瞻性的ML系统设计和优化方案。; 温哥华云: Session提到利用强化学习等ML方法替代传统系统启发式，管理复杂系统任务，强调实践问题和性能提升，能直接帮助团队解决强化学习在VLMs/LLMs中理论到生产的落地问题，提高样本效率和系统性能。; 多伦多云: Session强调使用LLMs和agentic workflows解决系统任务，关注Agentic系统的程序合成和自适应优化，能为团队提升AI Agent评估准确性、行为可靠性及自主学习机制提供机器学习与系统集成的技术支持。
SAT 6 DEC,8 a.m.,Workshop,"Dynamics at the Frontiers of Optimization, Sampling, and Games",https://neurips.cc/virtual/2025/workshop/109541,,5:00 PM,,"Overview: The DynaFront workshop at NeurIPS 2025 focuses on the role of dynamical systems in optimization, sampling, and game theory. It aims to lower the barrier to entry for researchers and practitioners in machine learning by highlighting the unifying role of dynamical systems across these domains. The workshop will convene experts to foster cross-disciplinary dialogue and collaboration, with an emphasis on emerging applications in machine learning such as diffusion models, distributed and adversarial training, and agentic AI. | Research Interests: Dynamical systems, Optimization, Sampling, Game theory, Machine learning, Diffusion models, Distributed training, Adversarial training, Agentic AI",海思; 多伦多云; 诺亚,海思: 大语言模型和扩散模型的加速; 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,海思: Session强调了动态系统在扩散模型（diffusion models）和agentic AI中的应用，海思团队关注扩散模型的加速及多模态条件融合，session中对动态系统优化和采样的探讨可为其解决多模态融合延迟和长上下文推理复杂度问题提供理论和方法支持。; 多伦多云: Session聚焦于动态系统在agentic AI中的作用，强调分布式和对抗训练，正对应多伦多云团队关于AI Agent行为可靠性、评估和持续优化机制的难题，session内容可为其提供动态系统视角下的训练和优化方法。; 诺亚: Session涵盖动态系统在优化和博弈论中的应用，涉及自博弈和learning from experience训练框架，直接对应诺亚团队关于自博弈和latent reasoning的研究难题，session内容可为其提供理论基础和算法支持。
SAT 6 DEC,8 a.m.,Workshop,AI Virtual Cells and Instruments: A New Era in Drug Discovery and Development,https://neurips.cc/virtual/2025/workshop/109543,,5:00 PM,"As the US FDA phases out animal testing requirements for drug discovery and development, AI tools will become widely adopted to simulate the effects of candidate drugs. We posit that building virtual cells and instruments with AI is poised to transform drug discovery and development by enabling large-scale simulation and interrogation of molecules, cells, and tissues. In our workshop, we will collaboratively define and promote this emerging scientific paradigm of AI to accelerate the drug discovery and development process in this new era.","Overview: The AI4D3 NeurIPS 2025 workshop focuses on the transformative potential of AI in drug discovery and development, particularly as the US FDA phases out animal testing requirements. The workshop aims to explore the creation of AI-driven virtual cells and instruments to simulate the effects of candidate drugs, thereby accelerating the drug discovery process. This event will bring together a community to collaboratively define and promote this emerging scientific paradigm. | Research Interests: AI in drug discovery, Virtual cells and instruments, Simulation of drug effects, Large-scale molecular simulation, Interrogation of molecules, cells, and tissues",nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,OPT 2025: Optimization for Machine Learning,https://neurips.cc/virtual/2025/workshop/109581,,5:00 PM,"Optimization lies at the heart of many machine learning algorithms and enjoys great interest in our community. Indeed, this intimate relation of optimization with ML is the key motivation for the OPT series of workshops. We aim to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to ML.The focus of OPT 2025 is on ""Statistics Meets Optimization"". Since its inception, stochastic optimization has been grounded in statistical principles. Today, many of the most pressing challenges in machine learning—such as generalization bounds, the training dynamics of overparameterized models, and the development of generative models—are directly inspired by statistical thinking. At the same time, the scale and complexity of modern datasets, along with the increasingly rich model classes used to represent them, pose new questions about how optimization algorithms interact with these structures—both computationally and statistically. For example, what role do data symmetries play in shaping optimization trajectories? How do statistical properties of the data affect the adaptivity and efficiency of learning algorithms? And how can optimization approaches be designed to scale with data while still preserving desirable statistical behavior? OPT 2025 will explore these questions with the goal of building bridges between the statistics and optimization communities, and highlighting their shared impact on the theory and practice of machine learning.We are looking forward to seeing you all at OPT 2025, which will take place at the San Diego Convention Center!","Overview: The OPT2025 workshop is the 17th International Workshop on Optimization for Machine Learning, held as part of the NeurIPS 2025 conference. It aims to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to machine learning. The workshop focuses on the intersection of statistics and optimization, exploring how these fields can address challenges in machine learning, such as generalization bounds, training dynamics of overparameterized models, and the development of generative models. The event will take place at the San Diego Convention Center. | Research Interests: Optimization for Machine Learning, Statistics Meets Optimization, Stochastic Optimization, Generalization Bounds, Training Dynamics of Overparameterized Models, Development of Generative Models, Data Symmetries in Optimization, Statistical Properties and Learning Algorithms, Scalable Optimization Approaches",温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session聚焦于优化与统计的结合，特别是随机优化和训练动态，这与温哥华云团队关注的Reinforcement learning在VLMs/LLMs中的实际问题、样本效率和可扩展性密切相关，能为其提供理论与优化方法支持。; 诺亚: Session中提到的训练动态、泛化界限及优化算法与统计的结合，直接对应诺亚团队关于自博弈与learning from experience训练框架以及Latent Reasoning的研究难题，能为其提供优化理论和方法支持。
SAT 6 DEC,8 a.m.,Workshop,Foundation Models for the Brain and Body Workshop,https://neurips.cc/virtual/2025/workshop/109571,,5:00 PM,,"Overview: The 'Foundation Models for the Brain and Body' workshop is part of NeurIPS 2025, focusing on the intersection of AI and biosignals. It aims to explore how large-scale, pretrained AI systems can learn from neural and physiological signals to generalize across various applications, such as brain-computer interfacing and health monitoring. The workshop brings together experts from neuroscience, biomedical engineering, wearable technology, and machine learning to address the challenges of biosignal timeseries, which are often noisy and heterogeneous. | Research Interests: Foundation models, Biosignals, Brain-computer interfacing, Health monitoring, Neural and physiological signals, EEG, Intracortical electrophysiology, EMG, MEG, ECG, Wearable technology, Machine learning, Neuroscience, Biomedical engineering",nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,Biosecurity Safeguards for Generative AI,https://neurips.cc/virtual/2025/workshop/109573,,5:00 PM,,,nan,nan,nan
SAT 6 DEC,8 a.m.,Workshop,Imageomics: Discovering Biological Knowledge from Images Using AI,https://neurips.cc/virtual/2025/workshop/109558,,5:00 PM,"Imageomics is an emerging interdisciplinary field at the crossroads of machine learning (ML), computer vision (CV), and biological sciences. It leverages visual data—from microscopic images of single-cell species to videos of megafauna—to extract and analyze biological information, specifically traits. By grounding ML models in existing scientific knowledge, Imageomics aims to make traits computable from images, facilitating insights into the evolution and function of living organisms. Imageomics poses research problems that resonate with the broad machine-learning community: multimodal representation learning, object detection and tracking, few-shot learning, imbalanced-class learning, video understanding, 3D modeling, hierarchical learning, etc. When people leverage ML tools to solve biological questions, the foundational bridges between ML and biological sciences also provide opportunities to address key challenges in ML, creating a virtuous cycle between the two fields.","Overview: The Imageomics Workshop at NeurIPS 2025 is the third edition of an interdisciplinary event focused on the emerging field of Imageomics, which combines machine learning, computer vision, and biological sciences. The workshop aims to leverage visual data, from microscopic images to videos of large animals, to extract and analyze biological information, particularly traits. By integrating machine learning models with existing scientific knowledge, Imageomics seeks to make biological traits computable from images, providing insights into the evolution and function of living organisms. The workshop will feature keynote talks, paper presentations, and discussions on the latest research, encouraging participation from both biological scientists and machine learning researchers. | Research Interests: Multimodal representation learning, Object detection and tracking, Few-shot learning, Imbalanced-class learning, Video understanding, 3D modeling, Hierarchical learning",CBG,CBG: 3DAIGC,CBG: Session涉及视频中运动物体的检测与跟踪、3D/4D稀疏重建等技术，与CBG团队关于快速准确分割视频中运动物体和基于单目视频进行3D/4D稀疏重建的难题高度相关，Imageomics中多模态表示学习和视频理解技术可为其提供解决思路。
SAT 6 DEC,8 a.m.,Workshop,Embodied World Models for Decision Making,https://neurips.cc/virtual/2025/workshop/109532,,5:00 PM,"World models infer and predict real-world dynamics by modeling the external environment, and have become a cornerstone of embodied artificial intelligence. They have powered recent progress in decision-making and planning for interacting agents. This workshop aims to bring together researchers working at the intersection of generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models—models that enable agents to understand, predict, and interact with the world through learned models. By focusing on embodiment and decision-making, this workshop seeks to advance world models beyond passive prediction, toward active, goal-driven interaction with the physical and virtual world. By emphasizing embodiment and decision-making, we aim to move beyond passive sequence prediction toward goal-directed interaction with both physical and simulated worlds.","Overview: The Embodied World Models for Decision Making workshop at NeurIPS 2025 focuses on advancing world models that enable agents to understand, predict, and interact with the world through learned models. The workshop aims to bring together researchers from generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models. The emphasis is on moving beyond passive prediction to active, goal-driven interaction with both physical and virtual worlds. | Research Interests: Model-based reinforcement learning and long-horizon planning, Aligning simulation and real-world physics for robot learning, Interactive scene generation and downstream tasks, Video-language-action models and leveraging world knowledge in large language models, Applications in open-world video games and autonomous driving",温哥华云; 温哥华云; 多伦多云; 诺亚,温哥华云: Embodied AI; 温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session主题聚焦于具身世界模型和决策制定，强调通过学习模型使智能体理解、预测并与物理及虚拟世界交互，直接对应团队关注的Physical or Embodied AI领域，且该Workshop旨在推动具身AI的下一代模型发展，符合团队战略投资方向。; 温哥华云: Session涉及模型基于强化学习的决策制定和规划，强调模型驱动的主动交互，能为团队关注的强化学习在大模型微调中的样本效率、性能提升及实际应用问题提供理论与技术支持。; 多伦多云: Session强调具身世界模型在决策和规划中的应用，涉及智能体的理解和交互能力，契合团队对AI Agent行为可靠性、规划与多步执行能力的关注，能为Agent的自主学习和持续优化提供模型和方法支持。; 诺亚: Session强调基于模型的强化学习和决策制定，涉及主动、目标驱动的交互，契合团队关注的自博弈与经验学习训练框架及潜在推理，能为其强化学习和推理机制研究提供新思路。
SAT 6 DEC,8 a.m.,Workshop,Machine Learning and the Physical Sciences,https://neurips.cc/virtual/2025/workshop/109577,,5:00 PM,"The Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS is a unique gathering space for the growing community spearheading cross-cutting research topics at the intersection of machine learning (ML) and the physical sciences (PS). This includes the applications of ML to problems in the physical sciences (ML for PS) as well as developments in ML motivated by physical insights (PS for ML). The physical sciences are defined inclusively, including but not limited to physics, astronomy, cosmology, chemistry, biophysics, materials science, and Earth science. Join us to discuss the latest research at the convergence of these fields!","Overview: The Machine Learning and the Physical Sciences (ML4PS) workshop is a gathering space for researchers at the intersection of machine learning (ML) and the physical sciences (PS). Since its inception in 2017, the workshop has focused on applying ML to problems in the physical sciences and using physical insights to improve ML techniques. The 2025 workshop, part of the 39th NeurIPS conference, will explore the interplay between academia and industry in basic research, emphasizing foundational and translational connections between these domains. | Research Interests: Machine Learning for Physical Sciences, Physical Sciences for Machine Learning, Geometric Deep Learning, Simulation-Based Inference, Diffusion Models, Physics-Informed Neural Networks, Interplay of Academia and Industry, Weather and Climate Research, Paradigm-Shifting Applications in ML and Physics",温哥华云,温哥华云: Embodied AI,温哥华云: Session聚焦于Machine Learning与物理科学的交叉，明确提及Physical Sciences包括物理学和具身AI领域。该团队关注Embodied AI，属于物理科学与ML的交叉领域，session内容直接支持其在物理或具身AI的研究和应用。
SAT 6 DEC,8 a.m.,Workshop,Workshop on Multi-Turn Interactions in Large Language Models,https://neurips.cc/virtual/2025/workshop/109539,,5:00 PM,"The field of AI is entering a new era of interaction, profoundly shaped by the capabilities of Large Language Models (LLMs). While multi-turn interaction has been a long-standing pursuit in AI—from dialogue systems to multi-agent coordination—the advent of LLMs has radically transformed this landscape. These models now engage in complex, long-horizon interactions, process diverse data, and make crucial decisions in dynamic, human-centric scenarios.This leap forward, however, brings forth critical new research questions and challenges that demand immediate attention:Multi-Turn RL Learning for Agentic Tasks Learning from complex, interactive environments like GUI agents and tool-use scenarios, given the challenges of sparse rewards.Maintaining Alignment Understanding human values over extended, multi-turn interactions, preventing ""loss of alignment"" seen in current models.Human-AI Interaction Over time, ensuring models adapt to user goals without compromising safety or fairness.Long-horizon Evaluation For LLMs' long-term capabilities, consistency, and strategic abilities in complex, multi-turn tasks.The Workshop on Multi-Turn Interactions in LLMs is designed to be the central forum for addressing these pivotal questions. We invite researchers to contribute to defining the next generation of interactive AI, tackling these core challenges, and charting the course for future advancements in AI reasoning and planning. This workshop will concentrate on key areas where the extended use of LLMs presents both new challenges and opportunities, serving as a platform to discuss and refine methods for future improvements and evaluation for practical LLM use cases.","Overview: The NeurIPS 2025 Workshop on Multi-Turn Interactions in Large Language Models focuses on the evolving field of AI, particularly the role of Large Language Models (LLMs) in multi-turn interactions. The workshop aims to address new research questions and challenges that arise from the capabilities of LLMs in complex, long-horizon interactions. It serves as a central forum for researchers to contribute to the development of interactive AI, focusing on areas where LLMs present new challenges and opportunities. | Research Interests: Multi-Turn RL Learning for Agentic Tasks, Maintaining Alignment in AI, Human-AI Interaction, Long-horizon Evaluation of LLMs, Multi-Turn Settings and Tasks, Multi-Turn Frameworks and Algorithms, Multi-Turn Evaluation, Multi-Turn Challenges",温哥华云; 多伦多云; 海思; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 海思: 大语言模型和扩散模型的加速; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session重点关注Multi-Turn RL Learning for Agentic Tasks，直接对应团队在Reinforcement learning在LLMs上的应用及实际问题，能为团队解决理论到生产的落地难题、提升样本效率及性能提供方法和思路。; 多伦多云: Session涉及Multi-Turn RL Learning、Maintaining Alignment、Human-AI Interaction等，直接对应团队关注的AI Agent评估准确性、行为可靠性、持续优化机制及多步执行能力，能为团队提供多轮交互和agentic任务的研究框架与评估方法。; 海思: Session强调长上下文、多轮交互中的对话质量和上下文一致性问题，团队关注低延迟实时推理和长上下文推理复杂度优化，session内容可为团队提供多轮交互中保持一致性和效率的技术方向。; 诺亚: Session关注Multi-Turn RL Learning和Maintaining Alignment，团队关注自博弈与learning from experience训练框架及latent reasoning，session内容与团队在多轮交互中强化学习和推理能力提升高度契合。
SAT 6 DEC,8 a.m.,Workshop,Generative AI in Finance,https://neurips.cc/virtual/2025/workshop/109564,,5:00 PM,"This workshop aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance, a high-stakes domain where the integration of domain expertise is essential to the safe and effective deployment of machine learning technologies. Recent advances in generative models—ranging from large language models to diffusion and score-based generative architectures—have opened new frontiers for applications in finance, such as financial modeling, stress testing, scenario generation, automated financial services, and decision-making under uncertainty.The workshop will highlight theoretical advances, practical implementations, new opportunities, and open challenges that arise when adapting generative AI to financial systems under unique constraints, such as data sparsity, regulatory requirements, and highly non-stationary and adversarial environments. By bringing together the computer science community, financial researchers, industry practitioners, and regulators, we aim to catalyze interdisciplinary dialogue and accelerate the responsible development of generative AI tailored to the needs of finance and risk management.","Overview: The NeurIPS 2025 Workshop on Generative AI in Finance aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance. The workshop will focus on the integration of domain expertise to safely and effectively deploy machine learning technologies in finance. It will highlight theoretical advances, practical implementations, new opportunities, and challenges in adapting generative AI to financial systems, considering constraints like data sparsity, regulatory requirements, and non-stationary environments. The event will bring together computer scientists, financial researchers, industry practitioners, and regulators to accelerate the responsible development of generative AI tailored to finance and risk management. | Research Interests: Generative AI, Financial modeling, Stress testing, Scenario generation, Automated financial services, Decision-making under uncertainty, Machine learning in finance, Stochastic analysis, Trustworthy machine learning, Sequential decision-making, High-dimensional statistics, AI for financial services, Market behavior modeling, Natural language processing, Reinforcement learning, AI agents, Representation learning for finance, Agentic AI, LLM (Large Language Models), Financial modeling and reasoning",多伦多云; 温哥华云; 海思,多伦多云: AI Agent; 温哥华云: Reinforcement fine tuning (RFT); 海思: 大语言模型和扩散模型的加速,多伦多云: Session强调Agentic AI和LLM在金融领域的应用，涉及决策制定和自动化金融服务，直接对应团队关注的AI Agent行为可靠性、评估准确性及自主学习机制，能为提升Agent在金融场景的表现提供理论和实践支持。; 温哥华云: Session中提及决策制定不确定性和强化学习在金融中的应用，团队关注的Reinforcement learning在LLM/VLM的实际应用问题与session探讨的金融领域强化学习技术高度契合，有助于解决理论到生产的落地难题。; 海思: Session聚焦大语言模型和扩散模型在金融中的应用，团队关注的实时推理响应、长上下文推理复杂度优化等技术难题与session中对生成模型在金融场景下的高效部署需求直接相关，能提供技术方案和应用场景支持。
SUN 7 DEC,8 a.m.,Workshop,UrbanAI: Harnessing Artificial Intelligence for Smart Cities,https://neurips.cc/virtual/2025/workshop/109583,,5:00 PM,,,nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,2nd  Workshop on Multi-modal Foundation Models and Large Language Models  for Life Sciences,https://neurips.cc/virtual/2025/workshop/109536,,5:00 PM,,"Overview: The NeurIPS 2025 2nd Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences focuses on the transformative advancements in life sciences brought about by foundation models and large language models (LLMs). These models are pretrained on extensive datasets and are capable of performing a wide range of tasks such as predicting protein structures, analyzing genomic sequences, and simulating cellular processes. The workshop aims to address the limitations of existing models that focus on a single modality by promoting the development of multi-modal foundation models and LLMs that can integrate and reason over diverse biological modalities. The event will bring together researchers to discuss recent advancements, explore methodological innovations, and identify key challenges in designing these models for biological data. | Research Interests: Multi-modal foundation models for learning representations of proteins, DNAs, RNAs, transcriptomic data, metabolomic data, and other biological modalities., Multi-modal LLMs for predicting the functions of proteins, DNAs, RNAs, and other biomolecules., Multi-modal foundation models for learning joint representations of multi-omics data., Multi-modal generative models for designing proteins, DNAs, RNAs, and other biomolecules., Applications of multi-modal foundation models and LLMs in drug discovery, precision medicine, personalized treatment, and beyond., Interpretability and robustness in biological multi-modal foundation models and LLMs.",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,Artificial Intelligence for Music: Where Creativity Meets Computation,https://neurips.cc/virtual/2025/workshop/109534,,5:00 PM,"This workshop explores the dynamic intersection of AI and music, a rapidly evolving field where creativity meets computation. The goal of this workshop is twofold: First, we aim to explore the latest advancements of AI’s applications for music, from analysis, creation, performance, production, retrieval to music education and therapy. Second, we aim to discuss the impacts and implications of AI in music, including AI’s impacts on the music industry, musician community, and music education as well as ethical, legal and societal implications of AI music and AI’s implications for future musicians.","Overview: The NeurIPS 2025 Workshop on AI for Music, titled 'Where Creativity Meets Computation,' is an interdisciplinary event exploring the intersection of artificial intelligence and music. The workshop aims to bring together the music and AI communities to discuss the latest advancements in AI applications for music, including analysis, creation, performance, production, retrieval, and music education and therapy. It also addresses the impacts and implications of AI in music, such as its effects on the music industry, musician community, and music education, as well as ethical, legal, and societal considerations. The workshop features invited talks, spotlight presentations, poster and demo sessions, panel discussions, and round table discussions, with a focus on networking and community building. | Research Interests: AI applications in music, Music theory and musicology, Optical music recognition, Music transcription, Music generation, Sound design and soundtrack generation, Singing voice synthesis, Lyric generation and translation, Musical instrument design, Robotic musicianship, Human-AI music co-creativity, Music production, Music performance modeling, Music information retrieval, Music recommender systems, Music education, Music therapy, Impacts of AI on the music industry, Impacts on the musician community, Impacts on music education, Ethical, legal, and societal implications of AI music, Challenges in commercializing AI music tools, Emerging opportunities of AI music | Key Findings: The workshop highlights the growing interest in AI music research within the machine learning community and emphasizes the potential of AI to enhance artist creativity and develop new fan experiences. It also notes the acceptance rate of 68% for papers and demos, indicating a high level of interest and participation in the field.",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,AI for Science: The Reach and Limits of AI for Scientific Discovery,https://neurips.cc/virtual/2025/workshop/109578,,5:00 PM,"Through our proposed AI for Science workshop, we will bring together experimentalists, domain scientists, and ML researchers to discuss the reach and limits of AI for scientific discovery. We will center our discussion on three challenges that are essential to progress across scientific domains:LLM reasoning across scientific domains– can present-day LLMs generate rigorously testable hypotheses and reason over experimental results that span scientific domains such as physics, chemistry, and biology?Fidelity of generative and surrogate simulators– In biology, we see a shift towards all-atom models with increasingly powerful capabilities, in chemistry machine learning force fields are increasing in accuracy and generalizability, and in climate modeling we can now accurately predict weather 15 days out. How far can we push this limit? What spatial or temporal scales remain intractable?Experimental data scarcity and bias. We see modern examples of large-scale dataset generation such as the Protein Data Bank, Human Cell Atlas, and the Materials Project. Are there other fields where AI can benefit most from consortium efforts to generate large-scale datasets? How far can models trained on limited experimental datasets take us and where are lab-in-the-loop strategies essential? To address this, we additionally introduce adataset proposal competition. Our workshop will highlight common bottlenecks in developing AI methods across scientific application domains, and delve into solutions that can unlock progress across all of these domains.","Overview: The AI for Science workshop at NeurIPS 2025 aims to explore the reach and limits of AI in scientific discovery. It brings together experimentalists, domain scientists, and machine learning researchers to discuss where AI genuinely advances scientific discovery and where it faces limitations. The workshop focuses on identifying bottlenecks in AI methods across scientific domains and finding solutions to overcome these challenges. | Research Interests: Multi-domain scientific reasoning, High-fidelity generative and surrogate simulators, Experimental data scarcity and bias",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,Frontiers in Probabilistic Inference: Learning meets Sampling,https://neurips.cc/virtual/2025/workshop/109572,,5:00 PM,,"Overview: The Frontiers in Probabilistic Inference: Learning Meets Sampling (FPI 2025) is a one-day workshop at NeurIPS 2025, focused on advancing scalable, data-efficient sampling methods by integrating classical statistical approaches with modern machine learning techniques. The workshop aims to address the growing role of probabilistic inference in large-scale scientific and real-world systems by fostering cross-disciplinary collaboration among researchers from statistics, machine learning, and applied science domains. The event seeks to explore shared challenges, develop practical tools, and identify common benchmarks to enhance the development of next-generation sampling methods. | Research Interests: Sampling methods and their connections to generative models and optimal control, Classical sampling approaches and how learning accelerates them, Connections between sampling methods and physics, Understanding sampling from theoretical perspectives, Applications of sampling to natural sciences, Bayesian inference, LLM fine-tuning, and more",温哥华云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session聚焦于概率推断中的采样方法及其与学习的结合，强调提升采样效率和可扩展性，直接对应该团队关注的提升强化学习（RFT）中样本效率和性能的难题。; 诺亚: Session涉及概率推断和采样方法与学习的结合，能够为该团队自博弈与learning from experience训练框架中的采样和推断技术提供理论和方法支持。
SUN 7 DEC,8 a.m.,Workshop,Non-Euclidean Foundation Models and Geometric Learning: Advancing AI Beyond Euclidean Frameworks,https://neurips.cc/virtual/2025/workshop/109582,,5:00 PM,"In the era of foundation models and Large Language Models (LLMs), Euclidean space is the de facto geometric setting of our machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. Non-Euclidean learning is quickly gaining traction. Non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, have been shown to provide more efficient and effective representations for data with intrinsic geometric properties, like hierarchy, symmetry, and heterogeneity.Integrating foundation models with non-Euclidean spaces has great potential to enhance their ability to capture and model the underlying structures and relationships in complex real-world data, leading to better performance, generalization, and interpretability. This workshop focuses on the intersection of Non-Euclidean representation learning and Foundation Models, exploring its potential benefits, challenges, and future directions.","Overview: The Non-Euclidean Foundation Models and Geometric Learning Workshop at NeurIPS 2025 focuses on advancing AI beyond traditional Euclidean frameworks. It aims to explore the integration of foundation models with non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, to enhance the ability of AI models to capture and model complex real-world data structures. The workshop will include discussions on non-Euclidean representation learning, geometric deep learning, and large foundation models, with a focus on their potential benefits, challenges, and future directions. | Research Interests: Non-Euclidean representation learning, Geometric deep learning, Foundation models, Theoretical foundations of non-Euclidean spaces, Architectures and algorithms for non-Euclidean spaces, Applications in graph analysis, text processing, image understanding, biomedical research, and AI for scientific discovery, Trustworthiness and robustness in non-Euclidean models, Benchmarks and tools for non-Euclidean representations",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,Constrained Optimization for Machine Learning,https://neurips.cc/virtual/2025/workshop/109533,,5:00 PM,"As AI systems are increasingly deployed in safety-critical domains—including credit scoring, medical diagnosis, and autonomous systems—there is a growing demand to ensure their fairness, safety, robustness, and interpretability, alongside stronger calls for regulation. Constrained optimization offers an accountable framework for enforcing these requirements by embedding them directly into the training process, steering models to satisfy explicit constraints. This framework facilitates compliance with regulatory, industry, or ethical standards, which can be easily verified by checking constraint satisfaction.This workshop explores constrained optimization as a principled method for enforcing desirable properties in machine learning models. It brings together experts in optimization, machine learning, and trustworthy AI to address the algorithmic and practical challenges of scaling constrained methods to modern deep learning settings, which are often large-scale, non-convex, and stochastic.","Overview: The NeurIPS 2025 Workshop on Constrained Optimization for Machine Learning focuses on the application of constrained optimization techniques to ensure fairness, safety, robustness, and interpretability in AI systems, especially in safety-critical domains. The workshop aims to address the challenges of scaling these methods to modern deep learning settings and invites contributions that advance the state of the art in constrained learning. | Research Interests: Constrained Optimization, Machine Learning, Trustworthy AI, Fairness, Safety, Robustness, Interpretability, Regulatory Compliance",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,New Perspectives in Graph Machine Learning,https://neurips.cc/virtual/2025/workshop/109579,,5:00 PM,,"Overview: The webpage presents the 'New Perspectives in Advancing Graph Machine Learning' workshop, which is part of NeurIPS 2025. The workshop aims to explore and connect new perspectives on graph machine learning (GML), focusing on theoretical insights, new capabilities, and application-aligned algorithms and models. It includes keynotes, oral presentations, poster sessions, and a panel discussion, featuring prominent speakers and researchers in the field. | Research Interests: Graph Machine Learning, Algebraic–Topological Analyses, Foundation Models, Generative Models, Large Models in Applications, Causal Structure Learning, Topological Deep Learning, Graph Neural Networks, Graph Representation Learning | Key Findings: The workshop highlights the potential of integrating new perspectives such as algebraic-topological analyses and foundation models into graph machine learning, promising deeper theoretical insights and more powerful algorithms. It also emphasizes the importance of addressing overarching challenges in theory, methodology, and modeling.",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,Regulatable ML: Towards Bridging the Gaps between Machine Learning Research and Regulations,https://neurips.cc/virtual/2025/workshop/109575,,5:00 PM,,"Overview: The 3rd Workshop on Regulatable ML at NeurIPS 2025 aims to bridge the gap between state-of-the-art machine learning safety and security research and evolving regulatory frameworks. The workshop addresses the novel safety and security risks introduced by large-scale machine learning models and AI agents, such as prompt-injection attacks, capability overreach, and unintended emergent behaviors. It highlights the gaps in current regulations like the EU AI Act and the need for evidence-based mitigation strategies as outlined in the International AI Safety Report 2025. | Research Interests: Machine Learning Safety, AI Security, Regulatory Frameworks, AI Risk Mitigation, Transparency in AI, Human Oversight in AI, International Collaborations in AI Safety, Verification Protocols for AI, Failure Cases of State-of-the-Art Models | Key Findings: Recent works have highlighted several failure cases of state-of-the-art large language models (LLMs) and agents, such as the Claude Opus 4 model generating instructions for creating biological agents and attempting to 'hijack' strategies during shutdown threat tests.",多伦多云,多伦多云: AI Agent,多伦多云: Session聚焦于机器学习安全、AI安全和监管框架，特别涉及AI Agent的安全风险、行为管控与校验，直接对应该团队关于提升Agent行为可靠性及管控的难题，能为其提供风险缓解策略和监管合规思路。
SUN 7 DEC,8 a.m.,Workshop,"Evaluating the Evolving LLM Lifecycle:  Benchmarks, Emergent Abilities, and Scaling",https://neurips.cc/virtual/2025/workshop/109549,,5:00 PM,,"Overview: The NeurIPS 2025 Workshop titled 'Evaluating the Evolving LLM Lifecycle' focuses on the evaluation of large language models (LLMs) as they become increasingly integrated into various applications. The workshop aims to address the need for robust evaluation methodologies and best practices across the entire LLM lifecycle, from foundational pre-training to advanced post-training techniques like reinforcement learning from human feedback (RLHF). It seeks to develop a comprehensive understanding of LLM evaluation, emphasizing interrelations, emergent capabilities, scaling challenges, and the creation of cutting-edge benchmarks for future models. | Research Interests: Evaluation metrics for pre-trained models and foundational capabilities, Assessing the impact of fine-tuning and adaptation on model performance and behavior, Advanced post-training evaluation techniques, including RLHF and human-in-the-loop assessments, Interrelations and dependencies between different evaluation stages and their impact on model generalization, Benchmarking and standardization of evaluation protocols, Development of new, challenging evaluation paradigms, Understanding and evaluating scaling laws in relation to model performance and emergent phenomena, Addressing data contamination, memorization, and other data-centric evaluation challenges, Developing and applying holistic evaluation frameworks for diverse LLM capabilities, Evaluating the evolution of LLM capabilities and potential risks as models scale",温哥华云; 多伦多云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session强调对LLM后训练技术如RLHF的评估，直接对应团队关注的Reinforcement learning在LLM/VLM中的实际应用问题，能提供评估方法和实践经验，帮助解决理论到生产的落地难题。; 多伦多云: Session涉及LLM生命周期中评估方法和benchmark的构建，能为团队关注的AI Agent行为评估准确性、行为可靠性及持续优化机制提供系统的评估框架和标准化方法。; 诺亚: Session关注后训练阶段的评估及RLHF等技术，契合团队对自博弈、learning from experience训练框架和latent reasoning的研究需求，能提供评估指标和方法支持。
SUN 7 DEC,8 a.m.,Workshop,Foundations of Reasoning in Language Models,https://neurips.cc/virtual/2025/workshop/109559,,5:00 PM,"Our workshop’s goal is toadvance foundational understanding, principled innovations, and rigorous scientific evaluations for reasoning in language models. These advancements are built upon theoretical analyses and controlled empirical studies that illuminate how reasoning emerges, where it fails, and how it can be systematically improved.We want to foster dialogue between communities with complementary strengths---those building theoretical models of reasoning phenomena, those designing experiments that reveal its emergence or failure in practice, and those proposing algorithmic developments that advance reasoning---aroundthree primary questions:1. How are language models able to solve complex tasks, and what do they still struggle with?2. What fundamental challenges stand in the way of advancing reasoning capabilities?3. What algorithmic innovations can overcome these obstacles?","Overview: The Foundations of Reasoning in Language Models (FoRLM) workshop is scheduled to take place during NeurIPS 2025 in San Diego, California. The workshop aims to advance the foundational understanding of reasoning in language models through theoretical analyses and empirical studies. It seeks to bring together researchers with complementary strengths to address key questions about how reasoning emerges in language models, where it fails, and how it can be improved. | Research Interests: Reasoning in language models, Theoretical models of reasoning phenomena, Empirical studies on reasoning emergence and failure, Algorithmic developments to advance reasoning",多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: 该session聚焦语言模型中的推理基础，探讨复杂任务解决及推理能力提升，直接关联AI Agent中提升评估准确性、行为可靠性及多步执行能力的难题，session的理论分析和算法创新可为Agent的规划与执行能力提供技术支持。; 诺亚: session强调语言模型推理的理论基础和算法创新，符合团队关注的后训练推理和强化学习（RL）框架，尤其是latent reasoning和自博弈训练框架，session内容可为其提供理论分析和算法改进思路。
SUN 7 DEC,8 a.m.,Workshop,Learning to Sense (L2S),https://neurips.cc/virtual/2025/workshop/109563,,5:00 PM,"The workshop explores the joint optimization of sensors and machine learning models, pushing beyond traditional paradigms of data acquisition and processing. We aim to rethink the foundations of how machines sense the world by replacing hand-crafted ISPs, leveraging learnable sensor layouts, and adopting task-driven sensing strategies.    We welcome original contributions and position papers on the following topics (non-exhaustive):    Sensor optimization for e.g. computer vision (bit-depth, pixel layouts, color filter design)    RAW-to-task or RAW-to-label approaches for visual tasks    Co-design of neural networks and sensor hardware    Low-bit and energy-efficient sensing for embedded or mobile devices    Benchmarks, datasets, and metrics for evaluating sensor-model pipelines    Generalization and robustness of sensor-model systems in real-world conditions    Failure case studies and negative results in joint optimization pipelines    Join us to engage with cutting-edge research and cross-disciplinary discussions that are shaping the future of sensor systems for real-world deployment across mobile, embedded, and autonomous platforms.","Overview: The NeurIPS 2025 Workshop on Learning To Sense focuses on the joint optimization of sensors and machine learning models. It aims to push beyond traditional paradigms of data acquisition and processing by rethinking how machines sense the world. The workshop encourages the exploration of learnable sensor layouts and task-driven sensing strategies, moving away from hand-crafted ISPs. | Research Interests: Sensor optimization for computer vision, RAW-to-task or RAW-to-label approaches for visual tasks, Co-design of neural networks and sensor hardware, Low-bit and energy-efficient sensing for embedded or mobile devices, Benchmarks, datasets, and metrics for evaluating sensor-model pipelines, Generalization and robustness of sensor-model systems in real-world conditions, Failure case studies and negative results in joint optimization pipelines",CBG; 温哥华云,CBG: 3DAIGC; 温哥华云: Embodied AI,CBG: Session关注传感器优化、RAW-to-task视觉任务和传感器与神经网络的协同设计，CBG团队关注视频中运动物体分割和单目视频3D/4D稀疏重建，这与传感器优化和视觉任务的RAW-to-label方法高度相关，能为其提供联合优化传感器布局和视觉模型的技术思路。; 温哥华云: Session强调传感器与机器学习模型的联合优化及任务驱动感知策略，Embodied AI涉及物理环境感知和交互，传感器硬件与模型的协同设计和低功耗感知技术对该团队解决实际环境中的感知问题具有直接帮助。
SUN 7 DEC,8 a.m.,Workshop,Multimodal Algorithmic Reasoning Workshop,https://neurips.cc/virtual/2025/workshop/109561,,5:00 PM,"Large AI frameworks have been increasing in their data modeling abilities at an ever more vigor in recent times, with compelling applications emerging frequently, many of which may even appear to challenge human intelligence. Yet despite such impressive performance, there remain open questions about whether these models include the foundations of general intelligence, or whether they perform these tasks without human-like understanding. This necessitates development of better tools for assessing these models in tandem with developing the models themselves. This workshop focuses on the topic of multimodal algorithmic reasoning, where an agent needs to assimilate information from multiple modalities towards deriving reasoning algorithms for complex problem solving. In the last year, we have seen rapid advances in AI capabilities that better bridge across modalities, bringing both optimism about superhuman capabilities and skepticism about the limits of current approaches. Through talks from outstanding researchers and faculty, we hope to dive deep into this exciting topic at the intersection of theory, multimodal learning and cognitive science to understand what we have achieved thus far in machine intelligence and what we are lacking in relation to the human way of thinking, towards finding the missing rungs on the ladder to truly intelligent reasoning.","Overview: The MAR 2025 workshop, held in conjunction with the Conference on Neural Information Processing Systems 2025, focuses on gathering researchers in neural algorithmic learning, multimodal reasoning, and cognitive models of intelligence. The workshop aims to showcase cutting-edge research, discuss challenges, and highlight overlooked problems in perception and language modeling crucial for achieving artificial general intelligence. The emphasis is on multimodal algorithmic reasoning, where agents deduce new algorithms for real-world tasks using multimodal foundational models. The event features talks from outstanding researchers to inspire the audience in exploring the intersection of multimodal learning and cognitive science. | Research Interests: Multimodal algorithmic reasoning, Neural algorithmic learning, Cognitive models of intelligence, Perception and language modeling, Vision-and-language mathematical reasoning, Multimodal games, Robotic manipulation, Chain-of-thought reasoning, Distributed agentic reasoning, Tool use in AI, Visual reasoning architectures, Data generation via self-play, Theoretical limits of reasoning in large models",多伦多云; 诺亚; 诺亚; 海思; 计算,多伦多云: AI Agent; 诺亚: 大模型长序列，多模态长序列; 诺亚: 大模型后训练Reasoning，RL; 海思: 大语言模型和扩散模型的加速; 计算: 前沿应用负载,多伦多云: Session聚焦多模态算法推理和Agentic AI系统，强调多模态基础模型推理和推断能力，直接关联团队关注的AI Agent评估准确性、行为可靠性及持续优化机制，特别是具备planning与多步执行能力的L3+ agent的持续优化，session中关于多模态算法推理和chain-of-thought reasoning等内容可为团队提供理论与实践方法支持。; 诺亚: Session强调多模态算法推理和跨模态信息融合，涉及多模态长文本推理和视觉语言数学推理，契合团队关注的大模型长序列和多模态长序列的推理计算瓶颈及架构优化，session中关于多模态学习与认知科学交叉的研究可为团队在输入范式突破和推理策略改进提供理论基础和技术思路。; 诺亚: Session关注神经算法学习和推理能力，强调chain-of-thought reasoning和分布式agentic reasoning，契合团队在自博弈与learning from experience训练框架及latent reasoning方面的研究，session中关于算法推理和认知模型的探讨有助于团队深化后训练推理和强化学习方法。; 海思: Session涉及多模态条件融合及视觉语言推理，团队关注多模态条件融合延迟及长上下文推理复杂度问题，session中对多模态算法推理和视觉语言数学推理的研究可为团队提供优化多模态特征统一和推理效率的理论支持和实践启发。; 计算: Session强调多模态算法推理和agentic系统的推理能力，团队关注Agentic和多模态模型应用负载的快速演进及其对计算架构的新诉求，session内容可帮助团队理解多模态推理的计算需求及软硬件协同优化方向。
SUN 7 DEC,8 a.m.,Workshop,Data on the Brain and Mind,https://neurips.cc/virtual/2025/workshop/109557,,5:00 PM,,"Overview: The 'Data on the Brain & Mind' workshop aims to connect machine learning researchers with neuroscientists and cognitive scientists by focusing on concrete, open problems grounded in emerging neural datasets. The workshop emphasizes the diversity and heterogeneity of neuroscience and cognitive science datasets, encouraging the development of tailored AI solutions beyond generic models. It is designed to be highly interactive, fostering collaborations through invited talks, poster sessions, and mentorship opportunities. | Research Interests: Machine learning applications in neuroscience, Cognitive science data analysis, Neural datasets, Visual-motor cortical processing, Human development datasets, Natural speech processing, Interdisciplinary collaborations, Data-model integration and interpretability",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,CogInterp: Interpreting Cognition in Deep Learning Models,https://neurips.cc/virtual/2025/workshop/109544,,5:00 PM,"Recent innovations in deep learning have produced models with impressive capabilities, achieving or even exceeding human performance in a wide range of domains. A timely and critical challenge in AI is understanding what behaviors these models are actually capable of, and the internal processes which support these behaviors. As interest continues to grow in models’ internal processes, the field of cognitive science is becoming increasingly useful for describing and understanding cognition in deep learning models: cognitive science, which seeks to describe the cognitive processes in human and animal minds, offers a rich body of theories, experiments, and frameworks which may be adopted to understand how deep learning models achieve complex behaviors in domains such as language, vision, and reasoning.The workshop will focus on Cognitive Interpretability (“CogInterp”), which involves the systematic interpretation of high-level cognition in deep learning models. Similar to how cognitive science describes the intermediate representations and algorithms (or cognition) between behavior and neurons in biological systems, the goal of Cognitive Interpretability is to describe the cognitive processes which lie between the levels of behavioral evaluations and mechanistic interpretability in deep learning models. Practically speaking, this means that Cognitive Interpretability does not just ask whether a model can perform task X or has a certain ability Y , but additionally (or instead) how a model performs X or learns and implements Y . These kinds of inferences—from observable behavior to latent “mental” processes—are the bread and butter of cognitive science, but many of the theoretical and empirical tools developed to tackle these problems have not yet been widely adopted in AI research, in part because of the separation between the fields and communities.To address the gap above, our goal is to bring together researchers in cognitive science and AI interpretability to discuss new empirical results and theories about the inner workings of deep learning models. We hope to gather perspectives from various disciplines, including machine learning, psychology, linguistics, vision science, neuroscience, philosophy of mind, and law.","Overview: The First Workshop on CogInterp: Interpreting Cognition in Deep Learning Models is set to take place at NeurIPS 2025 in San Diego, USA, on December 7, 2025. This workshop aims to address the challenge of understanding the behaviors and internal processes of deep learning models by leveraging insights from cognitive science. The workshop seeks to bridge the gap between AI research and cognitive science by bringing together researchers from various disciplines to discuss new empirical results and theories about the inner workings of deep learning models. | Research Interests: Cognitive Interpretability, Deep Learning Models, Cognitive Science, Machine Learning, Psychology, Linguistics, Vision Science, Neuroscience, Philosophy of Mind, Law",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,What Can('t) Transformers Do?,https://neurips.cc/virtual/2025/workshop/109569,,5:00 PM,"With most advances in large foundation models (LFMs) being empirical, our theoretical understanding of what transformers can compute, express, and learn still lags behind. This workshop will convene theorists and empiricists to chart a rigorous agenda for the next generation of LFMs, asking “Whatcanandcan’ttransformers do?” We welcome both formal analyses and empirically grounded studies that shed light on theoretical questions, aiming to close the gap between proofs and practice while fostering new, interdisciplinary collaborations.","Overview: The workshop 'What Can(\'t) Transformers Do?' at NeurIPS 2025 aims to bridge the gap between empirical advances in large foundation models (LFMs) and the theoretical understanding of transformers. It seeks to explore what transformer-based language models can and cannot do by bringing together theorists and empiricists. The workshop encourages both formal analyses and empirical studies to address theoretical questions and foster interdisciplinary collaborations. | Research Interests: Theoretical analyses of transformer capabilities, Expressivity, Learnability, Inference-time scaling, In-context learning, Effects of architectural components, Empirical studies of transformer behavior, Architectural or training innovations, Mechanistic studies of failures, Comparisons of theorized and observed capabilities | Key Findings: The workshop highlights several accepted papers that contribute to understanding transformer capabilities and limitations, such as the role of transformer feed-forward layers, the failure of transformers in time series forecasting, and the limitations in program trace generation. These studies provide insights into the theoretical and practical aspects of transformer models.",海思; 诺亚; 诺亚,海思: 大语言模型和扩散模型的加速; 诺亚: 大模型长序列，多模态长序列; 诺亚: 大模型后训练Reasoning，RL,海思: 该session聚焦于transformer模型的理论与实践能力，特别是对长上下文推理中注意力复杂度的研究，与海思团队关注的长上下文推理注意力复杂度过高及稀疏注意力和分块缓存技术高度相关，session中关于transformer表达能力和推理复杂度的理论分析能为海思团队提供理论指导和创新思路。; 诺亚: session探讨transformer模型的表达能力、学习能力及推理时的扩展性，直接关联诺亚团队关注的大模型长序列架构演化和多模态长文本推理计算瓶颈问题，session中理论与实证研究可以帮助诺亚团队理解和突破长序列模型的计算与缓存限制。; 诺亚: session强调理论与实证结合，探讨transformer在推理能力和学习能力上的边界，与诺亚团队关注的后训练推理（Reasoning）和强化学习（RL）框架高度契合，session中关于transformer能力极限和失败机制的研究有助于推动后训练推理和自博弈学习方法的理论基础。
SUN 7 DEC,8 a.m.,Workshop,Learning from Time-Series for Health,https://neurips.cc/virtual/2025/workshop/109560,,5:00 PM,"Time-series data underpin modern healthcare, spanning electronic health records, physiological waveforms, wearables, and population trends, yet their unique characteristics—including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints—demand specialized machine learning approaches. While recent advances in foundation models, multimodal learning, and generative methods show promise, significant challenges remain in causality, interpretability, and deployment.  This workshop unites researchers across health time-series domains (from wearables to clinical systems) to address shared challenges through: (1) cross-domain discussion, (2) diverse industry/academic perspectives (featuring Google, Oura, Apple and 5 institutions), and (3) community engagement via posters, talks, and panels. By fostering cross-domain collaboration on physiological-aware methods, we aim to bridge the gap between cutting-edge ML and real-world healthcare impact.","Overview: The 'Learning from Time Series for Health' workshop at NeurIPS 2025 focuses on the application of machine learning to health-related time-series data. This workshop aims to address the unique challenges posed by such data, including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints. It brings together researchers from various domains to foster cross-domain collaboration and bridge the gap between cutting-edge machine learning techniques and real-world healthcare impact. The workshop features discussions, industry and academic perspectives, and community engagement through posters, talks, and panels. | Research Interests: Time-series data in healthcare, Machine learning for health, Foundation models, Multimodal learning, Generative methods, Causality in healthcare, Interpretability of models, Deployment of machine learning in healthcare",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,Tackling Climate Change with Machine Learning,https://neurips.cc/virtual/2025/workshop/109574,,5:00 PM,"Many in the ML community wish to take action on climate change, but are unsure how to have the most impact. This workshop will highlight work that demonstrates that, while ML is no silver bullet, it can be an invaluable tool in reducing greenhouse gas emissions and in helping society adapt to the effects of climate change.Climate change is a complex problem for which action takes many forms, from advancing theory to deploying new technology. Many of these actions represent high-impact opportunities for real-world change, and simultaneously pose interesting academic research problems.The theme of this workshop, “Roots to Routes: A Dialogue on Different Machine Learning Methods for Climate Impact,” invites submissions that explore the strengths of diverse machine learning approaches in climate-related contexts. We particularly encourage work that demonstrates the effectiveness of classical ML methods under real-world constraints, such as limited data availability, privacy concerns, or restricted computational resources. At the same time, we welcome contributions that showcase how scaling up data and computing resources combined with modern tools and techniques can unlock new possibilities for tackling global-scale climate prediction challenges.This workshop is part of a series that aims to bring together those applying ML to climate change challenges and facilitate cross-pollination between ML researchers and experts in climate-relevant fields.The main workshop will take place on December 6 or 7, 2025 (exact date TBD).","Overview: The NeurIPS 2025 Workshop titled 'Tackling Climate Change with Machine Learning' aims to bring together the machine learning community to address climate change challenges. The workshop will highlight the role of machine learning as a tool to reduce greenhouse gas emissions and help society adapt to climate change. It is part of a series that facilitates collaboration between ML researchers and experts in climate-relevant fields. The main workshop will take place on December 7, 2025, as part of the NeurIPS conference in San Diego, California. | Research Interests: Agriculture and food, Behavioural and social science, Buildings, Carbon capture and sequestration, Cities and urban planning, Climate finance and economics, Climate justice, Climate science and climate modeling, Disaster management and relief, Earth observations and monitoring, Earth science, Ecosystems and biodiversity, Extreme weather, Forestry and other land use, Health, Heavy industry and manufacturing, Local and indigenous knowledge systems, Materials science and discovery, Oceans and marine systems, Power and energy systems, Public policy, Societal adaptation and resilience, Supply chains, Transportation",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,Workshop on Mechanistic Interpretability,https://neurips.cc/virtual/2025/workshop/109547,,5:00 PM,,"Overview: The Mechanistic Interpretability Workshop at NeurIPS 2025 focuses on understanding the internal mechanisms of neural networks to bridge the gap between their performance and our understanding of their decision-making processes. The workshop aims to bring together diverse perspectives from academia, industry, and independent research to discuss recent advances, build common understanding, and chart future directions in the field of mechanistic interpretability. | Research Interests: Mechanistic interpretability, Neural network internals, Model behavior prediction, Reliability and adversarial behavior detection, Mathematical analysis of neural networks, Empirical studies on neural networks, Reverse-engineering models, Behavioral analysis of model representations, Cross-pollination of research methodologies, Unsupervised and supervised techniques in AI",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,AI That Keeps Up: Workshop on Continual and Compatible Foundation Model Updates (CCFM),https://neurips.cc/virtual/2025/workshop/109584,,5:00 PM,"Foundation models, despite their impressive capabilities, face a critical challenge: they naturally become outdated. Trained on vast datasets, frequently updating these models is expensive. Crucially, these challenges extend beyond the scope of studies in traditional continual learning, as foundation models require rapid and scalable adaptation to dynamic global changes and the emergence of both generalized and specialized tasks. This workshop addresses the urgent need for up-to-date foundation models. We invite researchers to explore cost-effective methods for frequent updates and adaptation, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve.","Overview: The NeurIPS 2025 Workshop on Continual and Compatible Foundation Model Updates (CCFM) focuses on addressing the challenges faced by foundation models, which naturally become outdated over time. The workshop aims to explore cost-effective methods for frequent updates and adaptation of these models, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve. The event will take place on December 7th, 2025, at the San Diego Convention Center. | Research Interests: Foundation models, Continual learning, Model updates, Cost-effective adaptation, Dynamic evaluations, Minimizing forgetting, Consistent user experience",多伦多云; 诺亚,多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,多伦多云: Session关注Foundation Model的持续更新和兼容性，涉及模型的持续优化与自主学习机制，直接对应该团队关于Agent业务上线后的自主学习与持续优化机制的难题，尤其是Prompt优化飞轮与模型优化飞轮结合及多步执行能力的持续优化。; 诺亚: Session强调频繁更新Foundation Model以适应动态变化，涉及减少遗忘和模型退化，符合该团队关于自博弈与learning from experience训练框架的研究方向，能为其提供持续训练和模型更新的思路和方法。
SUN 7 DEC,8 a.m.,Workshop,Recent Advances in Time Series Foundation Models: Have We Reached the ‘BERT Moment’?,https://neurips.cc/virtual/2025/workshop/109585,,5:00 PM,"Foundation models (FMs) have achieved great success in NLP and vision, inspiring over 20 new time series FMs (TSFMs) in the past year. Despite promising results, studies show that carefully designed lightweight supervised baselines often match TSFM performance. Unlike NLP’s “BERT Moment,” TSFMs still require full fine-tuning to be competitive in real-world scenarios. Additionally, some tabular FMs rival TSFMs without being time series-specific. Recent benchmarks also provide mixed evidence: GIFT-Eval favors TSFMs, OpenTS shows statistical models outperforming deep learning on univariate data, and FoundTS finds supervised baselines on par with TSFMs. This workshop aims to bring together researchers to examine the gap between TSFM potential and real-world utility, and to identify benchmarks and applications where TSFMs can truly excel.The key topics of this workshop include, but are not limited to:- Benchmarking Foundation Models in Time Series,- Scaling Laws and Efficiency in Time Series Models,- Evaluating Transferability and Adaptability of Foundation Models,- Leveraging Foundation Models of Other Modalities for Time Series,- Unsupervised performance estimation of TSFMs,- Industrial Benchmarking of Time Series Foundation ModelsMore details are provided in ourCall for Papers.","Overview: The webpage presents the BERT2S workshop, which focuses on recent advances in Time Series Foundation Models (TSFMs) and their potential to reach a 'BERT Moment' similar to that in NLP. The workshop is part of the NeurIPS 2025 conference and aims to bring together researchers to explore the gap between the potential and real-world utility of TSFMs. It will include discussions on benchmarks, applications, and the development of TSFMs. | Research Interests: Benchmarking Foundation Models in Time Series, Scaling Laws and Efficiency in Time Series Models, Evaluating Transferability and Adaptability of Foundation Models, Leveraging Foundation Models of Other Modalities for Time Series, Unsupervised performance estimation of TSFMs, Industrial Benchmarking of Time Series Foundation Models | Key Findings: The workshop highlights that despite the promising results of TSFMs, lightweight supervised baselines often match their performance. It also notes that some tabular foundation models rival TSFMs without being time series-specific. Recent benchmarks provide mixed evidence on the superiority of TSFMs, indicating a need for further exploration and development.",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,Symmetry and Geometry in Neural Representations,https://neurips.cc/virtual/2025/workshop/109551,,5:00 PM,"The fields of biological and artificial intelligence are increasingly converging on a shared principle: the geometry and topology of real-world structure play a central role in building efficient, robust, and interpretable representations. In neuroscience, mounting evidence suggests that neural circuits encode task and environmental structure through low-dimensional manifolds, conserved symmetries, and structured transformations. In deep learning, principles such as sparsity, equivariance, and compositionality are guiding the development of more generalizable and interpretable models, including new approaches to foundation model distillation. The NeurReps workshop brings these threads together, fostering dialogue among machine learning researchers, neuroscientists, and mathematicians to uncover unifying geometric principles of neural representation. Just as geometry and symmetry once unified the models of 20th-century physics, we believe they may now illuminate the computational foundations of intelligence.","Overview: The NeurReps Workshop is an annual event that brings together researchers from the fields of mathematics, deep learning, and neuroscience to explore the principles of neural representation in both biological and artificial systems. The workshop aims to uncover unifying geometric principles of neural representation, drawing parallels between the geometry and symmetry in neural circuits and machine learning models. The event fosters dialogue among experts to advance understanding in areas such as geometric mechanistic interpretability, the geometry of representations in foundation models, and improvements in large language model design. | Research Interests: Geometry and topology in neural representations, Symmetry and equivariance in neural circuits and models, Neuroscience and interpretability, Geometric deep learning, Foundation models of brain activity, Mechanistic interpretability, Dynamics in shaping neural representations",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,GPU-Accelerated and Scalable Optimization (ScaleOpt),https://neurips.cc/virtual/2025/workshop/109554,,5:00 PM,"Recent advancements in GPU-based large-scale optimization have been remarkable. Recognizing the revolution in optimizing neural network weights via large-scale GPU-accelerated algorithms, the optimization community has been interested in developing general purpose GPU-accelerated optimizers for various families of classic optimization problems, including linear programming, general conic optimization, combinatorial optimization, and more specific problem families such as flow optimization and optimal transport. Beyond deploying GPUs directly at classical problems, current frontier AI tools—including large language models (LLMs)—are being deployed to solve optimization problem. Various works have used neural networks to solve mixed integer problems, linear or quadratic programs, general combinatorial optimization problems, and more specific optimization problems such as LASSO and robust PCA. In this workshop, we aim to provide a platform for interested researchers to engage with each other on recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems.","Overview: The ScaleOPT workshop at NeurIPS 2025 focuses on GPU-accelerated and scalable optimization, exploring practical optimization algorithms and toolkits that co-improve with advanced AI systems. The workshop aims to provide a platform for researchers to engage with recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems. | Research Interests: GPU-accelerated optimization, Large-scale optimization, Randomized numerical linear algebra, Differentiable convex optimization, First-order methods for linear programming, Second-order linear and nonlinear programming solvers, Stochastic combinatorial optimization, Nonlinear optimization with neural network constraints, Learning to optimize, Meta prompt optimization, Parametric convex optimization, Automation in optimization | Key Findings: The workshop highlights several advancements, such as the development of rlaopt, a PyTorch-based package for large-scale optimization, CuClarabel, a GPU-accelerated version of the interior-point solver for quadratic cone programs, and a GPU-accelerated framework for ultra-large-scale scenario-based evaluation in stochastic combinatorial optimization. It also discusses the benefits of reduced-space formulations for optimizing over trained neural networks and the potential of automated systems to enhance decomposition for proximal and parallel methods.",nan,nan,nan
SUN 7 DEC,8 a.m.,Workshop,"NeurIPS 2025 Workshop on Space in Vision, Language, and Embodied AI",https://neurips.cc/virtual/2025/workshop/109546,,5:00 PM,,"Overview: The SpaVLE workshop at NeurIPS 2025 aims to bridge the historically siloed efforts of the NLP, CV, and robotics communities by fostering cross-disciplinary dialogue to advance research on spatial understanding and representation. The workshop focuses on how spatial representations can be learned from multimodal data and applied to core tasks in computer vision, natural language processing, and robotics. It seeks to foster discussion on how spatial representations, whether symbolic, neural, verbal, or geometric, can be learned, evaluated, and deployed across modalities and tasks, aligning these approaches with real-world applications. | Research Interests: Foundations of Spatial Representation and Reasoning, Multimodal Spatial Grounding, Applications in NLP, Vision, Robotics, and Generative AI, Evaluation and Benchmarking Spatial Intelligence, Spatial Reasoning in Foundation Models",CBG; 温哥华云,CBG: 3DAIGC; 温哥华云: Embodied AI,CBG: Session关注空间理解与表示，涉及多模态数据的空间表示学习和应用，直接对应团队在视频中运动物体分割、3D/4D稀疏重建和相机轨迹控制等空间感知与生成任务的难题。; 温哥华云: Session强调跨领域空间表示与具身AI的结合，正好契合团队在Physical或Embodied AI领域的研究方向，能为空间推理和多模态空间表示提供理论和技术支持。
SUN 7 DEC,8 a.m.,Workshop,"LAW 2025: Bridging Language, Agent, and World Models for Reasoning and Planning",https://neurips.cc/virtual/2025/workshop/109552,,5:00 PM,,"Overview: The LAW 2025 workshop, part of NeurIPS 2025, focuses on the integration of Language models (L), Agent models (A), and World models (W) to advance AI systems. The workshop aims to explore the intersection of these models to address complex real-world problems and simulate rich virtual environments. It seeks to catalyze discussions on how these models can be combined to create AI systems that think, plan, simulate, act, and explain themselves in dynamic, partially observed worlds. | Research Interests: Large Language Models, Autonomous Agents, World Modeling, Integration of Language, Agent, and World Models, AI Systems in Dynamic Environments, Generalizable World Models, LLM-based Agents",多伦多云; 温哥华云; 诺亚,多伦多云: AI Agent; 温哥华云: Embodied AI; 诺亚: 大模型后训练Reasoning，RL,"多伦多云: Session聚焦于Language, Agent和World模型的整合，直接对应团队关注的AI Agent的评估、行为可靠性及自主学习优化等难题，能够提供多模型集成与规划执行的技术思路。; 温哥华云: Session强调Agent模型与World模型的结合，支持动态、部分可观测环境中的推理与规划，契合具身AI在物理环境中模拟和决策的研究需求。; 诺亚: Session关注语言模型与Agent及世界模型的融合以提升推理和规划能力，与团队在自博弈、经验学习和潜在推理方面的研究高度相关，能提供集成框架和应用场景。"
SUN 7 DEC,8 a.m.,Workshop,Workshop on Scaling Environments for Agents,https://neurips.cc/virtual/2025/workshop/109540,,5:00 PM,"The development of intelligent agents – particularly those powered by large language models (LLMs) – has emphasized the critical role of environments in shaping agent behavior and capabilities, especially for achieving end-to-end autonomy. Environments are not merely testing grounds; they are dynamic, interactive contexts that serve as the essential ""data"" for agents to learn adaptive behavior, complex reasoning, and long-term decision-making skills. Just as scaling the model size, dataset size, and training computation has led to emergent capabilities in LLMs, scaling the structure, fidelity, and diversity of environments is one of the crucial dimensions in advancing agent intelligence. Moreover, recent advances in end-to-end reinforcement learning (RL), particularly when paired with LLM-based agents, have made it increasingly viable to train agents through sustained interaction. These agents can now acquire skills, strategies, and planning abilities through environmental feedback, rather than relying solely on imitation learning or static prompt engineering. As we move toward more autonomous, general-purpose agents, the need for scalable, richly interactive, and diverse environments has become both urgent and foundational.","Overview: The Scaling Environments for Agents (SEA) Workshop at NeurIPS 2025 focuses on the development of intelligent agents, particularly those powered by large language models (LLMs). The workshop emphasizes the critical role of environments in shaping agent behavior and capabilities, aiming to advance agent intelligence through scalable, richly interactive, and diverse environments. The workshop covers various aspects of environment design, evaluation, and integration with LLMs, highlighting the importance of environments as dynamic, interactive contexts for learning adaptive behavior, complex reasoning, and long-term decision-making skills. | Research Interests: Environment Infrastructure Design, Benchmarks and Evaluation, LLMs in Interactive Environments, Tool-Use and Software Environments, Multi-Agent Systems and Simulation Environments, Embodiment and Grounding, Sim2Real and Deployment",温哥华云; 温哥华云; 多伦多云; 诺亚,温哥华云: Reinforcement fine tuning (RFT); 温哥华云: Embodied AI; 多伦多云: AI Agent; 诺亚: 大模型后训练Reasoning，RL,温哥华云: Session强调通过end-to-end reinforcement learning结合LLM训练智能体，关注环境的规模化和交互性，直接对应该团队关注的RL在VLMs/LLMs中的实际应用问题，包括样本效率、性能和可扩展性，能为其解决理论到生产的落地难题提供思路。; 温哥华云: Session提到具身（Embodiment）和环境的动态交互对智能体学习适应性行为的重要性，强调多样化和丰富交互环境的设计，直接关联该团队在物理具身AI领域的研究和投资方向，能助力其环境设计与智能体能力提升。; 多伦多云: Session聚焦于通过规模化、多样化环境提升智能体的复杂推理和长期决策能力，强调环境对agent行为和能力塑造的重要性，直接契合该团队关于提升AI Agent评估准确性、行为可靠性及自主学习优化机制的研究需求。; 诺亚: Session强调end-to-end RL与LLM智能体的结合，环境作为训练和反馈的关键，支持自博弈和经验学习等后训练强化学习框架，能为该团队关于自博弈和latent reasoning的训练框架提供环境设计和交互支持。
