#!/bin/bash

# Simple Web Content Extraction Script
# Usage: ./run_crawl.sh [URL] [SCHEMA_FIELDS]

echo "ğŸš€ Web Content Extraction Tool"
echo "=============================="

# Default settings
DEFAULT_URL="https://kdd2025.kdd.org/research-track-papers-2"
DEFAULT_SCHEMA="title author doi affiliation"

# Use provided arguments or defaults
URL=${1:-$DEFAULT_URL}
SCHEMA=${2:-$DEFAULT_SCHEMA}

echo "ğŸ“ URL: $URL"
echo "ğŸ“‹ Schema: $SCHEMA"
echo ""

# Run extraction
echo "ğŸ”„ Starting extraction..."
python crawl.py "$URL" --schema $SCHEMA --strategy two-pass --verbose

echo ""
echo "âœ… Done! Check the output CSV file."
echo ""
echo "ğŸ’¡ Usage examples:"
echo "   ./run_crawl.sh"
echo "   ./run_crawl.sh \"https://example.com\" \"title author date\""
echo "   ./run_crawl.sh \"https://news-site.com\" \"headline summary author\""