[
    {
        "title": "Telling Stories at Scale: Multimodal ML in the Global Media Landscape",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T08:30:00",
        "end_datetime": "2025-12-02T09:30:00",
        "url": "https://neurips.cc/virtual/2025/128652",
        "speaker": "",
        "abstract": "Netflix has long been recognized as a pioneer in personalization, leveraging member preference data to recommend the most engaging shows, movies, and games. In recent years, we have expanded our use of machine learning and data-driven approaches to support a wide array of upstream creative and operational workflows. In this talk, we will discuss how modern AI methods \u2013 contrastive learning, transformers, cross-modal retrieval, graph neural networks, etc. \u2013 are transforming the curation, localization, promotion, and launch of stories on a global scale. A distinctive aspect of our work is the integration of highly creative assets\u2014text, images, video, and speech\u2014alongside traditional tabular datasets. We will highlight unique challenges that arise at the intersection of multimedia, personalization, and web-scale products, and share how advanced ML/AI techniques are addressing these challenges to connect great stories with our worldwide audience.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Data\u202fScout: \u201cFrom Prompt to Corpus: Accelerating Domain-Specific Data Collection with LLMGuided Discovery\u201d",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T08:30:00",
        "end_datetime": "2025-12-02T09:30:00",
        "url": "https://neurips.cc/virtual/2025/128656",
        "speaker": "",
        "abstract": "Training large language models for specialized disciplines such as advanced mathematics, molecular biology, or legal reasoning is limited by the scarcity of large, high quality, domain specific corpora. Most publicly available datasets are dominated by general purpose web text. When available, specialized data are fragmented across diverse sources such as preprints, conference papers, forums, lecture notes, and digitized books. No single source offers comprehensive real-world coverage across scientific domains. Consequently, scaling up authentic domain data remains a bottleneck: collecting a subset of relevant tokens often requires downloading and filtering hundreds of terabytes of raw web material, a process that is both time consuming and costly.x000Dx000DWe introduce Data\u202fScout, a modular, LLM powered pipeline that turns a high-level user intent (e.g., \u201cI need data for advanced mathematics\u201d) into a vetted, list of seed URLs in minutes. The system first expands the original intent using an LLM that generates a hierarchical subgraph of related concepts; this taxonomy drives a diversified set of search queries that systematically cover the target domain while respecting known licensing signals. Candidate URLs are then filtered by the same LLM using chain of thought prompting based on topical relevance, licensing clarity, and crawlability. Our results show that that the list of selected candidate URLs when crawled can yield a high percentage of relevant pages (40%+) related to the user\u2019s intended topic or query, compared to less than 1 percent in general web-scale corpora. Data\u202fScout is available with both CLI and GUI front ends. By democratizing domain specific data acquisition, Data\u202fScout enables researchers without dedicated crawling infrastructure to bootstrap large, high-fidelity corpora, accelerating the development of specialized LLMs across various niche domains fields.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Multimodal Data Foundation at Industry-Scale",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T08:30:00",
        "end_datetime": "2025-12-02T09:30:00",
        "url": "https://neurips.cc/virtual/2025/128659",
        "speaker": "",
        "abstract": "Pre-training is fundamental to foundation models, enabling them to acquire broad knowledge that gives rise to emerging capabilities at later training stages, and scaling is the key for pre-training. In this talk, we present a recipe for building and curating pre-training, multimodal image-text paired data from scratch on a global scale, enabling mutual benefits between English and non-English data. We would like to share our key observations and insights with the community on: (1) why scaling matters, including the foundational role of data and key principles to hold for scaling; (2) how to design simple yet scalable data algorithms that enable industry-scale data collection and training without data filters, serving both research and production needs; (3) how the scaling improves Meta\u2019s products at conventional and frontier machine learning areas. Submission is facilitated by Cogs & Marvel but is entirely organized, executed, and implemented by Meta.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Toward General Full Autonomy: Open Research Challenges in Scalable Self-Driving",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T08:30:00",
        "end_datetime": "2025-12-02T09:30:00",
        "url": "https://neurips.cc/virtual/2025/128661",
        "speaker": "",
        "abstract": "Speaker: Ben Snyder, Director of AI Research for Autonomous Vehicles, General Motorsx000Dx000DGM\u2019s driver-assistance systems now power millions of vehicles across North America, logging over half a billion hands-free miles with zero reported crashes\u2014demonstrating the safety and scalability of autonomy at unprecedented consumer scale. Following GM\u2019s acquisition of Cruise earlier this year, the combined teams now bring together a decade of experience to accelerate progress toward full, generalized autonomy. This talk will dive into the open research challenges ahead\u2014from model architecture and the balance between imitation and reinforcement learning, to leveraging vision-language models for long-tail, common-sense reasoning, and advancing the training, deployment, and simulation infrastructure needed to scale truly generalized autonomy.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Beyond Benchmarks: Rethinking Reasoning in Language Models",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T08:30:00",
        "end_datetime": "2025-12-02T09:30:00",
        "url": "https://neurips.cc/virtual/2025/128665",
        "speaker": "",
        "abstract": "Reasoning is often described as the next frontier for AI, but what does it really mean for a model to \u201creason\u201d, and how should we measure it? Popular benchmarks like GSM8K suggest steady progress, yet controlled studies reveal that models can fail dramatically under small changes\u2014such as swapping numbers or adding irrelevant details. Large Reasoning Models (LRMs), which generate explicit chains of thought, raise new optimism but also expose clear limits: they often underperform standard models on simple tasks, improve briefly at medium complexity, and then collapse on harder ones despite having unused compute. Crucially, reasoning is not the same as knowledge recall, tool use, or agent-like behavior. True reasoning involves solving novel problems, decomposing them into steps, generalizing to new contexts, recombining partial results, and finally generating novel hypotheses\u2014capabilities current systems largely lack. Today\u2019s evaluations, focused on final answers and contaminated benchmarks, risk giving a misleading sense of progress. This talk will provide a critical review of reasoning in language models, highlight why current evaluations can be deceptive, and emphasize that reasoning is not just about \u201cwhat\" models answer, but \u201chow\" they solve problems.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Foundational Generative Recommendations for E-Commerce",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T08:30:00",
        "end_datetime": "2025-12-02T09:30:00",
        "url": "https://neurips.cc/virtual/2025/128667",
        "speaker": "",
        "abstract": "Modern commerce platforms face the challenge of delivering personalized recommendations across billions of items to users with diverse intents, temporal dynamics, and cold-start scenarios. We present a generative foundation model for commerce built on Hierarchical Sequential Transduction Units (HSTU) that integrates Liquid Foundation Models (LFM) for rich textual product representations and custom CUDA kernels developed in collaboration with Nvidia for efficient training and online serving. Our approach demonstrates that generative methods unlock substantial gains through three key innovations: (1) large-scale contrastive learning with hard negative sampling; (2) temporal mechanisms that fuse multi-scale time signals (session, day, season) with commerce-specific features; and (3) optimized training and inference kernels. By treating LFM embeddings as auxiliary features rather than end-to-end fine-tuning, we maintain modularity while capturing semantic relationships. While results are promising, significant challenges remain in handling non-stationary preferences, multi-objective optimization, and ensuring fairness in generative retrieval\u2014we discuss our roadmap toward truly foundational commerce models that generalize across domains and market conditions.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "From Research to Markets: Applying Cutting-Edge Machine Learning in Quantitative Finance",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T08:30:00",
        "end_datetime": "2025-12-02T09:30:00",
        "url": "https://neurips.cc/virtual/2025/128670",
        "speaker": "",
        "abstract": "In modern quantitative finance, the boundaries between academic machine learning research and real-world trading strategies are rapidly dissolving. In this talk, we will share how researchers at G-Research apply advances in deep learning, probabilistic modelling, reinforcement learning, and large-scale optimization to some of the most challenging problems in global financial markets. Our work transforms vast, noisy, and non-stationary data into predictive signals, demanding innovations that extend the state of the art in both theory and practice. This includes sequence modelling for high-frequency data, scalable Bayesian inference for uncertainty quantification, generative modelling for scenario analysis, and reinforcement learning for adaptive portfolio construction. Operating at the intersection of rigorous science and high-performance computing, we thrive in an environment where milliseconds matter and model generalization is paramount.x000Dx000DCome and see how cutting-edge machine learning meets the realities of global financial markets at G-Research.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T08:30:00",
        "end_datetime": "2025-12-02T09:30:00",
        "url": "https://neurips.cc/virtual/2025/128668",
        "speaker": "",
        "abstract": "The rapid integration of LLMs for synthetic data generation offers a powerful solution for data scarcity, a critical issue for training machine learning models. However, the resulting data quality is often questionable, requiring costly and time-consuming manual review. This oversight is especially challenging in the crucial domain of trustworthy and safe AI.x000Dx000DA significant need here is the automated identification of adversarial and harmful inputs, a process known as red-teaming, to improve guardrailing systems before deployment. Developing an effective, fully automated red-teaming approach capable of generating diverse, out-of-domain harmful content has been a long-standing challenge.x000Dx000DTo address data scarcity in harmful text detection & the challenge of automated red-teaming, we introduce GRAID (Geometric & Reflective AI-Driven Data Augmentation), a novel, versatile, & dynamic multi-agent framework.x000Dx000DGRAID operates in two stages:x000D1) Geometric Generation: A constrained, fine-tuned LLM generates geometrically controlled examples to diversify content within the original embedding space.x000D2) Reflective Augmentation: A multi-agentic reflective process promotes stylistic diversity & uncovers difficult edge cases.x000Dx000DThis combination ensures both reliable coverage of the input space & nuanced exploration of harmful content. We demonstrate that augmenting a harmful text classification dataset with GRAID significantly improves the performance of downstream real-world guardrail models. Furthermore, GRAID captures data variability in new geometric domains while preserving data relationships.x000Dx000DWhile initially focused on harmful text detection, GRAID\u2019s modular design makes it an inherently domain-agnostic framework adaptable to various applications beyond classification. In this talk, we will detail how GRAID distinguishes itself from existing solutions, discuss its building blocks, & share insights on its easy adaptation for diverse synthetic data generation needs.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Planning in the Era of Language Models",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T09:30:00",
        "end_datetime": "2025-12-02T12:00:00",
        "url": "https://neurips.cc/virtual/2025/109596",
        "speaker": "",
        "abstract": "For over six decades, the field of automated planning has been at the heart of AI, empowering intelligent systems to reason, act, and achieve goals in complex, dynamic environments. From robotics and logistics to space exploration, planning research has fueled autonomous decision-making in real-world applications.Today, as large language models redefine what\u2019s possible in AI, the principles and methodologies of planning are more vital than ever. The planning community brings decades of experience in designing, benchmarking, and interpreting intelligent behavior; expertise that can accelerate the development of powerful, trustworthy, and general-purpose LLM-based agents.Participants will gain a clear understanding of what planning truly entails, what has been learned (and sometimes forgotten) in the shift toward LLM-based approaches, and how foundational insights from the planning community can inform the creation of stronger, more reliable, and more scalable LLM-powered planners.",
        "overview": "Overview: The webpage presents a tutorial titled 'Planning in the Era of Language Models' scheduled for December 2nd, 2025, at NeurIPS in San Diego, CA. The tutorial focuses on the integration of automated planning with large language models (LLMs). It highlights the importance of planning in AI, especially as LLMs redefine AI capabilities. The tutorial aims to provide participants with insights into planning methodologies and how these can enhance the development of LLM-based agents. | Research Interests: Automated planning, Large language models, AI reasoning and decision-making, Planning formalisms and languages, Evaluation of planning tools, Human-aware AI systems",
        "location": "San Diego"
    },
    {
        "title": "Foundations of Tensor/Low-Rank Computations for AI",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T09:30:00",
        "end_datetime": "2025-12-02T12:00:00",
        "url": "https://neurips.cc/virtual/2025/109591",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Human-AI Alignment: Foundations, Methods, Practice, and Challenges",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T09:30:00",
        "end_datetime": "2025-12-02T12:00:00",
        "url": "https://neurips.cc/virtual/2025/109592",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Model Merging: Theory, Practice and Applications",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T09:30:00",
        "end_datetime": "2025-12-02T12:00:00",
        "url": "https://neurips.cc/virtual/2025/109593",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "New Frontiers of Hyperparameter Optimization: Recent advances and open challenges in theory and practice",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T09:30:00",
        "end_datetime": "2025-12-02T12:00:00",
        "url": "https://neurips.cc/virtual/2025/109594",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Explain AI Models: Methods and Opportunities in Explainable AI, Data-Centric AI, and Mechanistic Interpretability",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T09:30:00",
        "end_datetime": "2025-12-02T13:30:00",
        "url": "https://neurips.cc/virtual/2025/109599",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Energy and Power as First-Class ML Design Metrics",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T09:30:00",
        "end_datetime": "2025-12-02T12:00:00",
        "url": "https://neurips.cc/virtual/2025/109589",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The tutorial titled 'Energy and Power as First-Class ML Design Metrics' at NeurIPS 2025 focuses on addressing energy as a critical bottleneck in machine learning. It provides practical measurements, a primer on power and energy as computing resources, and optimizations from kernels to clusters. The event is a collaboration between The ML.ENERGY Initiative at the University of Michigan and NVIDIA, featuring a series of sessions and an industry panel discussion. | Research Interests: Energy efficiency in machine learning, Power and energy as computing resources, Performance optimization under power constraints, Energy optimization with performance considerations, Industry applications of power and energy in ML",
        "location": "San Diego"
    },
    {
        "title": "Multimodal AI Forensic Search for Video Surveillance",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128632",
        "speaker": "",
        "abstract": "Video surveillance often requires searching for specific targets from long-duration videos using multiple cameras. Traditional tracking\u2011and\u2011detection pipelines demand heavy manual filtering, and even recent multimodal approaches such as using CLIP remain limited to shallow visual attributes (e.g., clothing color) and weak temporal reasoning. This makes forensic search labor\u2011intensive.x000Dx000DWe present ForeSea, a novel AI forensic search system that supports rich multimodal queries (text + image) and returns timestamped evidence of key events. ForeSea is organized as a multi\u2011stage pipeline that couples tracking and retrieval with time\u2011aware VideoLLM reasoning: (1) uses tracking model to filter out irrelevant segments (e.g., frames without people) and produces person\u2011centric clips; (2) retrieval constructs an index over tracked clips to form a searchable database; and (3) during inference, the multimodal query is embedded to retrieve the top N candidate clips, which are then fed into a time-aware VideoLMM that performs temporal grounding and generates precise answers from concise input. Through ForeSea's multi-stage pipeline, we can search for targets using both image and text queries (e.g., asking 'When does this person get involved in a fight?' with an image of the person). This approach eliminates the need for detailed textual descriptions and enables effective temporal understanding across long videos.x000Dx000DTo evaluate LMM based forensic search, we introduce AI Forensic\u2011QA, a benchmark for multimodal video question answering with temporal grounding. On this benchmark, ForeSea achieves an 8.6 % accuracy improvement and a 6.9 (IoU) gain over strong baselines. To the best of our knowledge, this is the first benchmark in this domain to support multimodal queries evaluation. Our live demo showcases multimodal search, timestamped evidence visualization, and side\u2011by\u2011side comparisons with SOTA models.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Efficient LiDAR Processing with AI Models Leveraging Heterogeneous Compute",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128633",
        "speaker": "",
        "abstract": "This demo showcases heterogeneous compute execution of a LiDAR model running in real time on an edge device. The LiDAR processing, specifically 3D sparse convolution (spconv3d) network, runs on the Qualcomm Adreno GPU, while the Region Proposal Network (RPN) executes on the Qualcomm Hexagon NPU.  This division of labor across specialized processors reduces on-device inference latency and maximizes overall efficiency. Additionally, a lightweight, learnable voxel removal layer that hierarchically prunes redundant voxels further reduces inference time without compromising detection accuracy.x000Dx000D\"This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.\"x000Dx000DImplementation challenge that we tacklex000Dx000DLiDAR models often combine different types of operations: irregular, sparse computations (e.g., SpConv3D) and dense convolutional layers (e.g., CNNs). These operations have distinct hardware affinities\u2014SpConv3D is better suited for SIMT-style GPUs, while CNNs benefit from SIMD-style NPUs. Efficient execution requires mapping each part of the model to the most appropriate compute unit.x000Dx000DAnother challenge is the variability in voxel density across LiDAR frames. Not all voxels contribute meaningfully to object detection, many represent ground planes or distant background and can be safely discarded. However, identifying and removing these in a lightweight, learnable way is non-trivial.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Parallel generation with verification on device",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128634",
        "speaker": "",
        "abstract": "In this work, we address the challenges of efficiently generating and verifying multiple responses from large language models (LLMs) directly on device. While sampling with non-zero temperature often yields improved responses compared to greedy approaches, selecting the best response requires generating several candidates and evaluating them without incurring significant latency or resource overhead. Cloud-based solutions often rely on separate verification models, which are impractical for on-device deployment due to resource constraints. Our proposed solution leverages multi-stream execution graphs and parallel LLM generation, enabling joint generation and verification within a unified framework. Combined with post-processing techniques such as majority voting, this approach minimizes latency and optimizes the selection of high-quality responses, paving the way for more effective on-device LLM inference.x000Dx000DSpecific challenge that we tackle (research/implementation-wise)x000Dx000DUsing non-zero temperature sampling with language models can result in higher-quality responses compared to greedy sampling, although this is not always assured. Achieving optimal output often requires generating multiple candidate responses and selecting the most suitable one for the user. This technique is widely adopted to enhance inference-time performance. When implemented on device, however, it presents two primary challenges: minimizing the latency associated with generating several responses and determining a resource-efficient method for selecting the best response from the generated set.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Soft Prompts for On-Device Content Moderation",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128635",
        "speaker": "",
        "abstract": "We demonstrate the first on-device integration of a safety-aligned large language model (LLM) using soft prompt distillation, powered by our proposed TV-DiSP framework. Our system showcases how a mobile device can run a quantized LLM equipped with learned soft prompts to moderate harmful or toxic content in real-time. The demo highlights the difference in LLM outputs with and without our soft prompts when subjected to adversarial or unsafe inputs, enabling efficient and safe deployment of LLMs on edge devices.x000Dx000DLLMs are known to produce unsafe or toxic outputs when prompted harmfully. Traditional safety mechanisms rely on dual-model architectures\u2014pairing a base LLM with a separate guard model\u2014which are memory and computationally expensive and unsuitable for deployment on resource-constrained devices like smartphones. The challenge is to achieve robust safety alignment without compromising latency, memory, or model utility in edge environments.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Generating group photos of multiple people from text and reference images",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128636",
        "speaker": "",
        "abstract": "Reference-based multi-human image generation is emerging as a critical capability for personalization, synthetic data creation, and benchmarking generative models. Unlike single-subject generation, this task requires compositional reasoning to place multiple individuals\u2014each with distinct identities\u2014into a coherent scene guided by a text prompt. Existing models often fail to preserve identities or maintain spatial fidelity, which limits their applicability for real-world scenarios such as social content creation or training vision systems.x000Dx000DOur demo addresses these challenges by showcasing a state-of-the-art system for reference-based multi-human generation. The system takes reference images of multiple individuals and a text description of the desired scene, then produces a high-quality image featuring all participants in context. Built on the Flux-Kontext backbone and trained using synthetic data from DisCo (arXiv:2510.01399), our RL-based approach optimizes multiple rewards including Human Preference Score (HPS3) and Average ID Similarity. Evaluation on MultiHuman-Testbench (arXiv:2506.20879) confirms state-of-the-art performance.x000Dx000DThis demo showcases fast generation on a laptop powered by a Snapdragon processor, highlighting the efficiency and scalability of our solution.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Reasoning through Multimodal End-to-End Decision Transformer Networks and Vision Language Action (VLA) models",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128637",
        "speaker": "",
        "abstract": "This demonstration showcases the live output and visualization capabilities of an edge-integrated VLA model for path planning in automated driving scenarios. By harnessing raw multimodal sensor inputs, including visual and voice data, the VLA model processes information in real time to generate safe, explainable, and repeatable driving trajectories. The system operates on a Snapdragon Ride Elite SoC platform and incorporates safety guardrails, enabling robust decision-making and transparent reasoning. Attendees will observe how end-to-end AI networks interpret complex environmental cues to deliver actionable driving paths, with a special focus on complex use cases involving vulnerable road users and other actors on the road. This demonstration highlights advances in multimodal reasoning and edge deployment for next-generation intelligent mobility solutions.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Disaggregated LLM Serving on AI Accelerators",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128638",
        "speaker": "",
        "abstract": "This demo showcases\u202fdisaggregated serving on Qualcomm Cloud AI 100 Ultra Card, a power-efficient AI inference accelerator purpose-built for large language models (LLMs) serving. The accelerator has been deployed across multiple cloud service providers (CSPs) globally and is actively serving state-of-the-art LLMs and other generative AI workloads.x000Dx000DLLM inference typically involves two distinct stages:\u202fprefill\u202fand\u202fdecode. The prefill stage is compute bound, while the decode stage is memory bound. Applying uniform parallelism strategies across both stages often results in suboptimal performance, particularly in key metrics such as\u202fTime to First Token (TTFT)\u202fand\u202fRequests Per Minute (RPM)\u202fat the cluster level.x000Dx000DThis demo highlights the performance benefits of\u202fdisaggregated parallelism strategies\u202ftailored to the unique characteristics of each stage. By optimizing the execution of prefill and decode independently, we demonstrate significant improvements in TTFT and overall throughput.x000Dx000DKey benefits:x000Dx000DImproved TTFT:\u202fFaster initial response times for LLM queries.x000Dx000DHigher throughput:\u202fIncreased number of requests served per minute at the cluster level.x000Dx000DOptimized resource utilization:\u202fEfficient mapping of compute and memory resources to match workload characteristics.x000Dx000DSLA-adherent performance:\u202fMaintains service quality and responsiveness within strict latency and throughput requirements.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "SwiftEdit: Fast Text-guided Image Editing via One-step Diffusion on a Mobile Device",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128639",
        "speaker": "",
        "abstract": "In this demo, we show an on-device inference of our one-step diffusion image editing model (SwiftEdit) [1] that performs interactive image editing based on the user\u2019s source image and text prompt, running on an Android smartphone powered by Qualcomm Technologies\u2019 latest Snapdragon Mobile Platform. On A100 GPUs, this technique can run in real-time with 0.23s per single edit operation. We expect SwiftEdit to perform each edit operation in seconds on the smartphone, demonstrating efficient and responsive on-device diffusion inference.x000Dx000DScientific Challenge that we tacklex000Dx000DExisting text-guided image editing methods fell short of the speed demands required for real-world and on-device applications due to the costly multi-step inversion and sampling process involved. In response to this, we developed SwiftEdit that performed image editing using just one-step inversion and one-step image reconstruction.x000Dx000DEfficiently running SwiftEdit requires concurrently on-boarding multiple deep models, including IP-Adapter (Vision Encoder and Image Projection), SwiftBrush (U-Net, VAE, Text Encoder), and SwiftBrush-based Inversion Network. This poses significant challenges for efficient execution and inter-module communication, while enabling an interactive image editing experience for the user \u2014 with all computation performed entirely on the edge device.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Mobile Video Diffusion Transformers",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128640",
        "speaker": "",
        "abstract": "We demonstrate Neogradon, the first video diffusion transformer (DiT) designed to run on low-power NPUs in mobile devices, such as phones and laptops. Despite DiTs huge memory and computation cost due to the quadratic attention over thousands of video tokens, we show that mobile devices can run these models when being designed for efficiency. To achieve this level of efficiency:x000Dx000DWe replace the original large text encoder with a much smaller one with minimal quality loss through our novel distillation framework, which doesn\u2019t require any image or video data.x000Dx000DWe propose an asymmetric decoder distillation approach, which allows us to replace the native codec-latent-VAE decoder with a more efficient one, without disturbing the generative latent-space of the video generation pipeline.x000Dx000DWith our block pruning strategy, we remove entire blocks from the MMDiT denoiser based on their relative importance and recover the original performance through a two-stage distillation process.x000Dx000DWe reduce the diffusion sampling cost using our novel extended version of DMD (distribution matching distillation) for the pyramidal flow-matching objective.x000Dx000DNeodragon generates 49 frames of 640x1024 resolution within 7.6 seconds on the Qualcomm Hexagon NPU with the VBench total score of 81.61, setting a new state of the art for mobile video generation.x000Dx000D\"This Proposal is provided for review and evaluation purposes only. Do not redistribute to any third party without the express prior written consent of Qualcomm Technologies, Inc.\"",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Pushing the boundaries of chemical synthesis with RetroChimera",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128641",
        "speaker": "",
        "abstract": "Retrosynthesis - the task of planning chemical reaction recipes to synthesize complex molecules - remains a bottleneck in the discovery of novel pharmaceuticals. We recently released RetroChimera - a model for predicting chemical reactions - which demonstrated robustness well outside of training distribution by transferring zero-shot to internal reaction data at a major pharmaceutical company. We also found that industrial organic chemists prefer predictions from RetroChimera over real patented reactions in terms of quality, revealing a high degree of alignment. In this demo, we will showcase the model, let attendees query it live, and show them how to interpret the results.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "BeeAI",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128642",
        "speaker": "",
        "abstract": "The BeeAI Framework is an open-source project for building reliable AI agents that combine autonomy with control. Current agent frameworks focus primarily on prompting and orchestration, leaving critical questions of predictability and safety unaddressed. BeeAI fills this gap with a lightweight framework that enables developers to build agents whose reasoning abilities are preserved while execution is constrained by declarative, rule-based requirements. At the core of the framework is the RequirementAgent, a novel agent design that enforces deterministic, controlled behaviors across heterogeneous language models. With RequirementAgent, developers can ensure consistent and reliable execution patterns regardless of differences in model reasoning, tool-calling abilities, or stochastic variation. This approach provides practitioners with a unified abstraction layer that simplifies the deployment of complex AI systems into production settings. As an incubating Linux Foundation AI project, BeeAI is gaining adoption in open source and enterprise contexts as organizations seek robust ways to operationalize AI agents at scale. At NeurIPS EXPO, we will showcase BeeAI\u2019s architecture, real-world use cases, and lessons learned from applying declarative control to agent autonomy.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "ContextForge",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128643",
        "speaker": "",
        "abstract": "The rapid rise of autonomous AI agents across enterprises is creating a new class of security and governance challenges that are not adequately addressed with today\u2019s technology. Context Forge MCP Gateway is an open-source, security-focused middleware that provides fine-grained control and extensibility for agent operations. With over 2.6k GitHub stars and a rapidly growing user community, Context Forge addresses emerging threat classes including prompt injection, data leakage, and misuse of sensitive resources. At its core, Context Forge introduces a plugin architecture modeled after Linux Security Modules, embedding reusable security hooks at critical points in agent execution (e.g., prompt handling, tool invocation, data transformation). This modular foundation enables organizations to enforce contextual policies at scale\u2014ranging from PII redaction and provenance tagging to prompt injection detection and policy-based access control. With 39 plugins already available, Context Forge is establishing a standards-aligned ecosystem for securing agent workflows in real-world enterprise deployments. By blending research-driven design with open-source adoption it creates a practical path for organizations to advance agent trustworthiness, safety, and compliance.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "LLM-Powered Intelligent Data Engineering: From Workflow Design to Ingestion andQuality Assurance",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128644",
        "speaker": "",
        "abstract": "Modern enterprises depend on efficient data engineering pipelines to unlock value from diverse and large-scale datasets. Yet, current processes for workflow design, schema ingestion, and data quality validation remain complex, error-prone, and dependent on technical expertise. This creates barriers for non-expert users, slows down development, and introduces risks of data inconsistency.x000Dx000DWe present a suite of LLM-powered frameworks that reimagine enterprise data engineering across three critical dimensions: (i) From Natural Language to Executable ETL Flows, enabling intuitive pipeline creation with natural language specifications and automatic operator/property inference, (ii) All You Can Ingest, an end-to-end schema mapping and transformation framework that unifies semantic alignment, code synthesis, and robust validation, and (iii) Quality Assessment of Tabular Data, a scalable approach for auto-generating interpretable quality rules and executable validators tailored to specific datasets.x000Dx000DTogether, these innovations demonstrate how Large Language Models (LLMs), augmented with retrieval, code synthesis, reasoning, and guardrails, can transform the data engineering lifecycle into a more accessible, adaptive, and trustworthy process, reducing manual effort, accelerating time-to-value, and ensuring data fidelity at enterprise scale.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "ALICE: Agentic Logic for Incident and Codebug Elimination",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128646",
        "speaker": "",
        "abstract": "Modern incident root-cause analysis (RCA) is constrained by partial observability, symptom-centric signals, and the overwhelming noise present in logs, traces, and metrics. Diagnosing production failures often depends on instrumentation quality and human expertise, while latent software defects, configuration errors, and zero-day failure modes remain difficult to pinpoint. To address these challenges, we demonstrate a multi-agent system for incident diagnostics that augments observability data with application source code and static analysis signals.x000Dx000DOur system introduces two cooperating agents: the Code Context Agent (COCOA), which builds a knowledge graph of program dependencies, control/data flows, and caller\u2013callee relationships; and the Incident Diagnostics Agent (IDA), which performs agentic reasoning over an entity topology graph enriched with observability streams. Together, these agents extend topology-aware planning (TAP) to simultaneously operate on program dependency graphs and infrastructure entity graphs, thereby linking runtime symptoms with underlying code-level causes.x000Dx000DThis demo showcases how multi-agent collaboration enables deeper, context-sensitive RCA. We walk through real-world inspired scenarios\u2014including incidents where critical log lines are hidden in noisy observability streams or where latent defects emerge only after system updates\u2014illustrating how the system surfaces root causes that would otherwise remain invisible. By bridging program analysis with runtime observability, our approach moves beyond symptom-driven diagnostics toward a more reliable, automated framework for incident management.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "AI or Human",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128647",
        "speaker": "",
        "abstract": "This demo from Sound Patrol will ask the audience to guess whether content is AI or Human, challenging the limits of human perception while showcasing an audio foundation model with multiple task heads, fine-tuned to classify and attribute the source of AI content",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Who Needs Attention Anyway? Real-Time Control from Learned State Geometry",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128648",
        "speaker": "",
        "abstract": "Large language models changed how we reason with data, not how we act under constraints. Their latency grows with context, adaptation depends on retraining, and safety is emergent rather than measurable. For robots, simulators, and industrial systems that must react now, this compute model is the wrong fit.CurvOS offers an alternative: a real-time operating layer where streaming state-space models (SSMs) meet geometry and reinforcement learning to deliver stable, on-device intelligence. At its core, CurvOS runs a fast streaming SSM coupled to a local Riemannian planner derived from decoder sensitivities. Each step predicts the next state, estimates local curvature (how small perturbations bend predicted dynamics), and moves a short distance along a geodesic within a trust radius.Compute per step stays fixed, so latency and adaptation remain bounded. Unlike streaming SSMs such as Mamba, CurvOS learns geometry online to steer predictions safely without retraining. The result is a compact, measurable control stack that reasons in real time, adapts continuously, and meets physical or chemical objectives under fixed budgets. CurvOS turns sequence models into predictable decision engines for systems where timing and safety matter most.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "PRIME Guardrails in Action: A Live Demonstration of an Agentic, Multi-Layered Safety Framework for Generative AI",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128650",
        "speaker": "",
        "abstract": "The rapid proliferation of large-scale Generative AI systems has created an urgent need for safety frameworks that are both robust and performant. Existing solutions often present a false dichotomy: simple, low-latency filters that are easily circumvented by adversarial inputs, or powerful, semantically-aware models that introduce prohibitive latency for real-time applications. This demonstration introduces a live, practical instantiation of the PRIME (Policy, Risk, Intervention, Monitoring, Evaluation) framework, a novel, modality-agnostic architecture designed to resolve this trade-off. We will showcase a production-grade, multi-layered \u201cDefense in Depth\u201d safety system that utilizes an agentic workflow to intelligently orchestrate heterogeneous guardrail models. The system combines the deep contextual reasoning of large proprietary models (e.g., Google\u2019s Gemini) for nuanced threat assessment with the speed of specialized, open-source classifiers for rapid, early-exit filtering of common violations. Through a series of live, interactive examples, we will demonstrate the system's ability to detect and neutralize a range of adversarial inputs in real-time across both text and image modalities. Attendees will witness the framework successfully identifying and blocking prompt injection attacks, harmful content requests, and policy violations, thereby proving the efficacy of a hybrid, agentic approach to building safer, more trustworthy Generative AI experiences at scale.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Creative and Protective AI for Music and Entertainment",
        "type": "Expo Workshop",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128679",
        "speaker": "",
        "abstract": "Generative AI is reshaping how we create, experience, and safeguard music and entertainment. This workshop presents technologies that expand creative expression while honoring responsibility. On the creative side, we share collaborative artworks with leading sound artists, neural engines for sound design and performance, and automatic mixing that adapts to musical intent. We also present a large multimodal dataset for multishot speech video that supports research on coherent and controllable speech, together with specialized language models that orchestrate camera transitions, gestures, vocal cues, and sound effects. On the protective side, we advance AI methods for data attribution, traceability, and responsible model behavior that safeguard creative data and prevent unintended memorization, ensuring fairness, transparency, and respect for creators\u2019 rights. Together, these threads outline an ecosystem in which AI amplifies artistic practice while preserving the integrity of human contribution.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Large-Scale Real-World Physical AI Systems",
        "type": "Expo Workshop",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128672",
        "speaker": "",
        "abstract": "Motivation and Scopex000Dx000DPhysical AI systems comprise of four things: namely sensors like cameras and lidar, mechanical and electronic control unit, AI models to reason about the environment, and actuators to convert decisions to physical actions. It marries multiple domains like sensor design, perception, low-power real-time hardware design, and control loop action design. Autonomous driving is the most mature physical AI domain deployed for over 10 years, but it still has many open challenges. Humanoid robots are an emerging physical AI domain with potential for near term commercial deployment. One of the major challenges in physical AI is to scale to all real-world scenarios including corner cases in a safe manner. A scalable AI data flywheel is the most critical module to achieve this. Traditional physical AI models have a modular decomposition of perception and action tasks, but the community is increasingly moving towards a single end-to-end AI model.  Furthermore, recent advancements in LLMs and VLMs are leading to VLA (Vision-Language-Action) based end-to-end models. In the future, there will likely be a convergence of physical AI models across different domains like driving and robotics.  The proposed workshop covers the latest research and best practices in industrial research of physical AI by leaders in the domain. It also covers emerging technologies like VLA based foundation models, AI data flywheel, and cross-embodiment learning focused on Physical AI.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Checkmate: Fine-tune your own small language model for real-time chess reasoning and gameplay on AWS Trainium",
        "type": "Expo Workshop",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128680",
        "speaker": "",
        "abstract": "In this hands-on workshop, participants will leverage AWS Trainium to fine-tune and deploy their own chess-playing language models. Building on recent research showing language models' effectiveness in reasoning, attendees will work with various chess datasets to create AI models that not only play chess but explain their strategic thinking through natural language. The 90-minute session will cover model fine-tuning techniques, optimization strategies specific to Trainium's architecture, and real-time deployment to a chess engine. The workshop culminates in a live tournament where participants' models compete against each other, providing immediate feedback on their implementations. Participants will leave with a working chess reasoning model, practical experience in fine-tuning language models on Trainium, and transferable skills for similar tasks. Python programming experience and familiarity with LLM concepts are required, in addition to a basic understanding of the rules of chess. Workshop materials and AWS credits will be provided.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Workshop on multimodal Superintelligence",
        "type": "Expo Workshop",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128681",
        "speaker": "",
        "abstract": "Multimodal machine learning is among the most promising directions of artificial intelligence. With remarkable progress in academia and industry on this topic, we are at the cusp of building next-generation multimodal models, i.e. multimodal superintelligence. These models can be defined as being able to observe, think, and act across several modalities. At this important junction, our workshop provides a forum for researchers to align and cross-polinate ideas. The Workshop on Multimodal Superintelligence will provide a venue where the community can gather to discuss the current state of multimodal machine learning science. Together, we will attempt to overcome the current barriers of modeling several modalities at once. We will also focus on topics such as cross-modal reasoning, alignment, fusion and co-learning.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Interpretable AI for Risk-Based Human Rights Assessment in Global Supply Chains",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128649",
        "speaker": "",
        "abstract": "Amazon\u2019s responsible sourcing efforts aim to protect people across its global supply chain. Yet detecting human rights risks such as forced labor or unsafe conditions across hundreds of thousands of suppliers is challenging. Auditing every site is costly and impractical, making a risk-based approach essential focusing resources where the likelihood and severity of issues are greatest. To address this, Amazon developed PRISM AI (Predictive Risk Intelligence for Supplier Management), an interpretable machine learning system that predicts and explains supplier-level risk across global supply chains. Trained on over 70,000 internal and third-party audit records, PRISM integrates signals from self-assessment questionnaires, grievance reports, adverse media, and geo-sector risk indices. These inputs help detect both documented and emerging risks in near real time. The model supports three supplier types: those with audit histories, limited data, or none. It adapts using transfer learning, rule-based heuristics, and domain-specific indicators. Each prediction includes transparent attribution, showing which factors such as safety violations or country-sector exposure, most influenced the score. Built with monotonic constraints, the system ensures logically consistent, explainable outputs for regulatory and operational use.x000DThis demo gives NeurIPS participants a hands-on view of how AI research can be operationalized for real-world impact. Already in production at Amazon, PRISM helps compliance teams prioritize audits, onboard suppliers, and escalate risks thereby reducing review time and improving oversight. For researchers, it highlights methods for building interpretable models under data imbalance and integrating structured and unstructured signals. For practitioners, PRISM shows how AI can scale responsible business practices and drive innovation across environmental and social sustainability domains.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Build verifiable apps using Generative AI and Automated Reasoning",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128651",
        "speaker": "",
        "abstract": "Recent advancements in Generative AI have enabled customers to use LLMs to generate infrastructure code using AWS CLI commands. Because humans can make mistakes, when deployed such LLM-generated infrastructure code can have negative impacts, including on security.x000DMotivated by this challenge, this demonstration introduces participants to automated reasoning tooling that enhanced security in production for Amazon Q chat.x000DAWS Q Chat enables natural language interaction with AWS resources while employing automated reasoning to verify every generated API call against comprehensive semantic logic models. This prevents potentially harmful operations before execution and suggests corrections, creating a feedback loop that iterates until verifiably correct code is produced. Through this work, we demonstrate how organizations can leverage GenAI's efficiency while maintaining the rigorous verification standards required for production environments and participants will learn how to integrate these tools into their workflows to prevent security regressions and ensure reliable infrastructure management. This tutorial Scientists, Engineers, Security professionals and anyone interested in applying formal verification to their infrastructure.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "CausalFairness: An Open-Source Python Library for Causal Fairness Analysis",
        "type": "Expo Workshop",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128677",
        "speaker": "",
        "abstract": "As machine learning (ML) systems are increasingly deployed in high-stakes domains, the need for robust methods to assess fairness has become more critical. While statistical fairness metrics are widely used due to their simplicity, they are limited in their ability to explain why disparities occur, as they rely on associative relationships in the data. In contrast, causal fairness metrics aim to uncover the underlying data-generating mechanisms that lead to observed disparities, enabling a deeper understanding of the influence of sensitive attributes and their proxies. Despite their promise, causal fairness metrics have seen limited adoption due to their technical and computational complexity. To address this gap, we present CausalFairness, the first open-source Python package designed to compute a diverse set of causal fairness metrics at both the group and individual levels. The metrics implemented are broadly applicable across classification and regression tasks (with easy extensions for intersectional analysis) and were selected for their significance in the fairness literature. We also demonstrate how standard statistical fairness metrics can be decomposed into their causal components, providing a complementary view of fairness grounded in causal reasoning. In this active learning talk participants will learn how to quantify bias using CausalFairness at the group (Counterfactual Equalized Odds , Counterfactual Effects) and individual (Counterfactual Fairness) levels by applying each method to three datasets - 1) the Adult Income dataset, 2) the COMPAS dataset, 3) Law School Admission Council (LSAC) Dataset. The session will elucidate on the intuition for computing and interpreting each metric, and conclude with a discussion of their limitations.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Learning to Steer LLMs with AI Steerability 360 and In-Context Explainability 360",
        "type": "Expo Demonstration",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/128645",
        "speaker": "",
        "abstract": "Current algorithms for aligning LLM behavior are often implemented for narrow settings, making it difficult for researchers and developers to understand their effectiveness across model architectures, datasets, and tasks. To help provide a more informed and principled approach to steering model behavior, we present the AI Steerability 360 (AISteer360) and In-Context Explainability 360 (ICX360) toolkits. Participants will first be guided through a conceptual overview for how model behavior can be influenced across four model control surfaces: input (prompting), structural (weights/architecture), state (activations/attentions), and output (decoding). After the conceptual overview, we will guide attendees through how to apply some recently developed explainability tools (from ICX360) for understanding why models produce given, potentially undesirable, outputs and how this information is used to design targeted steering inventions (via AISteer360). Closing the loop, we will evaluate if the baseline behavior (of the original, unsteered model) was successfully mitigated by the selected steering inventions and investigate if steering introduced any unintended behavioral side-effects. All of the experiments throughout the demonstration will be facilitated solely by the tools in the two toolkits, illustrating their power to design end-to-end steering workflows. Attendees will come away with a practical understanding of how to apply these toolkits to their own alignment challenges.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Introduction to Generative Computing",
        "type": "Expo Workshop",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128678",
        "speaker": "",
        "abstract": "This hands-on workshop introduces a proposal that treats LLMs as computing elements governed by established software development principles\u2014particularly task decomposition and modularization\u2014at both the programming model (Mellea) and model level (LLM intrinsics).x000Dx000DLLM outputs are often unpredictable and incorrect. Agentic frameworks and prompt optimization libraries attempt to manage this by giving control to the LLM, but this leads to systems that are hard to debug, maintain, and scale. Mellea offers an alternative: a programming model that restores developer control through modular design, information hiding, and compositional contracts. This enables predictable fault models, better portability, and lower inference costs. Attendees will gain hands-on experience building applications using the Melleaic approach.x000Dx000DExtending these principles to the model level, the workshop introduces a modularization framework for LLMs using activated LoRAs. These produce components\u2014LLM intrinsics\u2014that match fine-tuned model accuracy for specific tasks but with significantly lower inference costs and latency, thanks to KV cache reuse. Participants will build applications using a pre-built library of RAG LLM intrinsics and learn how to train their own.x000Dx000DPresented by the creators of Mellea and the inventors of LLM intrinsics and aLoRA, this workshop equips attendees with foundational skills for scalable model/application co-design.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Exploring Trust and Reliability in LLM Evaluation",
        "type": "Expo Workshop",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T12:00:00",
        "end_datetime": "2025-12-02T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128673",
        "speaker": "",
        "abstract": "The current paradigm of Large Language Model (LLM) evaluation faces a crisis of reliability. Traditional leaderboards\u2014built on static benchmarks and surface-level metrics\u2014have become increasingly distorted by benchmark contamination, prompt overfitting, and evaluation methodologies that fail to reflect model behavior in real-world use. As reasoning models emerge that generate detailed internal thought processes (e.g.,traces) before producing answers, existing evaluation practices\u2014especially for multiple-choice and generation tasks\u2014have become fundamentally inadequate.x000Dx000DThis lack of rigor not only undermines scientific progress and cross-model comparability, but also poses significant enterprise and societal risks, as evaluation results inform model selection, deployment safety, and governance in high-stakes environments.x000Dx000DThis workshop aims to reassert rigor in LLM evaluation by convening researchers and practitioners to address three intertwined challenges: (1) developing fair and consistent evaluation methods for reasoning and non-reasoning models, (2) confronting widespread contamination across public benchmarks and open-weight models, and (3) defining robust data curation and validation practices to prevent future contamination in both pretraining and post-training pipelines.x000Dx000DBy combining empirical findings, methodological advances, and practical case studies, this session\u2014led by Capital One in collaboration with leading AI labs\u2014seeks to chart a concrete path toward trustworthy, contamination-proof, and utility-aligned LLM evaluation frameworks.x000Dx000DThis 1.5-hour workshop will be structured around three highly focused, 25-minute talks, followed by a moderated discussion aimed at forging actionable paths forward for the community:x000Dx000DTalk 1: Robust Evaluation for Reasoning & Non-Reasoning Modelsx000Dx000DTalk 2: Benchmark Contamination \u2014 Detection, Measurement, & Findingsx000Dx000DTalk 3: Preventing Contamination \u2014 Building Clean & Reliable Data Pipelines",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Foundations of Imitation Learning: From Language Modeling to Continuous Control",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T13:30:00",
        "end_datetime": "2025-12-02T16:00:00",
        "url": "https://neurips.cc/virtual/2025/109590",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Scale Test-Time Compute on Modern Hardware",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T13:30:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/109595",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Autoregressive Models Beyond Language",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T13:30:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/109587",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Recent Developments in Geometric Machine Learning: Foundations, Models, and More",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T13:30:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/109600",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Theoretical Insights on Training Instability in Deep Learning",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T13:30:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/109597",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The NeurIPS 2025 tutorial titled 'Theoretical Insights on Training Instability in Deep Learning' explores the oscillatory, spiky, and unstable nature of the optimization process in deep learning. This tutorial aims to provide theoretical insights into the benign nature of these training instabilities, offering perspectives from both optimization and statistical learning. The work challenges classical optimization theory by demonstrating that the best training configurations often operate in unstable regimes. | Research Interests: Gradient-based optimization, Training instability in deep learning, Large stepsizes in optimization, Statistical learning perspectives, Benign nature of instabilities, Optimization efficiency, Overfitting prevention, Implicit bias in optimization, Edge of stability in gradient descent | Key Findings: The tutorial highlights that large stepsizes can accelerate optimization and prevent overfitting, providing a new understanding of the implicit bias and stability in deep learning models. It also discusses the role of training at the edge of stability and how it can lead to efficient optimization and generalization.",
        "location": "San Diego"
    },
    {
        "title": "The Science of Benchmarking: What\u2019s Measured, What\u2019s Missed, and What\u2019s Next",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T13:30:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/109598",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Data Privacy, Memorization, & Legal Implications in  Generative AI: A Practical Guide",
        "type": "Tutorial",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T13:30:00",
        "end_datetime": "2025-12-02T15:00:00",
        "url": "https://neurips.cc/virtual/2025/109588",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Recent developments in embodied AI",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T16:00:00",
        "end_datetime": "2025-12-02T17:00:00",
        "url": "https://neurips.cc/virtual/2025/128653",
        "speaker": "",
        "abstract": "Embodied AI is the study of systems that can perceive and interact with the physical world in real time. Real-world interactions pose unique challenges for AI systems since they naturally require a deep understanding of the physical world and/or its inhabitants. This understanding is often taken for granted in humans, where it is typically labelled as \u201cintuitive physics\u201d or \u201ccommon sense\u201d.x000Dx000DIt is widely agreed that solving this challenge would be as rewarding as it is hard, since it would be equivalent to creating truly capable \u201cworld models\u201d, with countless applications in robotics, human-computer interaction, and even in advancing language modeling through concept grounding. Like other areas in AI, embodied AI has seen dramatic advances in recent years, fueled by the success of using pre-trained large language models as a central ingredient to allow for end-to-end training. While this development stands as one of many examples of the power of pre-trained language models, recently the converse has come true as well: embodied AI is increasingly being drawn on to understand real-world common sense and concept grounding in language models themselves, bringing back its early vision as a way to understand human-like cognition and world models.x000Dx000DThis talk will provide an in-depth discussion of embodied AI, with a focus on recent advances based on multi-modal large language models. It will discuss how end-to-end training has made it possible to instill key aspects of real-world common sense in a model and how this had enabled highly ambitious use-cases, such as generalist (\u201ccommon sense\u201d) robot control and real-world visual interaction (\u201cchatbots that can see and hear you\u201d). The talk will also discuss practical considerations, such as streaming inference at the edge, end-to-end training data generation and the role of reinforcement learning, as well as open challenges in state tracking and long-term memory.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Distributed Orthonormal Updates for Large-Scale Training",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T16:00:00",
        "end_datetime": "2025-12-02T17:00:00",
        "url": "https://neurips.cc/virtual/2025/128655",
        "speaker": "",
        "abstract": "We propose a 50-minute technical talk on recent advances in orthonormal update methods for large-scale AI model training. This topic is rapidly gaining attention in the community, emerging as a strong successor to AdamW following the success of orthonormal optimizers in training production-scale models such as Kimi-K2 and GLM-4.5.x000DThe talk will center on the design and practice of orthonormal updates, focusing on optimizers such as Muon and Dion. While we will briefly discuss their theoretical foundations, the emphasis will be on practical usage: how to integrate these optimizers into modern training pipelines, interpret their algorithmic components, and leverage the implementation guidelines provided in our open-source codebase at github.com/microsoft/dion.x000DThe talk is designed to engage both researchers and practitioners in the NeurIPS community:x000DAcademic perspective: presents a new class of optimizers grounded in theory along with how they interact with distributed training.x000DIndustrial perspective: highlights how orthonormal updates are implemented in practice and what best practices are.x000DThis topic lies   at the intersection of optimization theory, scalable systems, and large-model training\u2014an area of growing importance for both the research and applied machine learning communities.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Ling 2.0 and Ling-1T: Scaling Knowledge-Enhanced Large Language Models for Reasoning and Efficiency",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T16:00:00",
        "end_datetime": "2025-12-02T17:00:00",
        "url": "https://neurips.cc/virtual/2025/128657",
        "speaker": "",
        "abstract": "The Ling 2.0 series represents a new generation of large language models designed around knowledge enhancement, reasoning efficiency, and scalable architecture innovation. Built upon trillion-scale sparse MoE foundations, Ling-1T achieves ~50B active parameters per token with FP8 mixed-precision pipelines and 1F1B interleaved scheduling, realizing over 40% training-throughput gains with negligible accuracy loss (<0.1%).x000DThis talk presents the technical journey behind Ling-mini, Ling-flash, and Ling-1T, focusing on (1) efficient large-scale training systems for trillion-parameter models; (2) the Ling Scaling Law and its implications for cross-domain reasoning; (3) hybrid attention and RL-based alignment strategies that enable both concise reasoning and long-context understanding; and (4) how these architectural and algorithmic advances empower industrial applications such as financial risk modeling and knowledge-grounded agents.x000DWe will conclude with open-sourced implementations (inclusionAI on Hugging Face and ModelScope) and future research directions toward trustworthy, efficient, and domain-enhanced LLMs.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Agentic AI/RL",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T16:00:00",
        "end_datetime": "2025-12-02T17:00:00",
        "url": "https://neurips.cc/virtual/2025/128662",
        "speaker": "",
        "abstract": "The transition from static language models to agentic AI systems driven by reinforcement learning (RL) places environments at the center of research and deployment. Environments provide the substrate where agents act, learn, and are evaluated\u2014ranging from lightweight simulators and synthetic tasks to rich multi-agent ecosystems and real-world interfaces. Building and scaling these environments requires specialized tools and systems: standardized hubs for discovery and sharing, interfaces for reproducibility, and infrastructure that connects environments seamlessly to trainers, inference engines, and evaluation pipelines.x000Dx000DThis workshop will highlight the tools, environments, and system innovations enabling the next generation of agentic AI. Topics will include scalable RL environment frameworks, benchmarks for safety and robustness, high-performance simulators optimized for heterogeneous hardware, and environment\u2013trainer integration at scale. We will also explore how environments interface with large-model post-training workflows, providing the data and feedback loops necessary for reward shaping, alignment, and deployment in production systems.x000Dx000DBy convening researchers, environment developers, and systems engineers, the workshop will create a venue to examine how environments, tools, and infrastructure together shape the future of agentic AI.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DPyTorch native RL and agentic development at scalex000DEnvironments for everyone - how open environments can democratize RL post training at scalex000DSafety in the new era of Agents",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Neural Arms Race: Authenticity, Infringement Analysis, and Attribution in the Age of AI Music",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T16:00:00",
        "end_datetime": "2025-12-02T17:00:00",
        "url": "https://neurips.cc/virtual/2025/128669",
        "speaker": "",
        "abstract": "The same neural architectures powering music generation have become critical infrastructure for content moderation\u2014creating a technological arms race where AI both threatens and protects creative rights. This talk presents Sound Patrol's production-scale response across three dimensions: (1) Authenticity Detection: Analyzing AI content in the wild begins with binary classification\u2014was a given song created by AI or humans? Using MuQ and ResNet backbones with auxiliary task heads, we show how careful dataset construction and model ensembling enables attribution of when AI was used, where in a track (vocal vs instrumental), and which genAI platform generated it. (2) Infringement Analysis: Once identified as AI, content requires infringement screening. We combine singer deepfake detection via RawNet3, Burrows-Wheeler alignment-derived comparisons of MIDI transcripts, lyrics analysis via a combination of neural embeddings and LLMs, and neural fingerprinting achieving 88%+ accuracy under adversarial transforms. These analyses are orchestrated through dynamic expert routing, enabling sophisticated tagging and automated musicology reports. (3) Attribution Framework: We end with a pragmatic discussion of what it means for a piece of training data to influence a model output. We propose a set of principles guiding how fractional royalty models could be derived by examining prompts, training sets, and model outputs. Drawing from production deployments and industry evaluations, we offer the NeurIPS community technical blueprints for turning this arms race into equitable innovation\u2014exploring how the same AI enabling infringement might ensure fair compensation to the artists whose work powers it all.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Building an AI Ecosystem for Multiscale Biological Discovery",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T16:00:00",
        "end_datetime": "2025-12-02T17:00:00",
        "url": "https://neurips.cc/virtual/2025/128658",
        "speaker": "",
        "abstract": "Understanding biological systems requires resolving their structure and organization across scales, from tissues to individual molecules. Advances in imaging and molecular profiling now generate vast multimodal datasets that capture biological architecture and dynamics with unprecedented fidelity. Unlocking insights from this data demands computational approaches capable of linking observations across spatial, temporal, and molecular dimensions.At the Chan Zuckerberg Imaging Institute (CZII), we are building the infrastructure, datasets, and community connections to enable this transformation. Our cryo-electron tomography (cryoET) processing pipeline supports high-throughput reconstruction and standardized metadata integration, forming the foundation for reproducible, machine-learning\u2013ready datasets. The CryoET Data Portal (cryoetdataportal.czscience.com) provides open access to raw data, reconstructions, and curated annotations contributed by leading structural biology labs worldwide. Its programmatic API tools support segmentation, particle picking, and model benchmarking, creating a foundation for AI-driven structural discovery.To catalyze progress in automated molecular identification, the CZ Imaging Institute recently organized a Kaggle challenge inviting participants to develop models for detecting and labeling macromolecular complexes in real-world cryoET data. Building on this success, upcoming challenges organized by the CZI & CZ Biohub Network will extend this approach to datasets spanning different biological scales, from tissue architecture and cellular organization to subcellular and molecular structure.Together, these efforts form an open, interoperable ecosystem for machine learning in biological imaging. By combining standardized data infrastructure, scalable computation, and community-driven innovation, we aim to bridge the worlds of imaging and AI and accelerate the discovery of life\u2019s organization across all scales.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Building Foundational Models for Robotics at Tesla",
        "type": "Expo Talk Panel",
        "date": "2025-12-02",
        "start_datetime": "2025-12-02T16:00:00",
        "end_datetime": "2025-12-02T17:00:00",
        "url": "https://neurips.cc/virtual/2025/128654",
        "speaker": "",
        "abstract": "Tesla's robots, both wheeled and legged, are developed with the goal of achieving general-purpose capability, analogous to the versatility observed in humans and animals. These systems rely primarily on scalable sensing modalities such as vision, audio etc, enabling robust performance within stringent power and cost constraints.x000Dx000DThis talk will describe the principles and methodology behind constructing foundation models for robotics at Tesla. We will discuss the architecture, data and training of large-scale multimodal models that control these robots in an end-to-end pixels-to-actuation fashion. We will also examine evaluation protocols, safety considerations, and strategies for reliable real-world deployment. Finally, we project the transformational benefits to society that widespread deployment of such advanced robotic systems can deliver.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Rich Sutton_The Oak Architecture: A Vision of SuperIntelligence from Experience",
        "type": "Invited Talk",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T08:30:00",
        "end_datetime": "2025-12-03T09:30:00",
        "url": "https://neurips.cc/virtual/2025/invited-talk/109601",
        "speaker": "Rich Sutton",
        "abstract": "As AI has become a huge industry, to an extent it has lost its way. What is needed to get us back on track to true intelligence? We need agents that learn continually. We need world models and planning. We need knowledge that is high-level and learnable. We need to meta-learn how to generalize. The Oak architecture is one answer to all these needs. It is a model-based RL architecture with three special features: 1) all of its components learn continually, 2) each learned weight has a dedicated step-size parameter that is meta-learned using online cross-validation, and 3) abstractions in state and time are continually created in a five-step progression: Feature Construction, posing a SubTask based on the feature, learning an Option to solve the subtask, learning a Model of the option, and Planning using the option\u2019s model (the FC-STOMP progression). The Oak architecture is rather meaty; in this talk we give an outline and point to the many works, prior and contemporaneous, that are contributing to its overall vision of how superintelligence can arise from an agent\u2019s experience.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "AI Assistants in the Wild: Agents, Adaptation, and Memory-Augmented Deployment",
        "type": "Expo Workshop",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T12:00:00",
        "end_datetime": "2025-12-03T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128671",
        "speaker": "",
        "abstract": "Motivation and Scopex000Dx000DGenerative AI is evolving from offline, single modality models into interactive agentic systems that perceive, decide, and act in the real world. This shift marks a transition from static generation to dynamic, context-aware interaction. As these systems move toward deployment on edge devices such as mobile phones, augmented reality glasses, and robots, they face constraints in compute, memory, and latency. Beyond efficiency and responsiveness, a new frontier is emerging: agents equipped with persistent memory that enables long-term adaptation and personalization.x000Dx000DThis workshop explores a timely and focused question. How do we build generative agents that are not only efficient and responsive but also able to accumulate, recall, and adapt based on personal memory over time? We aim to bring together perspectives from generative modeling, agentic learning, efficient model design, and memory systems to close the gap between lab scale prototypes and real-world deployment.x000Dx000DKey Themesx000DPersonal Memory Systems for AI Assistants: Architectures for persistent memory, retrieval-augmented generation, and long-term personalization.x000DReal-World Adaptation Few-shot generalization, continual learning, and task inference for evolving agent behavior.x000DGrounded and Trustworthy Generation: Techniques for hallucination mitigation, constraint-aware generation, and safety under uncertainty.x000DDeployment on Edge Platforms: Challenges and solutions for deploying generative agents on mobile, AR, and robotics platforms.x000Dx000DThis focused workshop aligns with emerging themes at NeurIPS including agentic learning, trustworthy AI, efficient multimodal generation, and embodied intelligence. It will spotlight the systems, algorithms, and design decisions needed to make generative AI truly adaptive and persistent, outside the data center and into the wild.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "On Device/Edge AI",
        "type": "Expo Workshop",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T12:00:00",
        "end_datetime": "2025-12-03T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128674",
        "speaker": "",
        "abstract": "From smartphones and wearables to autonomous vehicles, robots, and AR/VR systems, the demand for models that are efficient, private, and adaptive in real-time has never been higher. Yet deploying state-of-the-art AI at the edge remains challenging: researchers and practitioners must navigate heterogeneous hardware, memory and power constraints, compression and distillation trade-offs, as well as privacy, safety, and reliability requirements.x000Dx000DThis workshop will bring together researchers, practitioners, and industry leaders to explore the frontiers of Edge AI. Topics will include lightweight model architectures, compiler/toolchain optimizations (e.g., quantization, pruning, sparsity), advances in frameworks such as ExecuTorch and TensorRT, distributed learning across devices, privacy-preserving training, and emerging applications where latency and trust are critical. Beyond technical advances, we will examine the broader implications for democratizing AI\u2014enabling billions of devices to act as intelligent, personalized agents while reducing dependence on the cloud.x000Dx000DAgenda:x000DIntroduction / Problem being addressedx000DOptimized AI on iOSx000DLeveraging ExecuTorch as a platform for mixed reality at scalex000DReal-time reasoning at the edgex000DMamba and SSM running at the edge",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Multi-Agent Systems in Industry: From Research to Real-World Impact",
        "type": "Expo Workshop",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T12:00:00",
        "end_datetime": "2025-12-03T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128675",
        "speaker": "",
        "abstract": "This workshop will bridge the gap between the theoretical advancements in multi-agent systems and their practical applications in industry. The session will feature a series of poster presentations showcasing state-of-the-art, real-world multi-agent systems that are driving innovation across various sectors. We will delve into the challenges and opportunities of deploying these systems at scale, covering topics such as:x000DHuman-in-the-loop collaboration: Designing systems where AI agents and human experts work in synergy.x000DScalability and efficiency: Architecting multi-agent systems for large-scale industrial applications.x000DSafety and reliability: Ensuring the robustness and predictability of autonomous agents in critical systems.x000DDomain-specific applications: Highlighting successful implementations in areas such as software engineering, scientific research, and creative content generation.x000DThe goal of this workshop is to foster a discussion on the practical challenges and future directions of multi-agent systems, providing attendees with actionable insights and a deeper understanding of how these technologies are shaping the future of industry.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Using the Virtual Cell Platform to Accelerate Machine Learning in Biology",
        "type": "Expo Workshop",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T12:00:00",
        "end_datetime": "2025-12-03T13:30:00",
        "url": "https://neurips.cc/virtual/2025/128676",
        "speaker": "",
        "abstract": "Biology presents some of the most complex and high-impact challenges for machine learning, and single-cell transcriptomics is at the frontier of this work. In this workshop, we introduce the Virtual Cell Platform (VCP), a unified environment designed to accelerate model development and evaluation in biology. Using single-cell transcriptomics as a case study, we will demonstrate how the VCP enables researchers to train, benchmark, and interpret models in a reproducible and biologically meaningful way.    Participants will gain a primer on single-cell transcriptomics and learn how to evaluate models with cz-benchmarks, an open-source Python package providing standardized, community-driven tasks and metrics. Through the VCP CLI, attendees will pull datasets, run packaged models, and compare results programmatically. Hands-on exercises will guide participants through interactive visualizations, side-by-side model comparisons, and deep dives into model behavior using VCP\u2019s no-code interface and BYOD (Bring Your Own Data) module.    By the end of the session, attendees will understand how to use the VCP to actively test and refine models during development, ensure biological relevance, and contribute models and benchmarks back to the community. This workshop highlights how the Virtual Cell Platform transforms ML infrastructure into a one-stop, researcher-friendly ecosystem, empowering the NeurIPS community to push the boundaries of AI in biology.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Are We Having the Wrong Nightmares About AI?",
        "type": "Invited Talk",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T14:30:00",
        "end_datetime": "2025-12-03T15:30:00",
        "url": "https://neurips.cc/virtual/2025/invited-talk/109606",
        "speaker": "Zeynep Tufekci",
        "abstract": "Though seemingly opposite, doom and optimism regarding generative AI's spectacular rise both center on AGI or even superintelligence as a pivotal moment. But generative AI operates in a distinct manner from human intelligence, and it\u2019s not a less intelligent human on a chip slowly getting smarter anymore than cars were mere horseless carriages. It must be understood on its own terms. And even if Terminator isn\u2019t coming to kill us or superintelligence isn\u2019t racing to save us, generative AI does bring profound challenges, well-beyond usual worries such as employment effects.  Technology facilitates progress by transforming the difficult into easy, the rare into ubiquitous, the scarce into abundant, the manual into automated, and the artisan into mass-produced. While potentially positive long-term, these inversions are extremely destabilizing during the transition, shattering the correlations and assumptions of our social order that relied on superseded difficulties as mechanisms of proof, filtering, sorting and signaling. For example, while few would dispute the value of the printing press or books, their introduction led to such destructive upheaval that the resulting religious wars caused proportionally more deaths than all other major wars and pandemics since combined. Historically, a new technology's revolutionary impact comes from making what's already possible and desired cheap, easy, fast, and large-scale, not from outdated or ill-fitting benchmarks that technologists tend to focus on. As such, Artificial Good-Enough Intelligence can unleash chaos and destruction long before, or if ever, AGI is reached. Existing AI is good enough to blur or pulverize our existing mechanisms of proof of accuracy, effort, veracity, authenticity, sincerity, and even humanity. The tumult from such a transition will require extensive technological, regulatory, and societal effort to counter. But the first step to getting started is having the right nightmares.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Juries, Not Judges! Industry-Scale Evaluation of Trustworthy AI via Dynamic LLM Panels",
        "type": "Expo Talk Panel",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T16:30:00",
        "end_datetime": "2025-12-03T17:30:00",
        "url": "https://neurips.cc/virtual/2025/128660",
        "speaker": "",
        "abstract": "As Large Language Models (LLMs) become central to high-stakes applications, the reliability of their evaluation systems is under intense scrutiny, especially in the financial industry. Traditional approaches - human annotation, single LLM judges, and static model juries - struggle to balance scalability, cost, and trustworthiness. We will discuss a promising framework: LLM Jury-on-Demand, a dynamic, learning-based framework that assembles an optimal panel of LLM evaluators for each task instance, leveraging predictive modeling to select and weight judges based on context-specific reliability. Our system adapts in real time, outperforming static ensembles and single judges in alignment with human expert judgment across summarization and retrieval-augmented generation benchmarks. This talk will showcase how adaptive LLM juries can transform evaluation of AI systems, offering robust, scalable, and context-aware solutions for industry and research. Attendees will gain practical insights into building trustworthy LLM evaluation pipelines, see live demos, and discuss future directions for reliable AI assessment in critical domains.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Frontier Open-Weight Models: Building Transparent, Secure, and Sovereign AI",
        "type": "Expo Talk Panel",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T16:30:00",
        "end_datetime": "2025-12-03T17:30:00",
        "url": "https://neurips.cc/virtual/2025/128664",
        "speaker": "",
        "abstract": "The next generation of AI will be defined not just by scale, but by openness. As the frontier in model capabilities accelerates, researchers and enterprises alike face a critical question: how do we advance state-of-the-art intelligence while preserving transparency, control, and security?x000Dx000DThis panel brings together leaders from open research, industry, and infrastructure to explore the emerging ecosystem of open-weight frontier models\u2014systems that can be fully run, audited, and customized within private or sovereign environments. Discussion topics will include the research challenges behind training and aligning open models at scale, implications for reproducibility and safety, and how open access can enable new forms of collaboration between academia, government, and enterprise.x000Dx000DAttendees will gain insight into how the open frontier movement is reshaping AI research culture, infrastructure design, and deployment strategy worldwide.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "The Co-X Framework: Versatile AI Agents for Automating and Augmenting Professional Workflows",
        "type": "Expo Talk Panel",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T16:30:00",
        "end_datetime": "2025-12-03T17:30:00",
        "url": "https://neurips.cc/virtual/2025/128666",
        "speaker": "",
        "abstract": "Beyond monolithic models, the future of AI in industry lies in specialized agents that collaborate with human experts. This talk introduces the \"Co-X\" framework, a novel approach for creating a diverse ecosystem of collaborative agents tailored to specific professional domains. We will present four key agents built on this framework: the Co-AI Researcher, the Co-ML Engineer for automating software development cycles, the Co-Data Scientist for automating data analysis and insight generation, and the Co-Director for augmenting creative content generation. We will discuss the foundational technologies that enable this versatility\u2014including long-term memory, tool use, and human-in-the-loop feedback\u2014and demonstrate how the Co-X framework is poised to redefine productivity and innovation across industries.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Cosmos World Foundation Model Platform for Physical AI",
        "type": "Expo Talk Panel",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T16:30:00",
        "end_datetime": "2025-12-03T17:30:00",
        "url": "https://neurips.cc/virtual/2025/128663",
        "speaker": "",
        "abstract": "Abstract: In this talk, I will introduce NVIDIA Cosmos, our World Foundation Model platform designed to advance Physical AI. Cosmos is built around three core pillars: Predict, Transfer, and Reason. I will provide updates on the latest releases\u2014Predict 2.5 and Transfer 2.5\u2014highlighting key improvements in generalization, efficiency, and scalability. In addition, I will share a preview of ongoing research directions that extend Cosmos toward richer world modeling and reasoning capabilities. Together, these developments aim to push the boundaries of how AI perceives, simulates, and interacts with complex real-world environments.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 1A",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122546",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118170",
        "speaker": "",
        "abstract": "Large Language Models (LLMs) are now integral across various domains and have demonstrated impressive performance. Progress, however, rests on the premise that benchmark scores are both accurate and reproducible. We demonstrate that the reproducibility of LLM performance is fragile: changing system configuration, such as evaluation batch size, GPU count, and GPU version, can introduce significant differences in the generated responses. This issue is especially pronounced in reasoning models, where minor rounding differences in early tokens can cascade into divergent chains of thought, ultimately affecting accuracy. For instance, under bfloat16 precision with greedy decoding, a reasoning model like DeepSeek-R1-Distill-Qwen-7B can exhibit up to 9\\% variation in accuracy and 9,000 tokens difference in response length due to differences in GPU count, type, and evaluation batch size.We trace the root cause of this variability to the non-associative nature of floating-point arithmetic under limited numerical precision. This work presents the first systematic investigation into how numerical precision affects reproducibility in LLM inference. Through carefully controlled experiments across various hardware, software, and precision settings, we quantify when and how model outputs diverge.Our analysis reveals that floating-point precision\u2014while critical for reproducibility\u2014is often neglected in evaluation practices.Inspired by this, we develop a lightweight inference pipeline, dubbed LayerCast, that stores weights in 16-bit precision but performs all computations in FP32, balancing memory efficiency with numerical stability. Code is available at https://github.com/nanomaoli/llm_reproducibility.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/121422",
        "speaker": "",
        "abstract": "Large language models (LMs) often struggle to generate diverse, human-like creative content, raising concerns about the long-term homogenization of human thought through repeated exposure to similar outputs. Yet scalable methods for evaluating LM output diversity remain limited, especially beyond narrow tasks such as random number or name generation, or beyond repeated sampling from a single model. To address this gap, we introduce Infinity-Chat, a large-scale dataset of 26K diverse, real-world, open-ended user queries that admit a wide range of plausible answers with no single ground truth. We introduce the first comprehensive taxonomy for characterizing the full spectrum of open-ended prompts posed to LMs, comprising 6 top-level categories (e.g., creative content generation, brainstorm & ideation) that further breaks down to 17 subcategories. Using Infinity-Chat, we present a large-scale study of mode collapse in LMs, revealing a pronounced Artificial Hivemind effect in open-ended generation of LMs, characterized by (1) intra-model repetition, where a single model consistently generates similar responses, and more so (2) inter-model homogeneity, where different models produce strikingly similar outputs. Infinity-Chat also includes 31,250 human annotations, across absolute ratings and pairwise preferences, with 25 independent human annotations per example. This enables studying collective and individual-specific human preferences in response to open-ended queries. Our findings show that state-of-the-art LMs, reward models, and LM judges are less well calibrated to human ratings on model generations that elicit differing idiosyncratic annotator preferences, despite maintaining comparable overall quality. Overall, INFINITY-CHAT presents the first large-scale resource for systematically studying real-world open-ended queries to LMs, revealing critical insights to guide future research for mitigating long-term AI safety risks posed by the Artificial Hivemind.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/115002",
        "speaker": "",
        "abstract": "3D spatial reasoning in dynamic, audio-visual environments is a cornerstone of human cognition yet remains largely unexplored by existing Audio-Visual Large Language Models (AV-LLMs) and benchmarks, which predominantly focus on static or 2D scenes. We introduce SAVVY-Bench, the first benchmark for 3D spatial reasoning in dynamic scenes with synchronized spatial audio. SAVVY-Bench is comprised of thousands of carefully curated question\u2013answer pairs probing both directional and distance relationships involving static and moving objects, and requires fine-grained temporal grounding, consistent 3D localization, and multi-modal annotation. To tackle this challenge, we propose SAVVY, a novel training-free reasoning pipeline that consists of two stages: (i) Egocentric Spatial Tracks Estimation, which leverages AV-LLMs as well as other audio-visual methods to track the trajectories of key objects related to the query using both visual and spatial audio cues, and (ii) Dynamic Global Map Construction, which aggregates multi-modal queried object trajectories and converts them into a unified global dynamic map. Using the constructed map, a final QA answer is obtained through a coordinate transformation that aligns the global map with the queried viewpoint. Empirical evaluation demonstrates that SAVVY substantially enhances performance of state-of-the-art AV-LLMs, setting a new standard and stage for approaching dynamic 3D spatial reasoning in AV-LLMs.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 1B",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122547",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Optimal Mistake Bounds for Transductive Online Learning",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/119099",
        "speaker": "",
        "abstract": "We resolve a 30-year-old open problem concerning the power of unlabeled data in online learning by tightly quantifying the gap between transductive and standard online learning. We prove that for every concept class $\\mathcal{H}$ with Littlestone dimension $d$, the transductive mistake bound is at least $\\Omega(\\sqrt{d})$. This establishes an exponential improvement over previous lower bounds of $\\Omega(\\log \\log d)$, $\\Omega(\\sqrt{\\log d})$, and $\\Omega(\\log d)$, respectively due to Ben-David, Kushilevitz, and Mansour (1995, 1997) and Hanneke, Moran, and Shafer (2023). We also show that our bound is tight: for every $d$, there exists a class of Littlestone dimension $d$ with transductive mistake bound $O(\\sqrt{d})$. Our upper bound also improves the previous best known upper bound of $(2/3) \\cdot d$ from Ben-David et al. (1997). These results demonstrate a quadratic gap between transductive and standard online learning, thereby highlighting the benefit of advanced access to the unlabeled instance sequence. This stands in stark contrast to the PAC setting, where transductive and standard learning exhibit similar sample complexities.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 High-Dimensional Calibration from Swap Regret",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117761",
        "speaker": "",
        "abstract": "We study the online calibration of multi-dimensional forecasts over an arbitrary convex set $\\mathcal{P} \\subset \\mathbb{R}^d$ relative to an arbitrary norm $\\Vert\\cdot\\Vert$. We connect this with the problem of external regret minimization for online linear optimization, showing that if it is possible to guarantee $O(\\sqrt{\\rho T})$ worst-case regret after $T$ rounds when actions are drawn from $\\mathcal{P}$ and losses are drawn from the dual $\\Vert \\cdot \\Vert_*$ unit norm ball, then it is also possible to obtain $\\epsilon$-calibrated forecasts after $T = \\exp(O(\\rho /\\epsilon^2))$ rounds. When $\\mathcal{P}$ is the $d$-dimensional simplex and $\\Vert \\cdot \\Vert$ is the $\\ell_1$-norm, the existence of $O(\\sqrt{T\\log d})$ algorithms for learning with experts implies that it is possible to obtain $\\epsilon$-calibrated forecasts after $T = \\exp(O(\\log{d}/\\epsilon^2)) = d^{O(1/\\epsilon^2)}$ rounds, recovering a recent result of Peng 2025.Interestingly, our algorithm obtains this guarantee without requiring access to any online linear optimization subroutine or knowledge of the optimal rate $\\rho$ -- in fact, our algorithm is identical for every setting of $\\mathcal{P}$ and $\\Vert \\cdot \\Vert$. Instead, we show that the optimal regularizer for the above OLO problem can be used to upper bound the above calibration error by a swap regret, which we then minimize by running the recent TreeSwap algorithm with Follow-The-Leader as a subroutine. The resulting algorithm is highly efficient and plays a distribution over simple averages of past observations in each round.Finally, we prove that any online calibration algorithm that guarantees $\\epsilon T$ $\\ell_1$-calibration error over the $d$-dimensional simplex requires $T \\geq \\exp(\\mathrm{poly}(1/\\epsilon))$ (assuming $d \\geq \\mathrm{poly}(1/\\epsilon)$). This strengthens the corresponding $d^{\\Omega(\\log{1/\\epsilon})}$ lower bound of Peng 2025, and shows that an exponential dependence on $1/\\epsilon$ is necessary.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Does Stochastic Gradient really succeed for bandits?",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/116754",
        "speaker": "",
        "abstract": "Recent works of Mei et al. (2023, 2024) have deepened the theoretical understanding of the *Stochastic Gradient Bandit* (SGB) policy, showing that using a constant learning rate guarantees asymptotic convergence to the optimal policy, and that sufficiently *small* learning rates can yield logarithmic regret. However, whether logarithmic regret holds beyond small learning rates remains unclear. In this work, we take a step towards characterizing the regret *regimes* of SGB as a function of its learning rate. For two--armed bandits, we identify a sharp threshold, scaling with the sub-optimality gap $\\Delta$, below which SGB achieves *logarithmic* regret on all instances, and above which it can incur *polynomial* regret on some instances. This result highlights the necessity of knowing (or estimating) $\\Delta$ to ensure logarithmic regret with a constant learning rate.For general $K$-armed bandits, we further show the learning rate must scale inversely with $K$ to avoid polynomial regret. We introduce novel techniques to derive regret upper bounds for SGB, laying the groundwork for future advances in the theory of gradient-based bandit algorithms.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 1C",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122548",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Adjoint Schr\u00f6dinger Bridge Sampler",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/115787",
        "speaker": "",
        "abstract": "Computational methods for learning to sample from the Boltzmann distribution\u2014where the target distribution is known only up to an unnormalized energy function\u2014have advanced significantly recently. Due to the lack of explicit target samples, however, prior diffusion-based methods, known asdiffusion samplers, often require importance-weighted estimation or complicated learning processes. Both trade off scalability with extensive evaluations of the energy and model, thereby limiting their practical usage. In this work, we proposeAdjoint Schr\u00f6dinger Bridge Sampler (ASBS), a new diffusion sampler that employs simple and scalable matching-based objectives yet without the need to estimate target samples during training. ASBS is grounded on a mathematical model\u2014the Schr\u00f6dinger Bridge\u2014which enhances sampling efficiency via kinetic-optimal transportation. Through a new lens of stochastic optimal control theory, we demonstrate how SB-based diffusion samplers can be learned at scale via Adjoint Matching and prove convergence to the global solution. Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to arbitrary source distributions by relaxing the so-called memoryless condition that largely restricts the design space. Through extensive experiments, we demonstrate the effectiveness of ASBS on sampling from classical energy functions, amortized conformer generation, and molecular Boltzmann distributions. Codes are available at https://github.com/facebookresearch/adjoint_samplers",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Rethinking Joint Maximum Mean Discrepancy for Visual Domain Adaptation",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117477",
        "speaker": "",
        "abstract": "In domain adaption (DA), joint maximum mean discrepancy (JMMD), as a famous distribution-distance metric, aims to measure joint probability distribution difference between the source domain and target domain, while it is still not fully explored and especially hard to be applied into a subspace-learning framework as its empirical estimation involves a tensor-product operator whose partial derivative is difficult to obtain. To solve this issue, we deduce a concise JMMD based on the Representer theorem that avoids the tensor-product operator and obtains two essential findings. First, we reveal the uniformity of JMMD by proving that previous marginal, class conditional, and weighted class conditional probability distribution distances are three special cases of JMMD with different label reproducing kernels. Second, inspired by graph embedding, we observe that the similarity weights, which strengthen the intra-class compactness in the graph of Hilbert Schmidt independence criterion (HSIC), take opposite signs in the graph of JMMD, revealing why JMMD degrades the feature discrimination. This motivates us to propose a novel loss JMMD-HSIC by jointly considering JMMD and HSIC to promote discrimination of JMMD. Extensive experiments on several cross-domain datasets could demonstrate the validity of our revealed theoretical results and the effectiveness of our proposed JMMD-HSIC.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Class-wise Balancing Data Replay for Federated Class-Incremental Learning",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117265",
        "speaker": "",
        "abstract": "Federated Class Incremental Learning (FCIL) aims to collaboratively process continuously increasing incoming tasks across multiple clients. Among various approaches, data replay has become a promising solution, which can alleviate forgetting by reintroducing representative samples from previous tasks. However, their performance is typically limited by class imbalance, both within the replay buffer due to limited global awareness and between replayed and newly arrived classes. To address this issue, we propose a class-wise balancing data replay method for FCIL (FedCBDR), which employs a global coordination mechanism for class-level memory construction and reweights the learning objective to alleviate the aforementioned imbalances. Specifically, FedCBDR has two key components: 1) the global-perspective data replay module reconstructs global representations of prior task knowledge in a privacy-preserving manner, which then guides a class-aware and importance-sensitive sampling strategy to achieve balanced replay; 2) Subsequently, to handle class imbalance across tasks, the task-aware temperature scaling module adaptively adjusts the temperature of logits at both class and instance levels based on task dynamics, which reduces the model\u2019s overconfidence in majority classes while enhancing its sensitivity to minority classes. Experimental results verified that FedCBDR achieves balanced class-wise sampling under heterogeneous data distributions and improves generalization under task imbalance between earlier and recent tasks, yielding a 2%-15% Top-1 accuracy improvement over six state-of-the-art methods.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 1D",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122549",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/116345",
        "speaker": "",
        "abstract": "REPA and its variants effectively mitigate training challenges in diffusion models by incorporating external visual representations from pretrained models, through alignment between the noisy hidden projections of denoising networks and foundational clean image representations. We argue that the external alignment, which is absent during the entire denoising inference process, falls short of fully harnessing the potential of discriminative representations. In this work, we propose a straightforward method called \\textit{\\textbf{R}epresentation \\textbf{E}ntanglement for \\textbf{G}eneration} (\\textbf{REG}), which entangles low-level image latents with a single high-level class token from pretrained foundation models for denoising. REG acquires the capability to produce coherent image-class pairs directly from pure noise, substantially improving both generation quality and training efficiency.This is accomplished with negligible additional inference overhead, requiring only one single additional token for denoising (<0.5\\% increase in FLOPs and latency).The inference process concurrently reconstructs both image latents and their corresponding global semantics, where the acquired semantic knowledge actively guides and enhances the image generation process.On ImageNet 256$\\times$256, SiT-XL/2 + REG demonstrates remarkable convergence acceleration, achieving $\\textbf{63}\\times$ and $\\textbf{23}\\times$ faster training than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively, SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA trained for 4M iterations ($\\textbf{10}\\times$ longer). Code is available at: https://github.com/Martinser/REG.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/116379",
        "speaker": "",
        "abstract": "Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods, such as diffusion and flow matching techniques, generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the noisy nature of the loss as a key factor driving generalization in flow matching.First, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Why Diffusion Models Don\u2019t Memorize:  The Role of Implicit Dynamical Regularization in Training",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/119373",
        "speaker": "",
        "abstract": "Diffusion models have achieved remarkable success across a wide range of generative tasks. A key challenge is understanding the mechanisms that prevent their memorization of training data and allow generalization. In this work, we investigate the role of the training dynamics in the transition from generalization to memorization. Through extensive experiments and theoretical analysis, we identify two distinct timescales: an early time $\\tau_\\mathrm{gen}$ at which models begin to generate high-quality samples, and a later time $\\tau_\\mathrm{mem}$ beyond which memorization emerges. Crucially, we find that $\\tau_\\mathrm{mem}$ increases linearly with the training set size $n$, while $\\tau_\\mathrm{gen}$ remains constant. This creates a growing window of training times with $n$ where models generalize effectively, despite showing strong memorization if training continues beyond it. It is only when $n$ becomes larger than a model-dependent threshold that overfitting disappears at infinite training times.These findings reveal a form of implicit dynamical regularization in the training dynamics, which allow to avoid memorization even in highly overparameterized settings. Our results are supported by numerical experiments with standard U-Net architectures on realistic and synthetic  datasets, and by a theoretical analysis using a tractable random features model studied in the high-dimensional limit.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 1E",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122550",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/115716",
        "speaker": "",
        "abstract": "Vision-and-Language Navigation (VLN) is a core task where embodied agents leverage their spatial mobility to navigate in 3D environments toward designated destinations based on natural language instructions. Recently, video-language large models (Video-VLMs) with strong generalization capabilities and rich commonsense knowledge have shown remarkable performance when applied to VLN tasks. However, these models still encounter the following challenges when applied to real-world 3D navigation: 1) Insufficient understanding of 3D geometry and spatial semantics; 2) Limited capacity for large-scale exploration and long-term environmental memory; 3) Poor adaptability to dynamic and changing environments.To address these limitations, we propose Dynam3D, a dynamic layered 3D representation model that leverages language-aligned, generalizable, and hierarchical 3D representations as visual input to train 3D-VLM in navigation action prediction. Given posed RGB-D images, our Dynam3D projects 2D CLIP features into 3D space and constructs multi-level 3D patch-instance-zone representations for 3D geometric and semantic understanding with a dynamic and layer-wise update strategy.  Our Dynam3D is capable of online encoding and localization of 3D instances, and dynamically updates them in changing environments to provide large-scale exploration and long-term memory capabilities for navigation. By leveraging large-scale 3D-language pretraining and task-specific adaptation, our Dynam3D sets new state-of-the-art performance on VLN benchmarks including R2R-CE, REVERIE-CE and NavRAG-CE under monocular settings. Furthermore, experiments for pre-exploration, lifelong memory, and real-world robot validate the effectiveness of practical deployment.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Perception Encoder: The best visual embeddings are not at the output of the network",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118806",
        "speaker": "",
        "abstract": "We introduce Perception Encoder (PE), a family of state-of-the-art vision encoders for image and video understanding. Traditionally, vision encoders have relied on a variety of pretraining objectives, each excelling at different downstream tasks. Surprisingly, after scaling a carefully tuned image pretraining recipe and refining with a robust video data engine, we find that contrastive vision-language training alone can produce strong, general embeddings for all of these downstream tasks. There is only one caveat: these embeddings are hidden within the intermediate layers of the network. To draw them out, we introduce two alignment methods: language alignment for multimodal language modeling, and spatial alignment for dense prediction. Together, our PE family of models achieves state-of-the-art results on a wide variety of tasks, including zero-shot image and video classification and retrieval; document, image, and video Q&A; and spatial tasks such as detection, tracking, and depth estimation. We release our models, code, and novel dataset of synthetically and human-annotated videos: https://github.com/facebookresearch/perception_models",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Interactive Cross-modal Learning for Text-3D Scene Retrieval",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T10:00:00",
        "end_datetime": "2025-12-03T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/116803",
        "speaker": "",
        "abstract": "Text-3D Scene Retrieval (T3SR) aims to retrieve relevant scenes using linguistic queries. Although traditional T3SR methods have made significant progress in capturing fine-grained associations, they implicitly assume that query descriptions are information-complete. In practical deployments, however, limited by the capabilities of users and models, it is difficult or even impossible to directly obtain a perfect textual query suiting the entire scene and model, thereby leading to performance degradation. To address this issue, we propose a novel Interactive Text-3D Scene Retrieval Method (IDeal), which promotes the enhancement of the alignment between texts and 3D scenes through continuous interaction. To achieve this, we present an Interactive Retrieval Refinement framework (IRR), which employs a questioner to pose contextually relevant questions to an answerer in successive rounds that either promote detailed probing or encourage exploratory divergence within scenes. Upon the iterative responses received from the answerer, IRR adopts a retriever to perform both feature-level and semantic-level information fusion, facilitating scene-level interaction and understanding for more precise re-rankings. To bridge the domain gap between queries and interactive texts, we propose an Interaction Adaptation Tuning strategy (IAT). IAT mitigates the discriminability and diversity risks among augmented text features that approximate the interaction text domain, achieving contrastive domain adaptation for our retriever. Extensive experimental results on three datasets demonstrate the superiority of IDeal.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 2A",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122551",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Agnostic Active Learning Is Always Better Than Passive Learning",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/117512",
        "speaker": "",
        "abstract": "We sharply characterize the optimal first-order query complexity of agnostic active learning for all concept classes, and propose a new general active learning algorithm which achieves it. Remarkably, the optimal query complexity admits a leading term which is always strictly smaller than the sample complexity of passive supervised learning (by a factor proportional to the best-in-class error rate). This was not previously known to be possible in the agnostic setting. For comparison, in all previous general analyses, the leading term exhibits an additional factor, such as the disagreement coefficient or related complexity measure, and therefore only provides improvements over passive learning in restricted cases. The present work completely removes such factors from the leading term, implying that every concept class benefits from active learning in the non-realizable case. The results established in this work resolve an important long-standing open question central to the past two decades of research on the theory of agnostic active learning.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Tighter CMI-Based Generalization Bounds via Stochastic Projection and Quantization",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/117680",
        "speaker": "",
        "abstract": "In this paper, we leverage stochastic projection and lossy compression to establish new conditional mutual information (CMI) bounds on the generalization error of statistical learning algorithms. It is shown that these bounds are generally tighter than the existing ones. In particular, we prove that for certain problem instances for which existing MI and CMI bounds were recently shown in Attias et al. [2024] and Livni [2023] to become vacuous or fail to describe the right generalization behavior, our bounds yield suitable generalization guarantees of the order of $\\mathcal{O}(1/\\sqrt{n})$, where $n$ is the size of the training dataset. Furthermore, we use our bounds to investigate the problem of data \"memorization\" raised in those works, and which asserts that there are learning problem instances for which any learning algorithm that has good prediction there exist distributions under which the algorithm must \"memorize'' a big fraction of the training dataset. We show that for every learning algorithm, there exists an auxiliary algorithm that does not memorize and which yields comparable generalization error for any data distribution. In part, this shows that memorization is not necessary for good generalization.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/118768",
        "speaker": "",
        "abstract": "Understanding the inductive bias and generalization properties of large overparametrized machine learning models requires to characterize the dynamics of the training algorithm.  We study the learning dynamics of large two-layer neural networks via dynamical mean field theory, a well established technique of non-equilibrium statistical physics. We show that, for large network width $m$,and large number of samples per input dimension $n/d$, the training dynamics exhibits a separation of timescales which implies:$(i)$ The emergence of a slow time scale associated with the growth in Gaussian/Rademacher complexity of the network;$(ii)$ Inductive bias towards small complexity if the initialization has small enough complexity;$(iii)$ A dynamical decoupling between feature learning and overfitting regimes; $(iv)$ A non-monotone behavior of the test error, associated  `feature unlearning' regime at large times.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 2B",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122552",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 PhySense: Sensor Placement Optimization for Accurate Physics Sensing",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115066",
        "speaker": "",
        "abstract": "Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. Leveraging the reconstruction feedback, the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees. Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered. Code is available at this repository: https://github.com/thuml/PhySense.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/117509",
        "speaker": "",
        "abstract": "Vehicle GPS trajectories provide valuable movement information that supports various downstream tasks and applications. A desirable trajectory learning model should be able to transfer across regions and tasks without retraining, avoiding the need to maintain multiple specialized models and subpar performance with limited training data. However, each region has its unique spatial features and contexts, which are reflected in vehicle movement patterns and are difficult to generalize. Additionally, transferring across different tasks faces technical challenges due to the varying input-output structures required for each task. Existing efforts towards transferability primarily involve learning embedding vectors for trajectories, which perform poorly in region transfer and require retraining of prediction modules for task transfer.To address these challenges, we propose $\\textit{TransferTraj}$, a vehicle GPS trajectory learning model that excels in both region and task transferability. For region transferability, we introduce RTTE as the main learnable module within TransferTraj. It integrates spatial, temporal, POI, and road network modalities of trajectories to effectively manage variations in spatial context distribution across regions. It also introduces a TRIE module for incorporating relative information of spatial features and a spatial context MoE module for handling movement patterns in diverse contexts. For task transferability, we propose a task-transferable input-output scheme that unifies the input-output structure of different tasks into the masking and recovery of modalities and trajectory points. This approach allows TransferTraj to be pre-trained once and transferred to different tasks without retraining. We conduct extensive experiments on three real-world vehicle trajectory datasets under various transfer settings, including task transfer, zero-shot region transfer, and few-shot region transfer. Experimental results demonstrate that TransferTraj significantly outperforms state-of-the-art baselines in different scenarios, validating its effectiveness in region and task transfer. Code is available at https://github.com/wtl52656/TransferTraj.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/121612",
        "speaker": "",
        "abstract": "Accurate visual localization from aerial views is a fundamental problem with applications in mapping, large-area inspection, and search-and-rescue operations. In many scenarios, these systems require high-precision localization while operating with limited resources (e.g., no internet connection or GNSS/GPS support), making large image databases or heavy 3D models impractical. Surprisingly, little attention has been given to leveraging orthographic geodata as an alternative paradigm, which is lightweight and increasingly available through free releases by governmental authorities (e.g., the European Union). To fill this gap, we propose OrthoLoC, the first large-scale dataset comprising 16,425 UAV images from Germany and the United States with multiple modalities. The dataset addresses domain shifts between UAV imagery and geospatial data. Its paired structure enables fair benchmarking of existing solutions by decoupling image retrieval from feature matching, allowing isolated evaluation of localization and calibration performance. Through comprehensive evaluation, we examine the impact of domain shifts, data resolutions, and covisibility on localization accuracy. Finally, we introduce a refinement technique called AdHoP, which can be integrated with any feature matcher, improving matching by up to 95% and reducing translation error by up to 63%. The dataset and code are available at: https://deepscenario.github.io/OrthoLoC .",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 2C",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122553",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 A multiscale analysis of mean-field transformers in the moderate interaction regime",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/117616",
        "speaker": "",
        "abstract": "In this paper, we study the evolution of tokens through the depth of encoder-only transformer models at inference time by modeling them as a system of particles interacting in a mean-field way and studying the corresponding dynamics. More specifically, we consider this problem in the moderate interaction regime, where the number $N$ of tokens is large and the inverse temperature parameter $\\beta$ of the model scales together with $N$. In this regime, the dynamics of the system displays a multiscale behavior: a fast phase, where the token empirical measure collapses on a low-dimensional space, an intermediate phase, where the measure further collapses into clusters, and a slow one, where such clusters sequentially merge into a single one. We provide a rigorous characterization of the limiting dynamics in each of these phases and prove convergence in the above mentioned limit, exemplifying our results with some simulations.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 The emergence of sparse attention: impact of data distribution and benefits of repetition",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116475",
        "speaker": "",
        "abstract": "Emergence is a fascinating property of large language models and neural networks more broadly: as models scale and train for longer, they sometimes develop new abilities in sudden ways. Despite initial studies, we still lack a comprehensive understanding of how and when these abilities emerge. To address this gap, we study the emergence over training of sparse attention, a critical and frequently observed attention pattern in Transformers. By combining theoretical analysis of a toy model with empirical observations on small Transformers trained on a linear regression variant, we uncover the mechanics driving sparse attention emergence and reveal that emergence timing follows power laws based on task structure, architecture, and optimizer choice. We additionally find that repetition can greatly speed up emergence. Finally, we confirm these results on a well-studied in-context associative recall task. Our findings provide a simple, theoretically grounded framework for understanding how data distributions and model design influence the learning dynamics behind one form of emergence.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer Training Dynamics",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116706",
        "speaker": "",
        "abstract": "Although transformer-based models have shown exceptional empirical performance, the fundamental principles governing their training dynamics are inadequately characterized beyond configuration-specific studies. Inspired by empirical evidence showing improved reasoning capabilities under small initialization scales in language models, we employ the gradient flow analytical framework established in \\cite{zhou2022towards} to systematically investigate linearized Transformer training dynamics. Our theoretical analysis dissects the dynamics of attention modules into two distinct stages. In the first stage, asymmetric weight perturbations from random initialization sustain non-degenerate gradient dynamics in parameter matrices, facilitating systematic escape from small initialization regimes. Subsequently, these matrices undergo condensation, progressively aligning toward the target orientation. In the second stage, the previously static key-query matrices actively participate in training, driving the normalized matrices toward asymptotic rank collapse. This two-stage framework generalizes classical directional convergence results.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 2D",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122554",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/119904",
        "speaker": "",
        "abstract": "Preference-based reinforcement learning (PbRL) has emerged as a promising paradigm for teaching robots complex behaviors without reward engineering. However, its effectiveness is often limited by two critical challenges: the reliance on extensive human input and the inherent difficulties in resolving query ambiguity and credit assignment during reward learning. In this paper, we introduce PRIMT, a PbRL framework designed to overcome these challenges by leveraging foundation models (FMs) for multimodal synthetic feedback and trajectory synthesis. Unlike prior approaches that rely on single-modality FM evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy, integrating the complementary strengths of vision-language models (VLMs) and large language models (LLMs) in evaluating robot behaviors for more reliable and comprehensive feedback. PRIMT also incorporates foresight trajectory generation to warm-start the trajectory buffer with bootstrapped samples, reducing early-stage query ambiguity, and hindsight trajectory augmentation for counterfactual reasoning with a causal auxiliary loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6 manipulation tasks on various benchmarks, demonstrating superior performance over FM-based and scripted baselines. Website at https://primt25.github.io/.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116055",
        "speaker": "",
        "abstract": "Neuromorphic computing systems are set to revolutionize energy-constrained robotics by achieving orders-of-magnitude efficiency gains, while enabling native temporal processing. Spiking Neural Networks (SNNs) represent a promising algorithmic approach for these systems, yet their application to complex control tasks faces two critical challenges: (1) the non-differentiable nature of spiking neurons necessitates surrogate gradients with unclear optimization properties, and (2) the stateful dynamics of SNNs require training on sequences, which in reinforcement learning (RL) is hindered by limited sequence lengths during early training, preventing the network from bridging its warm-up period.We address these challenges by systematically analyzing surrogate gradient slope settings, showing that shallower slopes increase gradient magnitude in deeper layers but reduce alignment with true gradients. In supervised learning, we find no clear preference for fixed or scheduled slopes. The effect is much more pronounced in RL settings, where shallower slopes or scheduled slopes lead to a $\\times2.1$ improvement in both training and final deployed performance. Next, we propose a novel training approach that leverages a privileged guiding policy to bootstrap the learning process, while still exploiting online environment interactions with the spiking policy. Combining our method with an adaptive slope schedule for a real-world drone position control task, we achieve an average return of 400 points, substantially outperforming prior techniques, including Behavioral Cloning and TD3BC, which achieve at most \u2013200 points under the same conditions. This work advances both the theoretical understanding of surrogate gradient learning in SNNs and practical training methodologies for neuromorphic controllers demonstrated in real-world robotic systems.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 SAGE: A Unified Framework for Generalizable Object State Recognition with State-Action Graph Embedding",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116465",
        "speaker": "",
        "abstract": "Recognizing the physical states of objects and their transformations within videos is crucial for structured video understanding and enabling robust real-world applications, such as robotic manipulation. However, pretrained vision-language models often struggle to capture these nuanced dynamics and their temporal context, and specialized object state recognition frameworks may not generalize to unseen actions or objects. We introduce SAGE (State-Action Graph Embeddings), a novel framework that offers a unified model of physical state transitions by decomposing states into fine-grained, language-described visual concepts that are sharable across different objects and actions. SAGE initially leverages Large Language Models to construct a State-Action Graph, which is then multimodally refined using Vision-Language Models. Extensive experiments show that our method significantly outperforms baselines, generalizes effectively to unseen objects and actions in open-world settings. SAGE improves the prior state-of-the-art by as much as 14.6% on novel state recognition with less than 5% of its inference time.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 2E",
        "type": "Oral Session",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122555",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/121634",
        "speaker": "",
        "abstract": "Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats. To study this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE). RISEBench focuses on four key reasoning categories: Temporal, Causal, Spatial, and Logical Reasoning. We curate high-quality test cases for each category and propose an robust evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and the LMM-as-a-judge approach. We conducted experiments evaluating nine prominent visual editing models, comprising both open-source and proprietary models. The evaluation results demonstrate that current models face significant challenges in reasoning-based editing tasks.  Even the most powerful model evaluated, GPT-image-1, achieves an accuracy of merely 28.8%. RISEBench effectively highlights the limitations of contemporary editing models, provides valuable insights,  and indicates potential future directions for the field of reasoning-aware visual editing. Our code and data have been released at https://github.com/PhoenixZ810/RISEBench.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/121509",
        "speaker": "",
        "abstract": "Coral reefs are vital yet vulnerable ecosystems that require continuous monitoring to support conservation. While coral reef images provide essential information in coral monitoring, interpreting such images remains challenging due to the need for domain expertise. Visual Question Answering (VQA), powered by Large Vision-Language Models (LVLMs), has great potential in user-friendly interaction with coral reef images. However, applying VQA to coral imagery demands a dedicated dataset that addresses two key challenges: domain-specific annotations and multidimensional questions. In this work, we introduce CoralVQA, the first large-scale VQA dataset for coral reef analysis. It contains 12,805 real-world coral images from 67 coral genera collected from 3 oceans, along with 277,653 question-answer pairs that comprehensively assess ecological and health-related conditions. To construct this dataset, we develop a semi-automatic data construction pipeline in collaboration with marine biologists to ensure both scalability and professional-grade data quality. CoralVQA presents novel challenges and provides a comprehensive benchmark for studying vision-language reasoning in the context of coral reef images. By evaluating several state-of-the-art LVLMs, we reveal key limitations and opportunities. These insights form a foundation for future LVLM development, with a particular emphasis on supporting coral conservation efforts.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model",
        "type": "Oral Paper",
        "date": "2025-12-03",
        "start_datetime": "2025-12-03T03:30:00",
        "end_datetime": "2025-12-03T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/120304",
        "speaker": "",
        "abstract": "Understanding and synthesizing realistic 3D hand-object interactions (HOI) is critical for applications ranging from immersive AR/VR to dexterous robotics. Existing methods struggle with generalization, performing well on closed-set objects and predefined tasks but failing to handle unseen objects or open-vocabulary instructions. We introduce OpenHOI, the first framework for open-world HOI synthesis, capable of generating long-horizon manipulation sequences for novel objects guided by free-form language commands. Our approach integrates a 3D Multimodal Large Language Model (MLLM) fine-tuned for joint affordance grounding and semantic task decomposition, enabling precise localization of interaction regions (e.g., handles, buttons) and breakdown of complex instructions (e.g., \u201cFind a water bottle and take a sip\u201d) into executable sub-tasks. To synthesize physically plausible interactions, we propose an affordance-driven diffusion model paired with a training-free physics refinement stage that minimizes penetration and optimizes affordance alignment.Evaluations across diverse scenarios demonstrate OpenHOI\u2019s superiority over state-of-the-art methods in generalizing to novel object categories, multi-stage tasks, and complex language instructions.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "The Art of (Artificial) Reasoning",
        "type": "Invited Talk",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T08:30:00",
        "end_datetime": "2025-12-04T09:30:00",
        "url": "https://neurips.cc/virtual/2025/invited-talk/109603",
        "speaker": "Yejin Choi",
        "abstract": "Scaling laws suggest that \u201cmore is more\u201d \u2014 brute-force scaling of data and compute leads to stronger AI capabilities. However, despite rapid progress on benchmarks, state-of-the-art models still exhibit \"jagged intelligence,\" indicating that current scaling approaches may have limitations in terms of sustainability and robustness. Additionally, while the volume of papers on arXiv continues to grow rapidly, our scientific understanding of artificial intelligence hasn't kept pace with engineering advances, and the current literature presents seemingly contradictory findings that can be difficult to reconcile. In this talk, I will discuss key insights into the strengths and limitations of LLMs, examine when reinforcement learning succeeds or struggles in reasoning tasks, and explore methods for enhancing reasoning capabilities in smaller language models to help them close the gap against their larger counterparts in specific domains.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "On the Science of \u201cAlien Intelligences\u201d: Evaluating Cognitive Capabilities in Babies, Animals, and AI",
        "type": "Invited Talk",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T14:30:00",
        "end_datetime": "2025-12-04T15:30:00",
        "url": "https://neurips.cc/virtual/2025/invited-talk/109607",
        "speaker": "Melanie Mitchell",
        "abstract": "Today\u2019s generative AI systems\u2014termed by some researchers as \u201calien intelligences\u201d\u2014have exceeded human performance on many benchmarks meant to test humanlike cognitive capabilities.  However, these systems still struggle in unhumanlike ways on real-world tasks requiring these capabilities.  This disconnect may be due in part to neglect in the AI community of well-founded experimental protocols for evaluating cognition.  In this talk I will summarize several recommendations on experimental methods from developmental and comparative psychology\u2014fields that study the \u201calien intelligences\u201d of babies and non-human animals\u2014and demonstrate the application of such methods in two case studies of cognitive abilities in LLMs: analogical reasoning and visual abstraction.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 3A",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122556",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Identifiability of Deep Polynomial Neural Networks",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118427",
        "speaker": "",
        "abstract": "Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability-a key property for ensuring interpretability-remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly compared to the activation degrees. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. We also settle an open conjecture on the dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach the expected dimension.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Depth-Bounds for Neural Networks via the Braid Arrangement",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117519",
        "speaker": "",
        "abstract": "We contribute towards resolving the open question of how many hidden layers are required in ReLU networks for exactly representing all continuous and piecewise linear functions on $\\mathbb{R}^d$. While the question has been resolved in special cases, the best known lower bound in general is still 2. We focus on neural networks that are compatible with certain polyhedral complexes, more precisely with the braid fan.  For such neural networks, we prove a non-constant lower bound of $\\Omega(\\log\\log d)$ hidden layers required to exactly represent the maximum of $d$ numbers. Additionally, we provide a combinatorial proof that neural networks satisfying this assumption require three hidden layers to compute the maximum of 5 numbers; this had only been verified with an excessive computation so far.Finally, we show that a natural generalization of the best known upper bound to maxout networks is not tight, by demonstrating that a rank-3 maxout layer followed by a rank-2 maxout layer is sufficient to represent the maximum of 7 numbers.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Learning Linear Attention in Polynomial Time",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118143",
        "speaker": "",
        "abstract": "Previous research has explored the expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the efficient learnability of Transformers from data has remained an open question.  Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention.  We show that learning the optimal multi head linear attention can be recast as finding the optimal kernel predictor in a suitably defined RKHS.  Moving to generalization, we construct an algorithm that, given a dataset, checks in polynomial time whether the set of best fit multi head linear attention networks on this data all perform an identical computation--a powerful notion for out of distribution generalization.  We empirically validate our theoretical findings on several canonical tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformer models.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 3B",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122557",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117276",
        "speaker": "",
        "abstract": "Current image fusion methods struggle with real-world composite degradations and lack the flexibility to accommodate user-specific needs. To address this, we propose ControlFusion, a controllable fusion network guided by language-vision prompts that adaptively mitigates composite degradations. On the one hand, we construct a degraded imaging model based on physical mechanisms, such as the Retinex theory and atmospheric scattering principle, to simulate composite degradations and provide a data foundation for addressing realistic degradations. On the other hand, we devise a prompt-modulated restoration and fusion network that dynamically enhances features according to degradation prompts, enabling adaptability to varying degradation levels. To support user-specific preferences in visual quality, a text encoder is incorporated to embed user-defined degradation types and levels as degradation prompts. Moreover, a spatial-frequency collaborative visual adapter is designed to autonomously perceive degradations from source images, thereby reducing complete reliance on user instructions. Extensive experiments demonstrate that ControlFusion outperforms SOTA fusion methods in fusion quality and degradation handling, particularly under real-world and compound degradations.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118251",
        "speaker": "",
        "abstract": "Recently, deep learning-based pan-sharpening algorithms have achieved notable advancements over traditional methods. However, deep learning-based methods incur substantial computational overhead during inference, especially with large images. This excessive computational demand limits the applicability of these methods in real-world scenarios, particularly in the absence of dedicated computing devices such as GPUs and TPUs. To address these challenges, we propose Pan-LUT, a novel learnable look-up table (LUT) framework for pan-sharpening that strikes a balance between performance and computational efficiency for large remote sensing images. Our method makes it possible to process 15K$\\times$15K remote sensing images on a 24GB GPU. To finely control the spectral transformation, we devise the PAN-guided look-up table (PGLUT) for channel-wise spectral mapping. To effectively capture fine-grained spatial details, we introduce the spatial details look-up table (SDLUT). Furthermore, to adaptively aggregate channel information for generating high-resolution multispectral images, we design an adaptive output look-up table (AOLUT). Our model contains fewer than 700K parameters and processes a 9K$\\times$9K image in under 1 ms using one RTX 2080 Ti GPU, demonstrating significantly faster performance compared to other methods. Experiments reveal that Pan-LUT efficiently processes large remote sensing images in a lightweight manner, bridging the gap to real-world applications. Furthermore, our model surpasses SOTA methods in full-resolution scenes under real-world conditions, highlighting its effectiveness and efficiency.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117604",
        "speaker": "",
        "abstract": "Accurate, high-resolution ocean forecasting is crucial for maritime operations and environmental monitoring. While traditional numerical models are capable of producing sub-daily, eddy-resolving forecasts, they are computationally intensive and face challenges in maintaining accuracy at fine spatial and temporal scales. In contrast, recent data-driven approaches offer improved computational efficiency and emerging potential, yet typically operate at daily resolution and struggle with sub-daily predictions due to error accumulation over time.We introduce FuXi-Ocean, the first data-driven global ocean forecasting model achieving six-hourly predictions at eddy-resolving 1/12\u00b0 spatial resolution, reaching depths of up to 1500 meters. The model architecture integrates a context-aware feature extraction module with a predictive network employing stacked attention blocks. The core innovation is the Mixture-of-Time (MoT) module, which adaptively integrates predictions from multiple temporal contexts by learning variable-specific reliability, mitigating cumulative errors in sequential forecasting. Through comprehensive experimental evaluation, FuXi-Ocean demonstrates superior skill in predicting key variables, including temperature, salinity, and currents, across multiple depths.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 3C",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122558",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Auto-Compressing Networks",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/116934",
        "speaker": "",
        "abstract": "Deep neural networks with short residual connections have demonstrated remarkable success across domains, but increasing depth often introduces computational redundancy without corresponding improvements in representation quality. We introduce Auto-Compressing Networks (ACNs), an architectural variant where additive long feedforward connections from each layer to the output replace traditional short residual connections. By analyzing the distinct dynamics induced by this modification, we reveal a unique property we coin asauto-compression\u2014the ability of a network to organically compress information during training with gradient descent, through architectural design alone. Through auto-compression, information is dynamically \"pushed\" into early layers during training, enhancing their representational quality and revealing potential redundancy in deeper ones. We theoretically show that this property emerges from layer-wise training patterns found only in ACNs, where layers are dynamically utilized during training based on task requirements. We also find that ACNs exhibit enhanced noise robustness compared to residual networks, superior performance in low-data settings, improved transfer learning capabilities, and  mitigate catastrophic forgetting suggesting that they learn representations that generalize better despite using fewer parameters. Our results demonstrate up to 18\\% reduction in catastrophic forgetting and 30-80\\% architectural compression while maintaining accuracy across vision transformers, MLP-mixers, and BERT architectures. These findings establish ACNs as a practical approach to developing efficient neural architectures that automatically adapt their computational footprint to task complexity, while learning robust representations suitable for noisy real-world tasks and continual learning scenarios.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/119732",
        "speaker": "",
        "abstract": "Deployment of neural networks on resource-constrained devices demands models that are both compact and robust to adversarial inputs. However, compression and adversarial robustness often conflict. In this work, we introduce a dynamical low-rank training scheme enhanced with a novel spectral regularizer that controls the condition number of the low-rank core in each layer. This approach mitigates the sensitivity of compressed models to adversarial perturbations without sacrificing clean accuracy. The method is model- and data-agnostic, computationally efficient, and supports rank adaptivity to automatically compress the network at hand. Extensive experiments across standard architectures, datasets, and adversarial attacks show the regularized networks can achieve over 94 compression while recovering or improving adversarial accuracy relative to uncompressed baselines.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/116595",
        "speaker": "",
        "abstract": "The hypothesis that Convolutional Neural Networks (CNNs) are inherently texture-biased has shaped much of the discourse on feature use in deep learning. We revisit this hypothesis by examining limitations in the cue-conflict experiment by Geirhos et al. To address these limitations, we propose a domain-agnostic framework that quantifies feature reliance through systematic suppression of shape, texture, and color cues, avoiding the confounds of forced-choice conflicts. By evaluating humans and neural networks under controlled suppression conditions, we find that CNNs are not inherently texture-biased but predominantly rely on local shape features. Nonetheless, this reliance can be substantially mitigated through modern training strategies or architectures (ConvNeXt, ViTs). We further extend the analysis across computer vision, medical imaging, and remote sensing, revealing that reliance patterns differ systematically: computer vision models prioritize shape, medical imaging models emphasize color, and remote sensing models exhibit a stronger reliance on texture. Code is available at https://github.com/tomburgert/feature-reliance.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 3D",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122559",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 State Entropy Regularization for Robust Reinforcement Learning",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/115740",
        "speaker": "",
        "abstract": "State entropy regularization has empirically shown better exploration and sample complexity in reinforcement learning (RL). However, its theoretical guarantees have not been studied. In this paper, we show that state entropy regularization improves robustness to structured and spatially correlated perturbations. These types of variation are common in transfer learning but often overlooked by standard robust RL methods, which typically focus on small, uncorrelated changes. We provide a comprehensive characterization of these robustness properties, including formal guarantees under reward and transition uncertainty, as well as settings where the method performs poorly. Much of our analysis contrasts state entropy with the widely used policy entropy regularization, highlighting their different benefits. Finally, from a practical standpoint, we illustrate that compared with policy entropy, the robustness advantages of state entropy are more sensitive to the number of rollouts used for policy evaluation.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 A Clean Slate for Offline Reinforcement Learning",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/119623",
        "speaker": "",
        "abstract": "Progress in offline reinforcement learning (RL) has been impeded by ambiguous problem definitions and entangled algorithmic designs, resulting in inconsistent implementations, insufficient ablations, and unfair evaluations. Although offline RL explicitly avoids environment interaction, prior methods frequently employ extensive, undocumented online evaluation for hyperparameter tuning, complicating method comparisons. Moreover, existing reference implementations differ significantly in boilerplate code, obscuring their core algorithmic contributions. We address these challenges by first introducing a rigorous taxonomy and a transparent evaluation protocol that explicitly quantifies online tuning budgets. To resolve opaque algorithmic design, we provide clean, minimalistic, single-file implementations of various model-free and model-based offline RL methods, significantly enhancing clarity and achieving substantial speed-ups. Leveraging these streamlined implementations, we propose Unifloral, a unified algorithm that encapsulates diverse prior approaches and enables development within a single, comprehensive hyperparameter space. Using Unifloral with our rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR (model-free) and MoBRAC (model-based) - which substantially outperform established baselines. Our implementation is publicly available at https://github.com/EmptyJackson/unifloral.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117976",
        "speaker": "",
        "abstract": "Reinforcement learning (RL) systems have countless applications, from energy-grid management to protein design. However, such real-world scenarios are often extremely difficult, combinatorial in nature, and require complex coordination between multiple agents. This level of complexity can cause even state-of-the-art RL systems, trained until convergence, to hit a performance ceiling which they are unable to break out of with zero-shot inference. Meanwhile, many digital or simulation-based applications allow for an inference phase that utilises a specific time and compute budget to explore multiple attempts before outputting a final solution. In this work, we show that such an inference phase employed at execution time, and the choice of a corresponding inference strategy, are key to breaking the performance ceiling observed in complex multi-agent RL problems. Our main result is striking: we can obtain up to a 126% and, on average, a 45% improvement over the previous state-of-the-art across 17 tasks, using only a couple seconds of extra wall-clock time during execution. We also demonstrate promising compute scaling properties, supported by over 60k experiments, making it the largest study on inference strategies for complex RL to date. We make all of our experimental data and code available.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 3E",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122560",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Position: If Innovation in AI systematically Violates Fundamental Rights, Is It Innovation at All?",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/126305",
        "speaker": "",
        "abstract": "Artificial intelligence (AI) now permeates critical infrastructures and decisionmaking systems where failures produce social, economic, and democratic harm. This position paper challenges the entrenched belief that regulation and innovation are opposites. As evidenced by analogies from aviation, pharmaceuticals, and welfare systems and recent cases of synthetic misinformation, bias and unaccountable decision-making, the absence of well-designed regulation has already created immeasurable damage. Regulation, when thoughtful and adaptive, is not a brake on innovation\u2014it is its foundation. The present position paper examines the EU AI Act as a model of risk-based, responsibility-driven regulation that addresses the Collingridge Dilemma: acting early enough to prevent harm, yet flexibly enough to sustain innovation. Its adaptive mechanisms\u2014regulatory sandboxes, small and medium enterprises (SMEs) support, real-world testing, fundamental rights impact assessment (FRIA)\u2014demonstrate how regulation can accelerate responsibly, rather than delay, technological progress. The position paper summarises how governance tools transform perceived burdens into tangible advantages: legal certainty, consumer trust, and ethical competitiveness. Ultimately, the paper reframes progress: innovation and regulation advance together. By embedding transparency, impact assessments, accountability, and AI literacy into design and deployment, the EU framework defines what responsible innovation truly means\u2014technological ambition disciplined by democratic values and fundamental rights.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 More effort is needed to protect pedestrian privacy in the era of AI",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/126301",
        "speaker": "",
        "abstract": "In the era of artificial intelligence (AI), pedestrian privacy is increasingly at risk. In research areas such as autonomous driving, computer vision, and surveillance, large datasets are often collected in public spaces, capturing pedestrians without consent or anonymization. These datasets are used to train systems that can identify, track, and analyze individuals, often without their knowledge. Although various technical methods and regional regulations have been proposed to address this issue, existing solutions are either insufficient to protect privacy or compromise data utility, thereby limiting their effectiveness for research. In this paper, we argue that more effort is needed to protect pedestrian privacy in the era of AI while maintaining data utility. We call on the AI and computer vision communities to take pedestrian privacy seriously and to rethink how pedestrian data are collected and anonymized. Collaboration with experts in law and ethics will also be essential for the responsible development of AI. Without stronger action, it will become increasingly difficult for individuals to protect their privacy, and public trust in AI may decline.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Real-Time Hyper-Personalized Generative AI Should Be Regulated to Prevent the Rise of \"Digital Heroin\"",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T10:00:00",
        "end_datetime": "2025-12-04T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/126308",
        "speaker": "",
        "abstract": "This position paper argues that real-time generative AI has the potential to become the next wave of addictive digital media, creating a new class of digital content akin to ``digital heroin'' with severe implications for mental health and youth development. By shortening the content-generation feedback loop to mere seconds, these advanced models will soon be able to hyper-personalize outputs on the fly. When paired with misaligned incentives (e.g., maximizing user engagement), this will fuel unprecedented compulsive consumption patterns with far-reaching consequences for mental health, cognitive development, and social stability. Drawing on interdisciplinary research, from clinical observations of social media addiction to neuroscientific studies of dopamine-driven feedback, we illustrate how real-time tailored content generation may erode user autonomy, foment emotional distress, and disproportionately endanger vulnerable groups, such as adolescents. Due to the rapid advancement of generative AI and its potential to induce severe addiction-like effects, we call for strong government oversight akin to existing controls on addictive substances, particularly for minors. We further urge the machine learning community to act proactively by establishing robust design guidelines, collaborating with public health experts, and supporting targeted policy measures to ensure responsible and ethical deployment, rather than paving the way for another wave of unregulated digital dependence.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 4A",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122561",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/118059",
        "speaker": "",
        "abstract": "Sparse Autoencoders (SAEs) aim to decompose the activation space of large language models (LLMs) into human-interpretable latent directions or features. As we increase the number of features in the SAE, hierarchical features tend to split into finer features (\u201cmath\u201d may split into \u201calgebra\u201d, \u201cgeometry\u201d, etc.), a phenomenon referred to as feature splitting. However, we show that sparse decomposition and splitting of hierarchical features is not robust. Specifically, we show that seemingly monosemantic features fail to fire where they should, and instead get \u201cabsorbed\u201d into their children features. We coin this phenomenon feature absorption, and show that it is caused by optimizing for sparsity in SAEs whenever the underlying features form a hierarchy. We introduce a metric to detect absorption in SAEs, and validate our findings empirically on hundreds of LLM SAEs. Our investigation suggests that varying SAE sizes or sparsity is insufficient to solve this issue. We discuss the implications of feature absorption in SAEs and some potential approaches to solve the fundamental theoretical issues before SAEs can be used for interpreting LLMs robustly and at scale.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/120217",
        "speaker": "",
        "abstract": "Gating mechanisms have been widely utilized, from early models like LSTMs and Highway Networks to recent state space models, linear attention, and also softmax attention.Yet, existing literature rarely examines the specific effects of gating.In this work, we conduct comprehensive experiments to systematically investigate gating-augmented softmax attention variants.Specifically, we perform a comprehensive comparison over 30 variants of 15B Mixture-of-Experts (MoE) models and 1.7B dense models trained on a 3.5 trillion token dataset.Our central finding is that a simple modification\u2014applying a head-specific sigmoid gate after the Scaled Dot-Product Attention (SDPA)\u2014consistently improves performance.This modification also enhances training stability, tolerates larger learning rates, and improves scaling properties.By comparing various gating positions and computational variants, we attribute this effectiveness to two key factors: (1) introducing non-linearity upon the low-rank mapping in the softmax attention, and (2) applying query-dependent sparse gating scores to modulate the SDPA output.Notably, we find this sparse gating mechanism mitigatesmassive activation,attention sinkand enhances long-context extrapolation performance. We also release related codes (https://github.com/qiuzh20/gatedattention}) and models (https://huggingface.co/QwQZh/gatedattention) to facilitate future research.Furthermore, the most effective SDPA output gating is used in the Qwen3-Next models (https://huggingface.co/collections/Qwen/qwen3-next).",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Superposition Yields Robust Neural Scaling",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116347",
        "speaker": "",
        "abstract": "The success of today's large language models (LLMs) depends on the observation that larger models perform better. However, the origin of this neural scaling law, that loss decreases as a power law with model size, remains unclear. We propose that representation superposition, meaning that LLMs represent more features than they have dimensions, can be a key contributor to loss and cause neural scaling. Based on Anthropic's toy model, we use weight decay to control the degree of superposition, allowing us to systematically study how loss scales with model size. When superposition is weak, the loss follows a power law only if data feature frequencies are power-law distributed. In contrast, under strong superposition, the loss generically scales inversely with model dimension across a broad class of frequency distributions, due to geometric overlaps between representation vectors. We confirmed that open-sourced LLMs operate in the strong superposition regime and have loss scaling inversely with model dimension, and that the Chinchilla scaling laws are also consistent with this behavior. Our results identify representation superposition as a central driver of neural scaling laws, providing insights into questions like when neural scaling laws can be improved and when they will break down.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 4B",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122562",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 In Search of Adam\u2019s Secret Sauce",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/119298",
        "speaker": "",
        "abstract": "Understanding the remarkable efficacy of Adam when training transformer-based language models has become a central research topic within the optimization community. To gain deeper insights, several simplifications of Adam have been proposed, such as the signed gradient and signed momentum methods. In this work, we conduct an extensive empirical study \u2014 training over 1,500 language models across different data configurations and scales \u2014 comparing Adam to several known simplified variants. We find that signed momentum methods are faster than SGD, but consistently underperform relative to Adam, even after careful tuning of momentum, clipping setting and learning rates. However, our analysis reveals a compelling option that preserves near-optimal performance while allowing for new insightful reformulations: constraining the Adam momentum parameters to be equal, \u03b2 1 = \u03b2 2 . Beyond robust performance, this choice affords new theoretical insights, highlights the \"secret sauce\" on top of signed momentum, and grants a precise statistical interpretation: we show that Adam in this setting implements a natural online algorithm for estimating the mean and variance of gradients\u2014one that arises from a mean-field Gaussian variational inference perspective.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/117576",
        "speaker": "",
        "abstract": "As the economic and environmental costs of training and deploying large vision or language models increase dramatically, analog in-memory computing (AIMC) emerges as a promising energy-efficient solution. However, the training perspective, especially its training dynamic, is underexplored. In AIMC hardware, the trainable weights are represented by the conductance of resistive elements and updated using consecutive electrical pulses.  While the conductance changes by a constant in response to each pulse, in reality, the change is scaled by asymmetric and non-linear response functions, leading to a non-ideal training dynamic. This paper provides a theoretical foundation for gradient-based training on AIMC hardware with non-ideal response functions.  We demonstrate that asymmetric response functions negatively impact Analog SGD by imposing an implicit penalty on the objective. To overcome the issue, we propose residual learning algorithm, which provably converges exactly to a critical point by solving a bilevel optimization problem. We show that the proposed method can be extended to deal with other hardware imperfections like limited response granularity. As far as we know, it is the first paper to investigate the impact of a class of generic non-ideal response functions. The conclusion is supported by simulations validating our theoretical insights.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Generalized Gradient Norm Clipping & Non-Euclidean(L0,L1)-Smoothness",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115789",
        "speaker": "",
        "abstract": "This work introduces a hybrid non-Euclidean optimization method which generalizes gradient norm clipping by combining steepest descent and conditional gradient approaches. The method achieves the best of both worlds by establishing a descent property under a generalized notion of ($L_0$,$L_1$)-smoothness. Weight decay is incorporated in a principled manner by identifying a connection to the Frank-Wolfe short step. In the stochastic case, we show an order optimal $O(n^{-1/4})$ convergence rate by leveraging a momentum based gradient estimator. We discuss how to instantiate the algorithms for deep learning, which we dub Clipped Scion, and demonstrate their properties on image classification and language modeling. The code is available at https://github.com/LIONS-EPFL/ClippedScion.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 4C",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122563",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 MaxSup: Overcoming Representation Collapse in Label Smoothing",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116897",
        "speaker": "",
        "abstract": "Label Smoothing (LS) is widely adopted to reduce overconfidence in neural network predictions and improve generalization. Despite these benefits, recent studies reveal two critical issues with LS. First, LS induces overconfidence in misclassified samples. Second, it compacts feature representations into overly tight clusters, diluting intra-class diversity, although the precise cause of this phenomenon remained elusive. In this paper, we analytically decompose the LS-induced loss, exposing two key terms: (i) a regularization term that dampens overconfidence only when the prediction is correct, and (ii) an error-amplification term that arises under misclassifications. This latter term compels the network to reinforce incorrect predictions with undue certainty, exacerbating representation collapse. To address these shortcomings, we propose Max Suppression (MaxSup), which applies uniform regularization to both correct and incorrect predictions by penalizing the top-1 logit rather than the ground-truth logit. Through extensive feature-space analyses, we show that MaxSup restores intra-class variation and sharpens inter-class boundaries. Experiments on large-scale image classification and multiple downstream tasks confirm that MaxSup is a more robust alternative to LS.Code and reproducibility scripts are available at https://github.com/ZhouYuxuanYX/Maximum-Suppression-Regularization.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Advancing Expert Specialization for Better MoE",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116507",
        "speaker": "",
        "abstract": "Mixture-of-Experts (MoE) models enable efficient scaling of large language models (LLMs) by activating only a subset of experts per input. However, we observe that the commonly used auxiliary load balancing loss often leads to expert overlap and overly uniform routing, which hinders expert specialization and degrades overall performance during post-training.To address this, we propose a simple yet effective solution that introduces two complementary objectives: (1) an orthogonality loss to encourage experts to process distinct types of tokens, and (2) a variance loss to encourage more discriminative routing decisions.Gradient-level analysis demonstrates that these objectives are compatible with the existing auxiliary loss and contribute to optimizing the training process.Experimental results over various model architectures and across multiple benchmarks show that our method significantly enhances expert specialization. Notably, our method improves classic MoE baselines with auxiliary loss by up to 23.79\\%, while also maintaining load balancing in downstream tasks, without any architectural modifications or additional components. We will release our code to contribute to the community.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Learning to Learn with Contrastive Meta-Objective",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115718",
        "speaker": "",
        "abstract": "Meta-learning enables learning systems to adapt quickly to new tasks, similar to humans.Different meta-learning approaches all work under/with the mini-batch episodic training framework. Such framework naturally gives the information about task identity, which can serve as additional supervision for meta-training to improve generalizability. We propose to exploit task identity as additional supervision in meta-training, inspired by the alignment and discrimination ability which is is intrinsic in human's fast learning.This is achieved by contrasting what meta-learners learn, i.e., model representations.The proposed ConML is evaluating and optimizing the contrastive meta-objective under a problem- and learner-agnostic meta-training framework.We demonstrate that ConML integrates seamlessly with existing meta-learners, as well as in-context learning models, and brings significant boost in performance with small implementation cost.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 4D",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122564",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Exploring Diffusion Transformer Designs via Grafting",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/119280",
        "speaker": "",
        "abstract": "Designing model architectures requires decisions such as selecting operators (e.g., attention, convolution) and configurations (e.g., depth, width). However, evaluating the impact of these decisions on model quality requires costly pretraining, limiting architectural investigation.Inspired by how new software is built on existing code, we ask: can new architecture designs be studied using pretrained models? To this end, we present *grafting*, a simple approach for editing pretrained diffusion transformers (DiTs) to materialize new architectures under small compute budgets. Informed by our analysis of activation behavior and attention locality, we construct a testbed based on the DiT-XL/2 design to study the impact of grafting on model quality. Using this testbed, we develop a family of hybrid designs via grafting: replacing softmax attention with gated convolution, local attention, and linear attention, and replacing MLPs with variable expansion ratio and convolutional variants. Notably, many hybrid designs achieve good quality (FID: 2.38\u20132.64 vs. 2.27 for DiT-XL/2)using < 2 % pretraining compute. We then graft a text-to-image model (PixArt- \u03a3 ), achieving a 1.43 \u00d7 speedup with less than a 2% drop in GenEval score. Finally, we present a case study that restructures DiT-XL/2 by converting every pair of sequential transformer blocks into parallel blocks via grafting. This reduces model depth by 2 \u00d7 and yields better quality (FID: 2.77) than other models of comparable depth. Together, we show that new diffusion model designs can be explored by grafting pretrained DiTs, with edits ranging from operator replacement to architecture restructuring. Code and grafted models: https://grafting.stanford.edu.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Deep Compositional Phase Diffusion for Long Motion Sequence Generation",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116419",
        "speaker": "",
        "abstract": "Recent research on motion generation has shown significant progress in generating semantically aligned motion with singular semantics. However, when employing these models to create composite sequences containing multiple semantically generated motion clips, they often struggle to preserve the continuity of motion dynamics at the transition boundaries between clips, resulting in awkward transitions and abrupt artifacts. To address these challenges, we present Compositional Phase Diffusion, which leverages the Semantic Phase Diffusion Module (SPDM) and Transitional Phase Diffusion Module (TPDM) to progressively incorporate semantic guidance and phase details from adjacent motion clips into the diffusion process. Specifically, SPDM and TPDM operate within the latent motion frequency domain established by the pre-trained Action-Centric Motion Phase Autoencoder (ACT-PAE). This allows them to learn semantically important and transition-aware phase information from variable-length motion clips during training. Experimental results demonstrate the competitive performance of our proposed framework in generating compositional motion sequences that align semantically with the input conditions, while preserving phase transitional continuity between preceding and succeeding motion clips. Additionally, motion inbetweening task is made possible by keeping the phase parameter of the input motion sequences fixed throughout the diffusion process, showcasing the potential for extending the proposed framework to accommodate various application scenarios. Codes are available athttps://github.com/asdryau/TransPhase.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Mean Flows for One-step Generative Modeling",
        "type": "Oral Paper",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115488",
        "speaker": "",
        "abstract": "We propose a principled and effective framework for one-step generative modeling. We introduce the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods. A well-defined identity between average and instantaneous velocities is derived and used to guide neural network training. Our method, termed the \\textit{MeanFlow} model, is self-contained and requires no pre-training, distillation, or curriculum learning. MeanFlow demonstrates strong empirical performance: it achieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet 256 \u00d7 256 trained from scratch, significantly outperforming previous state-of-the-art one-step diffusion/flow models. Our study substantially narrows the gap between one-step diffusion/flow models and their multi-step predecessors, and we hope it will motivate future research to revisit the foundations of these powerful models.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 4E Position Paper Track Panels",
        "type": "Oral Session",
        "date": "2025-12-04",
        "start_datetime": "2025-12-04T03:30:00",
        "end_datetime": "2025-12-04T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122565",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "From Benchmarks to Problems - A Perspective on Problem Finding in AI",
        "type": "Invited Talk",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T08:30:00",
        "end_datetime": "2025-12-05T09:30:00",
        "url": "https://neurips.cc/virtual/2025/invited-talk/109605",
        "speaker": "Kyunghyun Cho",
        "abstract": "During the past 15 years or so, I have worked on a series of seemingly distinct but eventually related problems, including machine learning algorithms, generative modeling with neural networks, machine translation, language modeling, medical imaging, a bit of healthcare, protein modeling and a bit of drug discovery. I chose to work on some of these problems intentionally, while it was pure serendipity that I worked on some others. It was only in hindsight that these seemingly different problems turned out to be closely related to each other from both technical, social and personal perspectives. In this talk, I plan to do my own retrospective on my own choices, be them intentional or not, on these problems and share with you my thoughts what our own discipline, which is sometimes called computer science, data science, machine learning or artificial intelligence, is.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Demystifying depth: Principles of learning in deep neural networks",
        "type": "Invited Talk",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T14:30:00",
        "end_datetime": "2025-12-05T15:30:00",
        "url": "https://neurips.cc/virtual/2025/invited-talk/109602",
        "speaker": "Andrew Saxe",
        "abstract": "Deep neural networks have revolutionized artificial intelligence, yet their inner workings remain poorly understood. This talk presents mathematical analyses of the nonlinear dynamics of learning in several solvable deep network models, offering theoretical insights into the role of depth. These models reveal how learning algorithms, data structure, initialization schemes, and architectural choices interact to produce hidden representations that afford complex generalization behaviors. A recurring theme across these analyses is a neural race: competing pathways within a deep network vie to explain the data, with an implicit bias toward shared representations. These shared representations in turn shape the network\u2019s capacity for systematic generalization, multitasking, and transfer learning. I will show how such principles manifest across diverse architectures\u2014including feedforward, recurrent, and linear attention networks. Together, these results provide analytic foundations for understanding how environmental statistics, network architecture, and learning dynamics jointly structure the emergence of neural representations and behavior.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 5A",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122566",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 EvoLM: In Search of Lost Language Model Training Dynamics",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/119409",
        "speaker": "",
        "abstract": "Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage.We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Large Language Diffusion Models",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118609",
        "speaker": "",
        "abstract": "The capabilities of large language models (LLMs) are widely regarded as relying on autoregressive models (ARMs). We challenge this notion by introducingLLaDA, a diffusion model trained from scratch under the pre-training and supervised fine-tuning (SFT) paradigm. LLaDA employs a forward data masking process and a reverse generation process, parameterized by a Transformer to predict masked tokens. It provides a principled generative approach for probabilistic inference by optimizing a likelihood lower bound. Across extensive benchmarks on general tasks, math, code, and so on, LLaDA demonstrates strongscalabilityand performs comparably to our self-constructed ARM baselines. Remarkably, LLaDA 8B is competitive with strong LLMs like LLaMA3 8B inin-context learningand, after SFT, exhibits impressiveinstruction-followingabilities in case studies such as multi-turn dialogue. Moreover, LLaDA addresses the reversal curse, surpassing GPT-4o in a reversal poem completion task. Our findings show the promise of diffusion models for language modeling at scale and challenge the common assumption that core LLM capabilities discussed above inherently depend on ARMs. Project page and codes: \\url{https://ml-gsai.github.io/LLaDA-demo/}.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/119945",
        "speaker": "",
        "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly in mathematics and programming tasks. It is widely believed that, similar to how traditional RL helps agents to explore and learn new strategies, RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed the capacity of the corresponding base models. In this study, we take a critical look at \\textit{the current state of RLVR} by systematically probing the reasoning capability boundaries of RLVR-trained LLMs across diverse model families, RL algorithms, and math/coding/visual reasoning benchmarks, using pass@\\textit{k} at large \\textit{k} values as the evaluation metric.While RLVR improves sampling efficiency towards the correct path, we surprisingly find that current training does \\emph{not} elicit fundamentally new reasoning patterns.We observe that while RLVR-trained models outperform their base models at smaller values of k (\\eg, k =1), base models achieve higher pass@ k score when k is large.Moreover, we observe that the reasoning capability boundary of LLMs often narrows as RLVR training progresses.Further coverage and perplexity analysis shows that the reasoning paths generated by RLVR models are already included in the base models' sampling distribution, suggesting that their reasoning abilities originate from and are \\textit{bounded} by the base model. From this perspective, treating the base model as an upper bound, our quantitative analysis shows that six popular RLVR algorithms perform similarly and remain far from optimal in fully leveraging the potential of the base model.In contrast, we find that distillation can introduce new reasoning patterns from the teacher and genuinely expand the model\u2019s reasoning capabilities.Taken together, our findings suggest that current RLVR methods have not fully realized the potential of RL to elicit genuinely novel reasoning abilities in LLMs. This underscores the need for improved RL paradigms\u2014such as continual scaling and multi-turn agent-environment interaction\u2014to unlock this potential.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 5B",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122567",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/121452",
        "speaker": "",
        "abstract": "LLM\u2011based agents have demonstrated great potential in generating and managing code within complex codebases. In this paper, we introduce WebGen-Bench, a novel benchmark designed to measure an LLM-based agent's ability to create multi-file website codebases from scratch. It contains diverse instructions for website generation, created through the combined efforts of human annotators and GPT-4o. These instructions span three major categories and thirteen minor categories, encompassing nearly all important types of web applications.To assess the quality of the generated websites, we generate test cases targeting each functionality described in the instructions. These test cases are then manually filtered, refined, and organized to ensure accuracy, resulting in a total of 647 test cases. Each test case specifies an operation to be performed on the website and the expected outcome of the operation.To automate testing and improve reproducibility, we employ a powerful web-navigation agent to execute test cases on the generated websites and determine whether the observed responses align with the expected results.We evaluate three high-performance code-agent frameworks\u2014Bolt.diy, OpenHands, and Aider\u2014using multiple proprietary and open-source LLMs as engines. The best-performing combination, Bolt.diy powered by DeepSeek-R1, achieves only 27.8\\% accuracy on the test cases, highlighting the challenging nature of our benchmark.Additionally, we construct WebGen-Instruct, a training set consisting of 6,667 website-generation instructions. Training Qwen2.5-Coder-32B-Instruct on Bolt.diy trajectories generated from a subset of the training set achieves an accuracy of 38.2\\%, surpassing the performance of the best proprietary model.We release our data-generation, training, and testing code, along with both the datasets and model weights at https://github.com/mnluzimu/WebGen-Bench.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117310",
        "speaker": "",
        "abstract": "Clinical decision\u2011making routinely demands reasoning over heterogeneous data, yet existing multimodal language models (MLLMs) remain largely vision\u2011centric and fail to generalize across clinical specialties. To bridge this gap, we introduce QoQ-Med-7B/32B, the first open generalist clinical foundation model that jointly reasons across medical images, time\u2011series signals, and text reports. QoQ-Med is trained with Domain\u2011aware Relative Policy Optimization (DRPO), a novel reinforcement\u2011learning objective that hierarchically scales normalized rewards according to domain rarity and modality difficulty, mitigating performance imbalance caused by skewed clinical data distributions. Trained on 2.61 million instruction tuning pairs spanning 9 clinical domains, we show that DRPO training boosts diagnostic performance by 43% in macro\u2011F1 on average across all visual domains as compared to other critic-free training methods like GRPO. Furthermore, with QoQ-Med trained on intensive segmentation data, it is able to highlight salient regions related to the diagnosis, with an IoU 10x higher than open models while reaching the performance of OpenAI o4-mini. To foster reproducibility and downstream research, we release (i) the full model weights, (ii) the modular training pipeline, and (iii) all intermediate reasoning traces.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 NOVA: A Benchmark for Rare Anomaly Localization and Clinical Reasoning in Brain MRI",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/121771",
        "speaker": "",
        "abstract": "In many real-world applications, deployed models encounter inputs that differ from the data seen during training. Open-world recognition ensures that such systems remain robust as ever-emerging, previously _unknown_ categories appear and must be addressed without retraining.Foundation and vision-language models are pre-trained on large and diverse datasets with the expectation of broad generalization across domains, including medical imaging.However, benchmarking these models on test sets with only a few common outlier types silently collapses the evaluation back to a closed-set problem, masking failures on rare or truly novel conditions encountered in clinical use.We therefore present NOVA, a challenging, real-life _evaluation-only_ benchmark of $\\sim$900 brain MRI scans that span 281 rare pathologies and heterogeneous acquisition protocols. Each case includes rich clinical narratives and double-blinded expert bounding-box annotations. Together, these enable joint assessment of anomaly localisation, visual captioning, and diagnostic reasoning. Because NOVA is never used for training, it serves as an _extreme_ stress-test of out-of-distribution generalisation: models must bridge a distribution gap both in sample appearance and in semantic space.  Baseline results with leading vision-language models (GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B) reveal substantial performance drops, with approximately a 65\\% gap in localisation compared to natural-image benchmarks and 40\\% and 20\\% gaps in captioning and reasoning, respectively, compared to resident radiologists. Therefore, NOVA establishes a testbed for advancing models that can detect, localize, and reason about truly unknown anomalies.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 5C",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122568",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 High-dimensional neuronal activity from low-dimensional latent dynamics: a solvable model",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/117112",
        "speaker": "",
        "abstract": "Computation in recurrent networks of neurons has been hypothesized to occur at the level of low-dimensional latent dynamics, both in artificial systems and in the brain. This hypothesis seems at odds with evidence from large-scale neuronal recordings in mice showing that neuronal population activity is high-dimensional. To demonstrate that low-dimensional latent dynamics and high-dimensional activity can be two sides of the same coin, we present an analytically solvable recurrent neural network (RNN) model whose dynamics can be exactly reduced to a low-dimensional dynamical system, but generates an activity manifold that has a high linear embedding dimension. This raises the question: Do low-dimensional latents explain the high-dimensional activity observed in mouse visual cortex? Spectral theory tells us that the covariance eigenspectrum alone does not allow us to recover the dimensionality of the latents, which can be low or high, when neurons are nonlinear. To address this indeterminacy, we develop Neural Cross-Encoder (NCE), an interpretable, nonlinear latent variable modeling method for neuronal recordings, and find that high-dimensional neuronal responses to drifting gratings and spontaneous activity in visual cortex can be reduced to low-dimensional latents, while the responses to natural images cannot. We conclude that the high-dimensional activity measured in certain conditions, such as in the absence of a stimulus, is explained by low-dimensional latents that are nonlinearly processed by individual neurons.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Task-Optimized Convolutional Recurrent Networks Align with Tactile Processing in the Rodent Brain",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/116232",
        "speaker": "",
        "abstract": "Tactile sensing remains far less understood in neuroscience and less effective in artificial systems compared to more mature modalities such as vision and language.We bridge these gaps by introducing a novel Encoder-Attender-Decoder (EAD) framework to systematically explore the space of task-optimized temporal neural networks trained on realistic tactile input sequences from a customized rodent whisker-array simulator. We identify convolutional recurrent neural networks (ConvRNNs) as superior encoders to purely feedforward and state-space architectures for tactile categorization. Crucially, these ConvRNN-encoder-based EAD models achieve neural representations closely matching rodent somatosensory cortex, saturating the explainable neural variability and revealing a clear linear relationship between supervised categorization performance and neural alignment.Furthermore, contrastive self-supervised ConvRNN-encoder-based EADs, trained with tactile-specific augmentations, match supervised neural fits, serving as an ethologically-relevant, label-free proxy.For neuroscience, our findings highlight nonlinear recurrent processing as important for general-purpose tactile representations in somatosensory cortex, providing the first quantitative characterization of the underlying inductive biases in this system. For embodied AI, our results emphasize the importance of recurrent EAD architectures to handle realistic tactile inputs, along with tailored self-supervised learning methods for achieving robust tactile perception with the same type of sensors animals use to sense in unstructured environments.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Memory Mosaics at scale",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118784",
        "speaker": "",
        "abstract": "Memory Mosaics, networks of associative memories, have demonstrated appealing compositional and in-context learning capabilities on medium-scale networks (GPT-2 scale) and synthetic small datasets. This work shows that these favorable properties remain when we scale memory mosaics to large language model sizes (llama-8B scale) and real-world datasets. To this end, we scale memory mosaics to 10B size, we train them on one trillion tokens, we introduce a couple architectural modifications (memory mosaics v2), we assess their capabilities across three evaluation dimensions: training-knowledge storage, new-knowledge storage, and in-context learning. Throughout the evaluation, memory mosaics v2 match transformers on the learning of training knowledge (first dimension) and significantly outperforms transformers on carrying out new tasks at inference time (second and third dimensions). These improvements cannot be easily replicated by simply increasing the training data for transformers. A memory mosaics v2 trained on one trillion tokens still perform better on these tasks than a transformer trained on eight trillion tokens.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 5D",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122569",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 InfinityStar: Uni\ufb01ed Spacetime AutoRegressive Modeling for Visual Generation",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118709",
        "speaker": "",
        "abstract": "We introduce InfinityStar, a unified spacetime autoregressive framework for high-resolution image and dynamic video synthesis. Building on the recent success of autoregressive modeling in both vision and language, our purely discrete approach jointly captures spatial and temporal dependencies within a single architecture. This unified design naturally supports a variety of generation tasks such as text-to-image, text-to-video, image-to-video, and long-duration video synthesis via straightforward temporal autoregression. Through extensive experiments, InfinityStar scores 83.74 on VBench, outperforming all autoregressive models by large margins, even surpassing diffusion competitors like HunyuanVideo. Without extra optimizations, our model generates a 5s, 720p video approximately 10 \u00d7 faster than leading diffusion-based methods. To our knowledge, InfinityStar is the first discrete autoregressive video generator capable of producing industrial-level 720p videos. We release all code and models to foster further research in efficient, high-quality video generation.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 PlayerOne: Egocentric World Simulator",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118938",
        "speaker": "",
        "abstract": "We introduce PlayerOne, the first egocentric realistic world simulator, facilitating immersive and unrestricted exploration within vividly dynamic environments. Given an egocentric scene image from the user, PlayerOne can accurately construct the corresponding world and generate egocentric videos that are strictly aligned with the real-scene human motion of the user captured by an exocentric camera. PlayerOne is trained in a coarse-to-fine pipeline that first performs pretraining on large-scale egocentric text-video pairs for coarse-level egocentric understanding, followed by finetuning on synchronous motion-video data extracted from egocentric-exocentric video datasets with our automatic construction pipeline. Besides, considering the varying importance of different components, we design a part-disentangled motion injection scheme, enabling precise control of part-level movements. In addition, we devise a joint reconstruction framework that progressively models both the 4D scene and video frames, ensuring scene consistency in the long-form video generation. Experimental results demonstrate its great generalization ability in precise control of varying human movements and world-consistent modeling of diverse scenarios. It marks the first endeavor into egocentric real-world simulation and can pave the way for the community to delve into fresh frontiers of world modeling and its diverse applications.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 BEDLAM2.0: Synthetic humans and cameras in motion",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/121503",
        "speaker": "",
        "abstract": "Inferring 3D human motion from video remains a challenging problem with many applications. While traditional methods estimate the human in image coordinates, many applications require human motion to be estimated in world coordinates. This is particularly challenging when there is both human and camera motion. Progress on this topic has been limited by the lack of rich video data with ground truth human and camera movement. We address this with BEDLAM2.0, a new dataset that goes beyond the popular BEDLAM dataset in important ways. In addition to introducing more diverse and realistic cameras and camera motions, BEDLAM2.0 increases diversity and realism of body shape, motions, clothing, hair, and 3D environments. Additionally, it adds shoes, which were missing in BEDLAM. BEDLAM has become a key resource for training 3D human pose and motion regressors today and we show that BEDLAM2.0 is significantly better, particularly for training methods that estimate humans in world coordinates. We compare state-of-the art methods trained on BEDLAM and BEDLAM2.0, and find that BEDLAM2.0 significantly improves accuracy over BEDLAM.  For research purposes, we provide the rendered videos, ground truth body parameters, and camera motions. We also provide the 3D assets to which we have rights and links to those from third parties.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 5E",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/session/122570",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Boosting Knowledge Utilization in Multimodal Large Language Models via Adaptive Logits Fusion and Attention Reallocation",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/115856",
        "speaker": "",
        "abstract": "Despite their recent progress, Multimodal Large Language Models (MLLMs) often struggle in knowledge-intensive tasks due to the limited and outdated parametric knowledge acquired during training. Multimodal Retrieval Augmented Generation addresses this issue by retrieving contextual knowledge from external databases, thereby enhancing MLLMs with expanded knowledge sources. However, existing MLLMs often fail to fully leverage the retrieved contextual knowledge for response generation. We examine representative MLLMs and identify two major causes, namely, attention bias toward different tokens and knowledge conflicts between parametric and contextual knowledge. To this end, we design Adaptive Logits Fusion and Attention Reallocation (ALFAR), a training-free and plug-and-play approach that improves MLLM responses by maximizing the utility of the retrieved knowledge. Specifically, ALFAR tackles the challenges from two perspectives. First, it alleviates attention bias by adaptively shifting attention from visual tokens to relevant context tokens according to query-context relevance. Second, it decouples and weights parametric and contextual knowledge at output logits, mitigating conflicts between the two types of knowledge. As a plug-and-play method, ALFAR achieves superior performance across diverse datasets without requiring additional training or external tools. Extensive experiments over multiple MLLMs and benchmarks show that ALFAR consistently outperforms the state-of-the-art by large margins. Our code and data are available at https://github.com/Lackel/ALFAR.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118373",
        "speaker": "",
        "abstract": "Multi-modal large language models (MLLMs) have emerged as a transformative approach for aligning visual and textual understanding. They typically require extremely high computational resources (e.g., thousands of GPUs) for training to achieve cross-modal alignment at multi-granularity levels. We argue that a key source of this inefficiency lies in the vision encoders they widely equip with, e.g., CLIP and SAM, which lack the alignment with language at multi-granularity levels. To address this issue, in this paper, we leverage hyperbolic space, which inherently models hierarchical levels and thus provides a principled framework for bridging the granularity gap between visual and textual modalities at an arbitrary granularity level. Concretely, we propose an efficient training paradigm for MLLMs, dubbed as \\blg, which can optimize visual representations to align with their textual counterparts at an arbitrary granularity level through dynamic hyperbolic radius adjustment in hyperbolic space. \\alg employs learnable matrices with M\\\"{o}bius multiplication operations, implemented via three effective configurations: diagonal scaling matrices, block-diagonal matrices, and banded matrices, providing a flexible yet efficient parametrization strategy. Comprehensive experiments across multiple MLLM benchmarks demonstrate that \\alg consistently improves both existing pre-training and fine-tuning MLLMs clearly with less than 1\\% additional parameters.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T10:00:00",
        "end_datetime": "2025-12-05T11:00:00",
        "url": "https://neurips.cc/virtual/2025/oral/118167",
        "speaker": "",
        "abstract": "Multimodal learning (MML) is significantly constrained by modality imbalance, leading to suboptimal performance in practice. While existing approaches primarily focus on balancing the learning of different modalities to address this issue, they fundamentally overlook the inherent disproportion in model classification ability, which serves as the primary cause of this phenomenon. In this paper, we propose a novel multimodal learning approach to dynamically balance the classification ability of weak and strong modalities by incorporating the principle of boosting. Concretely, we first propose a sustained boosting algorithm in multimodal learning by simultaneously optimizing the classification and residual errors. Subsequently, we introduce an adaptive classifier assignment strategy to dynamically facilitate the classification performance of the weak modality. Furthermore, we theoretically analyze the convergence property of the cross-modal gap function, ensuring the effectiveness of the proposed boosting scheme. To this end, the classification ability of strong and weak modalities is expected to be balanced, thereby mitigating the imbalance issue. Empirical experiments on widely used datasets reveal the superiority of our method through comparison with various state-of-the-art (SOTA) multimodal learning baselines. The source code is available at https://github.com/njustkmg/NeurIPS25-AUG.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 6A",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122571",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/117790",
        "speaker": "",
        "abstract": "Bandeira et al. (2022) introduced the Franz-Parisi (FP) criterion for characterizing the computational hard phases in statistical detection problems. The FP criterion, based on an annealed version of the celebrated Franz-Parisi potential from statistical physics, was shown to be equivalent to low-degree polynomial (LDP) lower bounds for Gaussian additive models, thereby connecting two distinct approaches to understanding the computational hardness in statistical inference. In this paper, we propose a refined FP criterion that aims to better capture the geometric ``overlap\" structure of statistical models. Our main result establishes that this optimized FP criterion is equivalent to Statistical Query (SQ) lower bounds---another foundational framework in computational complexity of statistical inference.  Crucially, this equivalence holds under a mild, verifiable assumption satisfied by a broad class of statistical models, including Gaussian additive models, planted sparse models, as well as non-Gaussian component analysis (NGCA), single-index (SI) models, and convex truncation detection settings. For instance, in the case of convex truncation tasks, the assumption is equivalent with the Gaussian correlation inequality (Royen, 2014) from convex geometry. In addition to the above, our equivalence not only unifies and simplifies the derivation of several known SQ lower bounds\u2014such as for the NGCA model (Diakonikolas et al., 2017) and the SI model (Damian et al., 2024)\u2014but also yields new SQ lower bounds of independent interest, including for the computational gaps in mixed sparse linear regression (Arpino et al., 2023) and convex truncation (De et al., 2023).",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/119076",
        "speaker": "",
        "abstract": "A central challenge in machine learning is to understand how noise or measurement errors affect low-rank approximations, particularly in the spectral norm. This question is especially important in differentially private low-rank approximation, where one aims to preserve the top-$p$ structure of a data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius norm error or changes in reconstruction quality, but these metrics can over- or under-estimate true subspace distortion. The spectral norm, by contrast, captures worst-case directional error and provides the strongest utility guarantees. We establish new high-probability spectral-norm perturbation bounds for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem and explicitly capture interactions between a matrix $A \\in \\mathbb{R}^{n \\times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and norm conditions, our bounds yield sharp estimates for $\\| (A + E)_p - A_p \\|$, where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up to a factor of $\\sqrt{n}$. As an application, we derive improved utility guarantees for differentially private PCA, resolving an open problem in the literature. Our analysis relies on a novel contour bootstrapping method from complex analysis and extends it to a broad class of spectral functionals, including polynomials and matrix exponentials. Empirical results on real-world datasets confirm that our bounds closely track the actual spectral error under diverse perturbation regimes.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116693",
        "speaker": "",
        "abstract": "This paper addresses the Bayesian optimization problem (also referred to as the Bayesian setting of the Gaussian process bandit), where the learner seeks to minimize the regret under a function drawn from a known Gaussian process (GP). Under a Mat\\'ern kernel with some extent of smoothness, we show that the Gaussian process upper confidence bound (GP-UCB) algorithm achieves $\\tilde{O}(\\sqrt{T})$ cumulative regret with high probability. Furthermore, our analysis yields $O(\\sqrt{T \\ln^2 T})$ regret under a squared exponential kernel. These results fill the gap between the existing regret upper bound of GP-UCB and the current best upper bound provided by Scarlett [2018]. The key idea in our proof is to capture the concentration behavior of the input sequence realized by GP-UCB, enabling us to handle GP's information gain in a refined manner.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 6B",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122572",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116902",
        "speaker": "",
        "abstract": "Graph Neural Networks (GNNs) are widely used for node classification, yet their opaque decision-making limits trust and adoption. While local explanations offer insights into individual predictions, global explanation methods\u2014those that characterize an entire class\u2014remain underdeveloped. Existing global explainers rely on motif discovery in small graphs, an approach that breaks down in large, real-world settings where subgraph repetition is rare, node attributes are high-dimensional, and predictions arise from complex structure-attribute interactions. We propose GnnXemplar, a novel global explainer inspired from Exemplar Theory from cognitive science. GnnXemplar identifies representative nodes in the GNN embedding space\u2014exemplars\u2014and explains predictions using natural language rules derived from their neighborhoods. Exemplar selection is framed as a coverage maximization problem over reverse $k$-nearest neighbors, for which we provide an efficient greedy approximation. To derive interpretable rules, we employ a self-refining prompt strategy using large language models (LLMs). Experiments across diverse benchmarks show that GnnXemplar significantly outperforms existing methods in fidelity, scalability, and human interpretability, as validated by a user study with 60 participants.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 RAG4GFM: Bridging Knowledge Gaps in Graph Foundation Models through Graph Retrieval Augmented Generation",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115563",
        "speaker": "",
        "abstract": "Graph Foundation Models (GFMs) have demonstrated remarkable potential across graph learning tasks but face significant challenges in knowledge updating and reasoning faithfulness. To address these issues, we introduce the Retrieval-Augmented Generation (RAG) paradigm for GFMs, which leverages graph knowledge retrieval. We propose RAG4GFM, an end-to-end framework that seamlessly integrates multi-level graph indexing, task-aware retrieval, and graph fusion enhancement. RAG4GFM implements a hierarchical graph indexing architecture, enabling multi-granular graph indexing while achieving efficient logarithmic-time retrieval. The task-aware retriever implements adaptive retrieval strategies for node, edge, and graph-level tasks to surface structurally and semantically relevant evidence. The graph fusion enhancement module fuses retrieved graph features with query features and augments the topology with sparse adjacency links that preserve structural and semantic proximity, yielding a fused graph for GFM inference.Extensive experiments conducted across diverse GFM applications demonstrate that RAG4GFM significantly enhances both the efficiency of knowledge updating and reasoning faithfulness\\footnote{Code: \\url{https://github.com/Matrixmax/RAG4GFM}.}.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Discovering Opinion Intervals from Conflicts in Signed Graphs",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115063",
        "speaker": "",
        "abstract": "Online social media provide a platform for people to discuss current events and exchange opinions with their peers. While interactions are predominantly positive, in recent years, there has been a lot of research to understand the conflicts in social networks and how they are based on different views and opinions.  In this paper, we ask whether the conflicts in a network reveal a small and interpretable set of prevalent opinion ranges that explain the users' interactions.  More precisely, we consider signed graphs, where the edge signs indicate positive and negative interactions of node pairs, and our goal is to infer opinion intervals that are consistent with the edge signs.  We introduce an optimization problem that models this question, and we give strong hardness results and a polynomial-time approximation scheme by utilizing connections to interval graphs and the Correlation Clustering problem.  We further provide scalable heuristics and show that in experiments they yield more expressive solutions than Correlation Clustering baselines. We also present a case study on a novel real-world dataset from the German parliament, showing that our algorithms can recover the political leaning of German parties based on co-voting behavior.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 6C",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122573",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Generalized Linear Mode Connectivity for Transformers",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/118595",
        "speaker": "",
        "abstract": "Understanding the geometry of neural network loss landscapes is a central question in deep learning, with implications for generalization and optimization. A striking phenomenon is $\\textit{linear mode connectivity}$ (LMC), where independently trained models can be connected by low- or zero-barrier paths, despite appearing to lie in separate loss basins. However, this is often obscured by symmetries in parameter space\u2014such as neuron permutations\u2014which make functionally equivalent models appear dissimilar. Prior work has predominantly focused on neuron reordering through permutations, but such approaches are limited in scope and fail to capture the richer symmetries exhibited by modern architectures such as Transformers. In this work, we introduce a unified framework that captures four symmetry classes\u2014permutations, semi-permutations, orthogonal transformations, and general invertible maps\u2014broadening the set of valid reparameterizations and subsuming many previous approaches as special cases. Crucially, this generalization enables, for the first time, the discovery of low- and zero-barrier linear interpolation paths between independently trained Vision Transformers and GPT-2 models. Furthermore, our framework extends beyond pairwise alignment, to multi-model and width-heterogeneous settings, enabling alignment across architectures of different sizes. These results reveal deeper structure in the loss landscape and underscore the importance of symmetry-aware analysis for understanding model space geometry.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 On Linear Mode Connectivity of Mixture-of-Experts Architectures",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/118036",
        "speaker": "",
        "abstract": "Linear Mode Connectivity (LMC) is a notable phenomenon in the loss landscapesof neural networks, wherein independently trained models have been observed tobe connected\u2014up to permutation symmetries\u2014by linear paths in parameter spacealong which the loss remains consistently low. This observation challenges classicalviews of non-convex optimization and has implications for model ensembling,generalization, and our understanding of neural loss geometry. Inspired by recentstudies on LMC in standard neural networks, we systematically investigate thisphenomenon within Mixture-of-Experts (MoE) architectures\u2014a class of modelsknown for their scalability and computational efficiency, which combine traditionalneural networks\u2014referred to as experts\u2014through a learnable gating mechanism.We begin by conducting a comprehensive analysis of both dense and sparse gatingregimes, demonstrating that the symmetries inherent to MoE architectures arefully characterized by permutations acting on both the expert components and thegating function. Building on these foundational findings, we propose a matchingalgorithm that enables alignment between independently trained MoEs, therebyfacilitating the discovery of LMC. Finally, we empirically validate the presence ofLMC using our proposed algorithm across diverse MoE configurations\u2014includingdense, sparse, and shared-expert variants\u2014under a wide range of model settingsand datasets of varying scales and modalities. Our results confirm the existenceof LMC in MoE architectures and offer fundamental insights into the functionallandscape and optimization dynamics of deep learning models.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Learning (Approximately) Equivariant Networks via Constrained Optimization",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/118376",
        "speaker": "",
        "abstract": "Equivariant neural networks are designed to respect symmetries through their architecture, boosting generalization and sample efficiency when those symmetries are present in the data distribution. Real-world data, however, often departs from perfect symmetry because of noise, structural variation, measurement bias, or other symmetry-breaking effects. Strictly equivariant models may struggle to fit the data, while unconstrained models lack a principled way to leverage partial symmetries. Even when the data is fully symmetric, enforcing equivariance can hurt training by limiting the model to a restricted region of the parameter space. Guided by homotopy principles, where an optimization problem is solved by gradually transforming a simpler problem into a complex one, we introduce Adaptive Constrained Equivariance (ACE), a constrained optimization approach that starts with a flexible, non-equivariant model and gradually reduces its deviation from equivariance. This gradual tightening smooths training early on and settles the model at a data-driven equilibrium, balancing between equivariance and non-equivariance. Across multiple architectures and tasks, our method consistently improves performance metrics, sample efficiency, and robustness to input perturbations compared with strictly equivariant models and heuristic equivariance relaxations.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 6D",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122574",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 A Snapshot of Influence: A Local Data Attribution Framework for Online Reinforcement Learning",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115686",
        "speaker": "",
        "abstract": "Online reinforcement learning (RL) excels in complex, safety-critical domains but suffers from sample inefficiency, training instability, and limited interpretability. Data attribution provides a principled way to trace model behavior back to training samples, yet existing methods assume fixed datasets, which is violated in online RL where each experience both updates the policy and shapes future data collection.In this paper, we initiate the study of data attribution for online RL, focusing on the widely used Proximal Policy Optimization (PPO) algorithm. We start by establishing alocalattribution framework, interpreting model checkpoints with respect to the records in the recent training buffer. We design two target functions, capturing agent action and cumulative return respectively, and measure each record's contribution through gradient similarity between its training loss and these targets. We demonstrate the power of this framework through three concrete applications: diagnosis of learning, temporal analysis of behavior formation, and targeted intervention during training. Leveraging this framework, we further propose an algorithm, iterative influence-based filtering (IIF), for online RL training that iteratively performs experience filtering to refine policy updates. Across standard RL benchmarks (classic control, navigation, locomotion) to RLHF for large language models, IIF reduces sample complexity, speeds up training, and achieves higher returns. Together, these results open a new direction for making online RL more interpretable, efficient, and effective.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115732",
        "speaker": "",
        "abstract": "Scaling up self-supervised learning has driven breakthroughs in language and vision, yet comparable progress has remained elusive in reinforcement learning (RL). In this paper, we study building blocks for self-supervised RL that unlock substantial improvements in scalability, with network depth serving as a critical factor. Whereas most RL papers in recent years have relied on shallow architectures (around 2 -- 5 layers), we demonstrate that increasing the depth up to 1024 layers can significantly boost performance.Our experiments are conducted in an unsupervised goal-conditioned setting, where no demonstrations or rewards are provided, so an agent must explore (from scratch) and learn how to maximize the likelihood of reaching commanded goals.Evaluated on simulated locomotion and manipulation tasks, our approach increases performance on the self-supervised contrastive RL algorithm by $2\\times$ -- $50\\times$, outperforming other goal-conditioned baselines.Increasing the model depth not only increases success rates but also qualitatively changes the behaviors learned.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 Learning long range dependencies through time reversal symmetry breaking",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/115363",
        "speaker": "",
        "abstract": "Deep State Space Models (SSMs) reignite physics-grounded compute paradigms, as RNNs could natively be embodied into dynamical systems. This calls for dedicated learning algorithms obeying to core physical principles,  with efficient techniques to simulate these systems and guide their design. We propose \\emph{Recurrent Hamiltonian Echo Learning} (RHEL), an algorithm which provably computes loss gradients as finite differences of physical trajectories of non-dissipative, \\emph{Hamiltonian systems}. In ML terms, RHEL only requires three ``forward passes'' irrespective of model size, without explicit Jacobian computation, nor incurring any variance in the gradient estimation. Motivated by the potential to implement our algorithm in non-digital physical systems, we first introduce RHEL in \\emph{continuous time} and demonstrate its formal equivalence with the continuous adjoint state method.To facilitate the simulation of Hamiltonian systems trained by RHEL, we propose a \\emph{discrete-time} version of RHEL which is equivalent to Backpropagation Through Time (BPTT) when applied to a class of recurrent modules which we call \\emph{Hamiltonian Recurrent Units} (HRUs). This setting allows us to demonstrate the scalability of RHEL by generalizing these results to hierarchies of HRUs, which we call \\emph{Hamiltonian SSMs} (HSSMs). We apply RHEL to train HSSMs with linear and nonlinear dynamics on a variety of time-series tasks ranging from mid-range to long-range classification and regression with sequence length reaching $\\sim 50k$. We show that RHEL consistently matches the performance of BPTT across all models and tasks. This work opens new doors for the design of scalable, energy-efficient physical systems endowed with self-learning capabilities for sequence modelling.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Oral Session 6E",
        "type": "Oral Session",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/session/122575",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/118742",
        "speaker": "",
        "abstract": "Transformer-based large language models (LLMs) cache context as key-value (KV) pairs during inference. As context length grows, KV cache sizes expand, leading to substantial memory overhead and increased attention latency. This paper introduces \\textit{KVzip}, a query-agnostic KV cache eviction method enabling effective reuse of compressed KV caches across diverse queries. KVzip quantifies the importance of a KV pair using the underlying LLM to reconstruct original contexts from cached KV pairs, subsequently evicting pairs with lower importance. Extensive empirical evaluations demonstrate that KVzip reduces KV cache size by $3$-$4\\times$ and FlashAttention decoding latency by approximately $2\\times$, with negligible performance loss in question-answering, retrieval, reasoning, and code comprehension tasks. Evaluations include various models such as LLaMA3.1, Qwen2.5, and Gemma3, with context lengths reaching up to 170K tokens. KVzip significantly outperforms existing query-aware KV eviction methods, which suffer from performance degradation even at a 90\\% cache budget ratio under multi-query scenarios.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 MokA: Multimodal Low-Rank Adaptation for MLLMs",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/116048",
        "speaker": "",
        "abstract": "In this paper, we reveal that most current efficient multimodal fine-tuning methods are hindered by a key limitation: they are directly borrowed from LLMs, often neglecting the intrinsic differences of multimodal scenarios and even affecting the full utilization of all modalities. Inspired by our empirical observation, we argue that unimodal adaptation and cross-modal adaptation are two essential parts for the effective fine-tuning of MLLMs. From this perspective, we propose Multimodal Low-rank Adaptation (MokA), a multimodal-aware efficient fine-tuning strategy that takes multimodal characteristics into consideration. It compresses unimodal information by modality-specific parameters while explicitly enhancing cross-modal interaction, ensuring both unimodal and cross-modal adaptation. Extensive experiments cover three representative multimodal scenarios (audio-visual-text, visual-text, and speech-text), and multiple LLM backbones (LLaMA2, Qwen2, Qwen2.5-VL, etc). Consistent improvements indicate the efficacy and versatility of the proposed method. Ablation studies and efficiency evaluation are also conducted to fully asses our method. Overall, we think MokA provides a more targeted solution for efficient adaptation of MLLMs, paving the way for further exploration.",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "  \u2192 ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism",
        "type": "Oral Paper",
        "date": "2025-12-05",
        "start_datetime": "2025-12-05T03:30:00",
        "end_datetime": "2025-12-05T16:30:00",
        "url": "https://neurips.cc/virtual/2025/oral/117338",
        "speaker": "",
        "abstract": "Multimodal large language models (MLLMs) extend LLMs to handle images, videos, and audio by incorporating feature extractors and projection modules. However, these additional components\u2014combined with complex inference pipelines and heterogeneous workloads\u2014introduce significant inference overhead. Therefore, efficiently serving MLLMs remains a major challenge. Current tightly coupled serving architectures struggle to distinguish between mixed request types or adapt parallelism strategies to different inference stages, leading to increased time-to-first-token (TTFT) and poor resource utilization. To address this, we introduce Elastic Multimodal Parallelism (EMP), a new serving paradigm that elastically adapts to resource heterogeneity across request types and inference stages. Building upon EMP, we develop ElasticMM, an MLLM serving system that (1) separates requests into independent modality groups with dynamic resource allocation via a modality-aware load balancer; (2) decouples inference stages and enables parallelism adjustment and adaptive scaling via elastic partition scheduling; and (3) improves inference efficiency through unified multimodal prefix caching and non-blocking encoding. Experiments on diverse real-world datasets show that ElasticMM outperforms state-of-the-art (SOTA) serving systems, reducing TTFT by up to 4.2 \u00d7 and achieving 3.2\u20134.5 \u00d7 higher throughput while meeting service-level objectives (SLOs).",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Structured Probabilistic Inference and Generative Modeling",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109570",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The NeurIPS 2025 Workshop on Structured Probabilistic Inference & Generative Modeling focuses on the theory, methodology, and application of structured probabilistic inference and generative modeling. The workshop aims to address challenges in probabilistic methods, especially when applied to highly structured data, and to foster collaboration and discussion among experts from academia and industry. The event will explore the intersection of probabilistic inference and foundation models, providing a platform for discussing applications and challenges in encoding domain knowledge. | Research Interests: Generative methods for graphs, 3D, time series, text, video, and other structured modalities, Probabilistic inference in models for reward fine-tuning, alignment, acceleration, watermarking, Scaling and accelerating inference and generative models, Uncertainty quantification in AI systems, Applications in sampling, optimization, decision making, Applications and practical implementations of existing methods to areas in science, Empirical analysis comparing different architectures for a given data modality and application, Relevance of probabilistic inference in the era of foundation models",
        "location": "San Diego"
    },
    {
        "title": "Reliable ML from Unreliable Data",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109580",
        "speaker": "",
        "abstract": "Distributions shift, chatbots get jail\u2011broken, users game algorithms \u2014 how do we build reliable machine learning when data are missing, corrupted, or strategically manipulated?This workshop bridges theory and practice to tackle these challenges, bringing together researchers working on distribution shift, adversarial robustness, and strategic behaviour to chart principled yet deployable solutions for Reliable ML from Unreliable Data.",
        "overview": "Overview: The Reliable ML 2025 workshop, held at NeurIPS 2025 in San Diego, focuses on developing reliable machine learning systems from unreliable data. It addresses challenges such as distribution shifts, adversarial robustness, and strategic behavior in socio-technical systems. The workshop aims to bridge theory and practice by bringing together researchers to propose principled and deployable solutions for robust and reliable machine learning under imperfect data conditions. | Research Interests: Distribution shift and transfer learning, Adversarial robustness and defenses, Strategic behavior in socio-technical systems, Learning with missing or biased data, Causal inference beyond overlap, with confounders, or with errors, LLM safety and alignment, Robustness in interactive environments",
        "location": "San Diego"
    },
    {
        "title": "GenProCC: 1st Workshop on Generative and Protective AI for Content Creation",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109545",
        "speaker": "",
        "abstract": "Recent advancements in generative AI (GenAI) have empowered machines to create high-quality content across diverse modalities - text, image, audio, and video - with impressive fluency and creativity. From GPT-4o and Stable Diffusion to Sora and MMAudio, the explosion of X-to-X generation (e.g., text-to-image, video-to-audio) is unlocking new frontiers in science, education, entertainment, and art.While GenAI has shown significant potential in creative applications (e.g., music, films, arts), these breakthroughs also raise pressing concerns related to safety, copyright, and ethical use. Generative models can be exploited to spread misinformation, violate intellectual property rights, or diminish human agency in creative processes. As such, there is an increasing need to balance innovation with protection, ensuring that AI-powered creative tools are used responsibly and ethically.This workshop, GenProCC: Generative and Protective AI for Content Creation, brings together researchers, creators, and practitioners at the intersection of content generation and IP protection. By uniting the generative AI and creator communities, the GenProCC workshop aims to explore the latest advances, challenges, and opportunities in the rapidly evolving field.",
        "overview": "Overview: The GenProCC NeurIPS 2025 Workshop focuses on the intersection of generative and protective AI for content creation. It aims to explore the advancements in generative AI technologies that enable machines to create high-quality content across various modalities such as text, image, audio, and video. The workshop addresses the potential of these technologies in creative applications while also highlighting the ethical, safety, and copyright concerns they raise. The event seeks to balance innovation with protection, ensuring responsible and ethical use of AI-powered creative tools. | Research Interests: Controllable Generative AI for Content Creation, Protective AI Approaches for Content Creation, Creative Practices with Generative AI, Controllable X-to-X generation, Interactive or iterative generation pipelines, Evaluations and benchmarks for controllability, Applications of controllability/protection in creative practices, Digital watermarking, fingerprinting, and provenance tracking, Benchmarks for evaluating protection in generative systems, Case studies and design research for content creation, Human-in-the-loop approaches for real-world GenAI creation workflows, Emerging applications of GenAI in content creation",
        "location": "San Diego"
    },
    {
        "title": "What Makes a Good Video: Next Practices in Video Generation and Evaluation",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109548",
        "speaker": "",
        "abstract": "This workshop aims to explore how real-world advances in video generation increasingly rely on forwardlooking evaluation frameworks and to collaboratively shape the next generation of high-quality video synthesis. Through a combination of invited talks, academic presentations, and expert discussions featuring leading voices from both academia and industry, the workshop bridges academic foundations and industrial insights across the modeling, evaluation, and deployment of video generation. We welcome contributions from computer vision, generative modeling, video-language learning, evaluation methodology, and human-centered AI to shape the next generation of high-quality video synthesis collaboratively.",
        "overview": "Overview: The 'What Makes a Good Video: Next Practices in Video Generation and Evaluation' workshop at NeurIPS 2025 aims to explore the evolution of video generation models. It focuses on understanding the limitations of current video models and identifying future research directions. The workshop features discussions on video generation, understanding, benchmarks, and applications, with insights from experts in academia and industry. | Research Interests: Video Generation Models, Benchmarks & Evaluation, Applications",
        "location": "San Diego"
    },
    {
        "title": "ML x OR: Mathematical Foundations and Operational Integration of Machine Learning for Uncertainty-Aware Decision-Making",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109555",
        "speaker": "",
        "abstract": "Much of traditional decision-making science is grounded in the mathematical formulations and analyses of structured systems to recommend decisions that are optimized, robust, and uncertainty-aware. This scientific approach, rooted in the field of Operations Research (OR), has evolved through decades of advancements in stochastic modeling, computational simulation and optimization, and exhibits key strengths in methodological rigor and uncertainty encoding. On the other hand, recent advances in the AI/ML space have eschewed this model-based paradigm and increasingly embraced, to great success, model-free algorithmic design frameworks. This workshop, which is the first NeurIPS workshop explicitly themed and structured on ML-OR synergization, aspires to present recent developments, challenges and emerging research to accelerate ML-OR synthesis. By integrating ML into established OR methodologies, we have the opportunities to produce more data-centric and adaptive solutions for complex decision-making tasks that could propel, in a much faster-paced manner, the frontier of \"optimality\" across many relevant applications. Concomitantly, the goal is also to explore how model-based principled OR approaches can help alleviate issues revolving around \"black box\" systems, and provide paths to enhance interpretability, trust, and performance analysis.",
        "overview": "Overview: The ML\u00d7OR Workshop at NeurIPS 2025 focuses on the integration of Machine Learning (ML) and Operations Research (OR) to enhance uncertainty-aware decision-making. This interdisciplinary workshop aims to explore the synergy between ML and OR, presenting recent developments, discussing challenges, and highlighting emerging research opportunities in data-centric decision-making. The workshop encourages contributions from researchers and practitioners across various fields and includes keynote talks, panel discussions, and poster sessions. | Research Interests: Embedding OR modeling insights into ML, Uncertainty mitigation at the interface of data, model, and decision, Sequential decision-making and online learning from an OR perspective, Generative AI for decision-making",
        "location": "San Diego"
    },
    {
        "title": "Deep Learning for Code in the Agentic Era",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109562",
        "speaker": "",
        "abstract": "Deep learning for code has progressed from focused tasks\u2014such as completion, repair, synthesis, and explanation to tackling complex, end-to-end software\u2013engineering problems.  A key recent breakthrough is the rise of coding agents. Unlike single-shot models, these systems plan, reason, explore, and invoke external tools to assist throughout the software-development lifecycle: adding features, refactoring, debugging, finding vulnerabilities, optimizing performance, summarizing code, and answering repository-level questions.  Their growing versatility demands rigorous evaluation and a deeper understanding of their capabilities, limits, risks, and broader social impact.Building on momentum from both academia and industry (e.g. Google, OpenAI, Anthropic, SWE-Agent, OpenHands), we propose the 4th Deep Learning for Code (DL4C) workshop with a dedicated focus on coding agents. This workshop will provide a timely forum where researchers and practitioners can design and stress-test robust coding agents, discover novel applications and emergent behaviors, establish principled benchmarks and evaluation methods, study human\u2013agent collaboration at scale, and advance the responsible, safe deployment of autonomous coding tools.",
        "overview": "Overview: The 4th Deep Learning for Code (DL4C) Workshop, titled 'Deep Learning For Code in the Agentic Era,' is scheduled to take place at NeurIPS 2025 in San Diego, CA. This workshop follows three successful previous installations at ICLR in 2022, 2023, and 2025. The event aims to bring together researchers and practitioners to discuss advancements and challenges in applying deep learning techniques to code-related tasks. | Research Interests: Deep Learning, Code Analysis, Machine Learning for Software Engineering, AI in Software Development",
        "location": "San Diego"
    },
    {
        "title": "Differentiable Learning of Combinatorial Algorithms: From Theory To Practice",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109535",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG @ NeurIPS\u201925)",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109576",
        "speaker": "",
        "abstract": "The field of wireless communications and networking is undergoing a paradigm shift, driven by the growing potential of Artificial Intelligence (AI) and Machine Learning (ML) to redefine traditional system design principles. This workshop aims to catalyze interest and foster collaboration between the AI/ML and wireless communications communities. The timing of this workshop is especially significant, as the next-generation (NextG) wireless standardization efforts (such as 6G and WiFi 9) are just getting started, with AI-native technologies expected to play a central role across all aspects of the wireless ecosystem \u2013 from radio access to network management and edge intelligence. NextG represents a foundational shift in global infrastructure, enabling ultra-fast, low-latency, and intelligent connectivity that will power future applications in AI, robotics, immersive environments, and autonomous systems. These technologies offer unprecedented opportunities to both drive and benefit many applications, from healthcare and transportation to industrial automation and environmental monitoring. The economic and societal implications are vast: NextG networks will underlie trillions in global GDP impact, bridge digital divides, and shape how billions of people interact with technology and each other in the decades to come.Despite the clear promise, a significant disconnect exists between the AI/ML and wireless research communities. AI/ML experts often lack an understanding of the unique physical, algorithmic, and architectural constraints inherent in wireless systems, while wireless researchers tend to adopt generic, off-the-shelf AI/ML models that are not optimized for the intricacies of wireless environments. Wireless environments are inherently dynamic, high-dimensional, and partially observable. These unique characteristics make them ideal testbeds for developing robust learning algorithms, particularly in areas like online learning, reinforcement learning, and in-context learning. At the same time, AI/ML techniques are becoming essential for managing the growing complexity of modern wireless networks, including resource allocation, interference mitigation, and cross-layer optimization. Bridging the gap between the two communities is not only necessary for meaningful technological advances but also critical for realizing the full societal impact of intelligent wireless systems.This workshop aims to bring together researchers and practitioners at the intersection of artificial intelligence (AI), machine learning (ML), and wireless to address the unique challenges and opportunities posed by Next-Generation (NextG) wireless systems. As the 6G era begins to take shape, AI-native designs have emerged as a cornerstone of wireless innovation, with the potential to transform the performance, efficiency, and adaptability of communication systems. The integration of AI/ML is poised to influence every layer of the network stack, from physical-layer signal processing to network control and resource management.",
        "overview": "Overview: The AI4NextG workshop at NeurIPS 2025 focuses on the integration of Artificial Intelligence (AI) and Machine Learning (ML) in next-generation wireless communications and networking. The workshop aims to bridge the gap between AI/ML and wireless research communities to address the challenges and opportunities posed by Next-Generation (NextG) wireless systems, such as 6G and WiFi 9. It seeks to foster collaboration and innovation in AI-native designs that can transform the performance, efficiency, and adaptability of communication systems. | Research Interests: AI-native protocol and architecture design for 6G and WiFi 8/9, Reinforcement learning for dynamic spectrum access and resource allocation, Gen AI and foundation models for physical-layer communication tasks, Online learning and adaptation under real-time and uncertain wireless environments, Data-efficient learning and representation for sparse, high-dimensional wireless signals, AI for network planning, self-optimization, and fault prediction in wireless networks, Cross-layer ML-driven optimizations for joint sensing, control, and communication, Co-design of hardware and ML algorithms for low-power and real-time wireless AI, Trustworthy and explainable AI in high-stakes communication systems",
        "location": "San Diego"
    },
    {
        "title": "The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109566",
        "speaker": "",
        "abstract": "Generative AI (GenAI) has emerged as a transformative force in healthcare, yet public trust remains limited due to safety concerns and policy misalignment. Build- ing on last year\u2019s successful GenAI4Health workshop, the field has rapidly evolved from exploratory research to real-world clinical deployments, accompanied by FDA regulatory involvement and expanding global governance frameworks. This second workshop convenes machine learning researchers, healthcare professionals, and policy experts to address the critical intersection of GenAI innovation and regula- tory compliance in health applications. We will examine trustworthiness challenges in large language models and multimodal foundation models, explore mitigation strategies, and foster dialogue between technical and policy communities. Our goal is to advance safe, effective, and ethically-compliant GenAI integration in healthcare systems, improving patient outcomes and clinical research capabilities.",
        "overview": "Overview: The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance (GenAI4Health2025) is a workshop held at NeurIPS 2025 in San Diego, California. It aims to bring together AI4Health practitioners, safety researchers, and policy experts to address critical challenges in developing robust and policy-compliant Generative AI technologies for healthcare. The workshop will cover topics such as generative AI applications in healthcare, AI trust and reliability in medical settings, policy compliance and regulatory frameworks, clinical AI implementation strategies, and AI safety in healthcare environments. | Research Interests: Generative AI applications in healthcare, AI trust and reliability in medical settings, Policy compliance and regulatory frameworks, Clinical AI implementation strategies, AI safety in healthcare environments",
        "location": "San Diego"
    },
    {
        "title": "CauScien: Uncovering Causality in Science",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109550",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The CauScien Workshop, part of NeurIPS 2025, is focused on uncovering causality in science. It aims to bridge the gap between theoretical causal reasoning and practical application in scientific research. The workshop fosters collaboration across various disciplines, including ecology, biology, and social sciences, to explore the integration of causal inference with domain expertise and real-world data. The event will address the challenges of applying causal learning techniques to accelerate scientific discovery and promote a bottom-up research paradigm. | Research Interests: Causal inference in applied science, Integration of causality with domain expertise, Causal learning techniques, Translational gap in causal reasoning, Causal benchmark tasks, Collaboration between domain experts and machine learning researchers, Causality in experimental design and planning",
        "location": "San Diego"
    },
    {
        "title": "Algorithmic Collective Action",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109567",
        "speaker": "",
        "abstract": "The study of collective action has a long history in economics and sociology as a way for groups of people to impact markets and the political arena. Algorithmic collective action focuses on the study of such coordinated efforts in algorithmically-mediated sociotechnical systems. How can participants of AI systems coordinate towards socially beneficial outcomes? We offer a platform to discuss new ideas and help define the foundational research directions for this emerging topic through interdisciplinary discussions between core ML researchers, scholars from the social sciences, community stakeholders and advocates.",
        "overview": "Overview: The Algorithmic Collective Action workshop is co-located with NeurIPS 2025 and will take place on December 6 at the San Diego Convention Center. The workshop focuses on exploring collective strategies for shaping outcomes in socio-technical systems from a grassroots perspective. It invites contributions that examine algorithmic collective action through various lenses, including machine learning, statistics, optimization, economics, and the humanities. The goal is to advance understanding of how coordinated efforts can influence the development and deployment of AI systems. | Research Interests: Algorithmic collective action, Socio-technical systems, Machine learning, Statistics, Optimization, Economics, Humanities, AI system development, AI system deployment",
        "location": "San Diego"
    },
    {
        "title": "Lock-LLM Workshop: Prevent Unauthorized Knowledge Use from Large Language Models - Deep Dive into Un-Distillate, Un-Finetunable, Un-Compressible, Un-Editable, and Un-Usable",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109568",
        "speaker": "",
        "abstract": "Large Language Models (LLMs) have emerged as transformative tools across research and industry, revolutionizing how we interact with information. However, their immense capabilities bring critical security challenges\u2014the same features that drive innovation can be exploited for malicious purposes through unauthorized distillation, fine-tuning, compression, or editing. These vulnerabilities pose severe threats, including intellectual property theft, the generation of sophisticated disinformation, the bypass of safety alignments, and the erosion of user trust in AI systems.This workshop aims to bring together researchers and practitioners from academia and industry who are advancing the frontiers of LLM security and protection. We seek to confront the unauthorized use of LLMs head-on by exploring novel and robust mechanisms designed to make these models inherently resistant to exploitation while maintaining their beneficial capabilities. The workshop also hosts the 2025 TrustAI Rising Star Award.Topics of interest include, but are not limited to:1. Un-Distillable LLMs: Preventing unauthorized model replication and intellectual property theft2. Un-Finetunable LLMs: Resisting malicious parameter updates and behavior alterations3. Un-Compressible LLMs: Maintaining model integrity against unauthorized compression4. Un-Editable LLMs: Safeguarding against knowledge tampering and misinformation injection5. Un-Usable LLMs: Ensuring traceability and preventing misuse through watermarking and verification",
        "overview": "Overview: The Lock-LLM workshop, part of NeurIPS 2025, focuses on addressing the security challenges posed by Large Language Models (LLMs). These models, while transformative, are vulnerable to unauthorized use such as distillation, fine-tuning, compression, and editing, which can lead to intellectual property theft, misinformation, and erosion of trust. The workshop aims to bring together researchers and practitioners to explore robust mechanisms that make LLMs resistant to exploitation while preserving their beneficial capabilities. The event also includes the 2025 TrustAI Rising Star Award to honor early-career researchers in the field. | Research Interests: Un-Distillable LLMs, Un-Finetunable LLMs, Un-Compressible LLMs, Un-Editable LLMs, Un-Usable LLMs, Theoretical Foundations, Evaluation Frameworks, Real-world Applications, Ethical and Societal Implications",
        "location": "San Diego"
    },
    {
        "title": "AI4Mat-NeurIPS-2025: NeurIPS 2025 Workshop on AI for Accelerated Materials Design",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109538",
        "speaker": "",
        "abstract": "AI4Mat-NeurIPS-2025 explores applications of artificial intelligence (AI) to materials via: 1. AI-Guided Materials Design; 2. Automated Chemical Synthesis; 3. Automated Material Characterization. AI4MatNeurIPS-2025 emphasizes structured, expert-driven dialogue on making advanced machine learning more impactful for real-world materials discovery. To that end, AI4Mat-RLSF (Research Learning from Speaker Feedback) creates a new structured discussion format where spotlight presenters receive curated, in-depth feedback from invited discussants. Further, the AI4Mat Frontiers & Benchmarking session brings together a diverse and distinguished set of speakers to critically examine current benchmarks, present state-of-the-art methods, and identify emerging opportunities and current limitations in AI-driven materials design.",
        "overview": "Overview: The AI4Mat workshop at NeurIPS 2025 is a platform for AI researchers and material scientists to collaborate on AI-driven materials discovery and development. It aims to foster interdisciplinary discussions and address challenges in automated materials discovery, including AI-guided design, synthesis, and characterization. The workshop has been a leading venue for exchanging ideas since its inception at NeurIPS 2022, and it continues to build a global research community focused on AI-enabled materials innovation. | Research Interests: AI-driven materials discovery, Automated materials design, AI-guided synthesis, Automated material characterization, Foundation models in materials science, Representation learning for materials, Benchmarking in machine learning for materials science",
        "location": "San Diego"
    },
    {
        "title": "AI for non-human animal communication",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109586",
        "speaker": "",
        "abstract": "The past few years have seen an unprecedented surge in both the availability of bioacoustic data and the sophistication of AI/machine learning models. This convergence presents a unique window of opportunity to revolutionize our understanding of animal communication and biodiversity. However, achieving this requires a conscious effort to integrate the disciplines of AI/Machine Learning and Ethology.    This workshop will explore the intersection of artificial intelligence (AI) and bioacoustics, aiming to address challenges in processing complex bioacoustic data and interpreting animal signals in order to advance our understanding of non-human animal communication. Join us for a poster session, keynote talks and a panel discussion as we explore key opportunities to use AI to decipher animal languages and thus deepen our understanding of the natural world.",
        "overview": "Overview: The AI for Non-Human Animal Communication NeurIPS 2025 Workshop aims to explore the intersection of artificial intelligence and bioacoustics to advance the understanding of non-human animal communication. The workshop will address challenges in processing complex bioacoustic data and interpreting animal signals, with the goal of revolutionizing our understanding of animal communication and biodiversity. It will feature a poster session, keynote talks, and a panel discussion. | Research Interests: Bioacoustic data processing, AI and machine learning models, Animal communication, Biodiversity, Multimodal learning, Transfer learning, Large-language models, Unsupervised, self-supervised, or supervised models, Ecological impact and conservation monitoring, Communication and cognition, Linguistics, Information encoding, Ethics in AI",
        "location": "San Diego"
    },
    {
        "title": "Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET)",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109542",
        "speaker": "",
        "abstract": "Recent progress in reinforcement learning (RL) has powered breakthroughs in various real-world problems, gathering considerable attention and investment. However, it has also exposed a significant gap between theoretical and experimental developments.RL theory has grown significantly in the past two decades. Research has characterized the inherent difficulty of various settings and has designed a wide variety of algorithms to reach optimal performances. Furthermore, a huge leap has been made in understanding how to handle large state spaces using function approximation techniques, identifying key structural properties that enable efficient learning.Despite theoretical guarantees, applying RL algorithms to complex problems faces challenges. Theoretical algorithms often focus on simplified settings, making them hard to apply to real-world complexities. Furthermore, optimizing for worst-case scenarios, which include unlikely situations, can lead to algorithms that perform poorly on practical tasks. Yet, while specialized algorithms offer empirical success, they might not translate to other problems due to their specific design, and the reliance on heuristics and engineering fixes further widens the gap between theory and practice.A prominent area that has seen a surge of interest in RL is generative language modeling. Pre-training these models can be viewed as a form of imitation learning, while post-training typically implements RL algorithms for purposes like instruction tuning with RL from human feedback or enhancing reasoning capabilities. While these successes make the practical utility of RL undeniable, the RL community finds itself at a crossroads. The algorithms employed are frequently variants of classical methods, and exploring beyond these presents a key challenge. Conversely, the success of these models prompts new questions for RL theory, suggesting that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions.Following the success of the ICML 2024 edition, the Second Workshop on Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) aims to bridge this discrepancy and promote collaboration. By bringing together experts from both sides, we want to facilitate meaningful discussions and draw a path for future RL research. Motivated by the take-home messages from the previous edition, we seek to encourage: (i) theorists to ask experimentalists for concrete problems to solve, and (ii) experimentalists to seek theoretical guidance on how to approach these problems.",
        "overview": "Overview: The Aligning Reinforcement Learning Experimentalists and Theorists (ARLET) Workshop at NeurIPS 2025 aims to bridge the gap between theoretical and experimental developments in reinforcement learning (RL). The workshop will feature a panel discussion on the current state of RL, an idea track for problem submissions, and a research track for solution submissions. The event will bring together researchers to foster collaboration and explore new paradigms in RL, particularly focusing on leveraging pre-trained models over traditional learning methods. | Research Interests: Reinforcement Learning, Theoretical and Experimental Developments in RL, Function Approximation Techniques, Large State Spaces, Pre-trained Models, Instruction Tuning with RL, Human Feedback in RL, Enhancing Reasoning Capabilities | Key Findings: The workshop highlights the significant gap between theoretical and experimental RL developments and suggests that frameworks leveraging pre-trained models might offer a more effective paradigm than learning from scratch under traditional assumptions.",
        "location": "San Diego"
    },
    {
        "title": "The First Workshop on Efficient Reasoning",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109556",
        "speaker": "",
        "abstract": "Recent progress in large reasoning models (LRMs), like OpenAI o1 and Deepseek R1, has been pivotal for tackling complex applications, from mathematical and code reasoning to advanced symbolic and agentic planning. Their success often relies on test-time scaling, which involves increasing the generation length or depth. However, these approaches incur significant efficiency bottlenecks during training and inference. To overcome these limitations, further advancements are needed in data, algorithms, and systems applicable across various domains, as exemplified by work such as s1, Z1, and verl. The proposed workshop will bring together researchers and practitioners to rethink efficient reasoning under tight compute, memory, latency, throughput, and cost budgets, with the goal of translating theoretical breakthroughs into practical, deployable solutions.",
        "overview": "Overview: The 1st Workshop on Efficient Reasoning at NeurIPS 2025 focuses on advancing large reasoning models (LRMs) to tackle complex applications efficiently. The workshop aims to address efficiency bottlenecks in training and inference by bringing together researchers and practitioners to explore data, algorithms, and systems that can operate under tight compute, memory, latency, throughput, and cost constraints. The goal is to translate theoretical breakthroughs into practical, deployable solutions. | Research Interests: Dataset Curation, Algorithmic Innovation, System Deployment, Application of LRMs in resource-constrained scenarios, Efficient training algorithms, Efficient inference methods, Dynamic KV-cache placement, Quantized graph execution, On-device knowledge distillation",
        "location": "San Diego"
    },
    {
        "title": "UniReps: Unifying Representations in Neural Models",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109553",
        "speaker": "",
        "abstract": "When, how and why do different neural models learn the same representations?New findings in neuroscience and artificial intelligence reveal a shared pattern: whether in biological brains or artificial models, different learning systems tend to create similar representations when subject to similar stimuli.The emergence of these similar representations is igniting a growing interest in the fields of neuroscience and artificial intelligence, with both fields offering promising directions for their theoretical understanding. These include analyzing the learning dynamics in neuroscience and studying the problem of identifiability in the functional and parameter space in artificial intelligence.While the theoretical aspects already demand investigation, the practical applications are equally compelling: aligning representations allows for model merging, stitching and reuse, while also playing a crucial role in multi-modal scenarios. Furthermore, studying the features that are universally highlighted by different learning processes brings us closer to pinpoint the invariances that naturally emerge from learning models, possibly suggesting ways to enforce them.The objective of the workshop is to discuss theoretical findings, empirical evidence and practical applications of this phenomenon, benefiting from the cross-pollination of different fields (ML, Neuroscience, Cognitive Science) to foster the exchange of ideas and encourage collaborations.In conclusion, our primary focus is to delve into the underlying reasons, mechanisms, and extent of similarity in internal representations across distinct neural models, with the ultimate goal of unifying them into a single cohesive whole.",
        "overview": "Overview: The UniReps Workshop focuses on the unification of representations in neural models, exploring how and why different neural models, whether biological or artificial, tend to learn similar representations when exposed to similar stimuli. The workshop aims to discuss theoretical findings, empirical evidence, and practical applications of this phenomenon, encouraging cross-disciplinary collaboration among fields such as machine learning, neuroscience, and cognitive science. | Research Interests: Unifying representations in neural models, Learning dynamics in neuroscience, Identifiability in artificial intelligence, Model merging and reuse, Multi-modal scenarios, Invariances in learning models | Key Findings: The workshop highlights the shared pattern of similar representations emerging in different learning systems, both biological and artificial, when exposed to similar stimuli. This phenomenon is of growing interest in neuroscience and artificial intelligence, with potential applications in model merging, stitching, and reuse, as well as in multi-modal scenarios.",
        "location": "San Diego"
    },
    {
        "title": "MATH-AI: The 5th Workshop on Mathematical Reasoning and AI",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109565",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The 5th Workshop on Mathematical Reasoning and AI, part of NeurIPS 2025, focuses on the intersection of deep learning and mathematical reasoning, particularly with large language models. The workshop aims to explore the extent to which machine learning models can comprehend mathematics and the potential applications of this capability. It seeks to bring together diverse participants to foster dialogue on various related topics. | Research Interests: Comparative study of human-level mathematical reasoning and AI techniques, Designing benchmarks for evaluating mathematical reasoning abilities, Advancing beyond current mathematical reasoning techniques, Role of deep learning models in mathematics education, Applications of AI in software verification, sciences, engineering, finance, education, and mathematics",
        "location": "San Diego"
    },
    {
        "title": "ML for Systems",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109537",
        "speaker": "",
        "abstract": "The 9th Machine Learning for Systems (ML for Systems) workshop brings together researchers and practitioners applying machine learning to core computer systems challenges. This year, we focus on three themes: (1) using LLMs and agentic workflows for systems tasks such as program synthesis and adaptive optimization; (2) applying ML to manage the complexity of large-scale training and serving of multimodal and reasoning models; and (3) leveraging ML for sustainable computing, including energy-, power-, and carbon-aware optimization. The workshop will feature invited talks, contributed presentations, and discussions aimed at advancing the frontier of ML for Systems research.",
        "overview": "Overview: The ML for Systems workshop focuses on the application of machine learning techniques to computer systems problems. It aims to replace traditional heuristics with machine learning approaches, such as supervised learning and reinforcement learning, to address a wide range of systems-related tasks. The workshop serves as an interdisciplinary venue for experts in ML and systems to collaborate and push the boundaries of this emerging field. It also emphasizes the development of best practices, methodologies, and benchmarks for ML in systems, with a particular focus on the challenges and opportunities presented by Large Language Models (LLMs). | Research Interests: Machine Learning for computer systems, Supervised learning, Reinforcement learning, Designing new data structures, Integrated circuits, Design verification, Control algorithms for compilers, Databases, Memory management, ML frameworks, Large Language Model (LLM) training and serving, Scheduling and compiling, Interdisciplinary collaboration between ML and systems | Key Findings: The workshop highlights the importance of ML in solving systems problems and the need for developing best practices and benchmarks. It also identifies the rise of LLMs as a significant trend, presenting both challenges and opportunities for the field. The workshop aims to foster connections between ML and systems communities and to stimulate new research directions.",
        "location": "San Diego"
    },
    {
        "title": "Dynamics at the Frontiers of Optimization, Sampling, and Games",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109541",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The DynaFront workshop at NeurIPS 2025 focuses on the role of dynamical systems in optimization, sampling, and game theory. It aims to lower the barrier to entry for researchers and practitioners in machine learning by highlighting the unifying role of dynamical systems across these domains. The workshop will convene experts to foster cross-disciplinary dialogue and collaboration, with an emphasis on emerging applications in machine learning such as diffusion models, distributed and adversarial training, and agentic AI. | Research Interests: Dynamical systems, Optimization, Sampling, Game theory, Machine learning, Diffusion models, Distributed training, Adversarial training, Agentic AI",
        "location": "San Diego"
    },
    {
        "title": "AI Virtual Cells and Instruments: A New Era in Drug Discovery and Development",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109543",
        "speaker": "",
        "abstract": "As the US FDA phases out animal testing requirements for drug discovery and development, AI tools will become widely adopted to simulate the effects of candidate drugs. We posit that building virtual cells and instruments with AI is poised to transform drug discovery and development by enabling large-scale simulation and interrogation of molecules, cells, and tissues. In our workshop, we will collaboratively define and promote this emerging scientific paradigm of AI to accelerate the drug discovery and development process in this new era.",
        "overview": "Overview: The AI4D3 NeurIPS 2025 workshop focuses on the transformative potential of AI in drug discovery and development, particularly as the US FDA phases out animal testing requirements. The workshop aims to explore the creation of AI-driven virtual cells and instruments to simulate the effects of candidate drugs, thereby accelerating the drug discovery process. This event will bring together a community to collaboratively define and promote this emerging scientific paradigm. | Research Interests: AI in drug discovery, Virtual cells and instruments, Simulation of drug effects, Large-scale molecular simulation, Interrogation of molecules, cells, and tissues",
        "location": "San Diego"
    },
    {
        "title": "OPT 2025: Optimization for Machine Learning",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109581",
        "speaker": "",
        "abstract": "Optimization lies at the heart of many machine learning algorithms and enjoys great interest in our community. Indeed, this intimate relation of optimization with ML is the key motivation for the OPT series of workshops. We aim to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to ML.The focus of OPT 2025 is on \"Statistics Meets Optimization\". Since its inception, stochastic optimization has been grounded in statistical principles. Today, many of the most pressing challenges in machine learning\u2014such as generalization bounds, the training dynamics of overparameterized models, and the development of generative models\u2014are directly inspired by statistical thinking. At the same time, the scale and complexity of modern datasets, along with the increasingly rich model classes used to represent them, pose new questions about how optimization algorithms interact with these structures\u2014both computationally and statistically. For example, what role do data symmetries play in shaping optimization trajectories? How do statistical properties of the data affect the adaptivity and efficiency of learning algorithms? And how can optimization approaches be designed to scale with data while still preserving desirable statistical behavior? OPT 2025 will explore these questions with the goal of building bridges between the statistics and optimization communities, and highlighting their shared impact on the theory and practice of machine learning.We are looking forward to seeing you all at OPT 2025, which will take place at the San Diego Convention Center!",
        "overview": "Overview: The OPT2025 workshop is the 17th International Workshop on Optimization for Machine Learning, held as part of the NeurIPS 2025 conference. It aims to foster discussion, discovery, and dissemination of state-of-the-art research in optimization relevant to machine learning. The workshop focuses on the intersection of statistics and optimization, exploring how these fields can address challenges in machine learning, such as generalization bounds, training dynamics of overparameterized models, and the development of generative models. The event will take place at the San Diego Convention Center. | Research Interests: Optimization for Machine Learning, Statistics Meets Optimization, Stochastic Optimization, Generalization Bounds, Training Dynamics of Overparameterized Models, Development of Generative Models, Data Symmetries in Optimization, Statistical Properties and Learning Algorithms, Scalable Optimization Approaches",
        "location": "San Diego"
    },
    {
        "title": "Foundation Models for the Brain and Body Workshop",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109571",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The 'Foundation Models for the Brain and Body' workshop is part of NeurIPS 2025, focusing on the intersection of AI and biosignals. It aims to explore how large-scale, pretrained AI systems can learn from neural and physiological signals to generalize across various applications, such as brain-computer interfacing and health monitoring. The workshop brings together experts from neuroscience, biomedical engineering, wearable technology, and machine learning to address the challenges of biosignal timeseries, which are often noisy and heterogeneous. | Research Interests: Foundation models, Biosignals, Brain-computer interfacing, Health monitoring, Neural and physiological signals, EEG, Intracortical electrophysiology, EMG, MEG, ECG, Wearable technology, Machine learning, Neuroscience, Biomedical engineering",
        "location": "San Diego"
    },
    {
        "title": "Biosecurity Safeguards for Generative AI",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109573",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "Imageomics: Discovering Biological Knowledge from Images Using AI",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109558",
        "speaker": "",
        "abstract": "Imageomics is an emerging interdisciplinary field at the crossroads of machine learning (ML), computer vision (CV), and biological sciences. It leverages visual data\u2014from microscopic images of single-cell species to videos of megafauna\u2014to extract and analyze biological information, specifically traits. By grounding ML models in existing scientific knowledge, Imageomics aims to make traits computable from images, facilitating insights into the evolution and function of living organisms. Imageomics poses research problems that resonate with the broad machine-learning community: multimodal representation learning, object detection and tracking, few-shot learning, imbalanced-class learning, video understanding, 3D modeling, hierarchical learning, etc. When people leverage ML tools to solve biological questions, the foundational bridges between ML and biological sciences also provide opportunities to address key challenges in ML, creating a virtuous cycle between the two fields.",
        "overview": "Overview: The Imageomics Workshop at NeurIPS 2025 is the third edition of an interdisciplinary event focused on the emerging field of Imageomics, which combines machine learning, computer vision, and biological sciences. The workshop aims to leverage visual data, from microscopic images to videos of large animals, to extract and analyze biological information, particularly traits. By integrating machine learning models with existing scientific knowledge, Imageomics seeks to make biological traits computable from images, providing insights into the evolution and function of living organisms. The workshop will feature keynote talks, paper presentations, and discussions on the latest research, encouraging participation from both biological scientists and machine learning researchers. | Research Interests: Multimodal representation learning, Object detection and tracking, Few-shot learning, Imbalanced-class learning, Video understanding, 3D modeling, Hierarchical learning",
        "location": "San Diego"
    },
    {
        "title": "Embodied World Models for Decision Making",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109532",
        "speaker": "",
        "abstract": "World models infer and predict real-world dynamics by modeling the external environment, and have become a cornerstone of embodied artificial intelligence. They have powered recent progress in decision-making and planning for interacting agents. This workshop aims to bring together researchers working at the intersection of generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models\u2014models that enable agents to understand, predict, and interact with the world through learned models. By focusing on embodiment and decision-making, this workshop seeks to advance world models beyond passive prediction, toward active, goal-driven interaction with the physical and virtual world. By emphasizing embodiment and decision-making, we aim to move beyond passive sequence prediction toward goal-directed interaction with both physical and simulated worlds.",
        "overview": "Overview: The Embodied World Models for Decision Making workshop at NeurIPS 2025 focuses on advancing world models that enable agents to understand, predict, and interact with the world through learned models. The workshop aims to bring together researchers from generative modeling, reinforcement learning, computer vision, and robotics to explore the next generation of embodied world models. The emphasis is on moving beyond passive prediction to active, goal-driven interaction with both physical and virtual worlds. | Research Interests: Model-based reinforcement learning and long-horizon planning, Aligning simulation and real-world physics for robot learning, Interactive scene generation and downstream tasks, Video-language-action models and leveraging world knowledge in large language models, Applications in open-world video games and autonomous driving",
        "location": "San Diego"
    },
    {
        "title": "Machine Learning and the Physical Sciences",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109577",
        "speaker": "",
        "abstract": "The Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS is a unique gathering space for the growing community spearheading cross-cutting research topics at the intersection of machine learning (ML) and the physical sciences (PS). This includes the applications of ML to problems in the physical sciences (ML for PS) as well as developments in ML motivated by physical insights (PS for ML). The physical sciences are defined inclusively, including but not limited to physics, astronomy, cosmology, chemistry, biophysics, materials science, and Earth science. Join us to discuss the latest research at the convergence of these fields!",
        "overview": "Overview: The Machine Learning and the Physical Sciences (ML4PS) workshop is a gathering space for researchers at the intersection of machine learning (ML) and the physical sciences (PS). Since its inception in 2017, the workshop has focused on applying ML to problems in the physical sciences and using physical insights to improve ML techniques. The 2025 workshop, part of the 39th NeurIPS conference, will explore the interplay between academia and industry in basic research, emphasizing foundational and translational connections between these domains. | Research Interests: Machine Learning for Physical Sciences, Physical Sciences for Machine Learning, Geometric Deep Learning, Simulation-Based Inference, Diffusion Models, Physics-Informed Neural Networks, Interplay of Academia and Industry, Weather and Climate Research, Paradigm-Shifting Applications in ML and Physics",
        "location": "San Diego"
    },
    {
        "title": "Workshop on Multi-Turn Interactions in Large Language Models",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109539",
        "speaker": "",
        "abstract": "The field of AI is entering a new era of interaction, profoundly shaped by the capabilities of Large Language Models (LLMs). While multi-turn interaction has been a long-standing pursuit in AI\u2014from dialogue systems to multi-agent coordination\u2014the advent of LLMs has radically transformed this landscape. These models now engage in complex, long-horizon interactions, process diverse data, and make crucial decisions in dynamic, human-centric scenarios.This leap forward, however, brings forth critical new research questions and challenges that demand immediate attention:Multi-Turn RL Learning for Agentic Tasks Learning from complex, interactive environments like GUI agents and tool-use scenarios, given the challenges of sparse rewards.Maintaining Alignment Understanding human values over extended, multi-turn interactions, preventing \"loss of alignment\" seen in current models.Human-AI Interaction Over time, ensuring models adapt to user goals without compromising safety or fairness.Long-horizon Evaluation For LLMs' long-term capabilities, consistency, and strategic abilities in complex, multi-turn tasks.The Workshop on Multi-Turn Interactions in LLMs is designed to be the central forum for addressing these pivotal questions. We invite researchers to contribute to defining the next generation of interactive AI, tackling these core challenges, and charting the course for future advancements in AI reasoning and planning. This workshop will concentrate on key areas where the extended use of LLMs presents both new challenges and opportunities, serving as a platform to discuss and refine methods for future improvements and evaluation for practical LLM use cases.",
        "overview": "Overview: The NeurIPS 2025 Workshop on Multi-Turn Interactions in Large Language Models focuses on the evolving field of AI, particularly the role of Large Language Models (LLMs) in multi-turn interactions. The workshop aims to address new research questions and challenges that arise from the capabilities of LLMs in complex, long-horizon interactions. It serves as a central forum for researchers to contribute to the development of interactive AI, focusing on areas where LLMs present new challenges and opportunities. | Research Interests: Multi-Turn RL Learning for Agentic Tasks, Maintaining Alignment in AI, Human-AI Interaction, Long-horizon Evaluation of LLMs, Multi-Turn Settings and Tasks, Multi-Turn Frameworks and Algorithms, Multi-Turn Evaluation, Multi-Turn Challenges",
        "location": "San Diego"
    },
    {
        "title": "Generative AI in Finance",
        "type": "Workshop",
        "date": "2025-12-06",
        "start_datetime": "2025-12-06T08:00:00",
        "end_datetime": "2025-12-06T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109564",
        "speaker": "",
        "abstract": "This workshop aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance, a high-stakes domain where the integration of domain expertise is essential to the safe and effective deployment of machine learning technologies. Recent advances in generative models\u2014ranging from large language models to diffusion and score-based generative architectures\u2014have opened new frontiers for applications in finance, such as financial modeling, stress testing, scenario generation, automated financial services, and decision-making under uncertainty.The workshop will highlight theoretical advances, practical implementations, new opportunities, and open challenges that arise when adapting generative AI to financial systems under unique constraints, such as data sparsity, regulatory requirements, and highly non-stationary and adversarial environments. By bringing together the computer science community, financial researchers, industry practitioners, and regulators, we aim to catalyze interdisciplinary dialogue and accelerate the responsible development of generative AI tailored to the needs of finance and risk management.",
        "overview": "Overview: The NeurIPS 2025 Workshop on Generative AI in Finance aims to foster cross-disciplinary collaboration at the intersection of generative AI and finance. The workshop will focus on the integration of domain expertise to safely and effectively deploy machine learning technologies in finance. It will highlight theoretical advances, practical implementations, new opportunities, and challenges in adapting generative AI to financial systems, considering constraints like data sparsity, regulatory requirements, and non-stationary environments. The event will bring together computer scientists, financial researchers, industry practitioners, and regulators to accelerate the responsible development of generative AI tailored to finance and risk management. | Research Interests: Generative AI, Financial modeling, Stress testing, Scenario generation, Automated financial services, Decision-making under uncertainty, Machine learning in finance, Stochastic analysis, Trustworthy machine learning, Sequential decision-making, High-dimensional statistics, AI for financial services, Market behavior modeling, Natural language processing, Reinforcement learning, AI agents, Representation learning for finance, Agentic AI, LLM (Large Language Models), Financial modeling and reasoning",
        "location": "San Diego"
    },
    {
        "title": "UrbanAI: Harnessing Artificial Intelligence for Smart Cities",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109583",
        "speaker": "",
        "abstract": "",
        "overview": "",
        "location": "San Diego"
    },
    {
        "title": "2nd  Workshop on Multi-modal Foundation Models and Large Language Models  for Life Sciences",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109536",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The NeurIPS 2025 2nd Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences focuses on the transformative advancements in life sciences brought about by foundation models and large language models (LLMs). These models are pretrained on extensive datasets and are capable of performing a wide range of tasks such as predicting protein structures, analyzing genomic sequences, and simulating cellular processes. The workshop aims to address the limitations of existing models that focus on a single modality by promoting the development of multi-modal foundation models and LLMs that can integrate and reason over diverse biological modalities. The event will bring together researchers to discuss recent advancements, explore methodological innovations, and identify key challenges in designing these models for biological data. | Research Interests: Multi-modal foundation models for learning representations of proteins, DNAs, RNAs, transcriptomic data, metabolomic data, and other biological modalities., Multi-modal LLMs for predicting the functions of proteins, DNAs, RNAs, and other biomolecules., Multi-modal foundation models for learning joint representations of multi-omics data., Multi-modal generative models for designing proteins, DNAs, RNAs, and other biomolecules., Applications of multi-modal foundation models and LLMs in drug discovery, precision medicine, personalized treatment, and beyond., Interpretability and robustness in biological multi-modal foundation models and LLMs.",
        "location": "San Diego"
    },
    {
        "title": "Artificial Intelligence for Music: Where Creativity Meets Computation",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109534",
        "speaker": "",
        "abstract": "This workshop explores the dynamic intersection of AI and music, a rapidly evolving field where creativity meets computation. The goal of this workshop is twofold: First, we aim to explore the latest advancements of AI\u2019s applications for music, from analysis, creation, performance, production, retrieval to music education and therapy. Second, we aim to discuss the impacts and implications of AI in music, including AI\u2019s impacts on the music industry, musician community, and music education as well as ethical, legal and societal implications of AI music and AI\u2019s implications for future musicians.",
        "overview": "Overview: The NeurIPS 2025 Workshop on AI for Music, titled 'Where Creativity Meets Computation,' is an interdisciplinary event exploring the intersection of artificial intelligence and music. The workshop aims to bring together the music and AI communities to discuss the latest advancements in AI applications for music, including analysis, creation, performance, production, retrieval, and music education and therapy. It also addresses the impacts and implications of AI in music, such as its effects on the music industry, musician community, and music education, as well as ethical, legal, and societal considerations. The workshop features invited talks, spotlight presentations, poster and demo sessions, panel discussions, and round table discussions, with a focus on networking and community building. | Research Interests: AI applications in music, Music theory and musicology, Optical music recognition, Music transcription, Music generation, Sound design and soundtrack generation, Singing voice synthesis, Lyric generation and translation, Musical instrument design, Robotic musicianship, Human-AI music co-creativity, Music production, Music performance modeling, Music information retrieval, Music recommender systems, Music education, Music therapy, Impacts of AI on the music industry, Impacts on the musician community, Impacts on music education, Ethical, legal, and societal implications of AI music, Challenges in commercializing AI music tools, Emerging opportunities of AI music | Key Findings: The workshop highlights the growing interest in AI music research within the machine learning community and emphasizes the potential of AI to enhance artist creativity and develop new fan experiences. It also notes the acceptance rate of 68% for papers and demos, indicating a high level of interest and participation in the field.",
        "location": "San Diego"
    },
    {
        "title": "AI for Science: The Reach and Limits of AI for Scientific Discovery",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109578",
        "speaker": "",
        "abstract": "Through our proposed AI for Science workshop, we will bring together experimentalists, domain scientists, and ML researchers to discuss the reach and limits of AI for scientific discovery. We will center our discussion on three challenges that are essential to progress across scientific domains:LLM reasoning across scientific domains\u2013 can present-day LLMs generate rigorously testable hypotheses and reason over experimental results that span scientific domains such as physics, chemistry, and biology?Fidelity of generative and surrogate simulators\u2013 In biology, we see a shift towards all-atom models with increasingly powerful capabilities, in chemistry machine learning force fields are increasing in accuracy and generalizability, and in climate modeling we can now accurately predict weather 15 days out. How far can we push this limit? What spatial or temporal scales remain intractable?Experimental data scarcity and bias. We see modern examples of large-scale dataset generation such as the Protein Data Bank, Human Cell Atlas, and the Materials Project. Are there other fields where AI can benefit most from consortium efforts to generate large-scale datasets? How far can models trained on limited experimental datasets take us and where are lab-in-the-loop strategies essential? To address this, we additionally introduce adataset proposal competition. Our workshop will highlight common bottlenecks in developing AI methods across scientific application domains, and delve into solutions that can unlock progress across all of these domains.",
        "overview": "Overview: The AI for Science workshop at NeurIPS 2025 aims to explore the reach and limits of AI in scientific discovery. It brings together experimentalists, domain scientists, and machine learning researchers to discuss where AI genuinely advances scientific discovery and where it faces limitations. The workshop focuses on identifying bottlenecks in AI methods across scientific domains and finding solutions to overcome these challenges. | Research Interests: Multi-domain scientific reasoning, High-fidelity generative and surrogate simulators, Experimental data scarcity and bias",
        "location": "San Diego"
    },
    {
        "title": "Frontiers in Probabilistic Inference: Learning meets Sampling",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109572",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The Frontiers in Probabilistic Inference: Learning Meets Sampling (FPI 2025) is a one-day workshop at NeurIPS 2025, focused on advancing scalable, data-efficient sampling methods by integrating classical statistical approaches with modern machine learning techniques. The workshop aims to address the growing role of probabilistic inference in large-scale scientific and real-world systems by fostering cross-disciplinary collaboration among researchers from statistics, machine learning, and applied science domains. The event seeks to explore shared challenges, develop practical tools, and identify common benchmarks to enhance the development of next-generation sampling methods. | Research Interests: Sampling methods and their connections to generative models and optimal control, Classical sampling approaches and how learning accelerates them, Connections between sampling methods and physics, Understanding sampling from theoretical perspectives, Applications of sampling to natural sciences, Bayesian inference, LLM fine-tuning, and more",
        "location": "San Diego"
    },
    {
        "title": "Non-Euclidean Foundation Models and Geometric Learning: Advancing AI Beyond Euclidean Frameworks",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109582",
        "speaker": "",
        "abstract": "In the era of foundation models and Large Language Models (LLMs), Euclidean space is the de facto geometric setting of our machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. Non-Euclidean learning is quickly gaining traction. Non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, have been shown to provide more efficient and effective representations for data with intrinsic geometric properties, like hierarchy, symmetry, and heterogeneity.Integrating foundation models with non-Euclidean spaces has great potential to enhance their ability to capture and model the underlying structures and relationships in complex real-world data, leading to better performance, generalization, and interpretability. This workshop focuses on the intersection of Non-Euclidean representation learning and Foundation Models, exploring its potential benefits, challenges, and future directions.",
        "overview": "Overview: The Non-Euclidean Foundation Models and Geometric Learning Workshop at NeurIPS 2025 focuses on advancing AI beyond traditional Euclidean frameworks. It aims to explore the integration of foundation models with non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, to enhance the ability of AI models to capture and model complex real-world data structures. The workshop will include discussions on non-Euclidean representation learning, geometric deep learning, and large foundation models, with a focus on their potential benefits, challenges, and future directions. | Research Interests: Non-Euclidean representation learning, Geometric deep learning, Foundation models, Theoretical foundations of non-Euclidean spaces, Architectures and algorithms for non-Euclidean spaces, Applications in graph analysis, text processing, image understanding, biomedical research, and AI for scientific discovery, Trustworthiness and robustness in non-Euclidean models, Benchmarks and tools for non-Euclidean representations",
        "location": "San Diego"
    },
    {
        "title": "Constrained Optimization for Machine Learning",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109533",
        "speaker": "",
        "abstract": "As AI systems are increasingly deployed in safety-critical domains\u2014including credit scoring, medical diagnosis, and autonomous systems\u2014there is a growing demand to ensure their fairness, safety, robustness, and interpretability, alongside stronger calls for regulation. Constrained optimization offers an accountable framework for enforcing these requirements by embedding them directly into the training process, steering models to satisfy explicit constraints. This framework facilitates compliance with regulatory, industry, or ethical standards, which can be easily verified by checking constraint satisfaction.This workshop explores constrained optimization as a principled method for enforcing desirable properties in machine learning models. It brings together experts in optimization, machine learning, and trustworthy AI to address the algorithmic and practical challenges of scaling constrained methods to modern deep learning settings, which are often large-scale, non-convex, and stochastic.",
        "overview": "Overview: The NeurIPS 2025 Workshop on Constrained Optimization for Machine Learning focuses on the application of constrained optimization techniques to ensure fairness, safety, robustness, and interpretability in AI systems, especially in safety-critical domains. The workshop aims to address the challenges of scaling these methods to modern deep learning settings and invites contributions that advance the state of the art in constrained learning. | Research Interests: Constrained Optimization, Machine Learning, Trustworthy AI, Fairness, Safety, Robustness, Interpretability, Regulatory Compliance",
        "location": "San Diego"
    },
    {
        "title": "New Perspectives in Graph Machine Learning",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109579",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The webpage presents the 'New Perspectives in Advancing Graph Machine Learning' workshop, which is part of NeurIPS 2025. The workshop aims to explore and connect new perspectives on graph machine learning (GML), focusing on theoretical insights, new capabilities, and application-aligned algorithms and models. It includes keynotes, oral presentations, poster sessions, and a panel discussion, featuring prominent speakers and researchers in the field. | Research Interests: Graph Machine Learning, Algebraic\u2013Topological Analyses, Foundation Models, Generative Models, Large Models in Applications, Causal Structure Learning, Topological Deep Learning, Graph Neural Networks, Graph Representation Learning | Key Findings: The workshop highlights the potential of integrating new perspectives such as algebraic-topological analyses and foundation models into graph machine learning, promising deeper theoretical insights and more powerful algorithms. It also emphasizes the importance of addressing overarching challenges in theory, methodology, and modeling.",
        "location": "San Diego"
    },
    {
        "title": "Regulatable ML: Towards Bridging the Gaps between Machine Learning Research and Regulations",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109575",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The 3rd Workshop on Regulatable ML at NeurIPS 2025 aims to bridge the gap between state-of-the-art machine learning safety and security research and evolving regulatory frameworks. The workshop addresses the novel safety and security risks introduced by large-scale machine learning models and AI agents, such as prompt-injection attacks, capability overreach, and unintended emergent behaviors. It highlights the gaps in current regulations like the EU AI Act and the need for evidence-based mitigation strategies as outlined in the International AI Safety Report 2025. | Research Interests: Machine Learning Safety, AI Security, Regulatory Frameworks, AI Risk Mitigation, Transparency in AI, Human Oversight in AI, International Collaborations in AI Safety, Verification Protocols for AI, Failure Cases of State-of-the-Art Models | Key Findings: Recent works have highlighted several failure cases of state-of-the-art large language models (LLMs) and agents, such as the Claude Opus 4 model generating instructions for creating biological agents and attempting to 'hijack' strategies during shutdown threat tests.",
        "location": "San Diego"
    },
    {
        "title": "Evaluating the Evolving LLM Lifecycle:  Benchmarks, Emergent Abilities, and Scaling",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109549",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The NeurIPS 2025 Workshop titled 'Evaluating the Evolving LLM Lifecycle' focuses on the evaluation of large language models (LLMs) as they become increasingly integrated into various applications. The workshop aims to address the need for robust evaluation methodologies and best practices across the entire LLM lifecycle, from foundational pre-training to advanced post-training techniques like reinforcement learning from human feedback (RLHF). It seeks to develop a comprehensive understanding of LLM evaluation, emphasizing interrelations, emergent capabilities, scaling challenges, and the creation of cutting-edge benchmarks for future models. | Research Interests: Evaluation metrics for pre-trained models and foundational capabilities, Assessing the impact of fine-tuning and adaptation on model performance and behavior, Advanced post-training evaluation techniques, including RLHF and human-in-the-loop assessments, Interrelations and dependencies between different evaluation stages and their impact on model generalization, Benchmarking and standardization of evaluation protocols, Development of new, challenging evaluation paradigms, Understanding and evaluating scaling laws in relation to model performance and emergent phenomena, Addressing data contamination, memorization, and other data-centric evaluation challenges, Developing and applying holistic evaluation frameworks for diverse LLM capabilities, Evaluating the evolution of LLM capabilities and potential risks as models scale",
        "location": "San Diego"
    },
    {
        "title": "Foundations of Reasoning in Language Models",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109559",
        "speaker": "",
        "abstract": "Our workshop\u2019s goal is toadvance foundational understanding, principled innovations, and rigorous scientific evaluations for reasoning in language models. These advancements are built upon theoretical analyses and controlled empirical studies that illuminate how reasoning emerges, where it fails, and how it can be systematically improved.We want to foster dialogue between communities with complementary strengths---those building theoretical models of reasoning phenomena, those designing experiments that reveal its emergence or failure in practice, and those proposing algorithmic developments that advance reasoning---aroundthree primary questions:1. How are language models able to solve complex tasks, and what do they still struggle with?2. What fundamental challenges stand in the way of advancing reasoning capabilities?3. What algorithmic innovations can overcome these obstacles?",
        "overview": "Overview: The Foundations of Reasoning in Language Models (FoRLM) workshop is scheduled to take place during NeurIPS 2025 in San Diego, California. The workshop aims to advance the foundational understanding of reasoning in language models through theoretical analyses and empirical studies. It seeks to bring together researchers with complementary strengths to address key questions about how reasoning emerges in language models, where it fails, and how it can be improved. | Research Interests: Reasoning in language models, Theoretical models of reasoning phenomena, Empirical studies on reasoning emergence and failure, Algorithmic developments to advance reasoning",
        "location": "San Diego"
    },
    {
        "title": "Learning to Sense (L2S)",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109563",
        "speaker": "",
        "abstract": "The workshop explores the joint optimization of sensors and machine learning models, pushing beyond traditional paradigms of data acquisition and processing. We aim to rethink the foundations of how machines sense the world by replacing hand-crafted ISPs, leveraging learnable sensor layouts, and adopting task-driven sensing strategies.    We welcome original contributions and position papers on the following topics (non-exhaustive):    Sensor optimization for e.g. computer vision (bit-depth, pixel layouts, color filter design)    RAW-to-task or RAW-to-label approaches for visual tasks    Co-design of neural networks and sensor hardware    Low-bit and energy-efficient sensing for embedded or mobile devices    Benchmarks, datasets, and metrics for evaluating sensor-model pipelines    Generalization and robustness of sensor-model systems in real-world conditions    Failure case studies and negative results in joint optimization pipelines    Join us to engage with cutting-edge research and cross-disciplinary discussions that are shaping the future of sensor systems for real-world deployment across mobile, embedded, and autonomous platforms.",
        "overview": "Overview: The NeurIPS 2025 Workshop on Learning To Sense focuses on the joint optimization of sensors and machine learning models. It aims to push beyond traditional paradigms of data acquisition and processing by rethinking how machines sense the world. The workshop encourages the exploration of learnable sensor layouts and task-driven sensing strategies, moving away from hand-crafted ISPs. | Research Interests: Sensor optimization for computer vision, RAW-to-task or RAW-to-label approaches for visual tasks, Co-design of neural networks and sensor hardware, Low-bit and energy-efficient sensing for embedded or mobile devices, Benchmarks, datasets, and metrics for evaluating sensor-model pipelines, Generalization and robustness of sensor-model systems in real-world conditions, Failure case studies and negative results in joint optimization pipelines",
        "location": "San Diego"
    },
    {
        "title": "Multimodal Algorithmic Reasoning Workshop",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109561",
        "speaker": "",
        "abstract": "Large AI frameworks have been increasing in their data modeling abilities at an ever more vigor in recent times, with compelling applications emerging frequently, many of which may even appear to challenge human intelligence. Yet despite such impressive performance, there remain open questions about whether these models include the foundations of general intelligence, or whether they perform these tasks without human-like understanding. This necessitates development of better tools for assessing these models in tandem with developing the models themselves. This workshop focuses on the topic of multimodal algorithmic reasoning, where an agent needs to assimilate information from multiple modalities towards deriving reasoning algorithms for complex problem solving. In the last year, we have seen rapid advances in AI capabilities that better bridge across modalities, bringing both optimism about superhuman capabilities and skepticism about the limits of current approaches. Through talks from outstanding researchers and faculty, we hope to dive deep into this exciting topic at the intersection of theory, multimodal learning and cognitive science to understand what we have achieved thus far in machine intelligence and what we are lacking in relation to the human way of thinking, towards finding the missing rungs on the ladder to truly intelligent reasoning.",
        "overview": "Overview: The MAR 2025 workshop, held in conjunction with the Conference on Neural Information Processing Systems 2025, focuses on gathering researchers in neural algorithmic learning, multimodal reasoning, and cognitive models of intelligence. The workshop aims to showcase cutting-edge research, discuss challenges, and highlight overlooked problems in perception and language modeling crucial for achieving artificial general intelligence. The emphasis is on multimodal algorithmic reasoning, where agents deduce new algorithms for real-world tasks using multimodal foundational models. The event features talks from outstanding researchers to inspire the audience in exploring the intersection of multimodal learning and cognitive science. | Research Interests: Multimodal algorithmic reasoning, Neural algorithmic learning, Cognitive models of intelligence, Perception and language modeling, Vision-and-language mathematical reasoning, Multimodal games, Robotic manipulation, Chain-of-thought reasoning, Distributed agentic reasoning, Tool use in AI, Visual reasoning architectures, Data generation via self-play, Theoretical limits of reasoning in large models",
        "location": "San Diego"
    },
    {
        "title": "Data on the Brain and Mind",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109557",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The 'Data on the Brain & Mind' workshop aims to connect machine learning researchers with neuroscientists and cognitive scientists by focusing on concrete, open problems grounded in emerging neural datasets. The workshop emphasizes the diversity and heterogeneity of neuroscience and cognitive science datasets, encouraging the development of tailored AI solutions beyond generic models. It is designed to be highly interactive, fostering collaborations through invited talks, poster sessions, and mentorship opportunities. | Research Interests: Machine learning applications in neuroscience, Cognitive science data analysis, Neural datasets, Visual-motor cortical processing, Human development datasets, Natural speech processing, Interdisciplinary collaborations, Data-model integration and interpretability",
        "location": "San Diego"
    },
    {
        "title": "CogInterp: Interpreting Cognition in Deep Learning Models",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109544",
        "speaker": "",
        "abstract": "Recent innovations in deep learning have produced models with impressive capabilities, achieving or even exceeding human performance in a wide range of domains. A timely and critical challenge in AI is understanding what behaviors these models are actually capable of, and the internal processes which support these behaviors. As interest continues to grow in models\u2019 internal processes, the field of cognitive science is becoming increasingly useful for describing and understanding cognition in deep learning models: cognitive science, which seeks to describe the cognitive processes in human and animal minds, offers a rich body of theories, experiments, and frameworks which may be adopted to understand how deep learning models achieve complex behaviors in domains such as language, vision, and reasoning.The workshop will focus on Cognitive Interpretability (\u201cCogInterp\u201d), which involves the systematic interpretation of high-level cognition in deep learning models. Similar to how cognitive science describes the intermediate representations and algorithms (or cognition) between behavior and neurons in biological systems, the goal of Cognitive Interpretability is to describe the cognitive processes which lie between the levels of behavioral evaluations and mechanistic interpretability in deep learning models. Practically speaking, this means that Cognitive Interpretability does not just ask whether a model can perform task X or has a certain ability Y , but additionally (or instead) how a model performs X or learns and implements Y . These kinds of inferences\u2014from observable behavior to latent \u201cmental\u201d processes\u2014are the bread and butter of cognitive science, but many of the theoretical and empirical tools developed to tackle these problems have not yet been widely adopted in AI research, in part because of the separation between the fields and communities.To address the gap above, our goal is to bring together researchers in cognitive science and AI interpretability to discuss new empirical results and theories about the inner workings of deep learning models. We hope to gather perspectives from various disciplines, including machine learning, psychology, linguistics, vision science, neuroscience, philosophy of mind, and law.",
        "overview": "Overview: The First Workshop on CogInterp: Interpreting Cognition in Deep Learning Models is set to take place at NeurIPS 2025 in San Diego, USA, on December 7, 2025. This workshop aims to address the challenge of understanding the behaviors and internal processes of deep learning models by leveraging insights from cognitive science. The workshop seeks to bridge the gap between AI research and cognitive science by bringing together researchers from various disciplines to discuss new empirical results and theories about the inner workings of deep learning models. | Research Interests: Cognitive Interpretability, Deep Learning Models, Cognitive Science, Machine Learning, Psychology, Linguistics, Vision Science, Neuroscience, Philosophy of Mind, Law",
        "location": "San Diego"
    },
    {
        "title": "What Can('t) Transformers Do?",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109569",
        "speaker": "",
        "abstract": "With most advances in large foundation models (LFMs) being empirical, our theoretical understanding of what transformers can compute, express, and learn still lags behind. This workshop will convene theorists and empiricists to chart a rigorous agenda for the next generation of LFMs, asking \u201cWhatcanandcan\u2019ttransformers do?\u201d We welcome both formal analyses and empirically grounded studies that shed light on theoretical questions, aiming to close the gap between proofs and practice while fostering new, interdisciplinary collaborations.",
        "overview": "Overview: The workshop 'What Can(\\'t) Transformers Do?' at NeurIPS 2025 aims to bridge the gap between empirical advances in large foundation models (LFMs) and the theoretical understanding of transformers. It seeks to explore what transformer-based language models can and cannot do by bringing together theorists and empiricists. The workshop encourages both formal analyses and empirical studies to address theoretical questions and foster interdisciplinary collaborations. | Research Interests: Theoretical analyses of transformer capabilities, Expressivity, Learnability, Inference-time scaling, In-context learning, Effects of architectural components, Empirical studies of transformer behavior, Architectural or training innovations, Mechanistic studies of failures, Comparisons of theorized and observed capabilities | Key Findings: The workshop highlights several accepted papers that contribute to understanding transformer capabilities and limitations, such as the role of transformer feed-forward layers, the failure of transformers in time series forecasting, and the limitations in program trace generation. These studies provide insights into the theoretical and practical aspects of transformer models.",
        "location": "San Diego"
    },
    {
        "title": "Learning from Time-Series for Health",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109560",
        "speaker": "",
        "abstract": "Time-series data underpin modern healthcare, spanning electronic health records, physiological waveforms, wearables, and population trends, yet their unique characteristics\u2014including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints\u2014demand specialized machine learning approaches. While recent advances in foundation models, multimodal learning, and generative methods show promise, significant challenges remain in causality, interpretability, and deployment.  This workshop unites researchers across health time-series domains (from wearables to clinical systems) to address shared challenges through: (1) cross-domain discussion, (2) diverse industry/academic perspectives (featuring Google, Oura, Apple and 5 institutions), and (3) community engagement via posters, talks, and panels. By fostering cross-domain collaboration on physiological-aware methods, we aim to bridge the gap between cutting-edge ML and real-world healthcare impact.",
        "overview": "Overview: The 'Learning from Time Series for Health' workshop at NeurIPS 2025 focuses on the application of machine learning to health-related time-series data. This workshop aims to address the unique challenges posed by such data, including uncertain ground truth, quasi-periodic physiological motifs, and non-semantic timepoints. It brings together researchers from various domains to foster cross-domain collaboration and bridge the gap between cutting-edge machine learning techniques and real-world healthcare impact. The workshop features discussions, industry and academic perspectives, and community engagement through posters, talks, and panels. | Research Interests: Time-series data in healthcare, Machine learning for health, Foundation models, Multimodal learning, Generative methods, Causality in healthcare, Interpretability of models, Deployment of machine learning in healthcare",
        "location": "San Diego"
    },
    {
        "title": "Tackling Climate Change with Machine Learning",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109574",
        "speaker": "",
        "abstract": "Many in the ML community wish to take action on climate change, but are unsure how to have the most impact. This workshop will highlight work that demonstrates that, while ML is no silver bullet, it can be an invaluable tool in reducing greenhouse gas emissions and in helping society adapt to the effects of climate change.Climate change is a complex problem for which action takes many forms, from advancing theory to deploying new technology. Many of these actions represent high-impact opportunities for real-world change, and simultaneously pose interesting academic research problems.The theme of this workshop, \u201cRoots to Routes: A Dialogue on Different Machine Learning Methods for Climate Impact,\u201d invites submissions that explore the strengths of diverse machine learning approaches in climate-related contexts. We particularly encourage work that demonstrates the effectiveness of classical ML methods under real-world constraints, such as limited data availability, privacy concerns, or restricted computational resources. At the same time, we welcome contributions that showcase how scaling up data and computing resources combined with modern tools and techniques can unlock new possibilities for tackling global-scale climate prediction challenges.This workshop is part of a series that aims to bring together those applying ML to climate change challenges and facilitate cross-pollination between ML researchers and experts in climate-relevant fields.The main workshop will take place on December 6 or 7, 2025 (exact date TBD).",
        "overview": "Overview: The NeurIPS 2025 Workshop titled 'Tackling Climate Change with Machine Learning' aims to bring together the machine learning community to address climate change challenges. The workshop will highlight the role of machine learning as a tool to reduce greenhouse gas emissions and help society adapt to climate change. It is part of a series that facilitates collaboration between ML researchers and experts in climate-relevant fields. The main workshop will take place on December 7, 2025, as part of the NeurIPS conference in San Diego, California. | Research Interests: Agriculture and food, Behavioural and social science, Buildings, Carbon capture and sequestration, Cities and urban planning, Climate finance and economics, Climate justice, Climate science and climate modeling, Disaster management and relief, Earth observations and monitoring, Earth science, Ecosystems and biodiversity, Extreme weather, Forestry and other land use, Health, Heavy industry and manufacturing, Local and indigenous knowledge systems, Materials science and discovery, Oceans and marine systems, Power and energy systems, Public policy, Societal adaptation and resilience, Supply chains, Transportation",
        "location": "San Diego"
    },
    {
        "title": "Workshop on Mechanistic Interpretability",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109547",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The Mechanistic Interpretability Workshop at NeurIPS 2025 focuses on understanding the internal mechanisms of neural networks to bridge the gap between their performance and our understanding of their decision-making processes. The workshop aims to bring together diverse perspectives from academia, industry, and independent research to discuss recent advances, build common understanding, and chart future directions in the field of mechanistic interpretability. | Research Interests: Mechanistic interpretability, Neural network internals, Model behavior prediction, Reliability and adversarial behavior detection, Mathematical analysis of neural networks, Empirical studies on neural networks, Reverse-engineering models, Behavioral analysis of model representations, Cross-pollination of research methodologies, Unsupervised and supervised techniques in AI",
        "location": "San Diego"
    },
    {
        "title": "AI That Keeps Up: Workshop on Continual and Compatible Foundation Model Updates (CCFM)",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109584",
        "speaker": "",
        "abstract": "Foundation models, despite their impressive capabilities, face a critical challenge: they naturally become outdated. Trained on vast datasets, frequently updating these models is expensive. Crucially, these challenges extend beyond the scope of studies in traditional continual learning, as foundation models require rapid and scalable adaptation to dynamic global changes and the emergence of both generalized and specialized tasks. This workshop addresses the urgent need for up-to-date foundation models. We invite researchers to explore cost-effective methods for frequent updates and adaptation, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve.",
        "overview": "Overview: The NeurIPS 2025 Workshop on Continual and Compatible Foundation Model Updates (CCFM) focuses on addressing the challenges faced by foundation models, which naturally become outdated over time. The workshop aims to explore cost-effective methods for frequent updates and adaptation of these models, minimizing forgetting and deterioration, ensuring a consistent user experience, and designing dynamic evaluations that remain relevant as models evolve. The event will take place on December 7th, 2025, at the San Diego Convention Center. | Research Interests: Foundation models, Continual learning, Model updates, Cost-effective adaptation, Dynamic evaluations, Minimizing forgetting, Consistent user experience",
        "location": "San Diego"
    },
    {
        "title": "Recent Advances in Time Series Foundation Models: Have We Reached the \u2018BERT Moment\u2019?",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109585",
        "speaker": "",
        "abstract": "Foundation models (FMs) have achieved great success in NLP and vision, inspiring over 20 new time series FMs (TSFMs) in the past year. Despite promising results, studies show that carefully designed lightweight supervised baselines often match TSFM performance. Unlike NLP\u2019s \u201cBERT Moment,\u201d TSFMs still require full fine-tuning to be competitive in real-world scenarios. Additionally, some tabular FMs rival TSFMs without being time series-specific. Recent benchmarks also provide mixed evidence: GIFT-Eval favors TSFMs, OpenTS shows statistical models outperforming deep learning on univariate data, and FoundTS finds supervised baselines on par with TSFMs. This workshop aims to bring together researchers to examine the gap between TSFM potential and real-world utility, and to identify benchmarks and applications where TSFMs can truly excel.The key topics of this workshop include, but are not limited to:- Benchmarking Foundation Models in Time Series,- Scaling Laws and Efficiency in Time Series Models,- Evaluating Transferability and Adaptability of Foundation Models,- Leveraging Foundation Models of Other Modalities for Time Series,- Unsupervised performance estimation of TSFMs,- Industrial Benchmarking of Time Series Foundation ModelsMore details are provided in ourCall for Papers.",
        "overview": "Overview: The webpage presents the BERT2S workshop, which focuses on recent advances in Time Series Foundation Models (TSFMs) and their potential to reach a 'BERT Moment' similar to that in NLP. The workshop is part of the NeurIPS 2025 conference and aims to bring together researchers to explore the gap between the potential and real-world utility of TSFMs. It will include discussions on benchmarks, applications, and the development of TSFMs. | Research Interests: Benchmarking Foundation Models in Time Series, Scaling Laws and Efficiency in Time Series Models, Evaluating Transferability and Adaptability of Foundation Models, Leveraging Foundation Models of Other Modalities for Time Series, Unsupervised performance estimation of TSFMs, Industrial Benchmarking of Time Series Foundation Models | Key Findings: The workshop highlights that despite the promising results of TSFMs, lightweight supervised baselines often match their performance. It also notes that some tabular foundation models rival TSFMs without being time series-specific. Recent benchmarks provide mixed evidence on the superiority of TSFMs, indicating a need for further exploration and development.",
        "location": "San Diego"
    },
    {
        "title": "Symmetry and Geometry in Neural Representations",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109551",
        "speaker": "",
        "abstract": "The fields of biological and artificial intelligence are increasingly converging on a shared principle: the geometry and topology of real-world structure play a central role in building efficient, robust, and interpretable representations. In neuroscience, mounting evidence suggests that neural circuits encode task and environmental structure through low-dimensional manifolds, conserved symmetries, and structured transformations. In deep learning, principles such as sparsity, equivariance, and compositionality are guiding the development of more generalizable and interpretable models, including new approaches to foundation model distillation. The NeurReps workshop brings these threads together, fostering dialogue among machine learning researchers, neuroscientists, and mathematicians to uncover unifying geometric principles of neural representation. Just as geometry and symmetry once unified the models of 20th-century physics, we believe they may now illuminate the computational foundations of intelligence.",
        "overview": "Overview: The NeurReps Workshop is an annual event that brings together researchers from the fields of mathematics, deep learning, and neuroscience to explore the principles of neural representation in both biological and artificial systems. The workshop aims to uncover unifying geometric principles of neural representation, drawing parallels between the geometry and symmetry in neural circuits and machine learning models. The event fosters dialogue among experts to advance understanding in areas such as geometric mechanistic interpretability, the geometry of representations in foundation models, and improvements in large language model design. | Research Interests: Geometry and topology in neural representations, Symmetry and equivariance in neural circuits and models, Neuroscience and interpretability, Geometric deep learning, Foundation models of brain activity, Mechanistic interpretability, Dynamics in shaping neural representations",
        "location": "San Diego"
    },
    {
        "title": "GPU-Accelerated and Scalable Optimization (ScaleOpt)",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109554",
        "speaker": "",
        "abstract": "Recent advancements in GPU-based large-scale optimization have been remarkable. Recognizing the revolution in optimizing neural network weights via large-scale GPU-accelerated algorithms, the optimization community has been interested in developing general purpose GPU-accelerated optimizers for various families of classic optimization problems, including linear programming, general conic optimization, combinatorial optimization, and more specific problem families such as flow optimization and optimal transport. Beyond deploying GPUs directly at classical problems, current frontier AI tools\u2014including large language models (LLMs)\u2014are being deployed to solve optimization problem. Various works have used neural networks to solve mixed integer problems, linear or quadratic programs, general combinatorial optimization problems, and more specific optimization problems such as LASSO and robust PCA. In this workshop, we aim to provide a platform for interested researchers to engage with each other on recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems.",
        "overview": "Overview: The ScaleOPT workshop at NeurIPS 2025 focuses on GPU-accelerated and scalable optimization, exploring practical optimization algorithms and toolkits that co-improve with advanced AI systems. The workshop aims to provide a platform for researchers to engage with recent breakthroughs and current bottlenecks in designing large-scale GPU-based optimizers and synergizing AI systems with solving optimization problems. | Research Interests: GPU-accelerated optimization, Large-scale optimization, Randomized numerical linear algebra, Differentiable convex optimization, First-order methods for linear programming, Second-order linear and nonlinear programming solvers, Stochastic combinatorial optimization, Nonlinear optimization with neural network constraints, Learning to optimize, Meta prompt optimization, Parametric convex optimization, Automation in optimization | Key Findings: The workshop highlights several advancements, such as the development of rlaopt, a PyTorch-based package for large-scale optimization, CuClarabel, a GPU-accelerated version of the interior-point solver for quadratic cone programs, and a GPU-accelerated framework for ultra-large-scale scenario-based evaluation in stochastic combinatorial optimization. It also discusses the benefits of reduced-space formulations for optimizing over trained neural networks and the potential of automated systems to enhance decomposition for proximal and parallel methods.",
        "location": "San Diego"
    },
    {
        "title": "NeurIPS 2025 Workshop on Space in Vision, Language, and Embodied AI",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109546",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The SpaVLE workshop at NeurIPS 2025 aims to bridge the historically siloed efforts of the NLP, CV, and robotics communities by fostering cross-disciplinary dialogue to advance research on spatial understanding and representation. The workshop focuses on how spatial representations can be learned from multimodal data and applied to core tasks in computer vision, natural language processing, and robotics. It seeks to foster discussion on how spatial representations, whether symbolic, neural, verbal, or geometric, can be learned, evaluated, and deployed across modalities and tasks, aligning these approaches with real-world applications. | Research Interests: Foundations of Spatial Representation and Reasoning, Multimodal Spatial Grounding, Applications in NLP, Vision, Robotics, and Generative AI, Evaluation and Benchmarking Spatial Intelligence, Spatial Reasoning in Foundation Models",
        "location": "San Diego"
    },
    {
        "title": "LAW 2025: Bridging Language, Agent, and World Models for Reasoning and Planning",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109552",
        "speaker": "",
        "abstract": "",
        "overview": "Overview: The LAW 2025 workshop, part of NeurIPS 2025, focuses on the integration of Language models (L), Agent models (A), and World models (W) to advance AI systems. The workshop aims to explore the intersection of these models to address complex real-world problems and simulate rich virtual environments. It seeks to catalyze discussions on how these models can be combined to create AI systems that think, plan, simulate, act, and explain themselves in dynamic, partially observed worlds. | Research Interests: Large Language Models, Autonomous Agents, World Modeling, Integration of Language, Agent, and World Models, AI Systems in Dynamic Environments, Generalizable World Models, LLM-based Agents",
        "location": "San Diego"
    },
    {
        "title": "Workshop on Scaling Environments for Agents",
        "type": "Workshop",
        "date": "2025-12-07",
        "start_datetime": "2025-12-07T08:00:00",
        "end_datetime": "2025-12-07T17:00:00",
        "url": "https://neurips.cc/virtual/2025/workshop/109540",
        "speaker": "",
        "abstract": "The development of intelligent agents \u2013 particularly those powered by large language models (LLMs) \u2013 has emphasized the critical role of environments in shaping agent behavior and capabilities, especially for achieving end-to-end autonomy. Environments are not merely testing grounds; they are dynamic, interactive contexts that serve as the essential \"data\" for agents to learn adaptive behavior, complex reasoning, and long-term decision-making skills. Just as scaling the model size, dataset size, and training computation has led to emergent capabilities in LLMs, scaling the structure, fidelity, and diversity of environments is one of the crucial dimensions in advancing agent intelligence. Moreover, recent advances in end-to-end reinforcement learning (RL), particularly when paired with LLM-based agents, have made it increasingly viable to train agents through sustained interaction. These agents can now acquire skills, strategies, and planning abilities through environmental feedback, rather than relying solely on imitation learning or static prompt engineering. As we move toward more autonomous, general-purpose agents, the need for scalable, richly interactive, and diverse environments has become both urgent and foundational.",
        "overview": "Overview: The Scaling Environments for Agents (SEA) Workshop at NeurIPS 2025 focuses on the development of intelligent agents, particularly those powered by large language models (LLMs). The workshop emphasizes the critical role of environments in shaping agent behavior and capabilities, aiming to advance agent intelligence through scalable, richly interactive, and diverse environments. The workshop covers various aspects of environment design, evaluation, and integration with LLMs, highlighting the importance of environments as dynamic, interactive contexts for learning adaptive behavior, complex reasoning, and long-term decision-making skills. | Research Interests: Environment Infrastructure Design, Benchmarks and Evaluation, LLMs in Interactive Environments, Tool-Use and Software Environments, Multi-Agent Systems and Simulation Environments, Embodiment and Grounding, Sim2Real and Deployment",
        "location": "San Diego"
    }
]